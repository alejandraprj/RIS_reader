TY  - JOUR
AU  - Zwerts, JA
AU  - Stephenson, PJ
AU  - Maisels, F
AU  - Rowcliffe, M
AU  - Astaras, C
AU  - Jansen, PA
AU  - van der Waarde, J
AU  - Sterck, LEHM
AU  - Verweij, PA
AU  - Bruce, T
AU  - Brittain, S
AU  - van Kuijk, M
TI  - Methods for wildlife monitoring in tropical forests: Comparing human observations, camera traps, and passive acoustic sensors
T2  - CONSERVATION SCIENCE AND PRACTICE
LA  - English
KW  - automated classification
KW  - camera trapping
KW  - evidence-based conservation
KW  - passive acoustic monitoring
KW  - wildlife conservation
KW  - wildlife monitoring methods
KW  - LINE TRANSECT SURVEYS
KW  - MARK-RESIGHT MODELS
KW  - POPULATION-DENSITY
KW  - CAPTURE-RECAPTURE
KW  - POINT COUNTS
KW  - CAUTIONARY NOTE
KW  - BIRD SURVEYS
KW  - R PACKAGE
KW  - OCCUPANCY
KW  - BIODIVERSITY
AB  - Wildlife monitoring is essential for conservation science and data-driven decision-making. Tropical forests pose a particularly challenging environment for monitoring wildlife due to the dense vegetation, and diverse and cryptic species with relatively low abundances. The most commonly used monitoring methods in tropical forests are observations made by humans (visual or acoustic), camera traps, or passive acoustic sensors. These methods come with trade-offs in terms of species coverage, accuracy and precision of population metrics, available technical expertise, and costs. Yet, there are no reviews that compare the characteristics of these methods in detail. Here, we comprehensively review the advantages and limitations of the three mentioned methods, by asking four key questions that are always important in relation to wildlife monitoring: (1) What are the target species?; (2) Which population metrics are desirable and attainable?; (3) What expertise, tools, and effort are required for species identification?; and (4) Which financial and human resources are required for data collection and processing? Given the diversity of monitoring objectives and circumstances, we do not aim to conclusively prescribe particular methods for all situations. Neither do we claim that any one method is superior to others. Rather, our review aims to support scientists and conservation practitioners in understanding the options and criteria that must be considered in choosing the appropriate method, given the objectives of their wildlife monitoring efforts and resources available. We focus on tropical forests because of their high conservation priority, although the information put forward is also relevant for other biomes.
AD  - Univ Utrecht, Ecol & Biodivers, Utrecht, NetherlandsAD  - Univ Utrecht, Anim Behav & Cognit, Utrecht, NetherlandsAD  - Univ Lausanne, Dept Ecol & Evolut, Lab Conservat Biol, IUCN SSC Species Monitoring Specialist Grp, Lausanne, SwitzerlandAD  - Univ Stirling, Fac Nat Sci, Stirling FK9 4LA, ScotlandAD  - Wildlife Conservat Soc, Global Conservat Program, 2300 Southern Blvd, Bronx, NY USAAD  - ZSL Inst Zool, London, EnglandAD  - ELGO DIMITRA, Forest Res Inst, Thessaloniki, GreeceAD  - Wageningen Univ, Dept Environm Sci, Wageningen, NetherlandsAD  - Smithsonian Trop Res Inst, Panama City, PanamaAD  - WWF Cameroon, Yaounde, CameroonAD  - Univ Utrecht, Copernicus Inst Sustainable Dev, Utrecht, NetherlandsAD  - Zool Soc London Cameroon, Yaounde, CameroonAD  - James Cook Univ, Townsville, Qld, AustraliaAD  - Univ Oxford, Dept Zool, Interdisciplinary Ctr Conservat Sci ICCS, Oxford, EnglandC3  - League of European Research Universities - LERUC3  - Utrecht UniversityC3  - League of European Research Universities - LERUC3  - Utrecht UniversityC3  - University of LausanneC3  - University of StirlingC3  - Wildlife Conservation SocietyC3  - Wageningen University & ResearchC3  - Smithsonian InstitutionC3  - Smithsonian Tropical Research InstituteC3  - World Wildlife FundC3  - League of European Research Universities - LERUC3  - Utrecht UniversityC3  - James Cook UniversityC3  - League of European Research Universities - LERUC3  - University of OxfordFU  - Dutch Research Council (NWO); U.K. Government NERC CASE studentship [NE/M010376/1]; Research England
FX  - Dutch Research Council (NWO); Research England; U.K. Government NERC CASE studentship, Grant/Award Number: NE/M010376/1
CR  - Abrahams C., 2018, PRACT, V102, P20
CR  - Ahumada JA, 2020, ENVIRON CONSERV, V47, P1, DOI 10.1017/S0376892919000298
CR  - Aide TM, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111096
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Alldredge MW, 2007, ECOL APPL, V17, P948, DOI 10.1890/06-0685
CR  - Alvarez-Berrios N, 2016, TROP CONSERV SCI, V9, P832, DOI 10.1177/194008291600900216
CR  - Amstrup SC, 2010, HDB CAPTURE RECAPTUR
CR  - Arandjelovic M, 2010, BIOL CONSERV, V143, P1780, DOI 10.1016/j.biocon.2010.04.030
CR  - Arandjelovic M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014761
CR  - Araya-Salas M, 2017, METHODS ECOL EVOL, V8, P184, DOI 10.1111/2041-210X.12624
CR  - Astaras C, 2020, ENVIRON CONSERV, V47, P213, DOI 10.1017/S0376892920000193
CR  - Astaras C, 2017, FRONT ECOL ENVIRON, V15, P233, DOI 10.1002/fee.1495
CR  - Baker B, 2016, BIOSCIENCE, V66, P921, DOI 10.1093/biosci/biw120
CR  - Bas Y., 2017, J OPEN RES SOFTWARE, V5, DOI [10.5334/jors.154, DOI 10.5334/JORS.154]
CR  - Bas Y, 2008, BIODIVERS CONSERV, V17, P3403, DOI 10.1007/s10531-008-9420-6
CR  - Beaudrot L, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002357
CR  - Beery S., 2020, P IEE CVF C COMP VIS, P13075
CR  - Beery S, 2019, ARXIV190706772
CR  - Bessone M, 2020, J APPL ECOL, V57, P963, DOI 10.1111/1365-2664.13602
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Bohmann K, 2014, TRENDS ECOL EVOL, V29, P358, DOI 10.1016/j.tree.2014.04.003
CR  - Borah J, 2014, ORYX, V48, P149, DOI 10.1017/S0030605312000373
CR  - Borchers DL, 2008, BIOMETRICS, V64, P377, DOI 10.1111/j.1541-0420.2007.00927.x
CR  - Bowkett AE, 2009, CONSERV GENET, V10, P251, DOI 10.1007/s10592-008-9564-7
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Brauer CL, 2016, WILDLIFE SOC B, V40, P140, DOI 10.1002/wsb.619
CR  - Brooks Thomas M., 2015, BIODIVERSITY-OTTAWA, V16, P157, DOI 10.1080/14888386.2015.1075903
CR  - Buckland S.T., 2001, pi
CR  - Buckland ST, 2010, INT J PRIMATOL, V31, P833, DOI 10.1007/s10764-010-9431-5
CR  - Buxton RT, 2018, GLOB ECOL CONSERV, V16, DOI 10.1016/j.gecco.2018.e00493
CR  - Cappele N, 2021, ECOSPHERE, V12, DOI 10.1002/ecs2.3299
CR  - Cappelle N, 2019, AM J PRIMATOL, V81, DOI 10.1002/ajp.22962
CR  - Caravaggi A, 2017, REMOTE SENS ECOL CON, V3, P109, DOI 10.1002/rse2.48
CR  - Collett RA, 2017, ECOL EVOL, V7, P7527, DOI 10.1002/ece3.3275
CR  - Conservation Measures Partnership (CMP), 2020, OP STAND PRACT CONS
CR  - Cusack JJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126373
CR  - Darras K, 2019, ECOL APPL, V29, DOI 10.1002/eap.1954
CR  - Darras K, 2018, J APPL ECOL, V55, P2575, DOI 10.1111/1365-2664.13229
CR  - Dawson DK, 2009, J APPL ECOL, V46, P1201, DOI 10.1111/j.1365-2664.2009.01731.x
CR  - Deichmann JL, 2018, BIOTROPICA, V50, P713, DOI 10.1111/btp.12593
CR  - Despres-Einspenner ML, 2017, AM J PRIMATOL, V79, DOI 10.1002/ajp.22647
CR  - Devarajan K, 2020, ECOGRAPHY, V43, P1612, DOI 10.1111/ecog.04957
CR  - Diaz S., 2020, SUMMARY POLICYMAKERS
CR  - Digby A, 2013, METHODS ECOL EVOL, V4, P675, DOI 10.1111/2041-210X.12060
CR  - Diggins CA, 2016, WILDLIFE SOC B, V40, P654, DOI 10.1002/wsb.715
CR  - du Preez BD, 2014, BIOL CONSERV, V176, P153, DOI 10.1016/j.biocon.2014.05.021
CR  - Efford M, 2004, OIKOS, V106, P598, DOI 10.1111/j.0030-1299.2004.13043.x
CR  - Efford M.G., 2009, DENSITY4 4 SOFTWARE
CR  - EMLEN JT, 1992, J FIELD ORNITHOL, V63, P26
CR  - Enari H, 2019, ECOL INDIC, V98, P753, DOI 10.1016/j.ecolind.2018.11.062
CR  - Falzon G, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10010058
CR  - Fewster RM, 2009, BIOMETRICS, V65, P225, DOI 10.1111/j.1541-0420.2008.01018.x
CR  - Fiske IJ, 2011, J STAT SOFTW, V43, P1
CR  - Fitzpatrick MC, 2009, ECOL APPL, V19, P1673, DOI 10.1890/09-0265.1
CR  - Furuichi T, 1997, INT J PRIMATOL, V18, P1029, DOI 10.1023/A:1026356432486
CR  - Galvez N, 2016, BIOL CONSERV, V204, P350, DOI 10.1016/j.biocon.2016.10.019
CR  - Ganchev T, 2007, BIOACOUSTICS, V16, P281, DOI 10.1080/09524622.2007.9753582
CR  - Garland L, 2020, CAN J ZOOL, V98, P219, DOI 10.1139/cjz-2019-0081
CR  - Gaston KJ, 1998, J ANIM ECOL, V67, P995, DOI 10.1046/j.1365-2656.1998.6760995.x
CR  - Gaynor KM, 2018, SCIENCE, V360, P1232, DOI 10.1126/science.aar7121
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Gilbert NA, 2021, CONSERV BIOL, V35, P88, DOI 10.1111/cobi.13517
CR  - Glen AS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067940
CR  - Glover-Kapfer, 2017, WWF CONSERVATION TEC, V1
CR  - Glover-Kapfer P., 2017, WWF CONSERV TECHNOL, V1, P75
CR  - Glover-Kapfer P, 2019, REMOTE SENS ECOL CON, V5, P209, DOI 10.1002/rse2.106
CR  - Gray M, 2013, BIOL CONSERV, V158, P230, DOI 10.1016/j.biocon.2012.09.018
CR  - Greene DU, 2016, J FISH WILDL MANAG, V7, P99, DOI 10.3996/082015-JFWM-080
CR  - Gregory T, 2014, METHODS ECOL EVOL, V5, P443, DOI 10.1111/2041-210X.12177
CR  - Guthlin D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094537
CR  - Guillera-Arroita G, 2011, J AGR BIOL ENVIR ST, V16, P301, DOI 10.1007/s13253-010-0053-3
CR  - Guillera-Arroita G, 2010, METHODS ECOL EVOL, V1, P131, DOI 10.1111/j.2041-210X.2010.00017.x
CR  - Harmsen BJ, 2010, BIOTROPICA, V42, P126, DOI 10.1111/j.1744-7429.2009.00544.x
CR  - Head JS, 2013, ECOL EVOL, V3, P2903, DOI 10.1002/ece3.670
CR  - Hedges S., 2012, MONITORING ELEPHANTS, P172
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Heyer R., 2014, MEASURING MONITORING
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - Hines JE, 2010, ECOL APPL, V20, P1456, DOI 10.1890/09-0321.1
CR  - Hines J.E., 2006, PRESENCE 3 1 SOFTWAR
CR  - Hobbs MT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185026
CR  - Howe EJ, 2017, METHODS ECOL EVOL, V8, P1558, DOI 10.1111/2041-210X.12790
CR  - Hutto RL, 2009, J FIELD ORNITHOL, V80, P387, DOI 10.1111/j.1557-9263.2009.00245.x
CR  - IUCN, 2017, IUCN RED LIST THREAT
CR  - Joshi BD, 2020, GLOB ECOL CONSERV, V21, DOI 10.1016/j.gecco.2019.e00824
CR  - Joshi KA, 2017, EMU, V117, P233, DOI 10.1080/01584197.2017.1298970
CR  - Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
CR  - Kane MD, 2015, BIODIVERS CONSERV, V24, P3527, DOI 10.1007/s10531-015-1012-7
CR  - KARANTH KU, 1995, BIOL CONSERV, V71, P333, DOI 10.1016/0006-3207(94)00057-W
CR  - Kaya, 2021, P INT, DOI [10.21437/Interspeech.2021-154, DOI 10.21437/INTERSPEECH.2021-154]
CR  - Kays R, 2020, METHODS ECOL EVOL, V11, P700, DOI 10.1111/2041-210X.13370
CR  - Kendall WL, 2009, J APPL ECOL, V46, P1182, DOI 10.1111/j.1365-2664.2009.01732.x
CR  - Khwaja H, 2019, GLOB ECOL CONSERV, V20, DOI 10.1016/j.gecco.2019.e00769
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Kolowski JM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186679
CR  - Kuehl H.S., 2016, CHIMP SEE ONLINE CIT
CR  - Kuehl HS, 2007, ECOL APPL, V17, P2403, DOI 10.1890/06-0934.1
CR  - Kuhl H., 2008, BEST PRACTICE GUIDEL
CR  - Laake J.L., 2013, 201301 AFSC
CR  - Laing SE, 2003, J APPL ECOL, V40, P1102, DOI 10.1111/j.1365-2664.2003.00861.x
CR  - Latham MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102982
CR  - Leach EC, 2016, EMU, V116, P305, DOI 10.1071/MU15097
CR  - Linden DW, 2017, J APPL ECOL, V54, P2043, DOI 10.1111/1365-2664.12883
CR  - Mac Aodha O, 2014, INT C PATT RECOG, P9, DOI 10.1109/ICPR.2014.12
CR  - Mackenzie DI, 2005, J APPL ECOL, V42, P1105, DOI 10.1111/j.1365-2664.2005.01098.x
CR  - MacKenzie DI, 2002, ECOLOGY, V83, P2248, DOI 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2
CR  - Madsen AE, 2020, WILDLIFE SOC B, V44, P342, DOI 10.1002/wsb.1080
CR  - Marini F, 2009, EUR J WILDLIFE RES, V55, P107, DOI 10.1007/s10344-008-0222-7
CR  - Marques TA, 2013, BIOL REV, V88, P287, DOI 10.1111/brv.12001
CR  - McClintock BT, 2015, ECOL EVOL, V5, P4920, DOI 10.1002/ece3.1676
CR  - McShea W.J., 2014, PROTOCOL CAMERA TRAP
CR  - Meek P.D., 2013, Wildlife Biology in Practice, V9, P7
CR  - Meek PD, 2019, REMOTE SENS ECOL CON, V5, P160, DOI 10.1002/rse2.96
CR  - Meek PD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110832
CR  - Mennill DJ, 2012, METHODS ECOL EVOL, V3, P704, DOI 10.1111/j.2041-210X.2012.00209.x
CR  - Mielke A, 2013, ANIM BEHAV, V86, P475, DOI 10.1016/j.anbehav.2013.04.017
CR  - Miller DA, 2011, ECOLOGY, V92, P1422, DOI 10.1890/10-1396.1
CR  - Mills D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216447
CR  - Moore C. T., 2004, Animal Biodiversity and Conservation, V27, P287
CR  - Moore JF, 2020, ANIM CONSERV, V23, P561, DOI 10.1111/acv.12569
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Morgan D, 2016, INT J PRIMATOL, V37, P718, DOI 10.1007/s10764-016-9934-9
CR  - Mulatu KA, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101059
CR  - Myers N, 2000, NATURE, V403, P853, DOI 10.1038/35002501
CR  - Nichols JD, 2006, TRENDS ECOL EVOL, V21, P668, DOI 10.1016/j.tree.2006.08.007
CR  - Nipko RB, 2020, WILDLIFE SOC B, V44, P424, DOI 10.1002/wsb.1086
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - O'Brien TG, 2008, BIRD CONSERV INT, V18, pS144, DOI 10.1017/S0959270908000348
CR  - Ovaskainen O, 2018, ECOL LETT, V21, P1244, DOI 10.1111/ele.13092
CR  - Parsons AW, 2017, J MAMMAL, V98, P1547, DOI 10.1093/jmammal/gyx128
CR  - Pearse AT, 2015, WILDLIFE SOC B, V39, P87, DOI 10.1002/wsb.496
CR  - Pereira HM, 2013, SCIENCE, V339, P277, DOI 10.1126/science.1229931
CR  - Pijanowski BC, 2011, LANDSCAPE ECOL, V26, P1213, DOI 10.1007/s10980-011-9600-8
CR  - Plumptre AJ, 2006, PRIMATES, V47, P65, DOI 10.1007/s10329-005-0146-8
CR  - Plumptre AJ, 2000, J APPL ECOL, V37, P356, DOI 10.1046/j.1365-2664.2000.00499.x
CR  - Pollock KH, 2002, ENVIRONMETRICS, V13, P105, DOI 10.1002/env.514
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Ramirez JI, 2021, ECOL EVOL, V11, P7390, DOI 10.1002/ece3.7570
CR  - Rich LN, 2014, J MAMMAL, V95, P382, DOI 10.1644/13-MAMM-A-126
CR  - Richard-Hansen C, 2015, J TROP ECOL, V31, P423, DOI 10.1017/S0266467415000255
CR  - Richardson E, 2017, WILDLIFE RES, V44, P637, DOI 10.1071/WR16048
CR  - Roberts Nathan James, 2011, Bioscience Horizons, V4, P40, DOI 10.1093/biohorizons/hzr006
CR  - Rovero F., 2016, CAMERA TRAPPING WILD
CR  - Rowcliffe JM, 2008, J APPL ECOL, V45, P1228, DOI 10.1111/j.1365-2664.2008.01473.x
CR  - Rowcliffe JM, 2016, REMOTE SENS ECOL CON, V2, P84, DOI 10.1002/rse2.17
CR  - Rowcliffe JM, 2011, METHODS ECOL EVOL, V2, P464, DOI 10.1111/j.2041-210X.2011.00094.x
CR  - Royle JA, 2007, ECOLOGY, V88, P1813, DOI 10.1890/06-0669.1
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Salafsky N., 2001, ADAPTIVE MANAGEMENT
CR  - Scotson L, 2017, REMOTE SENS ECOL CON, V3, P158, DOI 10.1002/rse2.54
CR  - Sedlacek O, 2015, OSTRICH, V86, P213, DOI 10.2989/00306525.2015.1049669
CR  - Sheil D, 2001, CONSERV BIOL, V15, P1179, DOI 10.1046/j.1523-1739.2001.0150041179.x
CR  - Simpson R, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1049, DOI 10.1145/2567948.2579215
CR  - Sollmann R, 2013, BIOL CONSERV, V159, P405, DOI 10.1016/j.biocon.2012.12.025
CR  - Soltis J, 2005, ANIM BEHAV, V70, P589, DOI 10.1016/j.anbehav.2004.11.016
CR  - Steenweg R, 2018, ECOLOGY, V99, P172, DOI 10.1002/ecy.2054
CR  - Stephenson PJ, 2020, CURR OPIN ENV SUST, V45, P36, DOI 10.1016/j.cosust.2020.08.005
CR  - Stephenson PJ, 2020, FRONT ENV SCI-SWITZ, V8, DOI 10.3389/fenvs.2020.00061
CR  - Stephenson PJ, 2019, ENVIRON CONSERV, V46, P181, DOI 10.1017/S0376892919000092
CR  - Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
CR  - Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
CR  - STRINDBERG S, 2012, WILDLIFE CONSERVATIO, V41, P34
CR  - Sutherland WJ, 2008, CONSERVATION HDB RES
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tempel DJ, 2013, CONSERV BIOL, V27, P1087, DOI 10.1111/cobi.12074
CR  - Theuerkauf J, 2010, ANN ZOOL FENN, V47, P398, DOI 10.5735/086.047.0603
CR  - Thomas L, 2010, J APPL ECOL, V47, P5, DOI 10.1111/j.1365-2664.2009.01737.x
CR  - Tobler MW, 2008, ANIM CONSERV, V11, P169, DOI 10.1111/j.1469-1795.2008.00169.x
CR  - Troudet J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09084-6
CR  - van Vliet N, 2008, ECOL SOC, V13
CR  - Walsh PD, 1999, CONSERV BIOL, V13, P1194, DOI 10.1046/j.1523-1739.1999.98148.x
CR  - Wearn OR, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181748
CR  - Wei WD, 2020, ECOL INFORM, V55, DOI 10.1016/j.ecoinf.2019.101021
CR  - Welbourne DJ, 2016, REMOTE SENS ECOL CON, V2, P77, DOI 10.1002/rse2.20
CR  - White L., 2000, CONSERVATION RES AFR
CR  - Whitworth A, 2016, TROP CONSERV SCI, V9, P675, DOI 10.1177/194008291600900208
CR  - Whytock RC, 2021, METHODS ECOL EVOL, V12, P1080, DOI 10.1111/2041-210X.13576
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
CR  - Williamson E.A., 2008, BEST PRACTICE GUIDEL
CR  - Wilson D. E., 1996, MEASURING MONITORING
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - WWF, 2018, LIVING PLANET REPORT
CR  - Yoccoz NG, 2001, TRENDS ECOL EVOL, V16, P446, DOI 10.1016/S0169-5347(01)02205-4
CR  - Young S, 2018, ECOL EVOL, V8, P9947, DOI 10.1002/ece3.4464
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - DEC
PY  - 2021
VL  - 3
IS  - 12
DO  - 10.1111/csp2.568
AN  - WOS:000713636900001
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  185
ER  -

TY  - JOUR
AU  - Goodwin, KR
AU  - Gillam, EH
TI  - Testing Accuracy and Agreement among Multiple Versions of Automated Bat Call Classification Software
T2  - WILDLIFE SOCIETY BULLETIN
LA  - English
KW  - acoustic monitoring
KW  - bats
KW  - classification
KW  - echolocation
KW  - Kaleidoscope Pro
KW  - software
KW  - SonoBat
KW  - species identification
KW  - ECHOLOCATION CALLS
KW  - CAUTIONARY NOTE
KW  - IDENTIFICATION
KW  - BIRDS
KW  - BIAS
AB  - Passive acoustic monitoring is a common method of studying bats that involves recording echolocation calls of bats in their natural environment. Call sequences are then identified to species using automated acoustic analysis software. One limitation of acoustic software programs, particularly for long-term monitoring efforts, is that newer versions may provide results that are not directly comparable with older versions. However, there is little available information regarding how much or in what ways the versions differ, or which versions are most accurate. We evaluated 2 software programs used for automated bat call identification by testing a common set of echolocation call files across multiple versions of each program. We quantified the level of agreement on identification results and compared accuracy rates among the versions of each program. Level of agreement varied by species, recording location, and the software versions being compared. Overall percent agreement ranged from 28-82%. Newer versions were more conservative, in that they assigned fewer species-level identifications. However, newer versions were not substantially more accurate than older versions. Our conclusions suggest that bat researchers should be attentive to what software versions and settings are used as they plan and perform data analyses. Software developers could assist software users by providing more detailed information about their testing procedures and results, and what changes are associated with new versions. (c) 2021 The Wildlife Society.
AD  - North Dakota State Univ, Dept Biol Sci, Dept 2715,POB 6050, Fargo, ND 58108 USAC3  - North Dakota State University FargoFU  - National Park Service; North Dakota State University
FX  - We thank J. Szewczak and I. Agranat for explanations and insights on their respective software programs. We also thank J. Szewczak for providing a legacy copy of SonoBat Version 3.2.2. Test datasets of acoustic files were provided by A. Adams, L. Hooton, and the National Park Service Great Lakes Inventory and Monitoring Network. For the National Park Service dataset, B. Route, R. Knutson, A. Derkacz, J. Van Stappen, P. Burkman, K. Pemble, P. Matzinger, and others facilitated and conducted fieldwork, R. Key managed the database, and K. Gilland completed initial data processing. We thank E. Arnett (Associate Editor), A. Knipps (Editorial Assistant), S. Parsons, T. Parr, A. Kirschbaum, and 2 anonymous reviewers for their helpful comments on earlier drafts of this manuscript. Funding was provided by the National Park Service and North Dakota State University. Any use of trade, product, website, or firm names in this publication is for descriptive purposes only and does not imply endorsement by the U.S. Government.
CR  - Abrahams C, 2019, J ORNITHOL, V160, P685, DOI 10.1007/s10336-019-01649-8
CR  - Adams, 2013, ASSESSING ANAL BAT A
CR  - Barclay RMR, 1999, J MAMMAL, V80, P290, DOI 10.2307/1383229
CR  - Brabant R, 2018, BELG J ZOOL, V148, P119, DOI 10.26496/bjz.2018.21
CR  - Britzke ER, 2013, ACTA THERIOL, V58, P109, DOI 10.1007/s13364-013-0131-3
CR  - BYRT T, 1993, J CLIN EPIDEMIOL, V46, P423, DOI 10.1016/0895-4356(93)90018-V
CR  - Clement MJ, 2014, ECOL EVOL, V4, P3482, DOI 10.1002/ece3.1201
CR  - COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
CR  - Coleman LS, 2014, J FISH WILDL MANAG, V5, P217, DOI 10.3996/082013-JFWM-057
CR  - Courtois EA, 2016, ORYX, V50, P450, DOI 10.1017/S0030605315000083
CR  - Findlay SV, 2020, WILDLIFE SOC B, V44, P86, DOI 10.1002/wsb.1053
CR  - Ford WM, 2011, J FISH WILDL MANAG, V2, P125, DOI 10.3996/042011-JFWM-027
CR  - Fraser EE, 2018, CAN J ZOOL, V96, P505, DOI 10.1139/cjz-2017-0175
CR  - Frick Winifred F., 2013, Therya, V4, P69, DOI 10.12933/therya-13-109
CR  - Fritsch G, 2014, ECOL EVOL, V4, P2703, DOI 10.1002/ece3.1122
CR  - Froidevaux JSP, 2014, ECOL EVOL, V4, P4690, DOI 10.1002/ece3.1296
CR  - Gamer Matthias, 2019, CRAN
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Goerlitz HR, 2018, ECOL EVOL, V8, P5090, DOI 10.1002/ece3.4088
CR  - Goodwin, 2019, BAT POPULATION MONIT
CR  - Gorresen PM, 2008, J MAMMAL, V89, P11, DOI 10.1644/07-MAMM-A-022.1
CR  - Gwet, 2002, ASSESSMENT, V2, P1
CR  - Hallgren, 2012, PSYCHOLOGY, V8, P23
CR  - Hyzy BA, 2020, WILDLIFE SOC B, V44, P732, DOI 10.1002/wsb.1138
CR  - Janos, 2013, UTILIZING ACOUSTIC M
CR  - Jennings N, 2008, CAN J ZOOL, V86, P371, DOI 10.1139/Z08-009
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Kurta A., 2017, MAMMALS GREAT LAKES, V3
CR  - LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
CR  - Lemen C, 2015, WEST N AM NATURALIST, V75, P218, DOI 10.3398/064.075.0210
CR  - LoMartire, 2020, REL RELIABILITY COEF
CR  - Miller-Struttmann NE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179273
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Nelson Danielle V., 2017, Northwestern Naturalist, V98, P33
CR  - Nocera T, 2019, J FISH WILDL MANAG, V10, P346, DOI 10.3996/102018-JFWM-090
CR  - Pace DS, 2018, J WILDLIFE MANAGE, V82, P1062, DOI 10.1002/jwmg.21453
CR  - Penone C, 2013, CONSERV BIOL, V27, P979, DOI 10.1111/cobi.12083
CR  - R Core Team, 2018, R LANG ENV STAT COMP
CR  - Rognan Cameron B., 2012, Northwestern Naturalist, V93, P138
CR  - Russo D, 2018, CAN J ZOOL, V96, P63, DOI 10.1139/cjz-2017-0089
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Rydell J, 2018, ECOL INDIC, V84, P273, DOI 10.1016/j.ecolind.2017.08.070
CR  - Rydell J, 2017, ECOL INDIC, V78, P416, DOI 10.1016/j.ecolind.2017.03.023
CR  - Skalak SL, 2012, METHODS ECOL EVOL, V3, P490, DOI 10.1111/j.2041-210X.2011.00177.x
CR  - Stiffler LL, 2018, WETLANDS, V38, P605, DOI 10.1007/s13157-018-1003-z
CR  - Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI [DOI 10.1016/J.ACI.2018.08.003, 10.1016/j.aci.2018.08.003]
CR  - United States Fish and Wildlife Service, 2019, RANG WID IND BAT SUR
CR  - Wildlife Acoustics, 2019, KAL PROR NOT
CR  - Wildlife Acoustics, 2020, KAL PROR NOT
CR  - Wildlife Acoustics, 2019, KAL PROCL PERF DAT
CR  - Wingfield JE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176653
CR  - Wongpakaran N, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-61
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - DEC
PY  - 2021
VL  - 45
IS  - 4
SP  - 690
EP  - 705
DO  - 10.1002/wsb.1235
AN  - WOS:000731573700001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  52
ER  -

TY  - JOUR
AU  - Leon, AZ
AU  - Huvenne, VAI
AU  - Benoist, NMA
AU  - Ferguson, M
AU  - Bett, BJ
AU  - Wynn, RB
TI  - Assessing the Repeatability of Automated Seafloor Classification Algorithms, with Application in Marine Protected Area Monitoring
T2  - REMOTE SENSING
LA  - English
KW  - automated seafloor classification
KW  - machine learning algorithms
KW  - benthic habitat maps
KW  - autonomous underwater vehicles
KW  - Grey Level Co-occurrence Matrices
KW  - sidescan sonar
KW  - IMAGE-ANALYSIS
KW  - FUTURE
KW  - ACCURACY
KW  - SONAR
KW  - DISCRIMINATION
KW  - BACKSCATTER
KW  - AGREEMENT
KW  - FEATURES
AB  - The number and areal extent of marine protected areas worldwide is rapidly increasing as a result of numerous national targets that aim to see up to 30% of their waters protected by 2030. Automated seabed classification algorithms are arising as faster and objective methods to generate benthic habitat maps to monitor these areas. However, no study has yet systematically compared their repeatability. Here we aim to address that problem by comparing the repeatability of maps derived from acoustic datasets collected on consecutive days using three automated seafloor classification algorithms: (1) Random Forest (RF), (2) K-Nearest Neighbour (KNN) and (3) K means (KMEANS). The most robust and repeatable approach is then used to evaluate the change in seafloor habitats between 2012 and 2015 within the Greater Haig Fras Marine Conservation Zone, Celtic Sea, UK. Our results demonstrate that only RF and KNN provide statistically repeatable maps, with 60.3% and 47.2% agreement between consecutive days. Additionally, this study suggests that in low-relief areas, bathymetric derivatives are non-essential input parameters, while backscatter textural features, in particular Grey Level Co-occurrence Matrices, are substantially more effective in the detection of different habitats. Habitat persistence in the test area between 2012 and 2015 was 48.8%, with swapping of habitats driving the changes in 38.2% of the area. Overall, this study highlights the importance of investigating the repeatability of automated seafloor classification methods before they can be fully used in the monitoring of benthic habitats.
AD  - Univ Southampton, Univ Rd, Southampton SO17 1BJ, Hants, EnglandAD  - Natl Oceanog Ctr, European Way, Southampton SO14 3ZH, Hants, EnglandAD  - Joint Nat Conservat Comm, Monkstone House,City Rd, Peterborough PE1 1JY, EnglandAD  - Wild New Forest CIC, 252 Woodlands Rd, Woodlands SO40 7GH, EnglandC3  - University of SouthamptonC3  - NERC National Oceanography CentreC3  - University of SouthamptonFU  - NERC Marine Environmental Mapping Programme (MAREMAP); DEFRA project "Investigating the feasibility of using AUV and Glider technology for mapping and monitoring of the UK MPA network" [MB0118]; NERC Climate Linked Atlantic Sector Science (CLASS) project [NE/R015953/1]; CONICYT [PFCHA/MAGISTER BECAS CHILE/2017-73180206]; NERC [noc010009, NE/P020739/1] Funding Source: UKRI
FX  - This research was funded by the NERC Marine Environmental Mapping Programme (MAREMAP), the DEFRA project "Investigating the feasibility of using AUV and Glider technology for mapping and monitoring of the UK MPA network (MB0118)", and the NERC Climate Linked Atlantic Sector Science (CLASS) project (Grant no: NE/R015953/1); A.Z.L. was funded by the CONICYT PFCHA/MAGISTER BECAS CHILE/2017-73180206 Fellowship program.
CR  - Alevizos E, 2015, MAR GEOL, V370, P31, DOI 10.1016/j.margeo.2015.10.007
CR  - Anderson JT, 2008, ICES J MAR SCI, V65, P1004, DOI 10.1093/icesjms/fsn061
CR  - [Anonymous], 2016, 9 WILDL ENV PROT MAR
CR  - BARBER DG, 1991, PHOTOGRAMM ENG REM S, V57, P385
CR  - Battista T., 2006, MAR GEOD, V29, P89, DOI [DOI 10.1080/01490410600738021, 10.1080/01490410600738021]
CR  - Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
CR  - Benoist NMA, 2019, CONSERV BIOL, V33, P1174, DOI 10.1111/cobi.13312
CR  - Blondel P., 1996, GEOL SOC LOND SPEC P, V118, P17, DOI DOI 10.1144/GSL.SP.1996.118.01.02
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Bremner D, 2005, DISCRETE COMPUT GEOM, V33, P593, DOI 10.1007/s00454-004-1152-0
CR  - Brown CJ, 2011, ESTUAR COAST SHELF S, V92, P502, DOI 10.1016/j.ecss.2011.02.007
CR  - Calvert J, 2015, ICES J MAR SCI, V72, P1498, DOI 10.1093/icesjms/fsu223
CR  - Clausi DA, 2001, ATMOS OCEAN, V39, P183, DOI 10.1080/07055900.2001.9649675
CR  - COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
CR  - Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
CR  - Diesing M, 2015, J SEA RES, V100, P62, DOI 10.1016/j.seares.2014.10.013
CR  - Diesing M, 2014, CONT SHELF RES, V84, P107, DOI 10.1016/j.csr.2014.05.004
CR  - Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
CR  - Ferrier S, 2006, J APPL ECOL, V43, P393, DOI 10.1111/j.1365-2664.2006.01149.x
CR  - Foody GM, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5110199
CR  - Foody GM, 2010, REMOTE SENS ENVIRON, V114, P2271, DOI 10.1016/j.rse.2010.05.003
CR  - Foody GM, 2009, INT J REMOTE SENS, V30, P5273, DOI 10.1080/01431160903130937
CR  - Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
CR  - Foster SD, 2014, METHODS ECOL EVOL, V5, P287, DOI 10.1111/2041-210X.12156
CR  - Frost M., 2013, HLTH BIOL DIV SEAS E
CR  - Gavazzi GM, 2016, ESTUAR COAST SHELF S, V170, P45, DOI 10.1016/j.ecss.2015.12.014
CR  - HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
CR  - Harris PT, 2012, ELSEV INSIGHT, P3, DOI 10.1016/B978-0-12-385140-6.00001-3
CR  - Hasan RC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097339
CR  - Hasan RC, 2012, REMOTE SENS-BASEL, V4, P3427, DOI 10.3390/rs4113427
CR  - Herkul K, 2017, ESTUAR COAST SHELF S, V192, P57, DOI 10.1016/j.ecss.2017.04.026
CR  - Hogg OT, 2018, SCI TOTAL ENVIRON, V626, P384, DOI 10.1016/j.scitotenv.2018.01.009
CR  - Huo GY, 2016, IEEE SYS MAN CYBERN, P3794, DOI 10.1109/SMC.2016.7844825
CR  - Huvenne V., 2007, P 2 INT C EXH UND AC, P879, DOI 10.2174/1389201015666140922101637
CR  - Huvenne V.A.I., 2016, RRS JAMES COOK CRUIS
CR  - Huvenne VAI, 2002, MAR GEOL, V189, P323, DOI 10.1016/S0025-3227(02)00420-6
CR  - Ierodiaconou D, 2018, MAR GEOPHYS RES, V39, P271, DOI 10.1007/s11001-017-9338-z
CR  - Innangi S, 2019, MAR GEOPHYS RES, V40, P333, DOI 10.1007/s11001-018-9371-6
CR  - Ismail K, 2015, MAR GEOL, V362, P17, DOI 10.1016/j.margeo.2015.01.006
CR  - JAIN AK, 1990, J CHEM SOC PERK T 2, P11, DOI 10.1039/p29900000011
CR  - Jones DOB, 2019, SCI TOTAL ENVIRON, V668, P835, DOI 10.1016/j.scitotenv.2019.02.310
CR  - Kagesten G, 2019, GEOSCIENCES, V9, DOI 10.3390/geosciences9050237
CR  - Karoui I, 2009, IEEE T GEOSCI REMOTE, V47, P1621, DOI 10.1109/TGRS.2008.2006362
CR  - Lacharite M, 2018, MAR GEOPHYS RES, V39, P307, DOI 10.1007/s11001-017-9331-6
CR  - LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
CR  - Lecours V, 2017, FRONT MAR SCI, V4, DOI 10.3389/fmars.2017.00288
CR  - Li D, 2017, ESTUAR COAST SHELF S, V185, P11, DOI 10.1016/j.ecss.2016.12.001
CR  - LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/tit.1982.1056489
CR  - Lucieer VL, 2008, INT J REMOTE SENS, V29, P905, DOI 10.1080/01431160701311309
CR  - Lucieer V, 2013, ESTUAR COAST SHELF S, V117, P94, DOI 10.1016/j.ecss.2012.11.001
CR  - Lucieer V, 2011, CONT SHELF RES, V31, P1236, DOI 10.1016/j.csr.2011.04.016
CR  - Luque A, 2019, PATTERN RECOGN, V91, P216, DOI 10.1016/j.patcog.2019.02.023
CR  - McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
CR  - Misiuk B, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193647
CR  - Montereale-Gavazzi G, 2018, MAR GEOPHYS RES, V39, P229, DOI 10.1007/s11001-017-9323-6
CR  - Montereale-Gavazzi G, 2019, GEOSCIENCES, V9, DOI 10.3390/geosciences9010034
CR  - Morris KJ, 2014, LIMNOL OCEANOGR-METH, V12, P795, DOI 10.4319/lom.2014.12.795
CR  - Murray CC, 2015, GLOB ECOL CONSERV, V4, P110, DOI 10.1016/j.gecco.2015.06.003
CR  - Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
CR  - Prampolini M, 2018, ESTUAR COAST SHELF S, V207, P483, DOI 10.1016/j.ecss.2017.06.002
CR  - Preston J, 2009, APPL ACOUST, V70, P1277, DOI 10.1016/j.apacoust.2008.07.011
CR  - Rattray A, 2013, MAR ECOL PROG SER, V477, P1, DOI 10.3354/meps10264
CR  - Ruhl H.A., 2013, AUTONOMOUS ECOLOGICA
CR  - Snellen M, 2019, IEEE J OCEANIC ENG, V44, P142, DOI 10.1109/JOE.2018.2791878
CR  - Stephens D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142502
CR  - Stephens D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093950
CR  - Strong JA, 2019, ICES J MAR SCI, V76, P10, DOI 10.1093/icesjms/fsy161
CR  - Turner JA, 2018, ESTUAR COAST SHELF S, V204, P149, DOI 10.1016/j.ecss.2018.02.028
CR  - ULABY FT, 1986, IEEE T GEOSCI REMOTE, V24, P235, DOI 10.1109/TGRS.1986.289643
CR  - Walbridge S, 2018, GEOSCIENCES, V8, DOI 10.3390/geosciences8030094
CR  - Wells S, 2016, AQUAT CONSERV, V26, P101, DOI 10.1002/aqc.2680
CR  - Wilson MFJ, 2007, MAR GEOD, V30, P3, DOI 10.1080/01490410701295962
CR  - Wynn R.B., 2012, MB0118 DEFR NAT OC C
CR  - Wynn RB, 2014, MAR GEOL, V352, P451, DOI 10.1016/j.margeo.2014.03.012
CR  - Xiao XY, 2005, LANDSCAPE ECOL, V20, P375, DOI 10.1007/s10980-004-3161-z
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - MAY
PY  - 2020
VL  - 12
IS  - 10
DO  - 10.3390/rs12101572
AN  - WOS:000543394800039
N1  - Times Cited in Web of Science Core Collection:  16
Total Times Cited:  16
Cited Reference Count:  75
ER  -

TY  - JOUR
AU  - Kutugata, M
AU  - Baumgardt, J
AU  - Goolsby, JA
AU  - Racelis, AE
TI  - Automatic Camera-Trap Classification Using Wildlife-Specific Deep Learning in Nilgai Management
T2  - JOURNAL OF FISH AND WILDLIFE MANAGEMENT
LA  - English
KW  - Boselaphus tragocamelus
KW  - camera trap
KW  - cattle fever ticks
KW  - deep learning
KW  - nilgai
KW  - transfer learning
AB  - Camera traps provide a low-cost approach to collect data and monitor wildlife across large scales but hand-labeling images at a rate that outpaces accumulation is difficult. Deep learning, a subdiscipline of machine learning and computer science, can address the issue of automatically classifying camera-trap images with a high degree of accuracy. This technique, however, may be less accessible to ecologists or small-scale conservation projects, and has serious limitations. In this study, we trained a simple deep learning model using a dataset of 120,000 images to identify the presence of nilgai Boselaphus tragocamelus, a regionally specific nonnative game animal, in camera-trap images with an overall accuracy of 97%. We trained a second model to identify 20 groups of animals and one group of images without any animals present, labeled as "none,'' with an accuracy of 89%. Lastly, we tested the multigroup model on images collected of similar species, but in the southwestern United States, resulting in significantly lower precision and recall for each group. This study highlights the potential of deep learning for automating camera-trap image processing workflows, provides a brief overview of image-based deep learning, and discusses the often-understated limitations and methodological considerations in the context of wildlife conservation and species monitoring.
AD  - Univ Texas Rio Grande Valley, Sch Earth Environm & Marine Sci, 1201 W Univ Dr, Edinburg, TX 78539 USAAD  - Texas A&M Univ, Caesar Kleberg Wildlife Res Inst, Kingsville, TX 78363 USAAD  - ARS, USDA, Knipling Bushland US Livestock Insects Res Lab, Cattle Fever Tick Res Lab, Edinburg, TX 78541 USAC3  - University of Texas SystemC3  - University of Texas Rio Grande ValleyC3  - Texas A&M University SystemC3  - Texas A&M University KingsvilleC3  - United States Department of Agriculture (USDA)FU  - Integrated Pest Management of Cattle Fever Ticks [3094-32000-042-00-D]; U.S. Department of Agriculture National Institute of Food and Agriculture [2016-38422-25543]
FX  - Game camera images and initial processing was supported through appropriated research project 3094-32000-042-00-D, Integrated Pest Management of Cattle Fever Ticks. This article reports results of research only and mention of a proprietary product does not constitute an endorsement or recommendation by the U.S. Department of Agriculture for its use. U.S. Department of Agriculture is an equal opportunity provider and employer. Special thanks to Amelia Berle for data management, and research technicians who spent countless hours labeling images. Additional thanks to Dr. Rupesh Kariyat and Dr. Christofferson for providing access to computing equipment. We would also like to thank the journal reviewers and Associate Editor for their commitment to open access, which ensures applied conservation science remains accessible to all. Matthew Kutugata was supported by U.S. Department of Agriculture National Institute of Food and Agriculture Grant 2016-38422-25543.
CR  - Beery S, 2018, LECT NOTES COMPUT SC, V11220, P472, DOI 10.1007/978-3-030-01270-0_28
CR  - Chollet F., 2018, DEEP LEARNING PYTHON
CR  - Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
CR  - Foley AM, 2017, PREV VET MED, V146, P166, DOI 10.1016/j.prevetmed.2017.08.002
CR  - Gomez Alexander, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P747, DOI 10.1007/978-3-319-50835-1_67
CR  - Goolsby J.G., 2019, SUBTROPICAL AGR ENV, V70, P1
CR  - Guilford J.P., 1954, PSYCHOMETRIC METHODS, Vsecond
CR  - He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
CR  - Howe EJ, 2017, METHODS ECOL EVOL, V8, P1558, DOI 10.1111/2041-210X.12790
CR  - Ivan JS, 2016, METHODS ECOL EVOL, V7, P499, DOI 10.1111/2041-210X.12503
CR  - Leslie D.M., 2016, INT BORDERLAND CONCE
CR  - Leslie David M. Jr., 2008, Mammalian Species, DOI 10.1644/813.1
CR  - Lohmeyer KH, 2018, J MED ENTOMOL, V55, P515, DOI 10.1093/jme/tjy004
CR  - Azlan JM, 2006, RAFFLES B ZOOL, V54, P469
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - OConnell AF, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, P1, DOI 10.1007/978-4-431-99495-4
CR  - Rovero Francesco, 2006, Journal of East African Natural History, V95, P111, DOI 10.2982/0012-8317(2006)95[111:APNGSE]2.0.CO;2
CR  - Schmidly DJ, 2004, MAMMALS TEXAS
CR  - Srbek-Araujo AC, 2005, J TROP ECOL, V21, P121, DOI 10.1017/S0266467404001956
CR  - Swanson A, 2016, CONSERV BIOL, V30, P520, DOI 10.1111/cobi.12695
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Toda Y, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9237136
CR  - Ueda, 2020, INATURALIST RES GRAD, DOI [10.15468/ab3s5x, DOI 10.15468/AB3S5X]
CR  - Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
PU  - U S FISH & WILDLIFE SERVICE
PI  - SHEPHERDSTOWN
PA  - NATL CONSERVATION TRAINING CENTER, CONSERVATION LIBRARY, 698 CONSERVATION WAY, SHEPHERDSTOWN, WV 25443 USA
DA  - DEC
PY  - 2021
VL  - 12
IS  - 2
SP  - 412
EP  - 421
DO  - 10.3996/JFWM-20-076
AN  - WOS:000728017600001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  27
ER  -

TY  - JOUR
AU  - McClure, CJW
AU  - Martinson, L
AU  - Allison, TD
TI  - Automated monitoring for birds in flight: Proof of concept with eagles at a wind power facility
T2  - BIOLOGICAL CONSERVATION
LA  - English
KW  - Golden eagle
KW  - Bald eagle
KW  - Wind power
KW  - Wind farm
KW  - Bird monitoring
KW  - Renewable energy
KW  - POINT COUNTS
KW  - CONSERVATION
KW  - REGRESSION
KW  - PERFORMANCE
KW  - AIRCRAFT
KW  - MODELS
KW  - FOREST
AB  - Automated surveys for wildlife have the potential to improve data collection while averting mortality of animals Collisions of eagles at wind power facilities are particularly of concern and therefore an automated system that could detect birds, determine if they are eagles, and track their movement, might aid in curtailing wind turbines before collisions occur. Here, we use human observers and photographs to test the ability of a camera-based monitoring system, called IdentiFlight, to detect, classify, and track birds. IdentiFlight detected 96% of the bird flights detected by observers and detected 562% more birds than did observers. The discrepancy between observers and IdentiFlight seemed to be because the ability of observers to detect birds declined sharply by distance and toward the west. We reviewed photographs taken by IdentiFlight and determined that IdentiFlight misclassified nine of 149 eagles as non-eagles for a false negative rate of 6%, and 287 of 1013 non-eagles as eagles for a false positive rate of 28%. The median distance at classification for birds classified as eagles was 793 m and the median time from detection till classification was 0.4 s. Collectively, our results suggest that automated cameras can be effective means of detecting birds in flight and identifying eagles.
AD  - Peregrine Fund, 5668 W Flying Hawk Lane, Boise, ID 83709 USAAD  - Western EcoSyst Technol, 415 W 17th St Suite 200, Cheyenne, WY USAAD  - Amer Wind Wildlife Inst, 1110 Vermont Ave NW, Washington, DC 20015 USAFU  - Pattern Energy; Duke Energy Renewables; IdentiFlight, LLC; Boulder Imaging, Inc.
FX  - Pattern Energy, Duke Energy Renewables, IdentiFlight, LLC, and Boulder Imaging, Inc. provided financial support and facilitated this research. Duke Energy Renewables provided access to the study site and Boulder Imaging collated IdentiFlight data. Staff from IdentiFlight, LLC and Boulder Imaging reviewed our description of the IdentiFlight system for accuracy. None of our funders required approval of the manuscript before submission for publication. We thank Debora Hilleary, Greg Kaltenecker, and Casey Pozzanghera for reviewing photographs and Leah Dunn for making maps. We thank Carlos Jorquera and Tom Hiester for the description of the IdentiFlight system. We also thank Carlos Jorquera and Boulder Imaging for collating IdentiFlight data. We thank AWWI's Partner and Friend organizations for their support of this research. Bea Maas, Todd Katzner, and several anonymous reviewers provided helpful comments on earlier drafts of this manuscript. This research is a contribution of AWWI's Technology Innovation Program.
CR  - AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
CR  - Allan J. R., 2001, 3 JT ANN M CALG AB, P2001
CR  - Alquezar RD, 2015, WILSON J ORNITHOL, V127, P712, DOI 10.1676/14-104.1
CR  - Anderson A, 2015, TRANSPORT RES D-TR E, V38, P49, DOI 10.1016/j.trd.2015.04.027
CR  - Anderson D. L, 2017, APPL RAPTOR ECOLOGY
CR  - Arts K, 2015, AMBIO, V44, pS661, DOI 10.1007/s13280-015-0705-1
CR  - August T, 2015, BIOL J LINN SOC, V115, P731, DOI 10.1111/bij.12534
CR  - Berthiaume E, 2009, CONDOR, V111, P43, DOI 10.1525/cond.2009.080081
CR  - Bumham KP, 2002, MODEL SELECTION MULT
CR  - Burton AC, 2015, J APPL ECOL, V52, P675, DOI 10.1111/1365-2664.12432
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Desholm M, 2005, BIOL LETTERS, V1, P296, DOI 10.1098/rsbl.2005.0336
CR  - Dokter AM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074129
CR  - Drewitt AL, 2006, IBIS, V148, P29, DOI 10.1111/j.1474-919X.2006.00516.x
CR  - Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088
CR  - Gauthreaux SA, 2003, AUK, V120, P266, DOI 10.1642/0004-8038(2003)120[0266:ROABC]2.0.CO;2
CR  - Gerringer MB, 2016, WILDLIFE SOC B, V40, P150, DOI 10.1002/wsb.614
CR  - Graham MH, 2003, ECOLOGY, V84, P2809, DOI 10.1890/02-3114
CR  - HURVICH CM, 1989, BIOMETRIKA, V76, P297, DOI 10.2307/2336663
CR  - Jenkins AR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192515
CR  - Johnson DH, 2016, HUM-WILDL INTERACT, V10, P7
CR  - Leach EC, 2016, EMU, V116, P305, DOI 10.1071/MU15097
CR  - Loss SR, 2013, BIOL CONSERV, V168, P201, DOI 10.1016/j.biocon.2013.10.007
CR  - Mazerolle M., 2011, R PACKAGE VERSION, V1, P17
CR  - McClure CJW, 2012, CONDOR, V114, P482, DOI 10.1525/cond.2012.110139
CR  - McClure CJW, 2012, LANDSCAPE URBAN PLAN, V105, P417, DOI 10.1016/j.landurbplan.2012.01.011
CR  - McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
CR  - Nolte EG, 2016, AVIAN CONSERV ECOL, V11, DOI 10.5751/ACE-00894-110209
CR  - Pearce J, 2000, ECOL MODEL, V133, P225, DOI 10.1016/S0304-3800(00)00322-7
CR  - R Core Team, 2017, R LANG ENV STAT COMP
CR  - Seavy NE, 2011, J WILDLIFE MANAGE, V75, P344, DOI 10.1002/jwmg.37
CR  - Shonfield J., 2017, AVIAN CONSERV ECOL, V12
CR  - Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
CR  - Smallwood KS, 2013, WILDLIFE SOC B, V37, P19, DOI 10.1002/wsb.260
CR  - Sodhi NS, 2002, AUK, V119, P587, DOI 10.1642/0004-8038(2002)119[0587:CITABV]2.0.CO;2
CR  - Stock C., 2014, DTCOMPAIR COMP BINAR
CR  - USFWS, 2013, EAGL CONS PLAN GUID, V103
CR  - Watson RT, 2018, J RAPTOR RES, V52, P1, DOI 10.3356/JRR-16-100.1
CR  - Williams B.K., 2002, ANAL MANAGEMENT ANIM
CR  - ZWEIG MH, 1993, CLIN CHEM, V39, P561
PU  - ELSEVIER SCI LTD
PI  - OXFORD
PA  - THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
DA  - AUG
PY  - 2018
VL  - 224
SP  - 26
EP  - 33
DO  - 10.1016/j.biocon.2018.04.041
AN  - WOS:000439537600004
N1  - Times Cited in Web of Science Core Collection:  15
Total Times Cited:  16
Cited Reference Count:  40
ER  -

TY  - JOUR
AU  - Alwadai, HM
TI  - ASSESSMENT OF INVASIVE PLANT SPECIES, OPUNTIA SPP. (PRICKLY PEAR) IN RAYDAH PROTECTED AREA, ASEER, SAUDI ARABIA
T2  - APPLIED ECOLOGY AND ENVIRONMENTAL RESEARCH
LA  - English
KW  - ecosystem
KW  - biodiversity
KW  - Sarawat Mountains
KW  - Jumperus procera
KW  - Sentinel satellite data
KW  - ECOSYSTEM SERVICES
KW  - ALIEN PLANT
KW  - CLASSIFICATION
KW  - RICHNESS
KW  - IMPACT
KW  - HIGHLANDS
KW  - FORESTS
KW  - STANDS
AB  - Raydah protected area in an important declared protected area in Aseer area, Kingdom of Saudi Arabia that is rich in biodiversity, and provides habitat for nine of the ten indigenous bird species in the kingdom. Invasive plant Opuntia spp. in Raydah could threaten the natural balance among the indigenous species and thereafter affect the biological components of the ecosystem. This study evaluates the prevalence of invasive species and vegetation cover trends in Raydah protected area to identify possible interventions to conserve and protect the protected area. The results provide important and necessary information for the conservation and management of the Raydah Area and the Aseer Area's southwestern highlands. The study has demonstrated the potential of sentinel sensor for detection and mapping of invasive species such as Opuntia spp. with desirable accuracy. This encouraging result demonstrated the feasibility of developing a semi -automated process for mapping and analysing the distribution of Opuntia spp. and found better results compared to multispectral data with very high resolution. Assessment of the current situation of the Opuntia spp. in the protected area will provide scientific data base for future management plans to combat and control invasive plants and protect the protected area from their adverse effects.
AD  - King Khalid Univ, Coll Sci, Dept Biol, Abha, Saudi ArabiaC3  - King Khalid UniversityCR  - ABULFATIH HA, 1989, ARAB GULF J SCI RES, V7, P69
CR  - Aref I. M., 2013, International Journal of Plant, Animal and Environmental Sciences, V3, P234
CR  - Berhanu A., 2006, J DRY LAND, V2, P158
CR  - Boyd DS, 2011, ECOL INFORM, V6, P25, DOI 10.1016/j.ecoinf.2010.07.007
CR  - Bradley BA, 2006, ECOL APPL, V16, P1132, DOI 10.1890/1051-0761(2006)016[1132:CTLDOA]2.0.CO;2
CR  - Bradley BA, 2014, BIOL INVASIONS, V16, P1411, DOI 10.1007/s10530-013-0578-9
CR  - Branco S, 2015, J ENVIRON MANAGE, V149, P17, DOI 10.1016/j.jenvman.2014.09.026
CR  - Convention on Biological Diversity, 2008, AL SPEC THREAT EC HA
CR  - El-Juhany L. I., 2013, World Applied Sciences Journal, V21, P710
CR  - Fernandez GFC, 2013, INT J REMOTE SENS, V34, P7020, DOI 10.1080/01431161.2013.813091
CR  - Friis I, 2009, FLORA ETHIOPIA ERITR, V1, P193
CR  - Gaertner M, 2009, PROG PHYS GEOG, V33, P319, DOI 10.1177/0309133309341607
CR  - Griffiths B.S., 2012, ECOL PROCESS, V1, P6, DOI [DOI 10.1186/2192-1709-1-6, 10.1186/2192-1709-1-6]
CR  - Gurevitch J, 2004, TRENDS ECOL EVOL, V19, P470, DOI 10.1016/j.tree.2004.07.005
CR  - Hejda M, 2009, J ECOL, V97, P393, DOI 10.1111/j.1365-2745.2009.01480.x
CR  - Joshi C, 2004, P ISPRS, P669
CR  - Kingston N, 2003, ANN BOT-LONDON, V92, P31, DOI 10.1093/aob/mcg106
CR  - Lawrence R, 2004, REMOTE SENS ENVIRON, V90, P331, DOI 10.1016/j.rse.2004.01.007
CR  - Lovell S. J., 2006, Agricultural and Resource Economics Review, V35, P195
CR  - Mallick J, 2018, ARAB J GEOSCI, V11, DOI 10.1007/s12517-018-3580-9
CR  - Mallick J, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2302-9
CR  - Mallick RB, 2004, TRANSPORT RES REC, P1, DOI 10.3141/1891-01
CR  - Matongera TN, 2018, GEOCARTO INT, V33, P209, DOI 10.1080/10106049.2016.1240719
CR  - MCNEELY JA, 2005, INVASIVE ALIEN SPECI, P285
CR  - Negash L., 2010, SELECTION ETHIOPIAS
CR  - Niphadkar M, 2016, INT J REMOTE SENS, V37, P3074, DOI 10.1080/01431161.2016.1193795
CR  - Peerbhay K, 2016, ISPRS J PHOTOGRAMM, V121, P167, DOI 10.1016/j.isprsjprs.2016.09.014
CR  - Peerbhay KY, 2015, IEEE J-STARS, V8, P3107, DOI 10.1109/JSTARS.2015.2396577
CR  - Pejchar L, 2009, TRENDS ECOL EVOL, V24, P497, DOI 10.1016/j.tree.2009.03.016
CR  - Pimentel D, 2001, AGR ECOSYST ENVIRON, V84, P1, DOI 10.1016/S0167-8809(00)00178-X
CR  - Pysek P, 2010, ANNU REV ENV RESOUR, V35, P25, DOI 10.1146/annurev-environ-033009-095548
CR  - Raju SAJ., 2013, INT RES J ENV SCI, V2, P79
CR  - Rocchini D, 2015, PROG PHYS GEOG, V39, P283, DOI 10.1177/0309133315574659
CR  - Sax DF, 2008, P NATL ACAD SCI USA, V105, P11490, DOI 10.1073/pnas.0802290105
CR  - Thomas J, 2016, J ARID ENVIRON, V127, P53, DOI 10.1016/j.jaridenv.2015.10.009
CR  - Turlings L, 2000, INVASIVE PLANTS ANIM
CR  - van Wilgen BW, 2008, J ENVIRON MANAGE, V89, P336, DOI 10.1016/j.jenvman.2007.06.015
CR  - Vincent P., 2008, SAUDI ARABIA ENV OVE, DOI [10.1201/9780203030882, DOI 10.1201/9780203030882]
CR  - Warrag EI, 2019, APPL ECOL ENV RES, V17, P2325, DOI 10.15666/aeer/1702_23252338
CR  - WHEATER HS, 1989, P I CIVIL ENG PT 2, V87, P517, DOI 10.1680/iicep.1989.3776
PU  - CORVINUS UNIV BUDAPEST
PI  - BUDAPEST
PA  - VILLANYI UT 29/43, BUDAPEST, H-1118, HUNGARY
PY  - 2019
VL  - 17
IS  - 5
SP  - 10807
EP  - 10822
DO  - 10.15666/aeer/1705_1080710822
AN  - WOS:000490563900038
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  40
ER  -

TY  - JOUR
AU  - Fitzgerald, M
AU  - Nackoney, J
AU  - Potapov, PV
AU  - Turubanova, S
TI  - Agriculture is the primary driver of tree cover loss across the Forestiere region of the Republic of Guinea, Africa
T2  - ENVIRONMENTAL RESEARCH COMMUNICATIONS
LA  - English
KW  - tree cover loss
KW  - accuracy assessment
KW  - landsat
KW  - guinean forest of West Africa
KW  - biodiversity
KW  - protected areas
KW  - change detection
KW  - ESTIMATING AREA
KW  - GLOBAL ASSESSMENT
KW  - BIODIVERSITY
KW  - ACCURACY
KW  - NETWORK
AB  - Biodiversity hotspots are conservation priority areas that feature exceptionally high levels of species endemism and high levels of habitat loss. The Guinean Forests of West Africa hotspot, home to a quarter of all the mammal species of Africa, has experienced high levels of forest loss within its protected areas. Here, we analyzed tree cover loss and its proximate drivers within Guinee Forestiere, a high biodiversity region within the Guinean Forests of West Africa hotspot, both inside and outside protected areas. Using Landsat analysis ready data and a regionally calibrated, annual forest change detection model, we mapped tree cover loss occurring across this region from 2000 to 2018. We quantified the area of tree cover loss and identified proximate drivers using a statistical sample of reference data. The total tree cover loss in Guinee Forestiere between years 2000 and 2018 was 10,907 km(2) (SE 889 km(2)), which consists of approximately 25% of the region's total land area. Of this total loss, 364 km(2) (SE 91 km(2)) occurred within protected areas of high biodiversity value. Tree cover loss was not consistent across high biodiversity areas and did not appear to be related to protected area classification. Smallholder agriculture (subsistence and cash crop farming) was the primary driver of tree cover loss across Guinee Forestiere. This research provides multitemporal spatial data on tree cover dynamics that is required for effective implementation of sustainable management and biodiversity conservation strategies within the broader socioecological landscape of Guinee Forestiere. We also highlight important limitations to consider and address when using remote sensing to automate change detection across landscapes.
AD  - Kyoto Univ, Wildlife Res Ctr, Kyoto, JapanAD  - Univ Maryland, Dept Geog Sci, College Pk, MD 20742 USAC3  - Kyoto UniversityC3  - University System of MarylandC3  - University of Maryland College ParkFU  - Japan Society for the Promotion of Science [LGP-U04, 19J11961]
FX  - The authors would like to thank Dr Satoshi Hirata and the Primatology and Wildlife Sciences Program at Kyoto University. This work was supported by the Japan Society for the Promotion of Science (LGP-U04 and 19J11961). The authors declare that they have no conflicts of interest.
CR  - Bongaarts J, 2019, POPUL DEV REV, V45, P680, DOI 10.1111/padr.12283
CR  - Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
CR  - Brugiere D, 2009, BIODIVERS CONSERV, V18, P847, DOI 10.1007/s10531-008-9508-z
CR  - CBD, 2004, PROT AR ART 8 A E
CR  - CEPF, 2015, GUIN FOR W AFR CRIT
CR  - CEPF, 2016, ANN WORLDS 35 BIOD H
CR  - Chapin FS, 2000, NATURE, V405, P234, DOI 10.1038/35012241
CR  - Conservation International, 2021, CONS INT
CR  - FAO, 2010, RAPP NAT GUIN ROME E
CR  - Geldmann J, 2019, P NATL ACAD SCI USA, V116, P23209, DOI 10.1073/pnas.1908221116
CR  - Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1244693, 10.1126/science.1215904]
CR  - Hu XP, 2021, FRONT ECOL ENVIRON, V19, P91, DOI 10.1002/fee.2276
CR  - Isbell F, 2017, NATURE, V546, P65, DOI 10.1038/nature22899
CR  - IUCN, 2017, IUCN RED LIST THREAT
CR  - Ju JC, 2008, REMOTE SENS ENVIRON, V112, P1196, DOI 10.1016/j.rse.2007.08.011
CR  - Lin D, 2018, RESOURCES-BASEL, V7, DOI 10.3390/resources7030058
CR  - Mittermeier Russell A., 2004, P1
CR  - Molinario G, 2020, LAND-BASEL, V9, DOI 10.3390/land9010023
CR  - Morris RJ, 2010, PHILOS T R SOC B, V365, P3709, DOI 10.1098/rstb.2010.0273
CR  - Murguia DI, 2016, J ENVIRON MANAGE, V180, P409, DOI 10.1016/j.jenvman.2016.05.040
CR  - Myers N, 2000, NATURE, V403, P853, DOI 10.1038/35002501
CR  - Oldekop JA, 2016, CONSERV BIOL, V30, P133, DOI 10.1111/cobi.12568
CR  - Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
CR  - Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
CR  - Palahi M, 2021, NATURE, V592, pE15, DOI 10.1038/s41586-021-03292-x
CR  - Pimm SL, 2014, SCIENCE, V344, P987, DOI 10.1126/science.1246752
CR  - Potapov P, 2019, REMOTE SENS ENVIRON, V232, DOI 10.1016/j.rse.2019.111278
CR  - Potapov P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030426
CR  - PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
CR  - Rainer H., 2014, EXTRACTIVE IND APE C, V1, DOI [10.1017/CBO9781107590274, DOI 10.1017/CBO9781107590274]
CR  - Roe D., 2019, 24 IIED
CR  - Sonter LJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17928-5
CR  - Sonter LJ, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.1926
CR  - Stehman SV, 2014, INT J REMOTE SENS, V35, P4923, DOI 10.1080/01431161.2014.930207
CR  - Stehman SV, 2013, REMOTE SENS ENVIRON, V132, P202, DOI 10.1016/j.rse.2013.01.016
CR  - Tyukavina A, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat2993
CR  - UNEP-WCMC and IUCN, 2019, PROT PLAN WORLD DAT
CR  - UNESCO, 2019, WHAT AR BIOSPH RES
CR  - United Nations, 2015, A RES 70 1 TRANSF OU
CR  - Van Rompaey R., 2001, FOR SEA BIOD CONN GU
CR  - Watson JEM, 2014, NATURE, V515, P67, DOI 10.1038/nature13947
CR  - World Bank, 2019, GUIN OV
PU  - IOP Publishing Ltd
PI  - BRISTOL
PA  - TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
DA  - DEC 1
PY  - 2021
VL  - 3
IS  - 12
DO  - 10.1088/2515-7620/ac4278
AN  - WOS:000733972300001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  42
ER  -

TY  - JOUR
AU  - Martinez, LA
AU  - Mortelmans, J
AU  - Dillen, N
AU  - Debusschere, E
AU  - Deneudt, K
TI  - LifeWatch observatory data: phytoplankton observations in the Belgian Part of the North Sea
T2  - BIODIVERSITY DATA JOURNAL
LA  - English
KW  - phytoplankton
KW  - Belgium
KW  - marine
KW  - LifeWatch Belgium
KW  - FlowCAM
KW  - image recognition
KW  - HARMFUL ALGAL BLOOMS
KW  - COMMUNITY COMPOSITION
KW  - LONG-TERM
KW  - PLANKTON
KW  - IMPACT
AB  - Background
   This paper describes a phytoplankton data series generated through systematic observations in the Belgian Part of the North Sea (BPNS). Phytoplankton samples were collected during multidisciplinary sampling campaigns, visiting nine nearshore stations with monthly frequency and an additional eight offshore stations on a seasonal basis.
   New information
   The data series contain taxon-specific phytoplankton densities determined by analysis with the Flow Cytometer And Microscope (FlowCAM (R)) and associated image-based classification. The classification is performed by two separate semi-automated classification systems, followed by manual validation by taxonomic experts. To date, 637,819 biological particles have been collected and identified, yielding a large dataset of validated phytoplankton images. The collection and processing of the 2017-2018 dataset are described, along with its data curation, quality control and data storage. In addition, the classification of images using image classification algorithms, based on convolutional neural networks (CNN) from 2019 onwards, is also described. Data are published in a standardised format together with environmental parameters, accompanied by extensive metadata descriptions and finally labelled with digital identifiers for traceability. The data are published under a CC-BY 4.0 licence, allowing the use of the data under the condition of providing the reference to the source.
AD  - Flanders Marine Inst VLIZ, Wandelaarkaai 7, Oostende, BelgiumAD  - Univ Ghent, Dept Biol, Lab Protistol & Aquat Ecol, Ghent, BelgiumC3  - Ghent UniversityFU  - Research Foundation Flanders (FWO)
FX  - Funding for the data collection and management is provided by the Research Foundation Flanders (FWO) in the framework of the Flemish contribution to LifeWatch, which is a landmark European Research Infrastructures on the European Strategy Forum on Research (ESFRI) roadmap. Scientists and RV Simon Stevin crew joining the LifeWatch sampling campaigns are acknowledged for their practical support. The authors thank the Flemish Ministry of Mobility and Public Works (VLOOT) for operating the RV Simon Stevin and facilitating the surveys. We thank the reviewer for the very helpful comments.
CR  - Alvarez E, 2014, J PLANKTON RES, V36, P170, DOI 10.1093/plankt/fbt069
CR  - Alvarez E, 2012, J PLANKTON RES, V34, P454, DOI 10.1093/plankt/fbs017
CR  - Alvarez E, 2011, J PLANKTON RES, V33, P1119, DOI 10.1093/plankt/fbr012
CR  - Anderson DM, 2012, ANNU REV MAR SCI, V4, P143, DOI 10.1146/annurev-marine-120308-081121
CR  - [Anonymous], 2020, WORLD REGISTER MARIN
CR  - Benfield MC, 2007, OCEANOGRAPHY, V20, P172, DOI 10.5670/oceanog.2007.63
CR  - Breton E, 2006, LIMNOL OCEANOGR, V51, P1401, DOI 10.4319/lo.2006.51.3.1401
CR  - Buesseler KO, 2007, SCIENCE, V316, P567, DOI 10.1126/science.1137959
CR  - Camoying MG, 2016, LIMNOL OCEANOGR-METH, V14, P305, DOI 10.1002/lom3.10090
CR  - De Pooter D, 2017, BIODIVERS DATA J, V5, DOI 10.3897/BDJ.5.e10989
CR  - Edwards M, 2001, ICES J MAR SCI, V58, P39, DOI 10.1006/jmsc.2000.0987
CR  - Edwards M, 2010, TRENDS ECOL EVOL, V25, P602, DOI 10.1016/j.tree.2010.07.007
CR  - Emeis KC, 2015, J MARINE SYST, V141, P18, DOI 10.1016/j.jmarsys.2014.03.012
CR  - Field CB, 1998, SCIENCE, V281, P237, DOI 10.1126/science.281.5374.237
CR  - Gasparini S, 2000, J SEA RES, V43, P345, DOI 10.1016/S1385-1101(00)00016-2
CR  - Graham MD, 2018, LIMNOL OCEANOGR-METH, V16, P669, DOI 10.1002/lom3.10274
CR  - HALLEGRAEFF GM, 1993, PHYCOLOGIA, V32, P79, DOI 10.2216/i0031-8884-32-2-79.1
CR  - Haraguchi L, 2018, FRONT MAR SCI, V5, DOI 10.3389/fmars.2018.00272
CR  - Hutchins DA, 2017, NAT MICROBIOL, V2, DOI 10.1038/nmicrobiol.2017.58
CR  - Kraberg A., 2010, COASTAL PHYTOPLANKTO
CR  - Lacroix G, 2004, J SEA RES, V52, P149, DOI 10.1016/j.seares.2004.01.003
CR  - Lancelot C, 1987, OCEANOGRAPHIC LIT RE, V34, DOI [10.1016/0198-0254(87)90379-7, DOI 10.1016/0198-0254(87)90379-7]
CR  - Lee AJ, 1980, PHYS CHEM OCEANOGR B, P467, DOI 10.1016/s0422-9894(08)71359-x
CR  - Lloret L, 2018, BIODIVERS INF SCI ST, V2, DOI [10.3897/biss.2.25762, DOI 10.3897/BISS.2.25762]
CR  - LUND J. W. G., 1958, HYDROBIOLOGIA, V11, P143, DOI 10.1007/BF00007865
CR  - MARGALEF R, 1978, OCEANOL ACTA, V1, P493
CR  - Muelbert JH, 2019, FRONT MAR SCI, V6, DOI 10.3389/fmars.2019.00527
CR  - Muylaert K, 2006, J SEA RES, V55, P253, DOI 10.1016/j.seares.2005.12.002
CR  - Muylaert K, 2009, ESTUAR COAST SHELF S, V82, P335, DOI 10.1016/j.ecss.2009.01.024
CR  - Nohe A, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.126
CR  - Poulton NJ, 2010, MICROSCOPIC MOL METH, V47
CR  - Richardson AJ, 2004, SCIENCE, V305, P1609, DOI 10.1126/science.1100958
CR  - Sieracki CK, 1998, MAR ECOL PROG SER, V168, P285, DOI 10.3354/meps168285
CR  - Suikkanen S, 2007, ESTUAR COAST SHELF S, V71, P580, DOI 10.1016/j.ecss.2006.09.004
CR  - Tomas C.R., 1997, IDENTIFYING MARINE P
CR  - Wells ML, 2020, HARMFUL ALGAE, V91, DOI 10.1016/j.hal.2019.101632
CR  - Zingone A, 2015, ESTUAR COAST SHELF S, V162, P151, DOI 10.1016/j.ecss.2015.05.024
PU  - PENSOFT PUBLISHERS
PI  - SOFIA
PA  - 12 PROF GEORGI ZLATARSKI ST, SOFIA, 1700, BULGARIA
DA  - DEC 16
PY  - 2020
VL  - 8
DO  - 10.3897/BDJ.8.e57236
AN  - WOS:000600452700001
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  37
ER  -

TY  - JOUR
AU  - Brodie, S
AU  - Allen-Ankins, S
AU  - Towsey, M
AU  - Roe, P
AU  - Schwarzkopf, L
TI  - Automated species identification of frog choruses in environmental recordings using acoustic indices
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Acoustic indices
KW  - Acoustic monitoring
KW  - Automated species detection
KW  - Bioacoustics
KW  - Anurans
KW  - Frog chorusing
KW  - RECOGNITION
KW  - BIRDS
AB  - Acoustic monitoring provides opportunities for scaling up bioacoustic study of vocal animals to greater temporal and spatial scales. However, the large amounts of audio that can be easily and efficiently collected necessitates automated methods of analysis to extract useful ecological data. Acoustic indices have been used in spectrographic visualisation of long environmental recordings to successfully identify many biological sounds from their acoustic patterns and features. In particular, the choruses of several frog species are conspicuous in these spectrogram images which suggests that acoustic indices may be useful for detecting species in automated sound classification algorithms. The aim of this study was to investigate the use of acoustic indices as predictors in classification models for automated identification of frog species in environmental sound recordings from breeding habitats in north Queensland, Australia. Three types of classification models (random forests, support vector machines and gradient boosting) were trained and validated on a data set of 3274 1-minute audio segments labelled for the presence or absence of calling of 12 target frog species, and a feature set of 11 acoustic indices calculated on frequency bins of bandwidth 43.1 Hz. Classification performance was high for all 12 target species on the validation data set held out from the labelled training data (precision range 0.90-1.00 and recall range 0.83-0.99). However, performance declined for most target species when predicting frog calling on a further test data set taken from unseen recordings from the same sites. Best prediction results on the test data were achieved for species with the most training data, indicating accuracy may be improved by increasing training data, and this method is best suited to predicting chorusing of common species.
AD  - James Cook Univ, Coll Sci & Engn, Townsville, Qld 4817, AustraliaAD  - Queensland Univ Technol, Sci & Engn Fac, QUT Ecoacoust Res Grp, Brisbane, Qld 4000, AustraliaC3  - James Cook UniversityC3  - Queensland University of Technology (QUT)FU  - Australian Research Council [LP150100675]; Australian Government Research Training Program Scholarship
FX  - We thank Kiyomi Yasumiba, Ross Alford and Richard Duffy for obtaining the original set of field recordings used in this study, and the Fryer and Freestun families for access to the study dams at Hervey Range. We are also grateful to Kayla Mehes, Rishab Pillai and Ryan Searle for their assistance in manual analysis and labelling of audio. Funding for this work was provided by the Australian Research Council (Linkage grant number LP150100675 'Call Out and Listen In: A New Way to Detect and Control Invasive Species') and an Australian Government Research Training Program Scholarship. The Anindilyakwa Land Council were partners in the grant funding this study. This study was conducted under permission of Animal Ethics at James Cook University (permit no. A1838).
CR  - Acevedo MA, 2006, WILDLIFE SOC B, V34, P211, DOI 10.2193/0091-7648(2006)34[211:UADRSA]2.0.CO;2
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Australian Acoustic Observatory, 2019, A20 AUSTR AC OBS
CR  - Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
CR  - Bedoya C, 2014, ECOL INFORM, V24, P200, DOI 10.1016/j.ecoinf.2014.08.009
CR  - Bravo CJC, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.113
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
CR  - Chawla NV., 2004, ACM SIGKDD EXPLOR NE, V6, P1, DOI [10.1145/1007730.1007733, DOI 10.1145/1007730.1007733]
CR  - Crump PS, 2017, ECOL EVOL, V7, P3087, DOI 10.1002/ece3.2730
CR  - Dema T., 2018, FRESHW BIOL
CR  - Digby A, 2013, METHODS ECOL EVOL, V4, P675, DOI 10.1111/2041-210X.12060
CR  - Field SA, 2007, AUSTRAL ECOL, V32, P485, DOI 10.1111/j.1442-9993.2007.01715.x
CR  - Frommolt KH, 2014, ECOL INFORM, V21, P4, DOI 10.1016/j.ecoinf.2013.12.009
CR  - Gan H., 2018, IEEE 2018 DIGITAL IM
CR  - Ganchev T, 2007, BIOACOUSTICS, V16, P281, DOI 10.1080/09524622.2007.9753582
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Hagens SV, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199396
CR  - Indraswari K., 2018, FRESHW BIOL
CR  - Knight EC, 2020, BIOACOUSTICS, V29, P337, DOI 10.1080/09524622.2019.1606734
CR  - Kuhn M., 2013, APPL PREDICTIVE MODE, V26, DOI DOI 10.1007/978-1-46146849-3
CR  - Liaw A, 2018, PACKAGE RANDOMFOREST
CR  - Menardi G, 2014, DATA MIN KNOWL DISC, V28, P92, DOI 10.1007/s10618-012-0295-5
CR  - Noda JJ, 2016, EXPERT SYST APPL, V50, P100, DOI 10.1016/j.eswa.2015.12.020
CR  - Pieretti N, 2011, ECOL INDIC, V11, P868, DOI 10.1016/j.ecolind.2010.11.005
CR  - Potamitis I, 2014, APPL ACOUST, V80, P1, DOI 10.1016/j.apacoust.2014.01.001
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - R Core Team, 2019, R LANGUAGE ENV STAT
CR  - RStudio Team, 2019, RSTUDIO INT DEV R VE
CR  - Sanders CE, 2014, CONDOR, V116, P371, DOI 10.1650/CONDOR-13-098.1
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Sueur J, 2008, BIOACOUSTICS, V18, P213, DOI 10.1080/09524622.2008.9753600
CR  - Towsey M., 2018, ZENODO, DOI [10.5281/zenodo, DOI 10.5281/ZENODO]
CR  - Towsey M., 2018, Journal of Ecoacoustics, V2
CR  - Towsey M., 2017, CALCULATION ACOUSTIC
CR  - Towsey M, 2017, QUT ECOACOUSTICS AUD
CR  - Towsey M.W., 2015, ICDM 2015 INT C DAT
CR  - Towsey M, 2014, PROCEDIA COMPUT SCI, V29, P703, DOI 10.1016/j.procs.2014.05.063
CR  - Towsey M, 2014, ECOL INFORM, V21, P1, DOI 10.1016/j.ecoinf.2014.02.002
CR  - Waddle JH, 2009, HERPETOL CONSERV BIO, V4, P384
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - DEC
PY  - 2020
VL  - 119
DO  - 10.1016/j.ecolind.2020.106852
AN  - WOS:000579817600060
N1  - Times Cited in Web of Science Core Collection:  8
Total Times Cited:  8
Cited Reference Count:  40
ER  -

TY  - JOUR
AU  - Knight, EC
AU  - Hannah, KC
AU  - Foley, GJ
AU  - Scott, CD
AU  - Brigham, RM
AU  - Bayne, E
TI  - Recommendations for acoustic recognizer performance assessment with application to five common automated signal recognition programs
T2  - AVIAN CONSERVATION AND ECOLOGY
LA  - English
KW  - automated signal recognition
KW  - autonomous recording unit
KW  - bioacoustics
KW  - Common Nighthawk
KW  - recognizer
KW  - signal processing
KW  - AUTONOMOUS RECORDING UNITS
KW  - BAT ECHOLOCATION CALLS
KW  - GEOGRAPHIC-VARIATION
KW  - MICROPHONE ARRAYS
KW  - NEURAL-NETWORKS
KW  - CLASSIFICATION
KW  - IDENTIFICATION
KW  - BIRDS
KW  - SONG
KW  - TIME
AB  - Automated signal recognition software is increasingly used to extract species detection data from acoustic recordings collected using autonomous recording units (ARUs), but there is little practical guidance available for ecologists on the application of this technology. Performance evaluation is an important part of employing automated acoustic recognition technology because the resulting data quality can vary with a variety of factors. We reviewed the bioacoustic literature to summarize performance evaluation and found little consistency in evaluation, metrics employed, or terminology used. We also found that few studies examined how score threshold, i. e., cut-off for the level of confidence in target species classification, affected performance, but those that did showed a strong impact of score threshold on performance. We used the lessons learned from our literature review and best practices from the field of machine learning to evaluate the performance of five readily-available automated signal recognition programs. We used the Common Nighthawk (Chordeiles minor) as our model species because it has simple, consistent, and frequent vocalizations. We found that automated signal recognition was effective for determining Common Nighthawk presence-absence and call rate, particularly at low score thresholds, but that occupancy estimates from the data processed with recognizers were consistently lower than from data generated by human listening and became unstable at high score thresholds. Of the five programs evaluated, our convolutional neural network (CNN) recognizer performed best, with recognizers built in Song Scope and MonitoR also performing well. The RavenPro and Kaleidoscope recognizers were moderately effective, but produced more false positives than the other recognizers. Finally, we synthesized six general recommendations for ecologists who employ automated signal recognition software, including what to use as a test benchmark, how to incorporate score threshold, what metrics to use, and how to evaluate efficiency. Future studies should consider our recommendations to build a body of literature on the effectiveness of this technology for avian research and monitoring.
AD  - Univ Alberta, Dept Biol Sci, Bioacoust Unit, Edmonton, AB, CanadaAD  - WildResearch, WildRes Nightjar Survey, New Westminster, BC, CanadaAD  - Canadian Wildlife Serv, Environm & Climate Change Canada, Sackville, NB, CanadaAD  - Univ Regina, Dept Biol, Regina, SK, CanadaC3  - University of AlbertaC3  - Environment & Climate Change CanadaC3  - Canadian Wildlife ServiceC3  - University of ReginaFU  - Natural Sciences and Engineering Research Council of Canada; Alberta Biodiversity Monitoring Institute; Ecological Monitoring Committee for the Lower Athabasca; Joint Oil Sands Monitoring Program; Environment and Climate Change Canada; Mitacs; Baillie Fund; Science Horizons; Public Conservation Assistance Fund; TD Friends of the Environment Foundation
FX  - Our sincere thanks to the Subject Editor and three reviewers for their insightful comments, which greatly improved the clarity and accuracy of the manuscript. We gratefully acknowledge funding provided for the bioacoustic component of this work from the Natural Sciences and Engineering Research Council of Canada, the Alberta Biodiversity Monitoring Institute, the Ecological Monitoring Committee for the Lower Athabasca, and the Joint Oil Sands Monitoring Program. Funding for Common Nighthawk research was provided by the Natural Sciences and Engineering Research Council of Canada, Environment and Climate Change Canada, Mitacs, the Baillie Fund, Science Horizons, the Public Conservation Assistance Fund, and the TD Friends of the Environment Foundation.
CR  - Abadi M., 2015, TensorFlow: large-scale machine learning on heterogeneous systems
CR  - Acevedo MA, 2009, ECOL INFORM, V4, P206, DOI 10.1016/j.ecoinf.2009.06.005
CR  - Agranat I., 2009, AUTOMATICALLY IDENTI
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Anderson SE, 1996, J ACOUST SOC AM, V100, P1209, DOI 10.1121/1.415968
CR  - Armitage DW, 2010, ECOL INFORM, V5, P465, DOI 10.1016/j.ecoinf.2010.08.001
CR  - ARMSTRONG JT, 1965, ECOLOGY, V46, P619, DOI 10.2307/1935001
CR  - Bang A. V., 2014, INT J IMAGE PROCESSI, V1, P6
CR  - Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
CR  - BART J, 1984, AUK, V101, P307, DOI 10.1093/auk/101.2.307
CR  - Bedoya C., 2014, ECOLOGICAL INFORM, V24, P1
CR  - Belyaeva N. A., WHATFROG COMP CLASSI
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Brauer CL, 2016, WILDLIFE SOC B, V40, P140, DOI 10.1002/wsb.619
CR  - Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
CR  - Burnham KP., 2002, MODEL SELECTION MULT, V2
CR  - Cakir E, 2017, EUR SIGNAL PR CONF, P1744, DOI 10.23919/EUSIPCO.2017.8081508
CR  - Campbell M, 2012, J FIELD ORNITHOL, V83, P391, DOI 10.1111/j.1557-9263.2012.00389.x
CR  - Campbell P, 2010, EVOLUTION, V64, P1955, DOI 10.1111/j.1558-5646.2010.00962.x
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Catchpole CK, 2008, BIRD SONG: BIOLOGICAL THEMES AND VARIATIONS, 2ND EDITION, P1, DOI 10.1017/CBO9780511754791
CR  - Charif R.A., 2010, RAVEN PRO 1 4 USERS
CR  - Chesmore E. D., 2007, B ENTOMOL RES, V94, P1
CR  - Chu W, 2011, INT CONF ACOUST SPEE, P345
CR  - Colbert DS, 2015, WILDLIFE SOC B, V39, P757, DOI 10.1002/wsb.577
CR  - Colonna JG, 2015, EXPERT SYST APPL, V42, P7367, DOI 10.1016/j.eswa.2015.05.030
CR  - Crump PS, 2017, ECOL EVOL, V7, P3087, DOI 10.1002/ece3.2730
CR  - Davis J., 2006, KNOWLEDGE INTENSIVE, P233
CR  - Davis J., 2006, P 23 INT C MACH LEAR, P432
CR  - Demsar J, 2006, J MACH LEARN RES, V7, P1
CR  - Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
CR  - Digby A, 2013, METHODS ECOL EVOL, V4, P675, DOI 10.1111/2041-210X.12060
CR  - Dolezel P, 2015, INT J ENG RES AFR, V18, P184, DOI 10.4028/www.scientific.net/JERA.18.184
CR  - Dong XY, 2015, ECOL INFORM, V29, P66, DOI 10.1016/j.ecoinf.2015.07.007
CR  - Drake KL, 2016, WILDLIFE SOC B, V40, P346, DOI 10.1002/wsb.658
CR  - Duan S, 2013, P 25 INN APPL ART IN, P1519
CR  - Dufour O., 2014, SOUNDSCAPE SEMIOTICS, P83
CR  - Ehnes M, 2015, BIOACOUSTICS, V24, P111, DOI 10.1080/09524622.2014.994228
CR  - Environment Canada, 2016, SPECIES RISK ACT REC
CR  - Erbs F, 2017, J ACOUST SOC AM, V141, P2489, DOI 10.1121/1.4978000
CR  - Feng J., 2016, PLOS ONE, V8
CR  - Ferroudj M., 2015, THESIS
CR  - Forcey GM, 2006, J WILDLIFE MANAGE, V70, P1674, DOI 10.2193/0022-541X(2006)70[1674:COTDPA]2.0.CO;2
CR  - Furnas BJ, 2015, J WILDLIFE MANAGE, V79, P325, DOI 10.1002/jwmg.821
CR  - Ganchev T, 2007, BIOACOUSTICS, V16, P281, DOI 10.1080/09524622.2007.9753582
CR  - Ganchev TD, 2015, EXPERT SYST APPL, V42, P6098, DOI 10.1016/j.eswa.2015.03.036
CR  - Glotin H., 2016, 2016 IEEE INT WORKSH
CR  - Goeau H., 2017, LIFECLEF 2017 WORKIN, V1866, P8
CR  - Gonzalez R., 2010, 2010 4 INT C SIGN PR, P1
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Goyette JL, 2011, J FIELD ORNITHOL, V82, P279, DOI 10.1111/j.1557-9263.2011.00331.x
CR  - Gradisek A, 2017, BIOACOUSTICS, V26, P63, DOI 10.1080/09524622.2016.1190946
CR  - Grau J, 2015, BIOINFORMATICS, V31, P2595, DOI 10.1093/bioinformatics/btv153
CR  - Hafner S. D., 2017, SHORT INTRO ACOUSTIC
CR  - Harma A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P545
CR  - Haselmayer J, 2000, CONDOR, V102, P887, DOI 10.1650/0010-5422(2000)102[0887:ACOPCA]2.0.CO;2
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Holmes Stephen B., 2015, Canadian Field-Naturalist, V129, P115
CR  - Holmes SB, 2014, WILDLIFE SOC B, V38, P591, DOI 10.1002/wsb.421
CR  - Huang CJ, 2009, EXPERT SYST APPL, V36, P3737, DOI 10.1016/j.eswa.2008.02.059
CR  - Jaafar H., 2014, P 2014 INT C COMM SI, P172
CR  - Jahn O, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169041
CR  - Jaiswara R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075930
CR  - Jeliazkov A, 2016, GLOB ECOL CONSERV, V6, P208, DOI 10.1016/j.gecco.2016.02.008
CR  - Jennings N, 2008, CAN J ZOOL, V86, P371, DOI 10.1139/Z08-009
CR  - Joly A, 2016, LECT NOTES COMPUT SC, V9822, P286, DOI 10.1007/978-3-319-44564-9_26
CR  - Kaewtip K, 2013, INT CONF ACOUST SPEE, P768, DOI 10.1109/ICASSP.2013.6637752
CR  - Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
CR  - Kasten EP, 2010, ECOL INFORM, V5, P153, DOI 10.1016/j.ecoinf.2010.02.003
CR  - Katz J, 2016, BIOACOUSTICS, V25, P177, DOI 10.1080/09524622.2015.1133320
CR  - Kingma DP, 2014, ARXIV PREPRINT ARXIV
CR  - Koops HV, 2014, CEUR WORKSHOP PROC, V1180, P634
CR  - Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004
CR  - Lee H., 2017, LIBROSA 0 5 0
CR  - Luther DA, 2012, ANIM BEHAV, V83, P1059, DOI 10.1016/j.anbehav.2012.01.034
CR  - MacKenzie DI, 2002, ECOLOGY, V83, P2248, DOI 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2
CR  - McClintock BT, 2010, ECOLOGY, V91, P2446, DOI 10.1890/09-1287.1
CR  - Mencia E. L., 2013, P INT S NEUR INF SCA, P1
CR  - Mesaros A, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060162
CR  - Nicholson D, 2016, P 15 PYTH SCI C JUL, P57, DOI DOI 10.25080/MAJORA-629E541A-008
CR  - Arencibia JJN, 2015, INT CONF CONTEMP, P59, DOI 10.1109/IC3.2015.7346653
CR  - Noda JJ, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6120443
CR  - Noda JJ, 2016, EXPERT SYST APPL, V50, P100, DOI 10.1016/j.eswa.2015.12.020
CR  - Oliveira B. C., 2014, CIENCIA NATURA, V36, P1
CR  - Potamitis I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096936
CR  - Potamitis I, 2014, APPL ACOUST, V80, P1, DOI 10.1016/j.apacoust.2014.01.001
CR  - Prohl H, 2006, EVOLUTION, V60, P1669
CR  - Provost F., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P445
CR  - Ptacek L, 2016, BIOACOUSTICS, V25, P55, DOI 10.1080/09524622.2015.1089524
CR  - Qian K, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1317, DOI 10.1109/GlobalSIP.2015.7418412
CR  - R Core Team, 2019, R LANG ENV STAT COMP
CR  - Raffel C., 2014, P 15 INT SOC MUS INF
CR  - RAGHAVAN VV, 1989, ACM T INFORM SYST, V7, P205, DOI 10.1145/65943.65945
CR  - Ranjard L, 2008, J ACOUST SOC AM, V123, P4358, DOI 10.1121/1.2903861
CR  - Ranjard L, 2015, J ACOUST SOC AM, V137, P2542, DOI 10.1121/1.4919329
CR  - Ribeiro E., 2015, 20152 AMAL THEA REU
CR  - Rowe K. M. C., 2017, EMU AUSTRAL ORNITHOL, V117, P1
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Rydell J, 2017, ECOL INDIC, V78, P416, DOI 10.1016/j.ecolind.2017.03.023
CR  - Salamon J., 2016, PLOS ONE, V11
CR  - Salamon J, 2017, INT CONF ACOUST SPEE, P141, DOI 10.1109/ICASSP.2017.7952134
CR  - Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
CR  - Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260
CR  - Shonfield J, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00974-120114
CR  - Sidie-Slettedahl AM, 2015, WILDLIFE SOC B, V39, P626, DOI 10.1002/wsb.569
CR  - Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
CR  - Skowronski MD, 2006, J ACOUST SOC AM, V119, P1817, DOI 10.1121/1.2166948
CR  - Slabbekoorn H, 2002, PHILOS T R SOC B, V357, P493, DOI 10.1098/rstb.2001.1056
CR  - Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
CR  - Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
CR  - Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
CR  - Swiston KA, 2009, J FIELD ORNITHOL, V80, P42, DOI 10.1111/j.1557-9263.2009.00204.x
CR  - Tachibana RO, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092584
CR  - Tan L. N., 2012, INTERSPEECH
CR  - Tan LN, 2015, J ACOUST SOC AM, V137, P1069, DOI 10.1121/1.4906168
CR  - Thakur A, 2017, BIRD AUDIO DETECTION
CR  - Thessen A., 2016, ONE ECOSYST, V1, P8621, DOI [10.3897/oneeco.1.e8621, DOI 10.3897/ONEECO.1.E8621]
CR  - Tsai WH, 2014, J INF SCI ENG, V30, P1927
CR  - Turesson HK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163041
CR  - Ulloa JS, 2016, ECOL INFORM, V31, P91, DOI 10.1016/j.ecoinf.2015.11.012
CR  - Vega G, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.70
CR  - Ventura TM, 2015, EXPERT SYST APPL, V42, P8463, DOI 10.1016/j.eswa.2015.07.002
CR  - Vignolo L., 2016, 17 S ARG INT ART ASA, P53
CR  - Waddle JH, 2009, HERPETOL CONSERV BIO, V4, P384
CR  - Walters CL, 2012, J APPL ECOL, V49, P1064, DOI 10.1111/j.1365-2664.2012.02182.x
CR  - Wildlife Acoustics, 2011, SONG SCOP BIOAC SOFT
CR  - Wildlife Acoustics, 2016, CONV SONG SCOP REC K
CR  - Xie J., 2016, 2016 IEEE INT C PROG, P1, DOI DOI 10.1109/ICPHM.2016.7542845
CR  - Xie J, 2015, IEEE IMAGE PROC, P4190, DOI 10.1109/ICIP.2015.7351595
CR  - Yip DA, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00997-120111
CR  - YOUDEN WJ, 1950, CANCER-AM CANCER SOC, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
PU  - RESILIENCE ALLIANCE
PI  - WOLFVILLE
PA  - ACADIA UNIV, BIOLOGY DEPT, WOLFVILLE, NS B0P 1X0, CANADA
DA  - DEC
PY  - 2017
VL  - 12
IS  - 2
DO  - 10.5751/ACE-01114-120214
AN  - WOS:000419347000019
N1  - Times Cited in Web of Science Core Collection:  76
Total Times Cited:  79
Cited Reference Count:  131
ER  -

TY  - JOUR
AU  - Cardoso, AS
AU  - Renna, F
AU  - Moreno-Llorca, R
AU  - Alcaraz-Segura, D
AU  - Tabik, S
AU  - Ladle, RJ
AU  - Vaz, AS
TI  - Classifying the content of social media images to support cultural ecosystem service assessments using deep learning models
T2  - ECOSYSTEM SERVICES
LA  - English
KW  - Computer vision
KW  - Convolutional neural networks
KW  - Culturomics
KW  - iEcology
KW  - Nature contributions to people
KW  - Transfer learning
KW  - PROTECTED AREA
KW  - CONSERVATION
KW  - IDENTIFICATION
KW  - PERCEPTIONS
KW  - BUTTERFLIES
KW  - FRAMEWORK
AB  - Crowdsourced social media data has become popular for assessing cultural ecosystem services (CES). Nevertheless, social media data analyses in the context of CES can be time consuming and costly, particularly when based on the manual classification of images or texts shared by people. The potential of deep learning for automating the analysis of crowdsourced social media content is still being explored in CES research. Here, we use freely available deep learning models, i.e., Convolutional Neural Networks, for automating the classification of natural and human (e.g., species and human structures) elements relevant to CES from Flickr and Wikiloc images. Our approach is developed for Peneda-Ger <^>es (Portugal) and then applied to Sierra Nevada (Spain). For Peneda-Ger <^>es, image classification showed promising results (F1-score ca. 80%), highlighting a preference for aesthetics appreciation by social media users. In Sierra Nevada, even though model performance decreased, it was still satisfactory (F1-score ca. 60%), indicating a predominance of people's pursuit for cultural heritage and spiritual enrichment. Our study shows great potential from deep learning to assist in the automated classification of human-nature interactions and elements from social media content and, by extension, for supporting researchers and stakeholders to decode CES distributions, benefits, and values.
AD  - CIBIO, Ctr Invest Biodiversidade Recursos Gen, InBIO Lab Associado, Campus Vairao, P-4485661 Porto, PortugalAD  - Univ Porto, Dept Biol, Fac Ciencias, P-4099002 Porto, PortugalAD  - CIBIO, BIOPOLIS Program Genom, Biodivers & Land Planning, Campus Vairao, P-4485661 Vairao, PortugalAD  - Univ Porto, Inst Telecomunicacoes, Fac Ciencias, Rua Campo Alegre, Porto, PortugalAD  - Univ Granada, Andalusian Inter Univ Inst Earth Syst Res IISTA, iEcolab, Avda Mediterraneo S N, Granada 18006, SpainAD  - Univ Granada, Fac Ciencias, Dpto Botan, Av Fuentenueva S N, Granada 18003, SpainAD  - Univ Almeria, Andalusian Ctr Assessment & Monitoring Global, Crta San Urbano S-N, Almeria 04120, SpainAD  - Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Granada 18071, SpainAD  - Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Dept Comp Sci & Artificial Intelligence, DaSCI, Granada 18071, SpainAD  - Univ Fed Alagoas, Inst Biol Sci & Hlth, Maceio, Alagoas, BrazilC3  - Universidade do PortoC3  - Universidade do PortoC3  - University of GranadaC3  - University of GranadaC3  - Universidad de AlmeriaC3  - University of GranadaC3  - University of GranadaC3  - Universidade Federal de AlagoasFU  - FCT -Portuguese Foundation for Science and Technology [2020.01175, CEECIND/CP1601/CT0009]; Spanish Ministry of Science and Innovation; Regional Ministry of Environment of Andalucia; European Union's ERDF; University of Granada [A-TIC-458-UGR18]; European Union [854248]; Ministerio de Ciencia, Innovaci 'on y Universidades (Spain) [FJC2018-038131-I]
FX  - ASC is supported by the FCT -Portuguese Foundation for Science and Technology through the 2021 PhD Research Studentships [grant reference 2021.05426.BD]. ASV, DAS, FR, RML and ST acknowledge support from the EarthCul Project (reference PID2020-118041GB-I00), funded by the Spanish Ministry of Science and Innovation. FR acknowledges national funds from the FCT -Portuguese Foundation for Science and Technology through the program Stimulus for Scientific Employment Individual Support [contract reference CEECIND/01970/2017. RMLL is supported by the collaboration agreement between the Regional Ministry of Environment of Andalucia and the University of Granada for the project "Global Change Observatory of Sierra Nevada". ST acknowledges support from European Union's ERDF and University of Granada through project DeepL-ISCO (A-TIC-458-UGR18). RJL is supported by European Union's Horizon 2020 research and innovation programme grant 854248. ASV acknowledges support from the Ministerio de Ciencia, Innovaci ' on y Universidades (Spain) through the 2018 Juan de la Cierva-Formaci ' on program [contract reference FJC2018-038131-I] and from the FCT -Portuguese Foundation for Science and Technology through the program Stimulus for Scientific Employment -Individual Support [contract reference 2020.01175.CEECIND/CP1601/CT0009]. This paper contributes to the GEO BON working group on Ecosystem Services.
CR  - Almryad AS, 2020, ENG SCI TECHNOL, V23, P189, DOI 10.1016/j.jestch.2020.01.006
CR  - Blicharska M, 2017, ECOSYST SERV, V23, P55, DOI 10.1016/j.ecoser.2016.11.014
CR  - Bragagnolo C, 2016, CONSERV SOC, V14, P163, DOI 10.4103/0972-4923.191161
CR  - Bubalo M, 2019, LANDSCAPE URBAN PLAN, V184, P101, DOI 10.1016/j.landurbplan.2019.01.001
CR  - Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
CR  - Chan KMA, 2012, ECOL ECON, V74, P8, DOI 10.1016/j.ecolecon.2011.11.011
CR  - Cheng X, 2019, ECOSYST SERV, V37, DOI 10.1016/j.ecoser.2019.100925
CR  - Chollet F., 2015, KERAS
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Di Minin E, 2015, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00063
CR  - Dramsch J.S., 2018, SEG INT EXP 88 ANN M, P2036, DOI [10.1190/segam2018- 2996783.1, DOI 10.1190/SEGAM2018-2996783.1]
CR  - Ferreira AC, 2020, METHODS ECOL EVOL, V11, P1072, DOI 10.1111/2041-210X.13436
CR  - Fish R, 2016, ECOSYST SERV, V21, P208, DOI 10.1016/j.ecoser.2016.09.002
CR  - Fu JL, 2017, APSIPA TRANS SIGNAL, V6, DOI 10.1017/ATSIP.2017.12
CR  - Gliozzo G, 2016, ECOL SOC, V21, DOI 10.5751/ES-08436-210306
CR  - Goodness J, 2016, ECOL INDIC, V70, P597, DOI 10.1016/j.ecolind.2016.02.031
CR  - Gosal AS, 2020, ECOL INDIC, V117, DOI 10.1016/j.ecolind.2020.106638
CR  - Gosal AS, 2019, ECOSYST SERV, V38, DOI 10.1016/j.ecoser.2019.100958
CR  - Haines-Young R., 2018, COMMON INT CLASSIFIC
CR  - Hausmann A, 2018, CONSERV LETT, V11, DOI 10.1111/conl.12343
CR  - Havinga I, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99282-0
CR  - He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
CR  - Hsu H., 2005, ENCY BIOSTATISTICS, V6, DOI [10.1002/9780471462422.eoct969, DOI 10.1002/9780471462422.EOCT969, 10.1002/0470011815.b2a15112, DOI 10.1002/0470011815.B2A15112]
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - James K, 2020, METHODS ECOL EVOL, V11, P1509, DOI 10.1111/2041-210X.13473
CR  - Jaric I, 2020, TRENDS ECOL EVOL, V35, P630, DOI 10.1016/j.tree.2020.03.003
CR  - Jepson PR, 2017, BIOL CONSERV, V212, P183, DOI 10.1016/j.biocon.2017.03.032
CR  - King DB, 2015, ACS SYM SER, V1214, P1
CR  - Koblet O, 2020, LANDSCAPE URBAN PLAN, V197, DOI 10.1016/j.landurbplan.2020.103757
CR  - Ladle RJ, 2017, FRONT ECOL ENVIRON, V15, P290, DOI 10.1002/fee.1506
CR  - Ladle RJ, 2016, FRONT ECOL ENVIRON, V14, P270, DOI 10.1002/fee.1260
CR  - Langlois J, 2021, ECOL INDIC, V129, DOI 10.1016/j.ecolind.2021.107935
CR  - Li J., 2018, ADV NEURAL INFORM PR, P1586
CR  - Lusch B, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07210-0
CR  - Moreno-Llorca R, 2020, SCI TOTAL ENVIRON, V737, DOI 10.1016/j.scitotenv.2020.140067
CR  - Na B., 2020, ADV SCI TECHNOLOGY E, V5, P476
CR  - Nekola JC, 1999, J BIOGEOGR, V26, P867, DOI 10.1046/j.1365-2699.1999.00305.x
CR  - Norouzzadeh MS, 2021, METHODS ECOL EVOL, V12, P150, DOI 10.1111/2041-210X.13504
CR  - Retka J, 2019, OCEAN COAST MANAGE, V176, P40, DOI 10.1016/j.ocecoaman.2019.04.018
CR  - Richards DR, 2018, ECOSYST SERV, V31, P318, DOI 10.1016/j.ecoser.2017.09.004
CR  - Richards DR, 2015, ECOL INDIC, V53, P187, DOI 10.1016/j.ecolind.2015.01.034
CR  - Riechers M, 2016, ECOSYST SERV, V17, P33, DOI 10.1016/j.ecoser.2015.11.007
CR  - Ros-Candeira A, 2020, NAT CONSERV-BULGARIA, P1, DOI 10.3897/natureconservation.38.38325
CR  - Santarem F, 2015, TOUR MANAG PERSPECT, V16, P190, DOI 10.1016/j.tmp.2015.07.019
CR  - Seresinhe CI, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170170
CR  - Silva WA, 2021, APPL INTELL, V51, P396, DOI 10.1007/s10489-020-01805-1
CR  - Sitaula C, 2020, IEEE IJCNN
CR  - Vaz AS, 2020, CONSERV LETT, V13, DOI 10.1111/conl.12704
CR  - Srivastava S, 2018, PROCEEDINGS OF THE 2ND ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON AI FOR GEOGRAPHIC KNOWLEDGE DISCOVERY (GEOAI 2018), P43, DOI 10.1145/3281548.3281559
CR  - Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
CR  - Tan MX, 2019, PR MACH LEARN RES, V97
CR  - Tenkanen H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18007-4
CR  - Terry JCD, 2020, METHODS ECOL EVOL, V11, P303, DOI 10.1111/2041-210X.13335
CR  - Theivaprakasham H, 2021, J ASIA-PAC ENTOMOL, V24, P329, DOI 10.1016/j.aspen.2020.11.015
CR  - Thorat P., 2020, P INT C COMP SCI APP, P343, DOI [10.1007/978-981-15-0790-8_33, DOI 10.1007/978-981-15-0790-8_33]
CR  - Toivonen T, 2019, BIOL CONSERV, V233, P298, DOI 10.1016/j.biocon.2019.01.023
CR  - van der Wal R, 2015, AMBIO, V44, pS517, DOI 10.1007/s13280-015-0701-5
CR  - Vigl LE, 2021, PEOPLE NAT, V3, P673, DOI 10.1002/pan3.10199
CR  - Waldchen J, 2018, METHODS ECOL EVOL, V9, P2216, DOI 10.1111/2041-210X.13075
CR  - Wartmann FM, 2021, LANDSCAPE ECOL, V36, P2347, DOI 10.1007/s10980-020-01181-8
CR  - Weinstein BG, 2018, METHODS ECOL EVOL, V9, P1435, DOI 10.1111/2041-210X.13011
CR  - Willcock S, 2018, ECOSYST SERV, V33, P165, DOI 10.1016/j.ecoser.2018.04.004
CR  - Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022
CR  - Yoshimura N, 2017, ECOSYST SERV, V24, P68, DOI 10.1016/j.ecoser.2017.02.009
CR  - Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - APR
PY  - 2022
VL  - 54
DO  - 10.1016/j.ecoser.2022.101410
AN  - WOS:000777737000005
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  65
ER  -

TY  - JOUR
AU  - Wightman, PH
AU  - Henrichs, DW
AU  - Collier, BA
AU  - Chamberlain, MJ
TI  - Comparison of methods for automated identification of wild turkey gobbles
T2  - WILDLIFE SOCIETY BULLETIN
LA  - English
KW  - acoustic monitoring
KW  - autonomous call recognition
KW  - convolutional neural network
KW  - gobbling
KW  - Meleagris gallopavo
KW  - Raven Pro
KW  - wild turkey
KW  - AUTONOMOUS RECORDING UNITS
KW  - AUDIO RECORDINGS
KW  - BIRDS
KW  - CLASSIFICATION
KW  - SONGBIRDS
KW  - SOUNDS
KW  - COUNTS
AB  - Autonomous recording units (ARUs) allow for collection of extensive acoustic data sets, while reducing costs and time associated with traditional surveys used to determine gobbling chronology of male wild turkeys (Meleagris gallopavo). A challenge with ARUs is efficiently locating and identifying calls of interest, so autonomous call recognition (ACR) software such as Raven Pro have traditionally been used to identify wild turkey gobbles. However, ACR software often produces high false positive detections, requiring substantive time to verify selections as gobbles. We used ARUs across 3 study sites in the southeastern United States to collect 107,580 hours of ambient sound. We developed a convolutional neural network (CNN) to autonomously identify wild turkey gobbles and compared results of our CNN to results gathered using the commercially available program Raven Pro. After processing of ambient sound, the CNN detected 15,793 more gobbles than Raven Pro, and did so with 5,716,718 fewer selections. Collectively, our CNN improved precision from 0.01 to 0.32 relative to Raven Pro, while decreasing the time required for validation from 4,452 hours to 219. We found precision of our CNN varied across ARUs primarily due to differences in occurrence of ambient sounds similar to gobbles. Thus, we recommend that additional site-specific training data should be considered when developing CNNs. Our results suggest that researchers interested in describing gobbling activity by male wild turkeys should consider developing and applying CNNs for automated call recognition.
AD  - Univ Georgia, Warnell Sch Forestry & Nat Resources, Athens, GA 30602 USAAD  - Texas A&M Univ, Dept Oceanog, College Stn, TX 77843 USAAD  - Louisiana State Univ, Sch Renewable Nat Resources, Agr Ctr, Baton Rouge, LA 70803 USAC3  - University System of GeorgiaC3  - University of GeorgiaC3  - Texas A&M University SystemC3  - Texas A&M University College StationC3  - Louisiana State University SystemC3  - Louisiana State UniversityFU  - Warnell School of Forestry and Natural Resources at the University of Georgia; Louisiana State University Agricultural Center; Georgia Department Of Natural Resources; South Carolina Department of Natural Resources
FX  - Warnell School of Forestry and Natural Resources at the University of Georgia; Louisiana State University Agricultural Center; Georgia Department Of Natural Resources; South Carolina Department of Natural Resources
CR  - Abadi M., 2015, TensorFlow: large-scale machine learning on heterogeneous systems
CR  - Acevedo MA, 2006, WILDLIFE SOC B, V34, P211, DOI 10.2193/0091-7648(2006)34[211:UADRSA]2.0.CO;2
CR  - Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
CR  - Bevill W.V., 1973, P SE ASS GAME FISH C, V27, P62
CR  - Bioacoustics Research Program,, 2014, RAVEN PROINTERACTIVE
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Buckland ST, 2006, AUK, V123, P345, DOI 10.1642/0004-8038(2006)123[345:PSFSRM]2.0.CO;2
CR  - Buxton RT, 2016, ECOL EVOL, V6, P4697, DOI 10.1002/ece3.2242
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Casalena M.J., 2011, P NATL WILD TURKEY S, V10, P41
CR  - Chamberlain MJ, 2018, WILDLIFE SOC B, V42, P632, DOI 10.1002/wsb.932
CR  - Charif R.A., 2010, RAVEN PRO14 USERS MA
CR  - Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
CR  - Colbert DS, 2015, WILDLIFE SOC B, V39, P757, DOI 10.1002/wsb.577
CR  - Drake KL, 2016, WILDLIFE SOC B, V40, P346, DOI 10.1002/wsb.658
CR  - Furnas BJ, 2015, J WILDLIFE MANAGE, V79, P325, DOI 10.1002/jwmg.821
CR  - Gillespie D, 2013, J ACOUST SOC AM, V134, P2427, DOI 10.1121/1.4816555
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Goyette JL, 2011, J FIELD ORNITHOL, V82, P279, DOI 10.1111/j.1557-9263.2011.00331.x
CR  - Healy W.M., 1992, WILD TURKEY BIOL MAN, P46
CR  - Hutto RL, 2009, J FIELD ORNITHOL, V80, P387, DOI 10.1111/j.1557-9263.2009.00245.x
CR  - Isabelle J.L., 2015, P NATL WILD TURKEY S, V11, P249
CR  - Katz J, 2016, BIOACOUSTICS, V25, P177, DOI 10.1080/09524622.2015.1133320
CR  - King DB, 2015, ACS SYM SER, V1214, P1
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Krakauer AH, 2008, CONDOR, V110, P1, DOI 10.1525/cond.2008.110.1.1
CR  - Leach EC, 2016, EMU, V116, P305, DOI 10.1071/MU15097
CR  - Miller DA, 1997, J WILDLIFE MANAGE, V61, P840, DOI 10.2307/3802192
CR  - Premoli M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0244636
CR  - Rempel RS, 2005, J FIELD ORNITHOL, V76, P1, DOI 10.1648/0273-8570-76.1.1
CR  - Ruff ZJ, 2021, ECOL INDIC, V124, DOI 10.1016/j.ecolind.2021.107419
CR  - Ruff ZJ, 2020, REMOTE SENS ECOL CON, V6, P79, DOI 10.1002/rse2.125
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260
CR  - Shonfield J, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00974-120114
CR  - Swiston KA, 2009, J FIELD ORNITHOL, V80, P42, DOI 10.1111/j.1557-9263.2009.00204.x
CR  - Tegeler AK, 2012, WILDLIFE SOC B, V36, P21, DOI 10.1002/wsb.112
CR  - Towsey M, 2012, BIOACOUSTICS, V21, P107, DOI 10.1080/09524622.2011.648753
CR  - Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
CR  - Wakefield CT, 2020, J WILDLIFE MANAGE, V84, P448, DOI 10.1002/jwmg.21804
CR  - Wightman PH, 2019, J WILDLIFE MANAGE, V83, P325, DOI 10.1002/jwmg.21600
CR  - Zhong M, 2020, J ACOUST SOC AM, V147, P1834, DOI 10.1121/10.0000921
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - MAR
PY  - 2022
VL  - 46
IS  - 1
DO  - 10.1002/wsb.1246
AN  - WOS:000754625000001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  42
ER  -

TY  - JOUR
AU  - Hilasaca, LMH
AU  - Gaspar, LP
AU  - Ribeiro, MC
AU  - Minghim, R
TI  - Visualization and categorization of ecological acoustic events based on discriminant features
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Soundscape ecology
KW  - Discriminant features
KW  - Visualization
KW  - Classification
KW  - AVIAN SPECIES RICHNESS
KW  - INDEXES REFLECT
KW  - BIODIVERSITY
KW  - CLASSIFICATION
KW  - DIVERSITY
KW  - LANDSCAPE
KW  - SOUNDSCAPE
KW  - RECORDINGS
KW  - TEMPERATE
KW  - RESPONSES
AB  - Although sound classification in soundscape studies are generally performed by experts, the large growth of acoustic data presents a major challenge for performing such task. At the same time, the identification of more discriminating features becomes crucial when analyzing soundscapes, and this occurs because natural and anthropogenic sounds are very complex, particularly in Neotropical regions, where the biodiversity level is very high. In this scenario, the need for research addressing the discriminatory capability of acoustic features is of utmost importance to work towards automating these processes. In this study we present a method to identify the most discriminant features for categorizing sound events in soundscapes. Such identification is key to classification of sound events. Our experimental findings validate our method, showing high discriminatory capability of certain extracted features from sound data, reaching an accuracy of 89.91% for classification of frogs, birds and insects simultaneously. An extension of these experiments to simulate binary classification reached accuracy of 82.64%, 100.0% and 99.40% for the classification between combinations of frogs-birds, frogs-insects and birds-insects, respectively.
AD  - Univ Sao Paulo, Inst Ciencias Matemat & Comp ICMC, Sao Paulo, BrazilAD  - Sao Paulo State Univ UNESP, Dept Biodivers, Sao Paulo, BrazilAD  - Univ Coll Cork, Sch Comp Sci & Informat Technol, Cork, IrelandC3  - Universidade de Sao PauloC3  - Universidade Estadual PaulistaC3  - University College CorkFU  - Brazilian National Council for Scientific and Technological Development (CNPq) [307411/20168]; Coordination for the Improvement of Higher Education Personnel (CAPES) [133718/20182, 001]; FAPESP [2013/504212, 2020/017795]; CNPq [312045/20131, 312292/20163, 442147/20201]; PROCAD/CAPES [88881.068425/201401]
FX  - This research was partially supported by the Brazilian National Council for Scientific and Technological Development (CNPq) [Grant No. 307411/20168] and the Coordination for the Improvement of Higher Education Personnel (CAPES) [Grant No. 133718/20182] Finance Code 001. MCR thanks to FAPESP (processes #2013/504212; #2020/017795) , CNPq (processes #312045/20131; #312292/20163; #442147/20201) and PROCAD/CAPES (project #88881.068425/2014?01) for their financial support.
CR  - Agrawal DM, 2017, EUR SIGNAL PR CONF, P1809, DOI 10.23919/EUSIPCO.2017.8081521
CR  - Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1
CR  - [Anonymous], **DATA OBJECT**, DOI DOI 10.5281/ZENODO.3478579
CR  - Artur E, 2019, COMPUT GRAPH-UK, V84, P160, DOI 10.1016/j.cag.2019.08.015
CR  - Barros F., 2019, OIKOS, V128, DOI [10.1111/ofk.05910, DOI 10.1111/OFK.05910]
CR  - Bogert B. P., PROC
CR  - Boscolo D, 2017, PERSPECT ECOL CONSER, V15, P18, DOI 10.1016/j.pecon.2017.03.002
CR  - Butchart SHM, 2010, SCIENCE, V328, P1164, DOI 10.1126/science.1187512
CR  - Card S. K., 1999, READINGS INFORM VISU
CR  - Depraetere M, 2012, ECOL INDIC, V13, P46, DOI 10.1016/j.ecolind.2011.05.006
CR  - Dias F.F., 2018, THESIS
CR  - Dias FF, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101184
CR  - Eldridge A, 2018, ECOL INDIC, V95, P939, DOI 10.1016/j.ecolind.2018.06.012
CR  - Faceli K., 2011, INTELIGENCIA ARTIFIC
CR  - Fuller S, 2015, ECOL INDIC, V58, P207, DOI 10.1016/j.ecolind.2015.05.057
CR  - Gasc A, 2015, BIOL CONSERV, V191, P306, DOI 10.1016/j.biocon.2015.06.018
CR  - Gasc A, 2013, ECOL INDIC, V25, P279, DOI 10.1016/j.ecolind.2012.10.009
CR  - Haemer K.W., 1948, AM STAT, V2, P23
CR  - Hall M.A., 2000, P 17 INT C MACH LEAR, P359
CR  - Han NC, 2011, APPL ACOUST, V72, P639, DOI 10.1016/j.apacoust.2011.02.002
CR  - Harma A, 2001, IEEE T SPEECH AUDI P, V9, P769, DOI 10.1109/89.966080
CR  - Hu W, 2009, ACM T SENSOR NETWORK, V5, DOI 10.1145/1464420.1464424
CR  - Jia-Ming Liu, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P160, DOI 10.1109/ChinaSIP.2013.6625319
CR  - Johnson CN, 2017, SCIENCE, V356, P270, DOI 10.1126/science.aam9317
CR  - Joo W, 2011, LANDSCAPE URBAN PLAN, V103, P259, DOI 10.1016/j.landurbplan.2011.08.001
CR  - Jorge FC, 2018, ECOL INDIC, V91, P71, DOI 10.1016/j.ecolind.2018.04.001
CR  - Kasten EP, 2012, ECOL INFORM, V12, P50, DOI 10.1016/j.ecoinf.2012.08.001
CR  - Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
CR  - KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
CR  - LAMEL LF, 1981, IEEE T ACOUST SPEECH, V29, P777, DOI 10.1109/TASSP.1981.1163642
CR  - Machado RB, 2017, LANDSCAPE URBAN PLAN, V162, P36, DOI 10.1016/j.landurbplan.2017.01.014
CR  - Mammides C, 2017, ECOL INDIC, V82, P470, DOI 10.1016/j.ecolind.2017.07.017
CR  - Mazza IL, 2009, INTRO INFORM VISUALI, V1st
CR  - McFee B., 2015, PROC 14 PYTHON SCI C, V8, P18, DOI 10.25080/Majora-7b98e3ed-003
CR  - McInnes L., 2018, AR XIV180203426V3, P33
CR  - Miao JY, 2016, PROCEDIA COMPUT SCI, V91, P919, DOI 10.1016/j.procs.2016.07.111
CR  - Minghim R, 2020, ALGORITHMS, V13, DOI 10.3390/a13110302
CR  - Mitrovic D, 2010, ADV COMPUT, V78, P71, DOI 10.1016/S0065-2458(10)78003-7
CR  - Mittermeier R.A., 2011, BIODIVERSITY HOTSPOT, P3, DOI [10.1007/978-3-642-20992-5_1, DOI 10.1007/978-3-642-20992-5_1]
CR  - Moher D, 2009, BMJ-BRIT MED J, V339, DOI [10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.g7647]
CR  - Moreno-Gomez FN, 2019, ECOL INDIC, V103, P1, DOI 10.1016/j.ecolind.2019.03.024
CR  - Noda JJ, 2016, EXPERT SYST APPL, V50, P100, DOI 10.1016/j.eswa.2015.12.020
CR  - Parks SE, 2014, ECOL INFORM, V21, P81, DOI 10.1016/j.ecoinf.2013.11.003
CR  - Phillips YF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193345
CR  - Pieretti N, 2011, ECOL INDIC, V11, P868, DOI 10.1016/j.ecolind.2010.11.005
CR  - Pijanowski BC, 2011, LANDSCAPE ECOL, V26, P1213, DOI 10.1007/s10980-011-9600-8
CR  - Qian K, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1317, DOI 10.1109/GlobalSIP.2015.7418412
CR  - Raghuram MA, 2016, INT J SPEECH TECHNOL, V19, P791, DOI 10.1007/s10772-016-9372-2
CR  - Rao KS, 2014, SPRBRIEF ELECT, P1, DOI 10.1007/978-3-319-07130-5
CR  - Retamosa Izaguirre M.I.R.I., 2018, J ECOACOUSTICS, V2, P1, DOI [10.22261/jea.tnw2np, DOI 10.22261/JEA.TNW2NP]
CR  - Ribeiro MC, 2009, BIOL CONSERV, V142, P1141, DOI 10.1016/j.biocon.2009.02.021
CR  - ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
CR  - Sankupellay M, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
CR  - Scarpelli MDA, 2021, ECOL INDIC, V121, DOI 10.1016/j.ecolind.2020.107050
CR  - Scarpelli MDA, 2020, SCI TOTAL ENVIRON, V707, DOI 10.1016/j.scitotenv.2019.135403
CR  - Servick K, 2014, SCIENCE, V343, P834, DOI 10.1126/science.343.6173.834
CR  - Skinkff J., 2008, PLOS ONE, V3
CR  - Sninn I., 2015, BIOSEMIOTICS, V8, p493 502
CR  - Stowell D., 2014, CLEF
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Team RC, 2013, R LANG ENV STAT COMP
CR  - Terasawa H., 2005, ICAD2005
CR  - Towsey M, 2014, PROCEDIA COMPUT SCI, V29, P703, DOI 10.1016/j.procs.2014.05.063
CR  - Towsey M, 2014, ECOL INFORM, V21, P110, DOI 10.1016/j.ecoinf.2013.11.007
CR  - van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
CR  - Villanneva Rivera L.J., 2011, LANDSCAPE ECOL, V26, p1233 1246
CR  - Woods R.C., 2010, DIGITAL IMAGE PROCES, V3rd
CR  - Xie J, 2018, APPL ACOUST, V131, P79, DOI 10.1016/j.apacoust.2017.10.024
CR  - Xie J, 2016, APPL ACOUST, V113, P193, DOI 10.1016/j.apacoust.2016.06.029
CR  - Zhao Z, 2019, ECOL INDIC, V107, DOI 10.1016/j.ecolind.2019.105588
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - JUL
PY  - 2021
VL  - 126
DO  - 10.1016/j.ecolind.2020.107316
AN  - WOS:000647804300005
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  70
ER  -

TY  - JOUR
AU  - Edwards, T
AU  - Jones, CB
AU  - Corcoran, P
TI  - Identifying wildlife observations on twitter
T2  - ECOLOGICAL INFORMATICS
LA  - English
KW  - Wildlife observations
KW  - Supervised machine learning
KW  - Natural language processing
KW  - Social media
KW  - Crowdsourcing
KW  - Citizen science
KW  - SOCIAL MEDIA
AB  - Despite the potential of social media for environmental monitoring, concerns remain about the quality and reliability of the information automatically extracted. Notably there are many observations of wildlife on Twitter, but their automated detection is a challenge due to the frequent use of wildlife related words in messages that have no connection with wildlife observation. We investigate whether and what type of supervised machine learning methods can be used to create a fully automated text classification model to identify genuine wildlife observations on Twitter, irrespective of species type or whether Tweets are geo-tagged. We perform experiments with various techniques for building feature vectors that serve as input to the classifiers, and consider how they affect classification performance. We compare three classification approaches and perform an analysis of the types of features that are indicative for genuine wildlife observations on Twitter. In particular, we compare some classical machine learning algorithms, widely used in ecology studies, with state-of-the-art neural network models. Results showed that the neural network-based model Bidirectional Encoder Representations from Transformers (BERT) outperformed the classical methods. Notably this was the case for a relatively small training corpus, consisting of less than 3000 instances. This reflects that fact that the BERT classifier uses a transfer learning approach that benefits from prior learning on a very much larger collection of generic text. BERT performed particularly well even for Tweets that employed specialised language relating to wildlife observations. The analysis of possible indicative features for wildlife Tweets revealed interesting trends in the usage of hashtags that are unrelated to official citizen science campaigns. The findings from this study facilitate more accurate identification of wildlife-related data on social media which can in turn be used for enriching citizen science data collections.
AD  - Cardiff Univ, Sch Comp Sci & Informat, Queens Bldg,5 Parade, Cardiff CF24 3AA, WalesC3  - Cardiff UniversityCR  - Amano T, 2016, BIOSCIENCE, V66, P393, DOI 10.1093/biosci/biw022
CR  - Antoniou V, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5050064
CR  - Aristeidou M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245682
CR  - Arora S., 2017, INT C LEARN REPR
CR  - August TA, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100116
CR  - Barve V, 2014, ECOL INFORM, V24, P194, DOI 10.1016/j.ecoinf.2014.08.008
CR  - Blight AJ, 2009, MAR ECOL PROG SER, V396, P235, DOI 10.3354/meps08379
CR  - Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P5, DOI DOI 10.1162/TACL_A_00051
CR  - Bouazizi Mondher, 2019, Big Data Mining and Analytics, V2, P181, DOI 10.26599/BDMA.2019.9020002
CR  - Brants T., 2007, P 2007 JOINT C EMP M, P858
CR  - Cer D., 2018, ARXIV PREPRINT ARXIV
CR  - Chen JD, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P6252
CR  - Cohn JP, 2008, BIOSCIENCE, V58, P192, DOI 10.1641/B580303
CR  - Coltekin c, 2018, P 12 INT WORKSH SEM, P34, DOI [10.18653/v1/S18-1004, DOI 10.18653/V1/S18-1004]
CR  - Conneau A., 2017, P 2017 C EMP METH NA, DOI DOI 10.18653/V1/D17-1070
CR  - Daume S, 2016, ECOL INFORM, V31, P70, DOI 10.1016/j.ecoinf.2015.11.014
CR  - Daume S, 2014, FOREST ECOL MANAG, V316, P9, DOI 10.1016/j.foreco.2013.09.004
CR  - Davis A, 2017, WILDLIFE BIOL, DOI 10.2981/wlb.00307
CR  - DENG X, 2019, MULTIMED TOOLS APPL, V78
CR  - Devlin J, 2019, ARXIV181004805 CS, V1
CR  - Di Minin E, 2018, NAT ECOL EVOL, V2, P406, DOI 10.1038/s41559-018-0466-x
CR  - Di Minin E, 2015, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00063
CR  - Edwards T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255416
CR  - ElQadi MM, 2017, ECOL INFORM, V39, P23, DOI 10.1016/j.ecoinf.2017.02.006
CR  - Ethayarajh K, 2018, REPRESENTATION LEARNING FOR NLP, P91
CR  - Fan RE, 2008, J MACH LEARN RES, V9, P1871
CR  - Fritz S, 2012, ENVIRON MODELL SOFTW, V31, P110, DOI 10.1016/j.envsoft.2011.11.015
CR  - Gamb?ck B., 2017, P 1 WORKSH AB LANG O, P85, DOI [DOI 10.18653/V1/W17-3013, 10.18653/v1/W17-3013]
CR  - Ghermandi A, 2019, GLOBAL ENVIRON CHANG, V55, P36, DOI 10.1016/j.gloenvcha.2019.02.003
CR  - Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
CR  - Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
CR  - Huang X, 2020, IEEE T SUSTAIN ENERG, V11, P477, DOI 10.1109/TSTE.2019.2895601
CR  - Jauhiainen T, 2019, J ARTIF INTELL RES, V65, P675
CR  - Jeawak Shelan S., 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P51, DOI 10.1007/978-3-030-15712-8_4
CR  - Jeawak SS, 2020, COMPUT ENVIRON URBAN, V82, DOI 10.1016/j.compenvurbsys.2020.101487
CR  - Joachims Thorsten, 1998, EUR C MACH LEARN, P137, DOI [10.1007/BFb0026683, 10.1007/bfb0026683, DOI 10.1007/BFB0026683]
CR  - Jones, 2017, 13 INT C SPAT INF TH, DOI DOI 10.4230/LIPICS.COSIT.2017.21
CR  - Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI 10.18653/v1/e17
CR  - Kent JD, 2013, CARTOGR GEOGR INF SC, V40, P78, DOI 10.1080/15230406.2013.776727
CR  - Leivesley JA, 2021, EUR J WILDLIFE RES, V67, DOI 10.1007/s10344-021-01467-5
CR  - LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
CR  - Li H., 2018, P ISCRAM AS PAC C WE
CR  - Ljubesic, 2021, P 8 WORKSH NLP SIM L, P135
CR  - Lowry CS, 2013, GROUND WATER, V51, P151, DOI 10.1111/j.1745-6584.2012.00956.x
CR  - Martinc M, 2019, NAT LANG ENG, V25, P607, DOI 10.1017/S1351324919000299
CR  - McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41
CR  - McCann B, 2017, ADV NEUR IN, V30
CR  - Merity S., 2018, P INT C LEARN REPR, P1
CR  - Merkx D, 2020, ARXIV200509471
CR  - Mikolov T., 2013, ARXIV13013781, DOI DOI 10.5555/2999792.2999959
CR  - Mohammad S., 2018, P 12 INT WORKSH SEM, P1, DOI 10.18653/v1/S18-1001
CR  - Monkman GG, 2018, BIOL CONSERV, V228, P89, DOI 10.1016/j.biocon.2018.10.010
CR  - Newsam S, 2012, P ACM MULT 2012 WORK, P3, DOI [10.1145/2390790.2390794, DOI 10.1145/2390790.2390794]
CR  - Painho M., 2014, P AGILE, P4
CR  - Palomino M, 2016, INT J ENV RES PUB HE, V13, DOI 10.3390/ijerph13010142
CR  - Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
CR  - Pennington J., 2014, P 2014 C EMPIRICAL M, P1532, DOI [DOI 10.3115/V1/D14-1162, https://doi.org/10.3115/v1/D14-1162]
CR  - Peters M., 2018, LONG PAPERS, P2227
CR  - Poria S., 2016, P COLING, P1601
CR  - Reynard D, 2019, TRANSPORT RES D-TR E, V77, P449, DOI 10.1016/j.trd.2019.03.002
CR  - Schockaert S., 2018, 10 INT C GEOGR INF S
CR  - Soliman A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181657
CR  - Vaswani A, 2017, ADV NEUR IN, V30
CR  - Wolf T., 2019, ARXIV PREPRINT ARXIV
CR  - Xiao Y., 2016, ARXIV160200367
CR  - Xu Q, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00028
CR  - Yang Z., 2018, INT C LEARN REPR, DOI DOI 10.1109/ICMMT.2018.8563476
CR  - Zhong X, 2019, FINANC INNOV, V5, DOI 10.1186/s40854-019-0138-0
CR  - Zweig, P 2013 C N AM CHAPT, P746
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - MAR
PY  - 2022
VL  - 67
DO  - 10.1016/j.ecoinf.2021.101500
AN  - WOS:000729081800006
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  69
ER  -

TY  - JOUR
AU  - Seymour, AC
AU  - Dale, J
AU  - Hammill, M
AU  - Halpin, PN
AU  - Johnston, DW
TI  - Automated detection and enumeration of marine wildlife using unmanned aircraft systems (UAS) and thermal imagery
T2  - SCIENTIFIC REPORTS
LA  - English
KW  - AERIAL VEHICLES
AB  - Estimating animal populations is critical for wildlife management. Aerial surveys are used for generating population estimates, but can be hampered by cost, logistical complexity, and human risk. Additionally, human counts of organisms in aerial imagery can be tedious and subjective. Automated approaches show promise, but can be constrained by long setup times and difficulty discriminating animals in aggregations. We combine unmanned aircraft systems (UAS), thermal imagery and computer vision to improve traditional wildlife survey methods. During spring 2015, we flew fixed-wing UAS equipped with thermal sensors, imaging two grey seal (Halichoerus grypus) breeding colonies in eastern Canada. Human analysts counted and classified individual seals in imagery manually. Concurrently, an automated classification and detection algorithm discriminated seals based upon temperature, size, and shape of thermal signatures. Automated counts were within 95-98% of human estimates; at Saddle Island, the model estimated 894 seals compared to analyst counts of 913, and at Hay Island estimated 2188 seals compared to analysts' 2311. The algorithm improves upon shortcomings of computer vision by effectively recognizing seals in aggregations while keeping model setup time minimal. Our study illustrates how UAS, thermal imagery, and automated detection can be combined to efficiently collect population data critical to wildlife management.
AD  - Duke Univ, Marine Lab, Nicholas Sch Environm, Div Marine Sci & Conservat, 135 Duke Marine Lab Rd, Beaufort, NC 28516 USAAD  - Fisheries & Oceans Canada, Maurice Lamontagne Inst, Peches & Oceans Canada, CP 1000 POB 1000 850 Route Mer, Mont Joli, PQ G5H 3Z4, CanadaC3  - Duke UniversityC3  - Fisheries & Oceans CanadaFU  - Duke University Marine Lab, Fisheries and Oceans Canada; International Fund for Animal Welfare
FX  - This work was funded by the Duke University Marine Lab, Fisheries and Oceans Canada, and the International Fund for Animal Welfare. Thanks to Susan Heaslip, Kevin Bierlich, Elizabeth Mason, Lauren Arona, Rebecca Cope, and Logan Palin for help with field work and data analysis.
CR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - Buckland ST, 2005, ENCY BIOSTATISTICS
CR  - Burn DM, 2006, WILDLIFE SOC B, V34, P51, DOI 10.2193/0091-7648(2006)34[51:AOATIT]2.0.CO;2
CR  - Chabot D., 2016, J FIELD ORNITHOL, V1, P1
CR  - Chabot D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122588
CR  - Chretien LP, 2016, WILDLIFE SOC B, V40, P181, DOI 10.1002/wsb.629
CR  - Cohen JE, 2003, P NATL ACAD SCI USA, V100, P1781, DOI 10.1073/pnas.232715699
CR  - Conn PB, 2014, METHODS ECOL EVOL, V5, P1280, DOI 10.1111/2041-210X.12127
CR  - Durban JW, 2015, J UNMANNED VEH SYST, V3, P131, DOI 10.1139/juvs-2015-0020
CR  - Elarab M, 2015, INT J APPL EARTH OBS, V43, P32, DOI 10.1016/j.jag.2015.03.017
CR  - Fretwell PT, 2009, GLOBAL ECOL BIOGEOGR, V18, P543, DOI 10.1111/j.1466-8238.2009.00467.x
CR  - Gonzalez L., 2016, SENSORS, V14, P13778
CR  - Hodgson A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079556
CR  - Inoue J, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2004GL020336
CR  - Bonner S, 2013, BIOMETRICS, V69, P766, DOI 10.1111/biom.12045
CR  - Johnston, 2015, PLOS ONE, V10
CR  - Koh LP, 2012, TROP CONSERV SCI, V5, P121, DOI 10.1177/194008291200500202
CR  - KREBS C. J., 1994, ECOLOGY EXPT ANAL DI
CR  - Lancia Richard A., 2005, P106
CR  - Lavigne D.M., 1975, International Council for the Exploration of the Sea C.M., VN:12, P1
CR  - LAVIGUEUR L, 1993, CAN FIELD NAT, V107, P329
CR  - Lelli B, 2009, NORTHEAST NAT, V16, P239, DOI 10.1656/045.016.0206
CR  - Linchant J, 2015, MAMMAL REV, V45, P239, DOI 10.1111/mam.12046
CR  - Mancini F., 2013, REMOTE SENSING, V5, P5006
CR  - McMahon CR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092613
CR  - Merrill J., 2013, AGU FALL M, V1, P1741
CR  - Pater LL, 2009, J WILDLIFE MANAGE, V73, P788, DOI 10.2193/2006-235
CR  - Roman J, 2015, TRENDS ECOL EVOL, V30, P299, DOI 10.1016/j.tree.2015.04.003
CR  - Sasse DB, 2003, WILDLIFE SOC B, V31, P1015
CR  - Stark B, 2014, INT CONF UNMAN AIRCR, P1294, DOI 10.1109/ICUAS.2014.6842387
CR  - Wood SA, 2011, CAN J ZOOL, V89, P490, DOI 10.1139/Z11-012
CR  - Zhang CH, 2012, PRECIS AGRIC, V13, P693, DOI 10.1007/s11119-012-9274-5
PU  - NATURE PUBLISHING GROUP
PI  - LONDON
PA  - MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
DA  - MAR 24
PY  - 2017
VL  - 7
DO  - 10.1038/srep45127
AN  - WOS:000397311900001
N1  - Times Cited in Web of Science Core Collection:  89
Total Times Cited:  89
Cited Reference Count:  32
ER  -

TY  - JOUR
AU  - Wibowo, A
AU  - Hubert, N
AU  - Dahruddin, H
AU  - Steinke, D
AU  - Suhaimi, RA
AU  - Samuel
AU  - Atminarso, D
AU  - Anggraeni, DP
AU  - Trismawanti, I
AU  - Baumgartner, LJ
AU  - Ning, N
TI  - Assessing Temporal Patterns and Species Composition of Glass Eel (Anguilla spp.) Cohorts in Sumatra and Java Using DNA Barcodes
T2  - DIVERSITY-BASEL
LA  - English
KW  - species delimitation
KW  - DNA-based classification
KW  - genetic diversity
KW  - catadromy
KW  - conservation
KW  - FRESH-WATER FISHES
KW  - TROPICAL EELS
KW  - INSHORE MIGRATION
KW  - SIGNIFICANT-UNITS
KW  - POIGAR RIVER
KW  - CONSERVATION
KW  - RECRUITMENT
KW  - DIVERSITY
KW  - IDENTIFICATION
KW  - LEPTOCEPHALI
AB  - Anguillid eels are widely acknowledged for their ecological and socio-economic value in many countries. Yet, knowledge regarding their biodiversity, distribution and abundance remains superficial-particularly in tropical countries such as Indonesia, where demand for anguillid eels is steadily increasing along with the threat imposed by river infrastructure developments. We investigated the diversity of anguillid eels on the western Indonesian islands of Sumatra and Java using automated molecular classification and genetic species delimitation methods to explore temporal patterns of glass eel cohorts entering inland waters. A total of 278 glass eels were collected from monthly samplings along the west coast of Sumatra and the south coast of Java between March 2017 and February 2018. An automated, DNA-based glass eel identification was performed using a DNA barcode reference library consisting of 64 newly generated DNA barcodes and 117 DNA barcodes retrieved from BOLD for all nine Anguilla species known to occur in Indonesia. Species delimitation methods converged in delineating eight Molecular Operational Taxonomic Units (MOTUs), with A. nebolusa and A. bengalensis being undistinguishable by DNA barcodes. A total of four MOTUs were detected within the glass eel samples, corresponding to Anguilla bicolor, A. interioris, A. marmorata, and A. nebulosa/A. bengalensis. Monthly captures indicated that glass eel recruitment peaks in June, during the onset of the dry season, and that A. bicolor is the most prevalent species. Comparing indices of mitochondrial genetic diversity between yellow/silver eels, originating from several sites across the species range distribution, and glass eels, collected in West Sumatra and Java, indicated a marked difference. Glass eels displayed a much lower diversity than yellow/silver eels. Implications for the management of glass eel fisheries and species conservation are discussed.
AD  - Southeast Asian Fisheries Dev Ctr, Inland Fishery Resources Dev & Management Dept, Jalan HA Bastari 08, Jakabaring 30267, Palembang, IndonesiaAD  - Minist Marine Affairs & Fisheries, Agcy Marine & Fisheries Res & Human Resources, Res Inst Inland Fisheries & Extens, Jalan HA Bastari 08, Jakabaring 30267, Palembang, IndonesiaAD  - Univ Montpellier, CNRS, UMR 5554, EPHE,ISEM,IRD, Pl Eugene Bataillon, F-34095 Montpellier 05, FranceAD  - Indonesian Inst Sci LIPI, Res Ctr Biol, Div Zool, Jalan Raya Jakarta Bogor Km 46, Cibinong 16911, IndonesiaAD  - Ctr Biodivers Genom, Dept Integrat Biol, 50 Stone Rd E, Guelph, ON N1G 2W1, CanadaAD  - Charles Sturt Univ, Inst Land Water & Soc, POB 789, Albury, NSW 2640, AustraliaC3  - Ministry of Marine Affairs and FisheriesC3  - Centre National de la Recherche Scientifique (CNRS)C3  - Institut de Recherche pour le Developpement (IRD)C3  - Universite de MontpellierC3  - UDICE-French Research UniversitiesC3  - PSL Research University ParisC3  - Ecole Pratique des Hautes Etudes (EPHE)C3  - Indonesian Institute of SciencesC3  - Charles Sturt UniversityFU  - Research Institute for Inland Fisheries through DIPA 2017-2019; CFREF; Institut de Recherche pour le Developpement [226F2ABIOS]; French Embassy in Indonesia through the program "Science et Impact"; Campus France through a Bio-Asia grant (BIOSHOT project); ANR [ANR-17-ASIE-0006]
FX  - This research was funded by the Research Institute for Inland Fisheries through DIPA 2017-2019, by CFREF to the University of Guelph's Food from Thought program, by the "Institut de Recherche pour le Developpement" through annual funding and "Fonds d'Amorcage" (226F2ABIOS), by the French Embassy in Indonesia through the program "Science et Impact", by Campus France through a Bio-Asia grant (BIOSHOT project) and by ANR (ANR-17-ASIE-0006).
CR  - [Anonymous], 2015, UNEP WCMC PRELIMINAR
CR  - [Anonymous], 2014, EELS HUMANS
CR  - Aoyama J, 2007, ENVIRON BIOL FISH, V80, P445, DOI 10.1007/s10641-006-9143-z
CR  - Aoyama Jun, 2009, Aqua-Bioscience Monographs, V2, P1
CR  - Arai T, 1999, MAR ECOL PROG SER, V188, P299, DOI 10.3354/meps188299
CR  - Arai T, 2001, MAR ECOL PROG SER, V216, P253, DOI 10.3354/meps216253
CR  - Arai T, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05176
CR  - Arai T, 2017, SCI REP-UK, V7, DOI 10.1038/srep41649
CR  - Arai T, 2016, TROP ECOL, V57, P23
CR  - Avise J.C., 1989, MOL MARKERS NATURAL
CR  - Bermingham Eldredge, 1997, P113, DOI 10.1016/B978-012417540-2/50009-9
CR  - BKIPM, 2018, EELS TRADE INDONESIA
CR  - Bonhommeau S, 2008, FISH OCEANOGR, V17, P32, DOI 10.1111/j.1365-2419.2007.00453.x
CR  - Bouckaert R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003537
CR  - Breckwoldt A, 2016, MAR POLLUT BULL, V110, P790, DOI 10.1016/j.marpolbul.2016.08.040
CR  - Brown SDJ, 2012, MOL ECOL RESOUR, V12, P562, DOI 10.1111/j.1755-0998.2011.03108.x
CR  - Chang YLK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72916-5
CR  - Collet A, 2018, MITOCHONDRIAL DNA A, V29, P905, DOI 10.1080/24701394.2017.1383406
CR  - Dahruddin H, 2017, MOL ECOL RESOUR, V17, P288, DOI 10.1111/1755-0998.12528
CR  - Dekker W, 2016, ICES J MAR SCI, V73, P2442, DOI 10.1093/icesjms/fsw094
CR  - Delrieu-Trottin E, 2020, EVOL APPL, V13, P1451, DOI 10.1111/eva.12926
CR  - Elliott J.M., 1978, J ANIM ECOL, V47, P1033, DOI [10.2307/3708, DOI 10.2307/3708]
CR  - Enbody ED, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2022620118
CR  - Eschmeyer W.N., CATALOG FISHES ELECT
CR  - Fagan WF, 2006, ECOL LETT, V9, P51, DOI 10.1111/j.1461-0248.2005.00845.x
CR  - Fahmi MR, 2015, VIE MILIEU, V65, P139
CR  - Fahmi M.R., 2013, PHYLOGEOGRAPHY TROPI
CR  - FAO, 2018, PECH AQ
CR  - Farhana SN, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29049-7
CR  - Friedland KD, 2007, ICES J MAR SCI, V64, P519, DOI 10.1093/icesjms/fsm022
CR  - Fujisawa T, 2013, SYST BIOL, V62, P707, DOI 10.1093/sysbio/syt033
CR  - Garg T, 2018, J ENVIRON ECON MANAG, V92, P35, DOI 10.1016/j.jeem.2018.08.011
CR  - Gilpin M.E., 1986, P19
CR  - Hanzen C, 2020, MAR FRESHWATER RES, V71, P1543, DOI 10.1071/MF19390
CR  - Hayati Alfiah, 2017, Berkala Penelitian Hayati, V22, P43
CR  - Hebert PDN, 2003, P ROY SOC B-BIOL SCI, V270, pS96, DOI [10.1098/rspb.2002.2218, 10.1098/rsbl.2003.0025]
CR  - Ho SYW, 2006, TRENDS GENET, V22, P79, DOI 10.1016/j.tig.2005.11.006
CR  - Houde ED, 2016, FISH REPRODUCTIVE BIOLOGY: IMPLICATIONS FOR ASSESSMENT AND MANAGEMENT, 2ND EDITION, P98
CR  - Hubert N., 2015, DNA BARCODES, V3, P44, DOI [10.1515/dna-2015-0006, DOI 10.1515/DNA-2015-0006]
CR  - Hubert N., 2015, DNA BARCODES, V3, P144, DOI [10.1515/dna-2015-0018, DOI 10.1515/DNA-2015-0018]
CR  - Hubert N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002490
CR  - Hubert N, 2019, CONSERV GENET, V20, P517, DOI 10.1007/s10592-019-01152-w
CR  - Hubert N, 2015, MOL ECOL RESOUR, V15, P57, DOI 10.1111/1755-0998.12293
CR  - Hutama A, 2017, GLOB ECOL CONSERV, V12, P170, DOI 10.1016/j.gecco.2017.11.005
CR  - Ivanova NV, 2007, MOL ECOL NOTES, V7, P544, DOI 10.1111/j.1471-8286.2007.01748.x
CR  - Jacoby DMP, 2015, GLOB ECOL CONSERV, V4, P321, DOI 10.1016/j.gecco.2015.07.009
CR  - Jin Q, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064428
CR  - Kadarusman, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040627
CR  - Kapli P, 2017, BIOINFORMATICS, V33, P1630, DOI 10.1093/bioinformatics/btx025
CR  - Keith P., 2010, POISSONS CRUSTACES E
CR  - Kekkonen M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122481
CR  - KIMURA M, 1980, J MOL EVOL, V16, P111, DOI 10.1007/BF01731581
CR  - Kottelat M, 1993, FRESHWATER FISHES W
CR  - Kuroki M, 2014, CAN J ZOOL, V92, P749, DOI 10.1139/cjz-2013-0303
CR  - Lim H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163596
CR  - Limmon G, 2020, ECOL EVOL, V10, P3356, DOI 10.1002/ece3.6128
CR  - Lord C., 2013, POISSONS CRUSTAC S D
CR  - MORITZ C, 1994, TRENDS ECOL EVOL, V9, P373, DOI 10.1016/0169-5347(94)90057-4
CR  - Muchlisin Zainal A, 2017, F1000Res, V6, P258, DOI 10.12688/f1000research.10715.1
CR  - Ndobe S., 2015, J AGROECOL, V1, P12
CR  - NEI M, 1981, GENETICS, V97, P145
CR  - Nei M., 1987, MOL EVOLUTIONARY GEN, V1st
CR  - Nikolic N, 2020, MOL ECOL, V29, P565, DOI 10.1111/mec.15342
CR  - Ogilvie HA, 2017, MOL BIOL EVOL, V34, P2101, DOI 10.1093/molbev/msx126
CR  - Paradis E, 2019, BIOINFORMATICS, V35, P526, DOI 10.1093/bioinformatics/bty633
CR  - Paradis E, 2010, BIOINFORMATICS, V26, P419, DOI 10.1093/bioinformatics/btp696
CR  - Pauly, FISHBASE
CR  - PIANKA ER, 1970, AM NAT, V104, P592, DOI 10.1086/282697
CR  - Puillandre N, 2012, MOL ECOL, V21, P1864, DOI 10.1111/j.1365-294X.2011.05239.x
CR  - Ratnasingham S, 2007, MOL ECOL NOTES, V7, P355, DOI 10.1111/j.1471-8286.2007.01678.x
CR  - Ratnasingham S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066213
CR  - Righton D, 2013, J FISH BIOL, V83, P754, DOI 10.1111/jfb.12157
CR  - Ringuet S., 2002, TRAFFIC B INT, V19, P80
CR  - Rosenberg NA, 2002, NAT REV GENET, V3, P380, DOI 10.1038/nrg795
CR  - Shen YJ, 2019, MOL ECOL RESOUR, V19, P1278, DOI 10.1111/1755-0998.12961
CR  - Shiraishi H., 2015, EEL MARKET DYNAMICS
CR  - Shirotori F, 2016, FISHERIES SCI, V82, P915, DOI 10.1007/s12562-016-1030-8
CR  - Sholihah A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59544-9
CR  - Spracklen DV, 2015, ENVIRON RES LETT, V10, DOI 10.1088/1748-9326/10/9/091001
CR  - Stamatakis A, 2014, BIOINFORMATICS, V30, P1312, DOI 10.1093/bioinformatics/btu033
CR  - Stein FM, 2016, CONSERV GENET RESOUR, V8, P533, DOI 10.1007/s12686-016-0576-1
CR  - Steinke D, 2016, GENOME, V59, P959, DOI 10.1139/gen-2015-0212
CR  - Sugeha H.Y., 2008, MARINE RES INDONESIA, V33, P129, DOI [10.14203/mri.v33i2.486, DOI 10.14203/MRI.V33I2.486]
CR  - Sugeha HY, 2001, MAR ECOL PROG SER, V221, P233, DOI 10.3354/meps221233
CR  - TAJIMA F, 1989, GENETICS, V123, P585
CR  - Tanaka H, 2003, FISH PHYSIOL BIOCHEM, V28, P493, DOI 10.1023/B:FISH.0000030638.56031.ed
CR  - Tanaka H, 2001, AQUACULTURE, V201, P51, DOI 10.1016/S0044-8486(01)00553-1
CR  - Tesch FW, 2003, EEL BIOLOGY, P223
CR  - VOGLER AP, 1994, CONSERV BIOL, V8, P354, DOI 10.1046/j.1523-1739.1994.08020354.x
CR  - Watanabe S, 2003, EEL BIOLOGY, P3
CR  - WATTERSON GA, 1975, THEOR POPUL BIOL, V7, P256, DOI 10.1016/0040-5809(75)90020-9
CR  - Wibowo A, 2017, MAR FRESHWATER RES, V68, P1079, DOI 10.1071/MF16078
CR  - Wibowo A, 2015, PROCEDIA CHEM, V14, P76, DOI 10.1016/j.proche.2015.03.012
CR  - Wirth T, 2003, P ROY SOC B-BIOL SCI, V270, P681, DOI 10.1098/rspb.2002.2301
CR  - Zhang AB, 2012, MOL ECOL, V21, P1848, DOI 10.1111/j.1365-294X.2011.05235.x
CR  - Zhang AB, 2017, METHODS ECOL EVOL, V8, P627, DOI 10.1111/2041-210X.12682
CR  - Zhang JJ, 2013, BIOINFORMATICS, V29, P2869, DOI 10.1093/bioinformatics/btt499
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - MAY
PY  - 2021
VL  - 13
IS  - 5
DO  - 10.3390/d13050193
AN  - WOS:000653903000001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  97
ER  -

TY  - CPAPER
AU  - Nguyen, H
AU  - Maclagan, SJ
AU  - Nguyen, TD
AU  - Nguyen, T
AU  - Flemons, P
AU  - Andrews, K
AU  - Ritchie, EG
AU  - Phung, D
A1  - IEEE
TI  - Animal Recognition and Identification with Deep Convolutional Neural Networks for Automated Wildlife Monitoring
T2  - 2017 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA)
LA  - English
CP  - 4th IEEE / ACM / ASA International Conference on Data Science and Advanced Analytics (DSAA)
KW  - deep learning
KW  - convolutional neural networks
KW  - large scale image classification
KW  - animal recognition
KW  - wildlife monitoring
KW  - citizen science
KW  - CITIZEN SCIENCE
KW  - TOOL
AB  - Efficient and reliable monitoring of wild animals in their natural habitats is essential to inform conservation and management decisions. Automatic covert cameras or "camera traps" are being an increasingly popular tool for wildlife monitoring due to their effectiveness and reliability in collecting data of wildlife unobtrusively, continuously and in large volume. However, processing such a large volume of images and videos captured from camera traps manually is extremely expensive, time-consuming and also monotonous. This presents a major obstacle to scientists and ecologists to monitor wildlife in an open environment. Leveraging on recent advances in deep learning techniques in computer vision, we propose in this paper a framework to build automated animal recognition in the wild, aiming at an automated wildlife monitoring system. In particular, we use a single-labeled dataset from Wildlife Spotter project, done by citizen scientists, and the state-of-the-art deep convolutional neural network architectures, to train a computational system capable of filtering animal images and identifying species automatically. Our experimental results achieved an accuracy at 96.6% for the task of detecting images containing animal, and 90.4% for identifying the three most common species among the set of images of wild animals taken in South-central Victoria, Australia, demonstrating the feasibility of building fully automated wildlife observation. This, in turn, can therefore speed up research findings, construct more efficient citizen science based monitoring systems and subsequent management decisions, having the potential to make significant impacts to the world of ecology and trap camera images analysis.
AD  - Deakin Univ, Ctr Pattern Recognit & Data Analyt, Geelong, Vic, AustraliaAD  - Deakin Univ, Ctr Integrat Ecol, Burwood, AustraliaAD  - Australian Museum Res Inst, Sydney, NSW, AustraliaAD  - ABC Radio Natl, Ultimo, NSW, AustraliaC3  - Deakin UniversityC3  - Deakin UniversityC3  - Australian MuseumFU  - Telstra-Deakin Centre of Excellence in Big Data and Machine Learning
FX  - This work is partially supported by the Telstra-Deakin Centre of Excellence in Big Data and Machine Learning.
CR  - Abadi M, 2016, ABS160304467
CR  - Bishop C. M., 2006, MACH LEARN, V128, P1, DOI DOI 10.1002/9780471740360.EBS0904
CR  - Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
CR  - Bonney R, 2009, BIOSCIENCE, V59, P977, DOI 10.1525/bio.2009.59.11.9
CR  - Chen GB, 2014, IEEE IMAGE PROC, P858, DOI 10.1109/ICIP.2014.7025172
CR  - Chollet F., 2015, KERAS
CR  - Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
CR  - Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177
CR  - Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
CR  - Dickinson JL, 2010, ANNU REV ECOL EVOL S, V41, P149, DOI 10.1146/annurev-ecolsys-102209-144636
CR  - Fei-Fei L, 2005, PROC CVPR IEEE, P524
CR  - Gehring J., 2016, ARXIV PREPRINT ARXIV
CR  - Gehring J., 2017, ARXIV E PRINTS
CR  - Godley B. J., 2008, Endangered Species Research, V4, P3, DOI 10.3354/esr00060
CR  - Gomez Alexander, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P747, DOI 10.1007/978-3-319-50835-1_67
CR  - Gomez A., 2016, ARXIV160306169
CR  - He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
CR  - He Z., 2010, ARXIV PREPRINT ARXIV
CR  - Hulbert IAR, 2001, J APPL ECOL, V38, P869, DOI 10.1046/j.1365-2664.2001.00624.x
CR  - Irwin A, 1995, CITIZEN SCI STUDY PE
CR  - Kingma DP, 2014, ARXIV PREPRINT ARXIV
CR  - Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI [10.1145/3065386, DOI 10.1145/3065386]
CR  - LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
CR  - O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
CR  - Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
CR  - Ren XB, 2013, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2013.254
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - Silvertown J, 2009, TRENDS ECOL EVOL, V24, P467, DOI 10.1016/j.tree.2009.03.017
CR  - Simonyan K., 2014, ARXIV PREPRINT ARXIV, DOI 10.48550/arXiv.1409.1556
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Szewczyk R., 2004, P 2 INT C EMB NETW S, P214, DOI DOI 10.1145/1031495.1031521
CR  - Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
CR  - Vitousek PM, 1997, SCIENCE, V277, P494, DOI 10.1126/science.277.5325.494
CR  - Wang J., 2010, CVPR, DOI DOI 10.1109/CVPR.2010.5540018
CR  - White G.C., 2012, ANAL WILDLIFE RADIO
CR  - Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
PU  - IEEE
PI  - NEW YORK
PA  - 345 E 47TH ST, NEW YORK, NY 10017 USA
PY  - 2017
SP  - 40
EP  - 49
DO  - 10.1109/DSAA.2017.31
AN  - WOS:000454622300005
N1  - Times Cited in Web of Science Core Collection:  49
Total Times Cited:  51
Cited Reference Count:  37
ER  -

TY  - JOUR
AU  - Yang, LH
AU  - Yan, J
AU  - Li, HR
AU  - Cao, XY
AU  - Ge, BJ
AU  - Qi, ZC
AU  - Yan, XL
TI  - Real-Time Classification of Invasive Plant Seeds Based on Improved YOLOv5 with Attention Mechanism
T2  - DIVERSITY-BASEL
LA  - English
KW  - weed seeds
KW  - seed identification
KW  - target detection
KW  - convolutional neural network
KW  - YOLOv5
AB  - Seeds of exotic plants transported with imported goods pose a risk of alien species invasion in cross-border transportation and logistics. It is critical to develop stringent inspection and quarantine protocols with active management to control the import and export accompanied by exotic seeds. As a result, a method for promptly identifying exotic plant seeds is urgently needed. In this study, we built a database containing 3000 images of seeds of 12 invasive plants and proposed an improved YOLOv5 target detection algorithm that incorporates a channel attention mechanism. Given that certain seeds in the same family and genus are very similar in appearance and are thus difficult to differentiate, we improved the size model of the initial anchor box to converge better; moreover, we introduce three attention modules, SENet, CBAM, and ECA-Net, to enhance the extraction of globally important features while suppressing the weakening of irrelevant features, thereby effectively solving the problem of automated inspection of similar species. Experiments on an invasive alien plant seed data set reveal that the improved network model fused with ECA-Net requires only a small increase in parameters when compared to the original YOLOv5 network model and achieved greater classification and detection accuracy without affecting detection speed.
AD  - Shanghai Chenshan Bot Garden, Eastern China Conservat Ctr Wild Endangered Plant, Shanghai 201602, Peoples R ChinaAD  - Zhejiang Sci Tech Univ, Zhejiang Prov Key Lab Plant Secondary Metab & Reg, Coll Life Sci & Med, Hangzhou 310018, Peoples R ChinaAD  - Zhejiang Sci Tech Univ, Shaoxing Acad Biomed, Shaoxing 312366, Peoples R ChinaC3  - Chinese Academy of SciencesC3  - Zhejiang Sci-Tech UniversityC3  - Zhejiang Sci-Tech UniversityFU  - Special Fund for Scientific Research of Shanghai Landscaping & City Appearance Administrative Bureau [G212405, G222403, ZWGX1902]; Special Fundamental Work of the Ministry of Science and Technology [2014FY120400]; Natural Science Foundation of Zhejiang Province [LY21C030008]; Open Fund of Shaoxing Academy of Biomedicine of Zhejiang Sci-Tech University [SXAB202020]
FX  - This research was funded by the Special Fund for Scientific Research of Shanghai Landscaping & City Appearance Administrative Bureau, grant numbers G212405, G222403; National Wild Plant Germplasm Resource Center, grant number ZWGX1902; Special Fundamental Work of the Ministry of Science and Technology, grant number 2014FY120400; the Natural Science Foundation of Zhejiang Province, grant number LY21C030008; and the Open Fund of Shaoxing Academy of Biomedicine of Zhejiang Sci-Tech University, grant number SXAB202020.
CR  - Bochkovskiy A., 2020, ARXIV
CR  - Chtioui Y, 1996, J SCI FOOD AGR, V71, P433, DOI [10.1002/(SICI)1097-0010(199608)71:4<433::AID-JSFA596>3.3.CO;2-2, 10.1002/(SICI)1097-0010(199608)71:4&lt;433::AID-JSFA596&gt;3.0.CO;2-B]
CR  - Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
CR  - Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
CR  - Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
CR  - Glorot X., 2011, AISTATS, P315, DOI DOI 10.1.1.208.6449
CR  - Hamerly G, 2004, ADV NEUR IN, V16, P281
CR  - He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
CR  - He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23
CR  - Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
CR  - Javanmardi S, 2021, J STORED PROD RES, V92, DOI 10.1016/j.jspr.2021.101800
CR  - Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
CR  - Kundu Nidhi, 2021, DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence, P153, DOI 10.1145/3484824.3484913
CR  - Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
CR  - Loddo A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106269
CR  - Luo T., 2021, INF PROCESS AGR, P2214, DOI [10.1016/j.inpa.2021.10.002, DOI 10.1016/J.INPA.2021.10.002]
CR  - Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
CR  - Redmon J., 2018, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2017.690
CR  - Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
CR  - Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
CR  - Ren SQ, 2015, ADV NEUR IN, V28
CR  - Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
CR  - Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
CR  - Winther O., 2015, ARXIV150905329
CR  - Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
CR  - Xu HG, 2006, BIODIVERS CONSERV, V15, P2893, DOI 10.1007/s10531-005-2575-5
CR  - Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
CR  - Zhao JQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163095
CR  - Zhu LL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183776
CR  - Zuo Y, 2017, J BIOSAF, V26, P307
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - APR
PY  - 2022
VL  - 14
IS  - 4
DO  - 10.3390/d14040254
AN  - WOS:000787413800001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  30
ER  -

TY  - JOUR
AU  - Helminen, J
AU  - Linnansaari, T
AU  - Bruce, M
AU  - Dolson-Edge, R
AU  - Curry, RA
TI  - Accuracy and Precision of Low-Cost Echosounder and Automated Data Processing Software for Habitat Mapping in a Large River
T2  - DIVERSITY-BASEL
LA  - English
KW  - sonar
KW  - habitat
KW  - bathymetry
KW  - macrophyte biovolume
KW  - EcoSound
KW  - SEABED CLASSIFICATION
KW  - HYDROACOUSTIC METHODS
KW  - SPATIAL-DISTRIBUTION
KW  - ABUNDANCE
KW  - SIZE
KW  - MANAGEMENT
KW  - DYNAMICS
KW  - PATTERNS
KW  - SALMONID
KW  - BIOMASS
AB  - The development of consumer hydroacoustic systems continues to advance, enabling the use of low-cost methods for professional mapping purposes. Information describing habitat characteristics produced with a combination of low-cost commercial echosounder (Lowrance HDS) and a cloud-based automated data processing tool (BioBase EcoSound) was tested. The combination frequently underestimated water depth, with a mean absolute error of 0.17 +/- 0.13 m (avg +/- 1SD). The average EcoSound bottom hardness value was high (0.37-0.5) for all the substrate types found in the study area and could not be used to differentiate between the substrate size classes that varied from silt to bedrock. Overall, the bottom hardness value is not informative in an alluvial river bed setting where the majority of the substrate is composed of hard sands, gravels, and stones. EcoSound separated vegetation presence /absence with 85-100% accuracy and assigned vegetation height (EcoSound biovolume) correctly in 55% of instances but often overestimated it in other instances. It was most accurate when the vegetation canopy was <= 25% or >75% of the water column. Overall, as a low-cost, easy-to-use application EcoSound offers rapid data collection and allows users with no specialized skill requirements to make more detailed bathymetry and vegetation maps than those typically available for many rivers, lakes, and estuaries.
AD  - Univ New Brunswick, Canadian Rivers Inst, Dept Biol, POB 4400, Fredericton, NB E3B 5A3, CanadaAD  - Univ New Brunswick, Fac Forestry & Environm Management, POB 4400, Fredericton, NB E3B 5A3, CanadaC3  - University of New BrunswickC3  - University of New BrunswickFU  - NB Power; NSERC's Collaborative Research and Development programme [CRDPJ: 462708-13]; NSERC CREATE WATER scholarship; University of Helsinki
FX  - This research project is a part of Mactaquac Aquatic Ecosystem Study (MAES) funded by NB Power and NSERC's Collaborative Research and Development programme (CRDPJ: 462708-13). J.H was further funded by NSERC CREATE WATER scholarship and University of Helsinki travel grant.
CR  - Anderson JT, 2008, ICES J MAR SCI, V65, P1004, DOI 10.1093/icesjms/fsn061
CR  - Anderson MA, 2015, J SOIL SEDIMENT, V15, P1246, DOI 10.1007/s11368-015-1099-1
CR  - Anderson MA, 2011, WATER RES, V45, P4399, DOI 10.1016/j.watres.2011.05.029
CR  - BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
CR  - Boswell KM, 2007, ESTUAR COAST, V30, P607, DOI 10.1007/BF02841958
CR  - Bowen ZH, 2003, T AM FISH SOC, V132, P809, DOI 10.1577/T02-079
CR  - Bowen ZH, 2002, J AM WATER RESOUR AS, V38, P33, DOI 10.1111/j.1752-1688.2002.tb01532.x
CR  - Brown CJ, 2011, ESTUAR COAST SHELF S, V92, P502, DOI 10.1016/j.ecss.2011.02.007
CR  - Bruce Meghann, 2018, Canadian Field-Naturalist, V132, P231, DOI 10.22621/cfn.v132i3.1943
CR  - Chabot D, 2015, J UNMANNED VEH SYST, V3, P137, DOI 10.1139/juvs-2015-0021
CR  - Clark R. J., 2016, NITROGEN INVENTORIES
CR  - Curry R. A., 2005, HIST CHANGES LARGE R
CR  - DENNISON WC, 1993, BIOSCIENCE, V43, P86, DOI 10.2307/1311969
CR  - Dommisse M, 2005, MAR TECHNOL SOC J, V39, P90, DOI 10.4031/002533205787443926
CR  - Dunbar MJ, 2012, FISHERIES MANAG ECOL, V19, P500, DOI 10.1111/j.1365-2400.2011.00825.x
CR  - Formann E, 2007, GEOMORPHOLOGY, V90, P340, DOI 10.1016/j.geomorph.2006.10.029
CR  - Gautreau M., 2015, MACTAQUAC AQUATIC EC, V2015-014, P14
CR  - HEGGENES J, 1990, Regulated Rivers Research and Management, V5, P341, DOI 10.1002/rrr.3450050406
CR  - Holbrook B. V., 2008, J GT LAKES RES, V32, P680
CR  - Howell AW, 2019, AQUAT BOT, V155, P45, DOI 10.1016/j.aquabot.2019.02.001
CR  - Huising EJ, 1998, ISPRS J PHOTOGRAMM, V53, P245, DOI 10.1016/S0924-2716(98)00013-6
CR  - International Hydrographic Organization, 2005, INT HYDR ORG PUBL, V13
CR  - Jowett IG, 1996, NEW ZEAL J MAR FRESH, V30, P463, DOI 10.1080/00288330.1996.9516735
CR  - Kidd S., 2011, SAINTJOHN RIVER STAT
CR  - KONDOLF GM, 1993, WATER RESOUR RES, V29, P2275, DOI 10.1029/93WR00402
CR  - Lefsky M. A., 2006, BIO SCI, V52, P19
CR  - Legalle M, 2005, BIODIVERS CONSERV, V14, P1319, DOI 10.1007/s10531-004-9673-7
CR  - Leskovec J., 2018, 57 SUNY COLL ON, P57
CR  - Linnansaari T, 2008, J FISH BIOL, V72, P2518, DOI 10.1111/j.1095-8649.2008.01857.x
CR  - MACEINA MJ, 1984, J AQUAT PLANT MANAGE, V22, P35
CR  - Madsen JD, 2001, HYDROBIOLOGIA, V444, P71, DOI 10.1023/A:1017520800568
CR  - Marcus WA, 2010, EARTH SURF PROC LAND, V35, P1867, DOI 10.1002/esp.2094
CR  - Mielke S., 2016, AQUATIC VEGETATION D
CR  - Navico Inc, 2014, BIOBASE AUT MAPP US
CR  - Ndong M., NUMERICAL MODE UNPUB
CR  - Neckles HA, 2012, ESTUAR COAST, V35, P23, DOI 10.1007/s12237-011-9410-x
CR  - Palmer M, 1997, AMBIO, V26, P571
CR  - Penrose J. D., 2005, 32 COOP RES CTR COAS
CR  - Pickrill RA, 2003, OCEAN COAST MANAGE, V46, P601, DOI 10.1016/S0964-5691(03)00037-1
CR  - Powers J., 2015, HYDROBIOLOGIA
CR  - Progressive AE Inc, 2017, THOMPS LAK MAN FEAS
CR  - Radomski P, 2015, J AQUAT PLANT MANAGE, V53, P151
CR  - Riebe CS, 2014, WATER RESOUR RES, V50, P898, DOI 10.1002/2013WR014231
CR  - Sabol BM, 2002, ESTUARIES, V25, P133, DOI 10.1007/BF02696057
CR  - Sanchez-Carnero N, 2012, ESTUAR COAST SHELF S, V114, P175, DOI 10.1016/j.ecss.2012.08.018
CR  - Schooley JD, 2018, J APPL ICHTHYOL, V34, P364, DOI 10.1111/jai.13565
CR  - Simmonds J., 2005, FISHERIES ACOUSTICS, V5
CR  - Valley R. D., 2005, AQUAT BOT
CR  - Valley RD, 2016, J AQUAT PLANT MANAGE, V54, P95
CR  - Valley RD, 2015, J AQUAT PLANT MANAGE, V53, P121
CR  - van Walree PA, 2005, CONT SHELF RES, V25, P2273, DOI 10.1016/j.csr.2005.09.002
CR  - Westaway RM, 2003, INT J REMOTE SENS, V24, P795, DOI 10.1080/01431160110113070
CR  - Winfield IJ, 2015, ECOL INFORM, V30, P235, DOI 10.1016/j.ecoinf.2015.05.009
CR  - Zolezzi G, 2012, REV GEOPHYS, V50, DOI 10.1029/2012RG000392
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - JUL
PY  - 2019
VL  - 11
IS  - 7
DO  - 10.3390/d11070116
AN  - WOS:000481532700013
N1  - Times Cited in Web of Science Core Collection:  7
Total Times Cited:  7
Cited Reference Count:  54
ER  -

TY  - JOUR
AU  - Raphael, A
AU  - Dubinsky, Z
AU  - Iluz, D
AU  - Netanyahu, NS
TI  - Neural Network Recognition of Marine Benthos and Corals
T2  - DIVERSITY-BASEL
LA  - English
KW  - coral reef
KW  - marine ecosystem
KW  - deep learning
KW  - coral species
KW  - classification
KW  - REEFS
KW  - GRADIENT
KW  - CONSERVATION
KW  - PRODUCTIVITY
KW  - RESILIENCE
KW  - COMMUNITY
KW  - RECOVERY
KW  - JAKARTA
AB  - We present thorough this review the developments in the field, point out their current limitations, and outline its timelines and unique potential. In order to do so we introduce the methods used in each of the advances in the application of deep learning (DL) to coral research that took place between the years: 2016-2018. DL has unique capability of streamlining the description, analysis, and monitoring of coral reefs, saving time, and obtaining higher reliability and accuracy compared with error-prone human performance. Coral reefs are the most diverse and complex of marine ecosystems, undergoing a severe decline worldwide resulting from the adverse synergistic influences of global climate change, ocean acidification, and seawater warming, exacerbated by anthropogenic eutrophication and pollution. DL is an extension of some of the concepts originating from machine learning that join several multilayered neural networks. Machine learning refers to algorithms that automatically detect patterns in data. In the case of corals these data are underwater photographic images. Based on "learned" patterns, such programs can recognize new images. The novelty of DL is in the use of state-of-art computerized image analyses technologies, and its fully automated methodology of dealing with large data sets of images. Automated Image recognition refers to technologies that identify and detect objects or attributes in a digital video or image automatically. Image recognition classifies data into selected categories out of many. We show that Neural Network methods are already reliable in distinguishing corals from other benthos and non-coral organisms. Automated recognition of live coral cover is a powerful indicator of reef response to slow and transient changes in the environment. Improving automated recognition of coral species, DL methods already recognize decline of coral diversity due to natural and anthropogenic stressors. Diversity indicators can document the effectiveness of reef bioremediation initiatives. We explored the current applications of deep learning for corals and benthic image classification by discussing the most recent studies conducted by researchers. We review the developments in the field, point out their current limitations, and outline their timelines and unique potential. We also discussed a few future research directions in the fields of deep learning. Future needs are the age detection of single species, in order to track trends in their population recruitment, decline, and recovery. Fine resolution, at the polyp level, is still to be developed, in order to allow separation of species with similar macroscopic features. That refinement of DL will allow such comparisons and their analyses. We conclude that the usefulness of future, more refined automatic identification will allow reef comparison, and tracking long term changes in species diversity. The hitherto unused addition of intraspecific coral color parameters, will add the inclusion of physiological coral responses to environmental conditions and change thereof. The core aim of this review was to underscore the strength and reliability of the DL approach for documenting coral reef features based on an evaluation of the currently available published uses of this method. We expect that this review will encourage researchers from computer vision and marine societies to collaborate on similar long-term joint ventures.
AD  - Bar Ilan Univ, Mina & Everard Goodman Fac Life Sci, IL-5290002 Ramat Gan, IsraelAD  - Bar Ilan Univ, Dept Comp Sci, IL-5290002 Ramat Gan, IsraelAD  - Bar Ilan Univ, Gonda Brain Res Ctr, IL-5290002 Ramat Gan, IsraelC3  - Bar Ilan UniversityC3  - Bar Ilan UniversityC3  - Bar Ilan UniversityCR  - Anthony KRN, 2008, P NATL ACAD SCI USA, V105, P17442, DOI 10.1073/pnas.0804478105
CR  - Beijbom O., 2012, P 2012 IEEE C COMP V
CR  - Beijbom O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130312
CR  - Brandt K, 1883, ARCH ANAT PHYSL, V1, P445
CR  - BURNS TP, 1985, CORAL REEFS, V4, P117, DOI 10.1007/BF00300870
CR  - Cho K, 2015, ELEC DES ADV PACKAG, P15, DOI 10.1109/EDAPS.2015.7383697
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
CR  - Cleary DFR, 2016, MAR POLLUT BULL, V110, P701, DOI 10.1016/j.marpolbul.2016.04.042
CR  - Cleary DFR, 2014, MAR ECOL PROG SER, V501, P89, DOI 10.3354/meps10678
CR  - Cleary DFR, 2008, AQUAT SCI, V70, P419, DOI 10.1007/s00027-008-8077-2
CR  - Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
CR  - Cohen AL, 2009, GEOCHEM GEOPHY GEOSY, V10, DOI 10.1029/2009GC002411
CR  - Downs CA, 2016, ARCH ENVIRON CON TOX, V70, P265, DOI 10.1007/s00244-015-0227-7
CR  - Draper B. A., 2011, ARXIV11013354
CR  - Dubinsky Z., 2016, CNIDARIA PRESENT FUT, P469
CR  - Elawady M., 2015, ARXIV151109067V1
CR  - Fabricius KE, 2005, MAR POLLUT BULL, V50, P125, DOI 10.1016/j.marpolbul.2004.11.028
CR  - Field M.E., 2002, US CORAL REEFS IMPER
CR  - Fox HE, 2003, MAR POLLUT BULL, V46, P1024, DOI 10.1016/S0025-326X(03)00246-7
CR  - Goffredo S, 2009, LIMNOL OCEANOGR, V54, P930, DOI 10.4319/lo.2009.54.3.0930
CR  - Gomez-Rios A, 2019, EXPERT SYST APPL, V118, P315, DOI 10.1016/j.eswa.2018.10.010
CR  - Gorbunov MY, 2002, LIMNOL OCEANOGR, V47, P309, DOI 10.4319/lo.2002.47.1.0309
CR  - GOREAU TF, 1959, BIOL BULL, V116, P59, DOI 10.2307/1539156
CR  - He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
CR  - He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
CR  - Heery EC, 2018, MAR POLLUT BULL, V135, P654, DOI 10.1016/j.marpolbul.2018.07.041
CR  - Hoey AS, 2009, ECOSYSTEMS, V12, P1316, DOI 10.1007/s10021-009-9291-z
CR  - Huang Shichen, 2017, ARXIV171109224
CR  - Iluz D, 2017, ACS EARTH SPACE CHEM, V1, P316, DOI 10.1021/acsearthspacechem.7b00051
CR  - Johnson-Roberson M, 2006, OCEANS 2006 - ASIA PACIFIC, VOLS 1 AND 2, P116
CR  - JONES CG, 1994, OIKOS, V69, P373, DOI 10.2307/3545850
CR  - Kaandorp JA, 2003, PHILOS T R SOC B, V358, P1551, DOI 10.1098/rstb.2003.1339
CR  - Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
CR  - LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
CR  - Littler MM, 2006, HARMFUL ALGAE, V5, P565, DOI 10.1016/j.hal.2005.11.003
CR  - Longcore T, 2004, FRONT ECOL ENVIRON, V2, P191, DOI 10.2307/3868314
CR  - Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
CR  - LOYA Y, 1972, MAR BIOL, V13, P100, DOI 10.1007/BF00366561
CR  - Mahmood A, 2017, IEEE IMAGE PROC, P1597, DOI 10.1109/ICIP.2017.8296551
CR  - Mahmood A, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI [10.1109/OCEANS.2016.7761105, 10.1109/OPTIP.2016.7528488]
CR  - ODUM HT, 1955, ECOL MONOGR, V25, P291, DOI 10.2307/1943285
CR  - Pizarro O., 2008, OCEANS 2008, P1, DOI DOI 10.1109/OCEANS.2008.5152075
CR  - Ravikiran C., 2015, INT J ADV ENG MANAG, V1, P3
CR  - Rehman SU, 2012, NEW TRENDS IN QUALITATIVE AND QUANTITATIVE METHODS IN LIBRARIES, P25
CR  - Reyes A.K., 2015, P CLEF 2015 C TOUL F
CR  - Roberts CM, 2002, SCIENCE, V295, P1280, DOI 10.1126/science.1067728
CR  - Samoilys MA, 2000, ENVIRON BIOL FISH, V57, P289, DOI 10.1023/A:1007679109359
CR  - SCHUHMACHER H, 1985, CORAL REEFS, V4, P1, DOI 10.1007/BF00302198
CR  - Shaish L, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000644
CR  - Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
CR  - Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
CR  - Sun Y, 2014, ADV NEUR IN, V27
CR  - Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
CR  - Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
CR  - Tamir R, 2017, SCI REP-UK, V7, DOI 10.1038/srep42329
CR  - Tanaka JW, 1999, PERCEPT PSYCHOPHYS, V61, P1140, DOI 10.3758/BF03207619
CR  - Wang T, 2012, INT C PATT RECOG, P3304
CR  - West JM, 2003, CONSERV BIOL, V17, P956, DOI 10.1046/j.1523-1739.2003.02055.x
CR  - Wielgus J, 2010, CONSERV LETT, V3, P38, DOI 10.1111/j.1755-263X.2009.00084.x
CR  - Williams ID, 2019, FRONT MAR SCI, V6, DOI 10.3389/fmars.2019.00222
CR  - Wood E, 2001, COLLECTION CORAL REE
CR  - Yang J, 2010, PATTERN RECOGN, V43, P1454, DOI 10.1016/j.patcog.2009.11.014
CR  - Zhang S, 2013, ICML, P1058
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - JAN
PY  - 2020
VL  - 12
IS  - 1
DO  - 10.3390/d12010029
AN  - WOS:000513019300031
N1  - Times Cited in Web of Science Core Collection:  11
Total Times Cited:  11
Cited Reference Count:  64
ER  -

TY  - JOUR
AU  - Rydell, J
AU  - Nyman, S
AU  - Eklof, J
AU  - Jones, G
AU  - Russo, D
TI  - Testing the performances of automated identification of bat echolocation calls: A request for prudence
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Biosonar
KW  - Methodology
KW  - Software
KW  - Species identification
KW  - Ultrasound
KW  - ARTIFICIAL NEURAL-NETWORKS
KW  - ACOUSTIC IDENTIFICATION
KW  - CAUTIONARY NOTE
AB  - Echolocating bats are surveyed and studied acoustically with bat detectors routinely and worldwide, yet identification of species from calls often remains ambiguous or impossible due to intraspecific call variation and/or interspecific overlap in call design. To overcome such difficulties and to reduce workload, automated classifiers of echolocation calls have become popular, but their performance has not been tested sufficiently in the field. We examined the absolute performance of two commercially available programs (SonoChiro and Kaleidoscope) and one freeware package (BatClassify). We recorded noise from rain and calls of seven common bat species with Pettersson real-time full spectrum detectors in Sweden. The programs could always (100%) distinguish rain from bat calls, usually (68-100%) identify bats to group (Nyctalus/Vespertilio/Eptesicus, Pipistrellus, Myotis, Plecotus, Barbastella) and usually (83-99%) recognize typical calls of some species whose echolocation pulses are structurally distinct (Pipistrellus pygmaeus, Barbastella barbastellus). Species with less characteristic echolocation calls were not identified reliably, including Vespertilio murinus (16-26%), Myotis spp. (4-93%) and Plecotus auritus (0-89%). All programs showed major although different shortcomings and the often poor performance raising serious concerns about the use of automated classifiers for identification to species level in research and surveys. We highlight the importance of validating output from automated classifiers, and restricting their use to specific situations where identification can be made with high confidence. For comparison we also present the result of a manual identification test on a random subset of the files used to test the programs. It showed a higher classification success but performances were still low for more problematic taxa. (C) 2017 Elsevier Ltd. All rights reserved.
AD  - Lund Univ, Biol Dept, SE-22362 Lund, SwedenAD  - Skarpskyttevagen 30D, SE-22642 Lund, SwedenAD  - Krokdalsvagen 88, SE-51734 Bollebygd, SwedenAD  - Univ Bristol, Sch Biol Sci, Life Sci Bldg,24 Tyndall Ave, Bristol BS8 1TQ, Avon, EnglandAD  - Univ Napoli Federico II, Dipartimento Agr, Wildlife Res Unit, Lab Ecol Applicata,Sez Biol & Protez Sistemi Agr, Via Univ 100, Naples, ItalyC3  - League of European Research Universities - LERUC3  - Lund UniversityC3  - University of BristolC3  - University of Naples Federico IIFU  - Swedish Energy Agency [2016-000101]
FX  - We acknowledge Johan Ahlen, Arjan Boonman and Espen Jensen (in random order) for help with the manual identifications and the reviewers for many useful suggestions. Funding was provided by the Swedish Energy Agency through the Vindval program (2016-000101) to JR.
CR  - Ahlen I., 1981, REPORT 6
CR  - Ahlen I., 2011, FAUNA FLORA, V106, P2
CR  - ANDERSON ME, 1991, ANIM BEHAV, V42, P489, DOI 10.1016/S0003-3472(05)80048-X
CR  - Barclay RMR, 1999, J MAMMAL, V80, P290, DOI 10.2307/1383229
CR  - Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
CR  - Furmankiewicz J, 2013, ACTA CHIROPTEROL, V15, P371, DOI 10.3161/150811013X678991
CR  - Gorlitz H., 2010, CURR BIOL
CR  - Jennings N, 2008, CAN J ZOOL, V86, P371, DOI 10.1139/Z08-009
CR  - Jones G, 2007, P R SOC B, V274, P905, DOI 10.1098/rspb.2006.0200
CR  - Lehmann GUC, 2014, J INSECT CONSERV, V18, P909, DOI 10.1007/s10841-014-9700-2
CR  - Lemen C, 2015, WEST N AM NATURALIST, V75, P218, DOI 10.3398/064.075.0210
CR  - Lewandowski E., 2015, CONSERV BIOL
CR  - OBRIST MK, 1995, BEHAV ECOL SOCIOBIOL, V36, P207, DOI 10.1007/s002650050142
CR  - Parsons S, 2000, J EXP BIOL, V203, P2641
CR  - Parsons Stuart, 2009, P91
CR  - Rowse EG, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150884
CR  - Russo D, 2002, J ZOOL, V258, P91, DOI 10.1017/S0952836902001231
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Towsey M, 2014, ECOL INFORM, V21, P1, DOI 10.1016/j.ecoinf.2014.02.002
CR  - Walters CL, 2012, J APPL ECOL, V49, P1064, DOI 10.1111/j.1365-2664.2012.02182.x
CR  - Zagmajster Maja, 2003, Natura Sloveniae, V5, P27
CR  - Zamora-Gutierrez V, 2016, METHODS ECOL EVOL, V7, P1082, DOI 10.1111/2041-210X.12556
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - JUL
PY  - 2017
VL  - 78
SP  - 416
EP  - 420
DO  - 10.1016/j.ecolind.2017.03.023
AN  - WOS:000406435900043
N1  - Times Cited in Web of Science Core Collection:  61
Total Times Cited:  61
Cited Reference Count:  22
ER  -

TY  - JOUR
AU  - Chambert, T
AU  - Waddle, JH
AU  - Miller, DAW
AU  - Walls, SC
AU  - Nichols, JD
TI  - A new framework for analysing automated acoustic species detection data: Occupancy estimation and optimization of recordings post-processing
T2  - METHODS IN ECOLOGY AND EVOLUTION
LA  - English
KW  - acoustic recorder units
KW  - detection optimization
KW  - false positives
KW  - Hyla cinerea
KW  - information-rich data
KW  - Lithobates grylio
KW  - sensitivity
KW  - signal processing
KW  - specificity
KW  - SITE OCCUPANCY
KW  - POINT COUNTS
KW  - CONSERVATION
KW  - ABUNDANCE
KW  - RICHNESS
KW  - LANDSCAPE
KW  - DYNAMICS
KW  - DESIGN
KW  - MODELS
KW  - SOUNDS
AB  - The development and use of automated species detection technologies, such as acoustic recorders, for monitoring wildlife are rapidly expanding. Automated classification algorithms provide cost- and time-effective means to process information-rich data, but often at the cost of additional detection errors. Appropriate methods are necessary to analyse such data while dealing with the different types of detection errors. We developed a hierarchical modelling framework for estimating species occupancy from automated species detection data. We explore design and optimization of data post-processing procedures to account for detection errors and generate accurate estimates. Our proposed method accounts for both imperfect detection and false-positive errors and utilizes information about both occurrence and abundance of detections to improve estimation. Using simulations, we show that our method provides much more accurate estimates than models ignoring the abundance of detections. The same findings are reached when we apply the methods to two real datasets on North American frogs surveyed with acoustic recorders. When false positives occur, estimator accuracy can be improved when a subset of detections produced by the classification algorithm is post-validated by a human observer. We use simulations to investigate the relationship between accuracy and effort spent on post-validation, and found that very accurate occupancy estimates can be obtained with as little as 1% of data being validated. Automated monitoring of wildlife provides opportunity and challenges. Our methods for analysing automated species detection data help to meet key challenges unique to these data and will prove useful for many wildlife monitoring programmes.
AD  - Penn State Univ, Dept Ecosyst Sci & Management, University Pk, PA 16802 USAAD  - US Geol Survey, Patuxent Wildlife Res Ctr, Laurel, MD 20192 USAAD  - US Geol Survey, Wetland & Aquat Res, Lafayette, LA USAAD  - US Geol Survey, Wetland & Aquat Res, Gainesville, FL USAC3  - Pennsylvania Commonwealth System of Higher Education (PCSHE)C3  - Pennsylvania State UniversityC3  - Pennsylvania State University - University ParkC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - United States Department of the InteriorC3  - United States Geological SurveyFU  - Amphibian Research and Monitoring Initiative (USGS ARMI); United States Geological Survey's Greater Everglades Priority Ecosystem Science programme (USGS GEPES)
FX  - United States Geological Survey's Greater Everglades Priority Ecosystem Science programme (USGS GEPES); Amphibian Research and Monitoring Initiative (USGS ARMI)
CR  - Acevedo MA, 2006, WILDLIFE SOC B, V34, P211, DOI 10.2193/0091-7648(2006)34[211:UADRSA]2.0.CO;2
CR  - Acevedo MA, 2009, ECOL INFORM, V4, P206, DOI 10.1016/j.ecoinf.2009.06.005
CR  - Bailey LL, 2014, METHODS ECOL EVOL, V5, P1269, DOI 10.1111/2041-210X.12100
CR  - Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Chambert T., 2017, DRYAD DIGITAL REPOSI
CR  - Chambert T, 2015, METHODS ECOL EVOL, V6, P638, DOI 10.1111/2041-210X.12362
CR  - Chambert T, 2015, ECOLOGY, V96, P332, DOI 10.1890/14-1507.1
CR  - Clark CW, 2004, P ROY SOC B-BIOL SCI, V271, P1051, DOI 10.1098/rspb.2004.2699
CR  - Corn PS, 2011, COPEIA, P365, DOI 10.1643/CH-10-190
CR  - Crouch WB, 2002, J HERPETOL, V36, P185, DOI 10.1670/0022-1511(2002)036[0185:ATUOCS]2.0.CO;2
CR  - Dorcas Michael E., 2010, P281
CR  - Guillera-Arroita G, 2015, GLOBAL ECOL BIOGEOGR, V24, P276, DOI 10.1111/geb.12268
CR  - Haselmayer J, 2000, CONDOR, V102, P887, DOI 10.1650/0010-5422(2000)102[0887:ACOPCA]2.0.CO;2
CR  - Kery M, 2008, COMMUNITY ECOL, V9, P207, DOI 10.1556/ComEc.9.2008.2.10
CR  - Kery M, 2009, ECOLOGY, V90, P1279, DOI 10.1890/07-1794.1
CR  - Knutson MG, 1999, CONSERV BIOL, V13, P1437, DOI 10.1046/j.1523-1739.1999.98445.x
CR  - Lammers MO, 2008, J ACOUST SOC AM, V123, P1720, DOI 10.1121/1.2836780
CR  - MacKenzie DI, 2003, ECOLOGY, V84, P2200, DOI 10.1890/02-3090
CR  - MacSwiney MC, 2008, J APPL ECOL, V45, P1364, DOI 10.1111/j.1365-2664.2008.01531.x
CR  - McClintock BT, 2010, ECOLOGY, V91, P2446, DOI 10.1890/09-1287.1
CR  - Miller DA, 2011, ECOLOGY, V92, P1422, DOI 10.1890/10-1396.1
CR  - Miller DAW, 2015, METHODS ECOL EVOL, V6, P557, DOI 10.1111/2041-210X.12342
CR  - Miller DAW, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065808
CR  - Miller DAW, 2012, J ANIM ECOL, V81, P1288, DOI 10.1111/j.1365-2656.2012.02001.x
CR  - Miller DAW, 2012, ECOL APPL, V22, P1665
CR  - Nichols JD, 2007, ECOLOGY, V88, P1395, DOI 10.1890/06-1474
CR  - O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
CR  - Plummer M, 2013, RJAGS BAYESIAN GRAPH
CR  - Plummer M., 2003, P 3 INT WORKSH DISTR, V3, P20, DOI DOI 10.1038/S41598-018-29599-W
CR  - Pollock KH, 2002, ENVIRONMETRICS, V13, P105, DOI 10.1002/env.514
CR  - Price SJ, 2012, FRESHWATER BIOL, V57, P193, DOI 10.1111/j.1365-2427.2011.02699.x
CR  - R Core Team, 2017, R LANG ENV STAT COMP
CR  - Rempel RS, 2005, J FIELD ORNITHOL, V76, P1, DOI 10.1648/0273-8570-76.1.1
CR  - Royle JA, 2006, ECOLOGY, V87, P835, DOI 10.1890/0012-9658(2006)87[835:GSOMAF]2.0.CO;2
CR  - Royle JA, 2004, CONSERV BIOL, V18, P1378, DOI 10.1111/j.1523-1739.2004.00147.x
CR  - Simons TR, 2007, AUK, V124, P986, DOI 10.1642/0004-8038(2007)124[986:EAOTAD]2.0.CO;2
CR  - Waddle J. H., 2017, COMPUTER AUTOMATED F
CR  - Waddle JH, 2009, HERPETOL CONSERV BIO, V4, P384
CR  - Walls SC, 2014, WETL ECOL MANAG, V22, P625, DOI 10.1007/s11273-014-9356-4
CR  - Williams B.K., 2002, ANAL MANAGEMENT ANIM
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - Zwart MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102770
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - MAR
PY  - 2018
VL  - 9
IS  - 3
SP  - 560
EP  - 570
DO  - 10.1111/2041-210X.12910
AN  - WOS:000426867600012
N1  - Times Cited in Web of Science Core Collection:  28
Total Times Cited:  29
Cited Reference Count:  44
ER  -

TY  - JOUR
AU  - Stringham, OC
AU  - Moncayo, S
AU  - Hill, KGW
AU  - Toomes, A
AU  - Mitchell, L
AU  - Ross, JV
AU  - Cassey, P
TI  - Text classification to streamline online wildlife trade analyses
T2  - PLOS ONE
LA  - English
AB  - Automated monitoring of websites that trade wildlife is increasingly necessary to inform conservation and biosecurity efforts. However, e-commerce and wildlife trading websites can contain a vast number of advertisements, an unknown proportion of which may be irrelevant to researchers and practitioners. Given that many wildlife-trade advertisements have an unstructured text format, automated identification of relevant listings has not traditionally been possible, nor attempted. Other scientific disciplines have solved similar problems using machine learning and natural language processing models, such as text classifiers. Here, we test the ability of a suite of text classifiers to extract relevant advertisements from wildlife trade occurring on the Internet. We collected data from an Australian classifieds website where people can post advertisements of their pet birds (n = 16.5k advertisements). We found that text classifiers can predict, with a high degree of accuracy, which listings are relevant (ROC AUC >= 0.98, F1 score >= 0.77). Furthermore, in an attempt to answer the question 'how much data is required to have an adequately performing model?', we conducted a sensitivity analysis by simulating decreases in sample sizes to measure the subsequent change in model performance. From our sensitivity analysis, we found that text classifiers required a minimum sample size of 33% (c. 5.5k listings) to accurately identify relevant listings (for our dataset), providing a reference point for future applications of this sort. Our results suggest that text classification is a viable tool that can be applied to the online trade of wildlife to reduce time dedicated to data cleaning. However, the success of text classifiers will vary depending on the advertisements and websites, and will therefore be context dependent. Further work to integrate other machine learning tools, such as image classification, may provide better predictive abilities in the context of streamlining data processing for wildlife trade related online data.
AD  - Univ Adelaide, Invas Sci & Wildlife Ecol Lab, Adelaide, SA, AustraliaAD  - Univ Adelaide, Sch Math Sci, Adelaide, SA, AustraliaC3  - University of AdelaideC3  - University of AdelaideFU  - Centre for Invasive Species Solutions [PO1-I-002]
FX  - This research was funded by the Centre for Invasive Species Solutions (https://invasives.com.au/) Grant Number: PO1-I-002. The funders did not play any role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.
CR  - Bird S, 2009, NATURAL LANGUAGE PRO
CR  - Di Minin E, 2019, CONSERV BIOL, V33, P210, DOI 10.1111/cobi.13104
CR  - Dobson ADM, 2020, ONE EARTH, V2, P455, DOI 10.1016/j.oneear.2020.04.012
CR  - GBIF, 2020, WHAT IS GBIF
CR  - Guzella TS, 2009, EXPERT SYST APPL, V36, P10206, DOI 10.1016/j.eswa.2009.02.037
CR  - Hernandez-Castro J, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.10
CR  - Hinsley A, 2016, CONSERV BIOL, V30, P1038, DOI 10.1111/cobi.12721
CR  - Jaric I, 2020, TRENDS ECOL EVOL, V35, P630, DOI 10.1016/j.tree.2020.03.003
CR  - Lamba A, 2019, CURR BIOL, V29, pR977, DOI 10.1016/j.cub.2019.08.016
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Olden JD, 2021, HYDROBIOLOGIA, V848, P1967, DOI 10.1007/s10750-020-04407-7
CR  - Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
CR  - Perry PO., 2020, corpus: Text Corpus Analysis
CR  - Scheffers BR, 2019, SCIENCE, V366, P71, DOI 10.1126/science.aav5327
CR  - Sheng V. S., 2008, PROCEED INGS OFTHE 1, P614, DOI DOI 10.1145/1401890.1401965
CR  - Silge J., 2017, TEXT MINING R TIDY A
CR  - Siriwat P, 2020, J ASIA-PAC BIODIVERS, V13, P454, DOI 10.1016/j.japb.2020.03.012
CR  - Smith KF, 2009, SCIENCE, V324, P594, DOI 10.1126/science.1174460
CR  - Stringham OC, 2021, CONSERV BIOL, V35, P1130, DOI 10.1111/cobi.13675
CR  - Stringham OC, 2018, J APPL ECOL, V55, P2632, DOI 10.1111/1365-2664.13237
CR  - Sung YH, 2018, BIOL CONSERV, V227, P219, DOI 10.1016/j.biocon.2018.09.025
CR  - Vall-Ilosera M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172851
CR  - Wickham H., 2019, SCIENCE NEW YORK N Y
CR  - Wickham H., 2020, DPLYR GRAMMAR DATA M
CR  - Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
CR  - Woolnough Andrew P., 2020, Victorian Naturalist (Blackburn), V137, P203
CR  - Xu Q., 2019, FRONT BIG DATA, P2, DOI [10.3389/fdata.2019.00002, DOI 10.3389/FDATA.2019.00002]
PU  - PUBLIC LIBRARY SCIENCE
PI  - SAN FRANCISCO
PA  - 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
DA  - JUL 9
PY  - 2021
VL  - 16
IS  - 7
DO  - 10.1371/journal.pone.0254007
AN  - WOS:000674301400084
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  27
ER  -

TY  - JOUR
AU  - Roll, U
AU  - Correia, RA
AU  - Berger-Tal, O
TI  - Using machine learning to disentangle homonyms in large text corpora
T2  - CONSERVATION BIOLOGY
LA  - English
KW  - automated content analysis
KW  - big data
KW  - homographs
KW  - neural networks
KW  - reintroductions
KW  - systematic reviews
KW  - text mining
KW  - SYSTEMATIC REVIEWS
KW  - CONSERVATION
KW  - IDENTIFICATION
KW  - MANAGEMENT
AB  - Systematic reviews are an increasingly popular decision-making tool that provides an unbiased summary of evidence to support conservation action. These reviews bridge the gap between researchers and managers by presenting a comprehensive overview of all studies relating to a particular topic and identify specifically where and under which conditions an effect is present. However, several technical challenges can severely hinder the feasibility and applicability of systematic reviews, for example, homonyms (terms that share spelling but differ in meaning). Homonyms add noise to search results and cannot be easily identified or removed. We developed a semiautomated approach that can aid in the classification of homonyms among narratives. We used a combination of automated content analysis and artificial neural networks to quickly and accurately sift through large corpora of academic texts and classify them to distinct topics. As an example, we explored the use of the word reintroduction in academic texts. Reintroduction is used within the conservation context to indicate the release of organisms to their former native habitat; however, a Web of Science search for this word returned thousands of publications in which the term has other meanings and contexts. Using our method, we automatically classified a sample of 3000 of these publications with over 99% accuracy, relative to a manual classification. Our approach can be used easily with other homonyms and can greatly facilitate systematic reviews or similar work in which homonyms hinder the harnessing of large text corpora. Beyond homonyms we see great promise in combining automated content analysis and machine-learning methods to handle and screen big data for relevant information in conservation science.
AD  - Ben Gurion Univ Negev, Jacob Blaustein Inst Desert Res, Mitrani Dept Desert Ecol, IL-8499000 Midreshet Ben Gurion, IsraelAD  - Univ Oxford, Sch Geog & Environm, Oxford OX1 3QY, EnglandAD  - Univ Fed Alagoas, Inst Biol Sci & Hlth, Campus AC Simoes,Ave Lourival Melo Mota S-N, Maceio, AL, BrazilAD  - Univ Aveiro, DBIO, Aveiro, PortugalAD  - Univ Aveiro, CESAM Ctr Environm & Marine Studies, Aveiro, PortugalC3  - Ben Gurion UniversityC3  - League of European Research Universities - LERUC3  - University of OxfordC3  - Universidade Federal de AlagoasC3  - Universidade de AveiroC3  - Universidade de AveiroFU  - Kreitman Post-Doctoral Fellowship at the Ben-Gurion University of the Negev; Shamir fellowship of the Israeli Ministry of Science and Technology; Fundacao para a Ciencia e Tecnologia [SFRH/BPD/118635/2016]
FX  - U.R. is supported by the Kreitman Post-Doctoral Fellowship at the Ben-Gurion University of the Negev and the Shamir fellowship of the Israeli Ministry of Science and Technology. R.A.C. is supported by a post-doctoral grant from Fundacao para a Ciencia e Tecnologia (SFRH/BPD/118635/2016). This is publication number 951 of the Mitrani Department of Desert Ecology at the Ben-Gurion University of the Negev.
CR  - [Anonymous], 2017, HOM N
CR  - [Anonymous], 2017, NAT N
CR  - Bastian H, 2010, PLOS MED, V7, DOI 10.1371/journal.pmed.1000326
CR  - Bilotta GS, 2014, ENVIRON SCI POLICY, V42, P67, DOI 10.1016/j.envsci.2014.05.010
CR  - Bollier D., 2010, PROMISE PERIL BIG DA
CR  - Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
CR  - Cohen AM, 2005, BRIEF BIOINFORM, V6, P57, DOI 10.1093/bib/6.1.57
CR  - Connaway L. S., 2003, DESIDOC Bulletin of Information Technology, V23, P13
CR  - Cook CN, 2017, BIOL CONSERV, V209, P508, DOI 10.1016/j.biocon.2017.03.022
CR  - Correia RA, 2017, ECOL INDIC, V78, P549, DOI 10.1016/j.ecolind.2017.03.052
CR  - Dicks LV, 2014, TRENDS ECOL EVOL, V29, P607, DOI 10.1016/j.tree.2014.09.004
CR  - dos Santos JG, 2015, BIODIVERS CONSERV, V24, P2853, DOI 10.1007/s10531-015-0981-x
CR  - Feinerer I, 2015, R PACKAGE VERSION 0
CR  - Feinerer I, 2008, J STAT SOFTW, V25, P1
CR  - Feldman R., 2007, TEXT MINING HDB ADV
CR  - Ferreira C, 2016, BIOL REV, V91, P597, DOI 10.1111/brv.12185
CR  - Fisher R, 2011, CONSERV LETT, V4, P64, DOI 10.1111/j.1755-263X.2010.00146.x
CR  - Gough D., 2017, INTRO SYSTEMATIC REV
CR  - He W, 2013, INT J INFORM MANAGE, V33, P464, DOI 10.1016/j.ijinfomgt.2013.01.001
CR  - Hersh W, 2009, HEALTH INFORM SER, P3
CR  - Hey T., 2003, GRID COMPUTING MAKIN, P809, DOI DOI 10.1002/0470867167.CH36
CR  - IUCN/SSC, 2013, GUID REINTR OTH CONS
CR  - Kasemsap K, 2016, E DISCOVERY TOOLS AP, P275, DOI DOI 10.4018/978-1-5225-0474-0.CH015
CR  - Kennan MA, 2012, AUST ACAD RES LIBR, V43, P56
CR  - Krauthammer M, 2004, J BIOMED INFORM, V37, P512, DOI 10.1016/j.jbi.2004.08.004
CR  - Kulkarni A, 2008, LECT NOTES COMPUT SC, V5091, P500
CR  - Ladle RJ, 2016, FRONT ECOL ENVIRON, V14, P270, DOI 10.1002/fee.1260
CR  - Lawrence S, 1999, FIRST IEEE/POPOV WORKSHOP ON INTERNET TECHNOLOGIES AND SERVICES, PROCEEDINGS, P18, DOI 10.1109/INTS.1999.874002
CR  - Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98
CR  - Lefebvre C, 2013, SYST REV-LONDON, V2, DOI 10.1186/2046-4053-2-78
CR  - LONDON G, 1968, AM DOC, V19, P137, DOI 10.1002/asi.5090190206
CR  - MARGOLIS J, 1967, SCIENCE, V155, P1213, DOI 10.1126/science.155.3767.1213
CR  - Mostafa MM, 2013, EXPERT SYST APPL, V40, P4241, DOI 10.1016/j.eswa.2013.01.019
CR  - Nassirtoussi AK, 2014, EXPERT SYST APPL, V41, P7653, DOI 10.1016/j.eswa.2014.06.009
CR  - Ngai E, 2016, P PACIS ASS INF SYST
CR  - Nielsen M.A., 2015, NEURAL NETWORKS DEEP
CR  - Nunez-Mir GC, 2016, METHODS ECOL EVOL, V7, P1262, DOI 10.1111/2041-210X.12602
CR  - O'Mara-Eves A, 2015, SYST REV, V4, DOI 10.1186/2046-4053-4-5
CR  - Olden JD, 2008, Q REV BIOL, V83, P171, DOI 10.1086/587826
CR  - Raffo J, 2009, RES POLICY, V38, P1617, DOI 10.1016/j.respol.2009.08.001
CR  - Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057
CR  - Raschke CA, 2003, DIGITAL REVOLUTION C
CR  - Roll U, 2016, BIOL CONSERV, V204, P42, DOI 10.1016/j.biocon.2016.03.037
CR  - Schuemie MJ, 2005, J COMPUT BIOL, V12, P554, DOI 10.1089/cmb.2005.12.554
CR  - Siebert S, 2015, ELIFE, V4, DOI 10.7554/eLife.10825
CR  - Silva FN, 2016, J INFORMETR, V10, P487, DOI 10.1016/j.joi.2016.03.008
CR  - Tacconelli E, 2010, THE LANCET INFECTIOU, V10, P226, DOI DOI 10.1016/S1473-3099(10)70065-7
CR  - Tejeda-Lorente A, 2014, INFORM SCIENCES, V261, P52, DOI 10.1016/j.ins.2013.10.036
CR  - Thomas J, 2011, RES SYNTH METHODS, V2, P1, DOI 10.1002/jrsm.27
CR  - Tsafnat G, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-74
CR  - Tzanis George, 2014, International Journal of Knowledge Discovery in Bioinformatics, V4, P42, DOI 10.4018/ijkdb.2014010104
CR  - University of York Centre for Reviews and Dissemination, 2009, SYSTEMATIC REV CRDS
CR  - Venables W.N., 2002, MODERN APPL STAT S, V4
CR  - Wehrens R, 2007, J STAT SOFTWARE, V21
CR  - Westgate MJ, 2017, CONSERV BIOL, V31, P1002, DOI 10.1111/cobi.12890
CR  - Westgate MJ, 2015, CONSERV BIOL, V29, P1606, DOI 10.1111/cobi.12605
CR  - Xu HX, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P561, DOI 10.1109/FSKD.2007.54
CR  - Yan J, 2016, SOM SELF ORGANIZING
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - JUN
PY  - 2018
VL  - 32
IS  - 3
SP  - 716
EP  - 724
DO  - 10.1111/cobi.13044
AN  - WOS:000433570000021
N1  - Times Cited in Web of Science Core Collection:  28
Total Times Cited:  29
Cited Reference Count:  58
ER  -

TY  - JOUR
AU  - Balantic, CM
AU  - Donovan, TM
TI  - Statistical learning mitigation of false positives from template-detected data in automated acoustic wildlife monitoring
T2  - BIOACOUSTICS-THE INTERNATIONAL JOURNAL OF ANIMAL SOUND AND ITS RECORDING
LA  - English
KW  - Automated acoustic monitoring
KW  - bioacoustics
KW  - false positives
KW  - machine learning
KW  - species identification
KW  - statistical learning
KW  - SPECIES OCCURRENCE
KW  - OCCUPANCY MODELS
KW  - FRAMEWORK
AB  - Audio sampling of the environment can provide long-term, landscape-scale presence-absence data to model populations of sound-producing wildlife. Automated detection systems allow researchers to avoid manually searching through large volumes of recordings, but often produce unacceptable false positive rates. We developed methods that allow researchers to improve template-based automated detection using a suite of statistical learning algorithms when false positive rates are problematic. To test our method, we acquired 668 hours of recordings in the Sonoran Desert, California USA between March 2016 and May 2017, and created spectrogram cross-correlation templates for three target avian species. We trained and tested five classification algorithms and four performance-weighted ensemble classifier methods on target signals and false alarms from March 2016, and then selected high-performing ensemble classifiers from the train/test phase to predict the class of new detections thereafter. For three target species, our ensemble classifiers were able to identify 98%, 81%, and 100% of false alarms compared with the baseline template detection system, and comparative positive predictive values improved from 6% to 69%, 87% to 95%, and 2% to 77%. We show that statistical learning approaches can be implemented to mitigate false detections acquired via template-based automated detection in automated acoustic wildlife monitoring.
AD  - Univ Vermont, Vermont Cooperat Fish & Wildlife Res Unit, Burlington, VT 05405 USAAD  - Univ Vermont, Rubenstein Sch Environm & Nat Resources, Vermont Cooperat Fish & Wildlife Res Unit, US Geol Survey, Burlington, VT USAC3  - University of VermontC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - University of VermontFU  - U.S. Bureau of Land Management [31409]; U.S. National Science Foundation IGERT Program [1144388]
FX  - This work was supported by the U.S. Bureau of Land Management [31409]; U.S. National Science Foundation IGERT Program [1144388].
CR  - Acevedo MA, 2009, ECOL INFORM, V4, P206, DOI 10.1016/j.ecoinf.2009.06.005
CR  - Agranat I., 2009, AUTOMATICALLY IDENTI
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Avisoft Bioacoustics, 2016, AV SASLAB PRO VERS 5
CR  - Balantic C, 2019, ECOL APPL, V29, DOI 10.1002/eap.1854
CR  - Banner KM, 2018, ECOL EVOL, V8, P6144, DOI 10.1002/ece3.4162
CR  - Bas Y., 2017, J OPEN RES SOFTWARE, V5, DOI [10.5334/jors.154, DOI 10.5334/JORS.154]
CR  - Bioacoustics Research Program, 2015, RAV PRO 1 5 INT SOUN
CR  - Bishop CM, 2006, PATTERN RECOGN
CR  - Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
CR  - Brauer CL, 2016, WILDLIFE SOC B, V40, P140, DOI 10.1002/wsb.619
CR  - Bravo CJC, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.113
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Buxton RT, 2012, J FIELD ORNITHOL, V83, P47, DOI 10.1111/j.1557-9263.2011.00355.x
CR  - Cerqueira M. C., 2016, METHODS ECOLOGY EVOL, V7, P1340, DOI DOI 10.1111/2041-210X.12599
CR  - Chambert T, 2018, METHODS ECOL EVOL, V9, P560, DOI 10.1111/2041-210X.12910
CR  - Chambert T, 2015, ECOLOGY, V96, P332, DOI 10.1890/14-1507.1
CR  - CinixSoft, 2014, CINIXSOFT REM SCHED
CR  - COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
CR  - Davis J., 2006, P 23 INT C MACH LEAR
CR  - Digipom, 2016, EAS VOIC REC PRO
CR  - Duan S, 2013, P 25 INN APPL ART IN, P1519
CR  - Figueroa H., 2012, XBAT
CR  - Furnas BJ, 2015, J WILDLIFE MANAGE, V79, P325, DOI 10.1002/jwmg.821
CR  - Gee J, 2013, GAMBELS QUAIL CALLIP, DOI [10.2173/bna.321, DOI 10.2173/BNA.321]
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Glotin, 2016, 2016 IEEE 26 INT WOR, P1, DOI [DOI 10.1109/MLSP.2016.7738875, 10.1109/MLSP.2016.7738875]
CR  - Hafner S., 2018, MONITOR ACOUSTIC TEM
CR  - Hastie Trevor, 2017, ELEMENTS STAT LEARNI, Vsecond, P61, DOI [DOI 10.1007/978-0-387-84858-7_14, DOI 10.1007/978-0-387-21606-5]
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Katz J, 2016, BIOACOUSTICS, V25, P177, DOI 10.1080/09524622.2015.1133320
CR  - Knight EC, 2019, BIOACOUSTICS, V28, P539, DOI 10.1080/09524622.2018.1503971
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Liaw A, 2002, FOREST@, V2, P18, DOI DOI 10.1177/154405910408300516
CR  - Mac Aodha O, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005995
CR  - Marques TA, 2013, BIOL REV, V88, P287, DOI 10.1111/brv.12001
CR  - Mellinger DK, 2000, J ACOUST SOC AM, V107, P3518, DOI 10.1121/1.429434
CR  - Miller DA, 2011, ECOLOGY, V92, P1422, DOI 10.1890/10-1396.1
CR  - Miller DAW, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065808
CR  - Ovaskainen O, 2018, ECOL LETT, V21, P1244, DOI 10.1111/ele.13092
CR  - Pollock KH, 2002, ENVIRONMETRICS, V13, P105, DOI 10.1002/env.514
CR  - Potamitis I, 2014, APPL ACOUST, V80, P1, DOI 10.1016/j.apacoust.2014.01.001
CR  - Powers David M W, 2007, SIE07001 FLIND U SCH
CR  - Ranjard L, 2017, METHODS ECOL EVOL, V8, P615, DOI 10.1111/2041-210X.12688
CR  - Romagosa CM, 2012, EURASIAN COLLARED DO, DOI [10.2173/bna.630, DOI 10.2173/BNA.630]
CR  - Royle JA, 2006, ECOLOGY, V87, P835, DOI 10.1890/0012-9658(2006)87[835:GSOMAF]2.0.CO;2
CR  - Ruiz-Gutierrez V, 2016, METHODS ECOL EVOL, V7, P900, DOI 10.1111/2041-210X.12542
CR  - Schutten M, 2016, P BELG DUTCH ART INT, P10
CR  - Shonfield J, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00974-120114
CR  - Sueur J, 2008, BIOACOUSTICS, V18, P213, DOI 10.1080/09524622.2008.9753600
CR  - Towsey M, 2012, BIOACOUSTICS, V21, P107, DOI 10.1080/09524622.2011.648753
CR  - Webster MD, 1999, VERDIN AURIPARUS FLA, DOI [10.2173/bna.470, DOI 10.2173/BNA.470]
CR  - Weinberger K., 2006, ADV NEURAL INFORM PR, V18, P1473, DOI DOI 10.1007/978-3-319-13168-9_
CR  - Wildlife Acoustics, 2016, KAL
CR  - Zhu X., 2007, KNOWLEDGE DISCOVERY
CR  - Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
PU  - TAYLOR & FRANCIS LTD
PI  - ABINGDON
PA  - 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
DA  - MAY 3
PY  - 2020
VL  - 29
IS  - 3
SP  - 296
EP  - 321
DO  - 10.1080/09524622.2019.1605309
AN  - WOS:000470380800001
N1  - Times Cited in Web of Science Core Collection:  7
Total Times Cited:  7
Cited Reference Count:  56
ER  -

TY  - JOUR
AU  - Kitzes, J
AU  - Schricker, L
TI  - The Necessity, Promise and Challenge of Automated Biodiversity Surveys Comment
T2  - ENVIRONMENTAL CONSERVATION
LA  - English
KW  - acoustic
KW  - machine learning
KW  - camera trap
KW  - citizen science
AB  - We are in the midst of a transformation in the way that biodiversity is observed on the planet. The approach of direct human observation, combining efforts of both professional and citizen scientists, has recently generated unprecedented amounts of data on species distributions and populations. Within just a few years, however, we believe that these data will be swamped by indirect biodiversity observations that are generated by autonomous sensors and machine learning classification models. In this commentary, we discuss three important elements of this shift towards indirect, technology-driven observations. First, we note that the biodiversity data sets available today cover a very small fraction of all places and times that could potentially be observed, which suggests the necessity of developing new approaches that can gather such data at even larger scales, with lower costs. Second, we highlight existing tools and efforts that are already available today to demonstrate the promise of automated methods to radically increase biodiversity data collection. Finally, we discuss one specific outstanding challenge in automated biodiversity survey methods, which is how to extract useful knowledge from observations that are uncertain in nature. Throughout, we focus on one particular type of biodiversity data - point occurrence records - that are frequently produced by citizen science projects, museum records and systematic biodiversity surveys. As indirect observation methods increase the spatiotemporal scope of these point occurrence records, ecologists and conservation biologists will be better able to predict shifting species distributions, track changes to populations over time and understand the drivers of biodiversity occurrence.
AD  - Univ Pittsburgh, Dept Biol Sci, Fifth & Ruskin Ave, Pittsburgh, PA 15260 USAC3  - Pennsylvania Commonwealth System of Higher Education (PCSHE)C3  - University of PittsburghFU  - Department of Biological Sciences; Mascaro Center for Sustainable Innovation at the University of Pittsburgh; Microsoft; National Geographic [NGS-55651T-18]
FX  - This work was supported by the Department of Biological Sciences and the Mascaro Center for Sustainable Innovation at the University of Pittsburgh, as well as Microsoft and National Geographic under grant NGS-55651T-18.
CR  - Bravo CJC, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.113
CR  - Buxton RT, 2018, GLOB ECOL CONSERV, V16, DOI 10.1016/j.gecco.2018.e00493
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - iNaturalist, 2019, INATURALIST COMP VIS
CR  - LifeCLEF, 2019, BIRDCLEF 2018 IMAGEC
CR  - Marconi S, 2019, PEERJ, V7, DOI 10.7717/peerj.5843
CR  - Microsoft, 2019, AI EARTH APIS APPL S
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Steenweg R, 2017, FRONT ECOL ENVIRON, V15, P26, DOI 10.1002/fee.1448
CR  - Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
CR  - Towsey M, 2014, ECOL INFORM, V21, P1, DOI 10.1016/j.ecoinf.2014.02.002
CR  - USFWS, 2019, USFWS IND BAT SUMM S
CR  - Zuur Alain F., 2009, P1
PU  - CAMBRIDGE UNIV PRESS
PI  - NEW YORK
PA  - 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
DA  - DEC
PY  - 2019
VL  - 46
IS  - 4
SP  - 247
EP  - 250
DO  - 10.1017/S0376892919000146
AN  - WOS:000511399300001
N1  - Times Cited in Web of Science Core Collection:  7
Total Times Cited:  7
Cited Reference Count:  15
ER  -

TY  - JOUR
AU  - Lapp, S
AU  - Wu, TH
AU  - Richards-Zawacki, C
AU  - Voyles, J
AU  - Rodriguez, KM
AU  - Shamon, H
AU  - Kitzes, J
TI  - Automated detection of frog calls and choruses by pulse repetition rate
T2  - CONSERVATION BIOLOGY
LA  - English
KW  - acoustic
KW  - amphibian
KW  - classification
KW  - detection
KW  - endangered
KW  - machine learning
KW  - monitoring
KW  - signal processing
KW  - ac&#250
KW  - stico
KW  - anfibio
KW  - aprendizaje mec&#225
KW  - nico
KW  - clasificaci&#243
KW  - n
KW  - detecci&#243
KW  - n
KW  - en peligro
KW  - monitoreo
KW  - procesamiento de se&#241
KW  - al
KW  - POPULATION DECLINES
KW  - AMPHIBIAN DECLINES
KW  - ATELOPUS-VARIUS
KW  - CONSERVATION
KW  - DISEASE
KW  - BIODIVERSITY
KW  - FORESTS
AB  - Anurans (frogs and toads) are among the most globally threatened taxonomic groups. Successful conservation of anurans will rely on improved data on the status and changes in local populations, particularly for rare and threatened species. Automated sensors, such as acoustic recorders, have the potential to provide such data by massively increasing the spatial and temporal scale of population sampling efforts. Analyzing such data sets will require robust and efficient tools that can automatically identify the presence of a species in audio recordings. Like bats and birds, many anuran species produce distinct vocalizations that can be captured by autonomous acoustic recorders and represent excellent candidates for automated recognition. However, in contrast to birds and bats, effective automated acoustic recognition tools for anurans are not yet widely available. An effective automated call-recognition method for anurans must be robust to the challenges of real-world field data and should not require extensive labeled data sets. We devised a vocalization identification tool that classifies anuran vocalizations in audio recordings based on their periodic structure: the repeat interval-based bioacoustic identification tool (RIBBIT). We applied RIBBIT to field recordings to study the boreal chorus frog (Pseudacris maculata) of temperate North American grasslands and the critically endangered variable harlequin frog (Atelopus varius) of tropical Central American rainforests. The tool accurately identified boreal chorus frogs, even when they vocalized in heavily overlapping choruses and identified variable harlequin frog vocalizations at a field site where it had been very rarely encountered in visual surveys. Using a few simple parameters, RIBBIT can detect any vocalization with a periodic structure, including those of many anurans, insects, birds, and mammals. We provide open-source implementations of RIBBIT in Python and R to support its use for other taxa and communities.
AD  - Univ Pittsburgh, Dept Biol Sci, Pittsburgh, PA 15260 USAAD  - Univ Nevada, Dept Biol, Reno, NV 89557 USAAD  - Natl Zool Pk, Smithsonian Conservat Biol Inst, Front Royal, VA USAC3  - Pennsylvania Commonwealth System of Higher Education (PCSHE)C3  - University of PittsburghC3  - Nevada System of Higher Education (NSHE)C3  - University of Nevada RenoC3  - Smithsonian InstitutionC3  - Smithsonian National Zoological Park & Conservation Biology InstituteFU  - Mascaro Center for Sustainable Development; Department of Biological Sciences at the University of Pittsburgh; National Science Foundation [1935507, 1551488, 1846403]; University of Pittsburgh Center for Research Computing
FX  - We thank T. Rhinehart for comments on earlier drafts of this manuscript, the Smithsonian Tropical Research Institute, and the C. Cruz family. This work was financially supported by the Mascaro Center for Sustainable Development and the Department of Biological Sciences at the University of Pittsburgh. This material is based upon work supported by the National Science Foundation under Grants 1935507 to J.K., 1551488 to J.V., and 1846403 to J.V. This research was also supported in part by the University of Pittsburgh Center for Research Computing through the resources provided. Finally, we thank American Prairie Reserve for allowing us to sample lands under their management, and American Prairie Reserve and John and Adrienne Mars for support.
CR  - Berger L, 1998, P NATL ACAD SCI USA, V95, P9031, DOI 10.1073/pnas.95.15.9031
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - COCROFT RB, 1990, COPEIA, P631
CR  - Cohen JM, 2019, GLOBAL CHANGE BIOL, V25, P927, DOI 10.1111/gcb.14489
CR  - Collins JP, 2005, PHILOS T R SOC B, V360, P309, DOI 10.1098/rstb.2004.1588
CR  - Cornell Lab of Ornithology, 2020, ALL BIRDS
CR  - Crawford AJ, 2010, P NATL ACAD SCI USA, V107, P13777, DOI 10.1073/pnas.0914115107
CR  - CRUMP ML, 1985, J PARASITOL, V71, P588, DOI 10.2307/3281428
CR  - Darras K, 2019, ECOL APPL, V29, DOI 10.1002/eap.1954
CR  - Dodd CK., 2010, AMPHIBIAN ECOLOGY CO
CR  - Dorcas M.E., 2009, CONSERV ECOL, P281
CR  - Dutilleux G, 2020, FRESHWATER BIOL, V65, P20, DOI 10.1111/fwb.13111
CR  - Garman H., 1892, SYNOPSIS REPTILES AM, P339
CR  - Gonzalez-del-Pliego P, 2019, CURR BIOL, V29, P1557, DOI 10.1016/j.cub.2019.04.005
CR  - Gonzalez-Maya JF, 2013, AMPHIBIA-REPTILIA, V34, P573, DOI 10.1163/15685381-00002910
CR  - Hill AP, 2019, HARDWAREX, V6, DOI 10.1016/j.ohx.2019.e00073
CR  - https://www.iucnredlist.org/en, 2020, IUCN RED LIST THREAT
CR  - Huetz C., 2012, SENSORS ECOLOGY INTE, P83
CR  - IUCN SSC Amphibian Specialist Group, 2020, AT VAR IUCN RED LIST
CR  - Lang WC, 1998, AM J PHYS, V66, P794, DOI 10.1119/1.18959
CR  - Lapp S., 2020, R RIBBIT
CR  - Lapp S., 2020, RIBBIT MANUSCRIPT NO
CR  - Lasseck M., 2013, P NEURAL INFORMATION
CR  - Lips KR, 2006, P NATL ACAD SCI USA, V103, P3165, DOI 10.1073/pnas.0506889103
CR  - Longcore JE, 1999, MYCOLOGIA, V91, P219, DOI 10.2307/3761366
CR  - Measey GJ, 2017, J APPL ECOL, V54, P894, DOI 10.1111/1365-2664.12810
CR  - Mellinger DK, 2007, OCEANOGRAPHY, V20, P36, DOI 10.5670/oceanog.2007.03
CR  - Narins Peter M., 2001, P61
CR  - Perez R, 2014, AMPHIB REPTILE CONSE, V8
CR  - Pierce BA, 2007, J HERPETOL, V41, P424, DOI 10.1670/0022-1511(2007)41[424:IVIFCS]2.0.CO;2
CR  - POUNDS JA, 1994, CONSERV BIOL, V8, P72, DOI 10.1046/j.1523-1739.1994.08010072.x
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Ryan MJ., 2001, ANURAN COMMUNICATION
CR  - SAVAGE J M, 1972, Herpetologica, V28, P77
CR  - Scheele B, 2019, SCIENCE, V363, P1459, DOI 10.1126/science.aav0379
CR  - Shamon H, 2021, ECOL INDIC, V120, DOI 10.1016/j.ecolind.2020.106928
CR  - Shonfield J, 2018, J RAPTOR RES, V52, P42, DOI 10.3356/JRR-17-52.1
CR  - Storfer A, 2003, DIVERS DISTRIB, V9, P151, DOI 10.1046/j.1472-4642.2003.00014.x
CR  - Voyles J, 2018, SCIENCE, V359, P1517, DOI 10.1126/science.aao4806
CR  - WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
CR  - Weller TJ, 2008, BIOL CONSERV, V141, P2279, DOI 10.1016/j.biocon.2008.06.018
CR  - Wildlife Acoustics, 2011, SONG SCOPE
CR  - Willacy RJ, 2015, AUSTRAL ECOL, V40, P625, DOI 10.1111/aec.12228
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - Xie J, 2018, ARTIF INTELL REV, V49, P375, DOI 10.1007/s10462-016-9529-z
CR  - Young BE, 2001, CONSERV BIOL, V15, P1213, DOI 10.1046/j.1523-1739.2001.00218.x
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - OCT
PY  - 2021
VL  - 35
IS  - 5
SP  - 1659
EP  - 1668
DO  - 10.1111/cobi.13718
AN  - WOS:000647834200001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  46
ER  -

TY  - JOUR
AU  - Keen, SC
AU  - Shiu, Y
AU  - Wrege, PH
AU  - Rowland, ED
TI  - Automated detection of low-frequency rumbles of forest elephants: A critical tool for their conservation
T2  - JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA  - English
KW  - FUNDAMENTAL-FREQUENCY
KW  - AFRICAN ELEPHANTS
KW  - CLASSIFICATION
KW  - RECOGNITION
KW  - MOVEMENTS
KW  - CALLS
AB  - African forest elephants (Loxodonta cyclotis) occupy large ranges in dense tropical forests and often use far-reaching vocal signals to coordinate social behavior. Elephant populations in Central Africa are in crisis, having declined by more than 60% in the last decade. Methods currently used to monitor these populations are expensive and time-intensive, though acoustic monitoring technology may offer an effective alternative if signals of interest can be efficiently extracted from the sound stream. This paper proposes an automated elephant call detection algorithm that was tested on nearly 4000 h of field recordings collected from five forest clearings in Central Africa, including sites both inside protected areas and in logging concessions. Recordings were obtained in different seasons, years, and under diverse weather conditions. The detector achieved an 83.2% true positive rate when the false positive rate is 5.5% (approximately 20 false positives per hour). These results suggest that this algorithm can enable analysis of long-term recording datasets or facilitate near-real-time monitoring of elephants in a wide range of settings and conditions. (C) 2017 Acoustical Society of America.
AD  - Cornell Univ, Bioacoust Res Program, 159 Sapsucker 1,Woods Rd, Ithaca, NY 14850 USAC3  - Cornell UniversityFU  - U.S. Fish and Wildlife Service [96200-9-G231, 98210-7-G205, 96200-0-G301]; International Fund for Animal Welfare; Robert G. and Jane V. Engle Foundation
FX  - The authors thank A. Turkalo and M. Thompson for their expertise and insight into acoustic monitoring of forest elephants in Central Africa, ELP volunteers for their help in tagging events in training and testing datasets, M. Zeppelzauer and A. Stoeger for sharing their acoustic data, and the Bioacoustics Research Program, and the Cornell lab of Ornithology for enabling this work. For permission to work in the Dzanga-Ndoki Park the authors thank the Dzanga Sangha Project, the Central African Republic Ministry of Water and Forest Resources. Permission to work in Gabon was generously granted by the Republic of Gabon Centre National de la Recherche Scientifique et Technologique. The Wildlife Conservation Society provided essential logistics support in the field. This study was supported by a generous donation from Scott and Karen Harder, and grants to P.H.W. from the U.S. Fish and Wildlife Service (96200-9-G231, 98210-7-G205, 96200-0-G301), the International Fund for Animal Welfare, The Robert G. and Jane V. Engle Foundation, and private contributors.
CR  - Archie EA, 2006, ANIM BEHAV, V71, P117, DOI 10.1016/j.anbehav.2005.03.023
CR  - Bioacoustics Research Program, 2014, RAV PRO INT SOUND AN
CR  - Blake S., 2003, THESIS
CR  - Blake S, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003546
CR  - Boersma P., 1993, P I PHONET SCI, V17
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Calupca T.A., 2000, J ACOUST SOC AM, V108, P2582, DOI DOI 10.1121/1.4743595
CR  - CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
CR  - Catchpole CK, 2008, BIRD SONG: BIOLOGICAL THEMES AND VARIATIONS, 2ND EDITION, P1
CR  - CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
CR  - DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
CR  - de Cheveigne A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
CR  - Fox EJS, 2008, BIOACOUSTICS, V18, P51, DOI 10.1080/09524622.2008.9753590
CR  - Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
CR  - Fristrup KM, 1992, WHOI9204
CR  - Hafner S., 2015, MONITOR ACOUSTIC TEM
CR  - HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
CR  - Klapuri AP, 2003, IEEE T SPEECH AUDI P, V11, P804, DOI 10.1109/TSA.2003.815516
CR  - Koch C, 2011, ADV ENG INFORM, V25, P507, DOI 10.1016/j.aei.2011.01.002
CR  - Kolowski JM, 2010, AFR J ECOL, V48, P1134, DOI 10.1111/j.1365-2028.2009.01204.x
CR  - Kroon D., 2010, CLASSIC ADABOOST CLA
CR  - LANGBAUER WR, 1991, J EXP BIOL, V157, P35
CR  - Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
CR  - Littlejohn M.J., 1977, P263
CR  - Maisels F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059469
CR  - Mallawaarachchi A, 2008, J ACOUST SOC AM, V124, P1159, DOI 10.1121/1.2945711
CR  - McComb K, 2000, ANIM BEHAV, V59, P1103, DOI 10.1006/anbe.2000.1406
CR  - McComb K, 2003, ANIM BEHAV, V65, P317, DOI 10.1006/anbe.2003.2047
CR  - Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
CR  - PAYNE R, 1971, ANN NY ACAD SCI, V188, P110, DOI 10.1111/j.1749-6632.1971.tb13093.x
CR  - POOLE JH, 1988, BEHAV ECOL SOCIOBIOL, V22, P385, DOI 10.1007/BF00294975
CR  - Poole JH, 2005, NATURE, V434, P455, DOI 10.1038/434455a
CR  - Poole Joyce H., 1994, P331
CR  - Poole Joyce H., 2011, P125
CR  - Pourhomayoun M, 2013, ARXIV13053635
CR  - Rabanal LI, 2010, BIOL CONSERV, V143, P1017, DOI 10.1016/j.biocon.2010.01.017
CR  - Redgwell RD, 2009, ALGORITHMS, V2, P907, DOI 10.3390/a2030907
CR  - Roch MA, 2007, J ACOUST SOC AM, V121, P1737, DOI 10.1121/1.2400663
CR  - Root-Gutteridge H, 2014, BIOACOUSTICS, V23, P55, DOI 10.1080/09524622.2013.817317
CR  - Slabbekoorn H, 2002, CONDOR, V104, P564, DOI 10.1650/0010-5422(2002)104[0564:BASTTB]2.0.CO;2
CR  - Soltis J, 2009, J COMP PSYCHOL, V123, P222, DOI 10.1037/a0015223
CR  - Sueur J, 2015, BIOSEMIOTICS-NETH, V8, P493, DOI 10.1007/s12304-015-9248-x
CR  - Sueur J, 2008, BIOACOUSTICS, V18, P213, DOI 10.1080/09524622.2008.9753600
CR  - Tchernichovski O, 2000, ANIM BEHAV, V59, P1167, DOI 10.1006/anbe.1999.1416
CR  - Thompson M. S., 2009, THESIS
CR  - Thompson ME, 2010, AFR J ECOL, V48, P654, DOI 10.1111/j.1365-2028.2009.01161.x
CR  - Turkalo Andrea, 1995, Pachyderm, V20, P45
CR  - Turkalo AK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0085154
CR  - Turkalo Andrea K., 2001, P207
CR  - Tyack PL, 2000, SPR HDB AUD, V12, P156
CR  - Venter PJ, 2010, BIOSYST ENG, V106, P286, DOI 10.1016/j.biosystemseng.2010.04.001
CR  - Wells K.D., 1988, P433
CR  - Wijayakulasooriya J. V., 2011, 2011 IEEE 6th International Conference on Industrial and Information Systems (ICIIS 2011), P244, DOI 10.1109/ICIINFS.2011.6038074
CR  - Wittemyer G, 2005, ANIM BEHAV, V69, P1357, DOI 10.1016/j.anbehav.2004.08.018
CR  - Wittemyer G, 2014, P NATL ACAD SCI USA, V111, P13117, DOI 10.1073/pnas.1403984111
CR  - Wrege PH, 2012, AFR J ECOL, V50, P176, DOI 10.1111/j.1365-2028.2011.01310.x
CR  - Wrege PH, 2010, CONSERV BIOL, V24, P1578, DOI 10.1111/j.1523-1739.2010.01559.x
CR  - Zeppelzauer M, 2015, BIOACOUSTICS, V24, P13, DOI 10.1080/09524622.2014.906321
PU  - ACOUSTICAL SOC AMER AMER INST PHYSICS
PI  - MELVILLE
PA  - STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
DA  - APR
PY  - 2017
VL  - 141
IS  - 4
SP  - 2715
EP  - 2726
DO  - 10.1121/1.4979476
AN  - WOS:000400619400056
N1  - Times Cited in Web of Science Core Collection:  5
Total Times Cited:  7
Cited Reference Count:  58
ER  -

TY  - JOUR
AU  - Anton, V
AU  - Germishuys, J
AU  - Bergstrom, P
AU  - Lindegarth, M
AU  - Obst, M
TI  - An open-source, citizen science and machine learning approach to analyse subsea movies
T2  - BIODIVERSITY DATA JOURNAL
LA  - English
KW  - marine biodiversity
KW  - autonomous underwater vehicles
KW  - remotely-operated vehicles
KW  - artificial intelligence
KW  - big data
KW  - image analysis
KW  - participatory science
KW  - Essential Biodiversity Variables
KW  - research infrastructure
KW  - biodiversity monitoring
AB  - Background
   The increasing access to autonomously-operated technologies offer vast opportunities to sample large volumes of biological data. However, these technologies also impose novel demands on ecologists who need to apply tools for data management and processing that are efficient, publicly available and easy to use. Such tools are starting to be developed for a wider community and here we present an approach to combine essential analytical functions for analysing large volumes of image data in marine ecological research.
   New information
   This paper describes the Koster Seafloor Observatory, an open-source approach to analysing large amounts of subsea movie data for marine ecological research. The approach incorporates three distinct modules to: manage and archive the subsea movies, involve citizen scientists to accurately classify the footage and, finally, train and test machine learning algorithms for detection of biological objects. This modular approach is based on open-source code and allows researchers to customise and further develop the presented functionalities to various types of data and questions related to analysis of marine imagery. We tested our approach for monitoring cold water corals in a Marine Protected Area in Sweden using videos from remotely-operated vehicles (ROVs). Our study resulted in a machine learning model with an adequate performance, which was entirely trained with classifications provided by citizen scientists. We illustrate the application of machine learning models for automated inventories and monitoring of cold water corals. Our approach shows how citizen science can be used to effectively extract occurrence and abundance data for key ecological species and habitats from underwater footage. We conclude that the combination of open-source tools, citizen science systems, machine learning and high performance computational resources are key to successfully analyse large amounts of underwater imagery in the future.
AD  - Wildlife Ai, New Plymouth, New ZealandAD  - Combine AB, Gothenburg, SwedenAD  - Gothenburg Univ, Dept Marine Sci, Gothenburg, SwedenAD  - SeAnalytics AB, Gothenburg, SwedenC3  - University of GothenburgFU  - Ocean Data Factory, an expert network - Sweden's Innovation Agency [2019-02256]; Swedish Agency for Marine and Water Management [956-19]; Swedish Research Council [829-2009-6278]; NeIC programme DeepDive; Horizon 2020 project ENVRIplus [654182]
FX  - The project was funded by Ocean Data Factory, an expert network supported by grants from Sweden's Innovation Agency (grant agreement no. 2019-02256), the Swedish Agency for Marine and Water Management (grant agreement no. 956-19) and the Swedish Research Council (through Swedish LifeWatch grant agreement no. 829-2009-6278). The presented work was furthermore supported by the NeIC programme DeepDive and the Horizon 2020 project ENVRIplus (grant agreement no. 654182).
CR  - Aceves-Bueno E., 2017, B ECOL SOC AM, V98, P278, DOI [10.1002/bes2.1336, DOI 10.1002/BES2.1336]
CR  - Anton V, 2019, KOSTER DATA MANAGEME
CR  - Bean TP, 2017, FRONT MAR SCI, V4, DOI 10.3389/fmars.2017.00263
CR  - Beijbom O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130312
CR  - Benedetti-Cecchi L, 2018, EUROPEAN MARINE BOAR
CR  - Costello MJ, 2005, ERLANGEN EARTH C SER, P771, DOI 10.1007/3-540-27673-4_41
CR  - Danovaro R, 2016, FRONT MAR SCI, V3, DOI 10.3389/fmars.2016.00213
CR  - Germishuys J, 2019, KOSTER YOLO OBJECT D
CR  - Guidi L., 2020, FUTURE SCI BRIEF 6 E, P1, DOI [10.5281/zenodo.3755793, DOI 10.5281/ZENODO.3755793]
CR  - Hardisty AR, 2019, ENVIRON RES LETT, V14, DOI 10.1088/1748-9326/aaf5db
CR  - Kissling WD, 2018, BIOL REV, V93, P600, DOI 10.1111/brv.12359
CR  - Lavaleye M, 2009, OCEANOGRAPHY, V22, P76, DOI 10.5670/oceanog.2009.08
CR  - Lopez-Vazquez V, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030726
CR  - Mack L, 2020, FRONT MAR SCI, V7, DOI 10.3389/fmars.2020.552047
CR  - Pereira HM, 2013, SCIENCE, V339, P277, DOI 10.1126/science.1229931
CR  - Picheral M, 2017, ECOTAXA TOOL TAXONOM
CR  - Ramirez S, 2020, FASTAPI FRAMEWORK 0
CR  - Redmon J., 2018, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2017.690
CR  - Teixeira T, 2020, STREAMLT 0 69 0
PU  - PENSOFT PUBLISHERS
PI  - SOFIA
PA  - 12 PROF GEORGI ZLATARSKI ST, SOFIA, 1700, BULGARIA
DA  - FEB 24
PY  - 2021
VL  - 9
DO  - 10.3897/BDJ.9.e60548
AN  - WOS:000621550300001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  19
ER  -

TY  - JOUR
AU  - Zamani, A
AU  - Dal Pos, D
AU  - Fric, ZF
AU  - Orfinger, AB
AU  - Scherz, MD
AU  - Bartonova, AS
AU  - Gante, HF
TI  - The future of zoological taxonomy is integrative, not minimalist
T2  - SYSTEMATICS AND BIODIVERSITY
LA  - English
KW  - automated morphological classification
KW  - biodiversity
KW  - citation mandate
KW  - eDNA
KW  - hyperdiverse taxa
KW  - integrative taxonomy
KW  - museomics
KW  - species description
KW  - systematics
KW  - taxonomic impediment
KW  - SPECIES DELIMITATION
KW  - MITOCHONDRIAL-DNA
KW  - BUTTERFLIES LEPIDOPTERA
KW  - NUCLEAR DISCORDANCE
KW  - HYMENOPTERA
KW  - ICHNEUMONIDAE
KW  - GENUS
KW  - COMPLEX
KW  - PHAEOGENINI
KW  - SYSTEMATICS
AB  - Roughly 18,000 species are described annually as new to science, while estimated extinction rates are comparable to or even exceeding these new discoveries. Considering the estimates of up to 15 million extant eukaryotic species on Earth, of which only about 2 million have been described so far, there has been a recent 'boom' of new potential approaches to more quickly discover and describe the millions of unknown species. This deficit is particularly noted in hyperdiverse taxa, as the current rate of species discovery is considered too slow. Recently, a 'minimalist' alpha taxonomic approach was proposed, relying solely on DNA barcoding and a habitus photograph, in a claimed effort to expedite the naming of new species to combat the so-called taxonomic impediment. In this paper, we point to limitations of minimalist taxonomy, present arguments in favour of the integrative approach, and finally explore a number of potential solutions to combat the taxonomic impediment in hyperdiverse taxa without sacrificing utility and quality for apparent speed and quantity.
AD  - Univ Turku, Biodivers Unit, Zool Museum, Turku 20500, FinlandAD  - Univ Cent Florida, Dept Biol, 4110 Libra Dr Rm 442, Orlando, FL 32816 USAAD  - Czech Acad Sci, Inst Entomol, Dept Biodivers & Conservat Biol, Biol Ctr, Branisovska 31, CZ-37005 Ceske Budejovice, Czech RepublicAD  - Univ Florida, Dept Entomol & Nematol, Gainesville, FL 32611 USAAD  - Florida A&M Univ, Ctr Water Resources, Tallahassee, FL 32301 USAAD  - Univ Copenhagen, Nat Hist Museum Denmark, DK-1350 Copenhagen, DenmarkAD  - Univ Lisbon, cE3c Ctr Ecol Evolut & Environm Changes, Lisbon, PortugalAD  - Katholieke Univ Leuven, Sect Ecol Evolut & Biodivers Conservat, Dept Biol, Charles Deberiotstr 32 Box 2439, B-3000 Leuven, BelgiumAD  - Royal Museum Cent Africa, Leuvensesteenweg 17, B-3080 Tervuren, BelgiumC3  - University of TurkuC3  - State University System of FloridaC3  - University of Central FloridaC3  - Czech Academy of SciencesC3  - Biology Centre of the Czech Academy of SciencesC3  - State University System of FloridaC3  - University of FloridaC3  - State University System of FloridaC3  - Florida A&M UniversityC3  - League of European Research Universities - LERUC3  - University of CopenhagenC3  - Universidade de LisboaC3  - League of European Research Universities - LERUC3  - KU LeuvenC3  - Royal Museum for Central AfricaFU  - USDA National Institute of Food and Agriculture [1021805]; Fundacao para a Ciencia e a Tecnologia (Lisbon) (F.C.T.) [PTDC/BIA-CBI/31644/2017]
FX  - This work was supported by the USDA National Institute of Food and Agriculture, 1890 Institution Capacity Building Grant Project 1021805 to A.B.O; and by Fundacao para a Ciencia e a Tecnologia (Lisbon) (F.C.T.) grant number PTDC/BIA-CBI/31644/2017 to H.F.G.
CR  - Abdala CS, 2020, SYST BIODIVERS, V19, P135, DOI 10.1080/14772000.2020.1844818
CR  - Ahmed MZ, 2015, FRONT ZOOL, V12, DOI 10.1186/s12983-015-0107-z
CR  - Ahrens D, 2021, ZOOTAXA, V5027, P151, DOI 10.11646/zootaxa.5027.2.1
CR  - Alves M.J., 2019, BIODIVERSITY INFORM, V3, DOI [10.3897/biss.3.37975, DOI 10.3897/BISS.3.37975]
CR  - Arthofer W, 2013, MOL ECOL, V22, P3850, DOI 10.1111/mec.12340
CR  - Bartonova AS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82433-8
CR  - Bond JE, 2022, DIVERSITY-BASEL, V14, DOI [10.3390/d14010005, 10.6084/m9.figshare.17263835.v1]
CR  - Brasero N, 2020, SYST BIODIVERS, V18, P12, DOI 10.1080/14772000.2020.1737843
CR  - Brawand D, 2014, NATURE, V513, P375, DOI 10.1038/nature13726
CR  - Breman FC, 2016, MOL ECOL RESOUR, V16, P1455, DOI 10.1111/1755-0998.12523
CR  - Call E, 2021, INSECT SYST DIVER, V5, DOI 10.1093/isd/ixaa021
CR  - Carstens BC, 2013, MOL ECOL, V22, P4369, DOI 10.1111/mec.12413
CR  - Chambers EA, 2020, SYST BIOL, V69, P184, DOI 10.1093/sysbio/syz042
CR  - Chaplin K, 2020, SYST BIOL, V69, P294, DOI 10.1093/sysbio/syz048
CR  - Costa WJEM, 2021, SYST BIODIVERS, V19, P601, DOI 10.1080/14772000.2021.1900947
CR  - D'Ercole J, 2021, PEERJ, V9, DOI 10.7717/peerj.11157
CR  - Dal Pos D, 2018, EUR J TAXON, V473, P1, DOI 10.5852/ejt.2018.473
CR  - Dayrat B, 2005, BIOL J LINN SOC, V85, P407, DOI 10.1111/j.1095-8312.2005.00503.x
CR  - de Carvalho MR, 2007, EVOL BIOL, V34, P140, DOI 10.1007/s11692-007-9011-6
CR  - DeSalle R, 2005, PHILOS T R SOC B, V360, P1905, DOI 10.1098/rstb.2005.1722
CR  - Di Giovanni F, 2018, ZOOTAXA, V4374, P594, DOI 10.11646/zootaxa.4374.4.8
CR  - Di Giovanni F, 2015, BIODIVERS DATA J, V3, DOI 10.3897/BDJ.3.e5057
CR  - Di Giovanni Filippo, 2016, Linzer Biologische Beitraege, V48, P495
CR  - Dinca V, 2021, COMMUN BIOL, V4, DOI 10.1038/s42003-021-01834-7
CR  - Dinca V, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.1311
CR  - Dinca V, 2015, SCI REP-UK, V5, DOI 10.1038/srep12395
CR  - Dinca V, 2011, P ROY SOC B-BIOL SCI, V278, P347, DOI 10.1098/rspb.2010.1089
CR  - Dowton M, 2014, SYST BIOL, V63, P639, DOI 10.1093/sysbio/syu028
CR  - Duperre Nadine, 2020, Megataxa, V1, P59, DOI 10.11646/megataxa.1.1.12
CR  - Ebach MC, 2011, CLADISTICS, V27, P550, DOI 10.1111/j.1096-0031.2011.00348.x
CR  - Ebach MC, 2005, NATURE, V434, P697, DOI 10.1038/434697b
CR  - Edwards DL, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2013.2765
CR  - Engel MS, 2021, ZOOL J LINN SOC-LOND, V193, P381, DOI 10.1093/zoolinnean/zlab072
CR  - Erpenbeck D, 2016, J MAR BIOL ASSOC UK, V96, P305, DOI 10.1017/S0025315415000521
CR  - Evans BJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220892
CR  - Feliciano K, 2021, SYST BIODIVERS, V19, P834, DOI 10.1080/14772000.2021.1939458
CR  - Fernandez-Triana JL, 2022, ZOOKEYS, P199, DOI 10.3897/zookeys.1087.76720
CR  - Funk DJ, 2003, ANNU REV ECOL EVOL S, V34, P397, DOI 10.1146/annurev.ecolsys.34.011802.132421
CR  - Gante HF, 2016, MOL ECOL, V25, P6143, DOI 10.1111/mec.13767
CR  - Gante HF, 2012, CURR BIOL, V22, pR956, DOI 10.1016/j.cub.2012.09.045
CR  - Gaston KJ, 2004, PHILOS T R SOC B, V359, P655, DOI 10.1098/rstb.2003.1442
CR  - Gaunet A, 2019, ZOOL SCR, V48, P507, DOI 10.1111/zsc.12355
CR  - Gebiola M, 2012, MOL ECOL, V21, P1190, DOI 10.1111/j.1365-294X.2011.05428.x
CR  - Geiger M, 2021, PEERJ, V9, DOI 10.7717/peerj.11192
CR  - Gregory TR, 2005, NATURE, V434, P1067, DOI 10.1038/4341067b
CR  - Hausmann A, 2011, SPIXIANA, V34, P47
CR  - Hebert PDN, 2003, P ROY SOC B-BIOL SCI, V270, pS96, DOI [10.1098/rspb.2002.2218, 10.1098/rsbl.2003.0025]
CR  - Hebert PDN, 2005, SYST BIOL, V54, P852, DOI 10.1080/10635150500354886
CR  - Hebert PDN, 2005, CAN J ZOOL, V83, P505, DOI 10.1139/Z05-026
CR  - Heinrich G., 1967, SYNOPSIS RECLASSIFIC, V1, P250
CR  - Hernandez-Roldan JL, 2016, MOL ECOL, V25, P4267, DOI 10.1111/mec.13756
CR  - Hinojosa JC, 2019, MOL ECOL, V28, P3857, DOI 10.1111/mec.15153
CR  - Hopkins T, 2019, ZOOKEYS, P33, DOI 10.3897/zookeys.878.37845
CR  - Hurst GDD, 2005, P ROY SOC B-BIOL SCI, V272, P1525, DOI 10.1098/rspb.2005.3056
CR  - International Commission on Zoological Nomenclature (ICZN), 1999, INT CODE ZOOLOGICAL, Vfourth
CR  - Johansson N, 2020, EUR J TAXON, V724, P70, DOI 10.5852/ejt.2020.724.1159
CR  - Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
CR  - Klopfstein S., 2019, ENTOMOLOGICAL COMMUN, V1, pec010, DOI [https://doi.org/10.37486/2675-1305.ec01006, DOI 10.37486/2675-1305.EC01006, 10.37486/2675-1305.ec01006]
CR  - Klopfstein S, 2014, ZOOTAXA, V3801, P1, DOI 10.11646/zootaxa.3801.1.1
CR  - Kodandaramaiah U, 2013, ECOL EVOL, V3, P5167, DOI 10.1002/ece3.886
CR  - Lima LR, 2020, SYST BIODIVERS, V18, P771, DOI 10.1080/14772000.2020.1795742
CR  - Lipscomb D, 2003, TRENDS ECOL EVOL, V18, P65, DOI 10.1016/S0169-5347(02)00060-5
CR  - Litman J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208639
CR  - Lukhtanov VA, 2009, MOL ECOL RESOUR, V9, P1302, DOI 10.1111/j.1755-0998.2009.02577.x
CR  - Malinsky M, 2018, NAT ECOL EVOL, V2, P1940, DOI 10.1038/s41559-018-0717-x
CR  - Mason NA, 2020, SYST BIODIVERS, V18, P269, DOI 10.1080/14772000.2020.1730475
CR  - McGuire JA, 2018, PEERJ, V6, DOI 10.7717/peerj.4470
CR  - Meier JI, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14363
CR  - Meier R, 2022, CLADISTICS, V38, P264, DOI 10.1111/cla.12489
CR  - Meier R, 2017, SYST ENTOMOL, V42, P301, DOI 10.1111/syen.12215
CR  - Meierotto S, 2019, DEUT ENTOMOL Z, V66, P119, DOI 10.3897/dez.66.34683
CR  - Mora C, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001127
CR  - Moritz C, 2004, PLOS BIOL, V2, P1529, DOI 10.1371/journal.pbio.0020354
CR  - Mutanen M, 2016, SYST BIOL, V65, P1024, DOI 10.1093/sysbio/syw044
CR  - Nevado B, 2011, MOL BIOL EVOL, V28, P2253, DOI 10.1093/molbev/msr043
CR  - Newton LG, 2020, MOL ECOL, V29, P2269, DOI 10.1111/mec.15483
CR  - Novacek M.J., 1992, EXTINCTION PHYLOGENY, P1
CR  - Olave M, 2014, SYST BIOL, V63, P263, DOI 10.1093/sysbio/syt106
CR  - Pante E, 2015, MOL ECOL, V24, P525, DOI 10.1111/mec.13048
CR  - Papakostas S, 2016, SYST BIOL, V65, P508, DOI 10.1093/sysbio/syw016
CR  - Pham NT, 2020, ZOOTAXA, V4802, P301, DOI 10.11646/zootaxa.4802.2.5
CR  - Pinheiro HT, 2019, SCIENCE, V365, P873, DOI 10.1126/science.aay7174
CR  - Puillandre N, 2012, MOL ECOL, V21, P2671, DOI 10.1111/j.1365-294X.2012.05559.x
CR  - Rancilhac L, 2020, J NAT HIST, V54, P87, DOI 10.1080/00222933.2020.1748243
CR  - Ratnasingham S, 2007, MOL ECOL NOTES, V7, P355, DOI 10.1111/j.1471-8286.2007.01678.x
CR  - Ritter S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078107
CR  - Ronco F, 2021, NATURE, V589, P76, DOI 10.1038/s41586-020-2930-4
CR  - Ronco F, 2020, J GREAT LAKES RES, V46, P1067, DOI 10.1016/j.jglr.2019.05.009
CR  - Rousse P, 2016, ZOOKEYS, P77, DOI 10.3897/zookeys.636.10216
CR  - Rousse P, 2014, EUR J TAXON, V91, P1, DOI 10.5852/ejt.2014.91
CR  - Rousse P, 2013, ZOOKEYS, P1, DOI 10.3897/zookeys.354.5968
CR  - Ruane S, 2017, MOL ECOL RESOUR, V17, P1003, DOI 10.1111/1755-0998.12655
CR  - Scherz MD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75431-9
CR  - Seberg O, 2003, TRENDS ECOL EVOL, V18, P63, DOI 10.1016/S0169-5347(02)00059-9
CR  - Selfa Jesus, 1994, Entomofauna, V15, P237
CR  - Sharkey M, 2021, ZOOKEYS, P191, DOI 10.3897/zookeys.1033.66186
CR  - Sharkey MJ, 2021, ZOOKEYS, P1, DOI 10.3897/zookeys.1013.55600
CR  - Srivathsan A, 2021, BMC BIOL, V19, DOI 10.1186/s12915-021-01141-x
CR  - Stork Nigel E., 1997, P41
CR  - Straube N, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210474
CR  - Straube N, 2021, MOL ECOL RESOUR, V21, P2299, DOI 10.1111/1755-0998.13433
CR  - Taberlet P, 2018, ENVIRONMENTAL DNA: FOR BIODIVERSITY RESEARCH AND MONITORING, P1, DOI 10.1093/oso/9780198767220.001.0001
CR  - Tereshkin A. M., 2009, Linzer Biologische Beitraege, V41, P1317
CR  - Toews DPL, 2012, MOL ECOL, V21, P3907, DOI 10.1111/j.1365-294X.2012.05664.x
CR  - Toth JP, 2017, BIOL J LINN SOC, V121, P267, DOI 10.1093/biolinnean/blw037
CR  - Valan M, 2019, SYST BIOL, V68, P876, DOI 10.1093/sysbio/syz014
CR  - Varga O, 2020, ZOOTAXA, V4852, P590, DOI [10.11646/ZOOTAXA.4852.5.9, 10.11646/zootaxa.4852.5.9]
CR  - Vences M, 2021, SPIXIANA, V44, P175
CR  - Vences Miguel, 2021, Megataxa, V6, P77, DOI 10.11646/megataxa.6.2.1
CR  - Vieites DR, 2009, P NATL ACAD SCI USA, V106, P8267, DOI 10.1073/pnas.0810821106
CR  - Wachter GA, 2015, MOL ECOL, V24, P863, DOI 10.1111/mec.13077
CR  - Weston JNJ, 2020, SYST BIODIVERS, V18, P57, DOI 10.1080/14772000.2020.1729891
CR  - Wheat CW, 2008, MOL PHYLOGENET EVOL, V47, P893, DOI 10.1016/j.ympev.2008.03.013
CR  - Wheeler QD, 2004, SCIENCE, V303, P285, DOI 10.1126/science.303.5656.285
CR  - Wheeler Q, 2018, INTEGR COMP BIOL, V58, P1118, DOI 10.1093/icb/icy067
CR  - Wheeler QD, 2008, SYST ENTOMOL, V33, P2, DOI 10.1111/j.1365-3113.2007.00411.x
CR  - Wheeler QD, 2009, ZOOLOGIA, V26, P1
CR  - Wiemers M, 2007, FRONT ZOOL, V4, DOI 10.1186/1742-9994-4-8
CR  - Wiens JJ, 2004, SYST BIOL, V53, P653, DOI 10.1080/10635150490472959
CR  - Will KW, 2005, SYST BIOL, V54, P844, DOI 10.1080/10635150500354878
CR  - Wuhrl L., 2021, BIORXIV
CR  - Yang B, 2022, SYST BIOL, V71, P690, DOI 10.1093/sysbio/syab076
CR  - Zamani A, 2022, SYST ENTOMOL, DOI 10.1111/syen.12538
CR  - Zamani A, 2021, SYST ENTOMOL, V46, P1, DOI 10.1111/syen.12444
PU  - TAYLOR & FRANCIS LTD
PI  - ABINGDON
PA  - 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
DA  - DEC 31
PY  - 2022
VL  - 20
IS  - 1
DO  - 10.1080/14772000.2022.2063964
AN  - WOS:000797800300001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  124
ER  -

TY  - JOUR
AU  - Mahum, R
AU  - Munir, H
AU  - Mughal, ZUN
AU  - Awais, M
AU  - Khan, FS
AU  - Saqlain, M
AU  - Mahamad, S
AU  - Tlili, I
TI  - A novel framework for potato leaf disease detection using an efficient deep learning model
T2  - HUMAN AND ECOLOGICAL RISK ASSESSMENT
LA  - English
KW  - Classification
KW  - disease detection
KW  - deep learning
KW  - potato leaf diseases
KW  - PLANT
KW  - RECOGNITION
AB  - Potato disease management plays a valuable role in the agriculture field as it might cause a significant loss in crops production. Therefore, timely recognition and classification of potato leaves diseases are necessary to minimize the loss, however, it is time taking task and requires human efforts. Thus, an accurate automated technique for timely detection and classification is needed to cope with the aforementioned challenges.There exist techniques grounded on machine learning and deep learning procedures that use the existing dataset i.e., 'The Plant Village Dataset' and perform classification into only two classes in potato leaves. Therefore, this article proposes a technique based on an improved deep learning algorithm that uses the potato leaf visual features to classify them into five classes i.e., Potato Late Blight (PLB), Potato Early Blight (PEB), Potato Leaf Roll (PLR), Potato Verticillium_wilt (PVw) and Potato Healthy (PH) class. The propose model is trained on the existing dataset i.e., "The Plant Village" that comprises of images having two ailments such as Early Blight (EB) and Late Blight (LB), and a Healthy class for potato leaves. Additionally, we have gathered the data for classes i.e., Potato Leaf Roll (PLR), Potato Verticillium_wilt (PVw) and Potato Healthy (PH) manually. A pre-trained Efficient DenseNet model has been employed utilizing an extra transition layer in DenseNet-201 to classify the potato leave diseases efficiently. Moreover, the usage of the reweighted cross-entropy loss function makes our proposed algorithm more robust as the training data is highly imbalanced. The dense connections with regularization power help to minimize the overfitting during the training of small training sets of potato leaves samples. The proposed algorithm is a novel and first technique to address and report the successful implementation for the detection and classification of four diseases in potato leaves. The algorithm's performance was evaluated on the testing set and gave an accuracy of 97.2%. Various experiments have been performed to confirm that our proposed algorithm is more consistent and proficient to detect and classify potato leaves diseases than existing models.
AD  - Univ Engn & Technol Taxila, Dept Comp Sci, Taxila, PakistanAD  - Univ Sindh, Dept Physiol, Jamshoro, Sindh, PakistanAD  - Univ Sialkot, Dept Biochem & Mol Biol, Sialkot, Punjab, PakistanAD  - Univ Sialkot, Dept Biotechnol, Sialkot, Punjab, PakistanAD  - Univ Teknol Petronas, Dept Comp & Informat Sci, Seri Iskandar, Perak, MalaysiaAD  - Al Zulfi Majmaah Univ, Coll Sci, Phys Dept, Al Zulfi, Saudi ArabiaC3  - University of Engineering & Technology TaxilaC3  - University of SindhC3  - Universiti Teknologi PetronasC3  - Majmaah UniversityFU  - Deanship of Scientific Research at Majmaah University [R-2022-104]; university of engineering and technology Taxila
FX  - The corresponding author Dr. Iskander Tlili would like to thank Deanship of Scientific Research at Majmaah University for supporting this work under the Project Number No. R-2022-104.
FX  - The authors extend their appreciation to the university of Sialkot and university of engineering and technology Taxila.
CR  - Amara J., 2017, DEEP LEARN BAS APPR, P79
CR  - Aparajita, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P758, DOI 10.1109/TSP.2017.8076090
CR  - Ashqar BA., 2018, IMAGE BASED TOMATO L
CR  - Athanikar Girish, 2016, INT J COMP SCI MOB C, V5, P76
CR  - Bharali P, 2019, COMM COM INF SC, V1025, P194, DOI 10.1007/978-981-15-1384-8_16
CR  - Biswas S, 2014, 2014 IEEE CANADA INTERNATIONAL HUMANITARIAN TECHNOLOGY CONFERENCE (IHTC)
CR  - Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
CR  - Butte S, ARXIV PREPRINT ARXIV
CR  - Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
CR  - Devi TG, 2019, CLUSTER COMPUT, V22, P13415, DOI 10.1007/s10586-018-1949-x
CR  - Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
CR  - Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
CR  - Gul H, 2021, SAUDI J BIOL SCI, V28, P247, DOI 10.1016/j.sjbs.2020.09.056
CR  - Hang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194161
CR  - Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
CR  - Hu YH, 2016, SPECTROSC SPECT ANAL, V36, P515, DOI 10.3964/j.issn.1000-0593(2016)02-0515-05
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - Hughes D., 2015, ARXIV151108060
CR  - Iqbal Md Asif, 2020, 2020 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET), P43, DOI 10.1109/WiSPNET48689.2020.9198563
CR  - Islam M, 2017, CAN CON EL COMP EN
CR  - Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
CR  - Khalifa NEM., 2021, MACHINE LEARNING BIG, P63
CR  - Khan WU., 2022, ARXIV PREPRINT ARXIV
CR  - Lee T-Y., 2021, SN COMPUT SCI, V2, P1, DOI [10.1007/s42979-021-00691-9, DOI 10.1007/S42979-021-00691-9]
CR  - Mahmood A, 2021, IEEE T VEH TECHNOL, V70, P13294, DOI 10.1109/TVT.2021.3121146
CR  - Mahum R, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010026
CR  - Mahum R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186189
CR  - Masazhar ANI, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATION (ICSIMA 2017)
CR  - Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
CR  - Mondal D, 2015, 2015 INTERNATIONAL CONFERENCE ON SOFT COMPUTING TECHNIQUES AND IMPLEMENTATIONS (ICSCTI)
CR  - Oppenheim D., 2017, ADV ANIMAL BIOSC, V8, P244, DOI [10.1017/S2040470017001376, DOI 10.1017/S2040470017001376]
CR  - Oppenheim D, 2019, PHYTOPATHOLOGY, V109, P1083, DOI 10.1094/PHYTO-08-18-0288-R
CR  - Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
CR  - Patil P, 2017, IEEE I C COMP INT CO, P1071
CR  - Pavel MI, 2020, INT C MOB COMP SUST
CR  - Pinki FT., 2017, 2017 20 INT C COMP I, P1
CR  - Rangarajan AK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59108-x
CR  - Ranjan Malvika, 2015, INT J TECHNICAL RES, P331
CR  - Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
CR  - Rothe Prashant R., 2019, Innovations in Computer Science and Engineering. Proceedings of the Fifth ICICSE 2017. Lecture Notes in Networks and Systems (LNNS 32), P19, DOI 10.1007/978-981-10-8201-6_3
CR  - Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
CR  - Singh Kuldeep, 2019, International Journal of Information Technology, V11, P485, DOI 10.1007/s41870-018-0134-z
CR  - Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
CR  - Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
CR  - Soni P, 2016, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, INTELLIGENT CONTROL AND ENERGY SYSTEMS (ICPEICES 2016)
CR  - Sun GL, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/6070129
CR  - Tian Y, 2011, INTELL AUTOM SOFT CO, V17, P519, DOI 10.1080/10798587.2011.10643166
CR  - Tiwari D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P461, DOI 10.1109/ICICCS48265.2020.9121067
CR  - Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
CR  - Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7
CR  - Zhang SW, 2015, J ANIM PLANT SCI, V25, P42
PU  - TAYLOR & FRANCIS INC
PI  - PHILADELPHIA
PA  - 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
DO  - 10.1080/10807039.2022.2064814
AN  - WOS:000783775600001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  51
ER  -

TY  - JOUR
AU  - Chabot, D
AU  - Dillon, C
AU  - Francis, CM
TI  - An approach for using off-the-shelf object-based image analysis software to detect and count birds in large volumes of aerial imagery
T2  - AVIAN CONSERVATION AND ECOLOGY
LA  - English
KW  - abundance estimation
KW  - aerial surveys
KW  - automation
KW  - census techniques
KW  - data analysis
KW  - image processing
KW  - population monitoring
KW  - remote sensing
KW  - REMOTELY-SENSED IMAGERY
KW  - AUTOMATED DETECTION
KW  - POPULATION
KW  - PHOTOGRAPHS
KW  - SYSTEMS
KW  - SIZE
KW  - CLASSIFICATION
KW  - FLAMINGOS
KW  - ABUNDANCE
KW  - ANIMALS
AB  - Computer-automated image analysis techniques can save time and resources for detecting and counting birds in aerial imagery. Sophisticated object-based image analysis (OBIA) software is now widely available and has proven effective for various challenging detection tasks, but there is a need to develop accessible and readily adaptable procedures that can be implemented in an operational context. We developed a systematic, repeatable approach using commercial off-the-shelf OBIA software, and tested its effectiveness and efficiency to detect and count Lesser Snow Geese (Chen caerulescens caerulescens) in large numbers of images of breeding colonies across the Canadian Arctic that present a variety of landscapes, numerous confounding features, and varying illumination conditions and exposure levels. Coarse-scale review of analysis results was necessary to remove conspicuous clusters of commission errors, thus rendering the technique semiautomated. It was effective for imagery with spatial resolutions of 4-5 cm, producing overall accurate estimates of goose numbers compared to manual counts (R2 = 0.998, regression coefficient = 0.974) in 41 test images drawn from several breeding colonies. The total automated count (19,920) across all test images exceeded the manual count (19,836) by just 0.4%. We estimate the typical time required to review images for errors to be only 5-10% of that required to count birds manually. This could reduce the person-time required to analyze aerial photos of the major Arctic colonies of Snow Geese from several months to several days. Our approach could be adapted to many other bird detection tasks in aerial imagery by anyone possessing at least basic skills in image analysis and geographic information systems.
AD  - droneMetrics, Ottawa, ON, CanadaAD  - Environm & Climate Change Canada, Canadian Wildlife Serv, Ottawa, ON, CanadaC3  - Environment & Climate Change CanadaC3  - Canadian Wildlife ServiceFU  - Canadian Wildlife Service, Environment and Climate Change Canada
FX  - This research was funded by the Canadian Wildlife Service, Environment and Climate Change Canada. We thank K. Dufour for helping to arrange access to the imagery, and M. Mitchell for providing details on imagery acquisition and postprocessing. The work presented in this paper was entirely conducted using preexisting aerial imagery of birds that was collected by federal wildlife agencies in accordance with appropriate licenses and protocols.
CR  - Andrew ME, 2017, REMOTE SENS ECOL CON, V3, P66, DOI 10.1002/rse2.38
CR  - BAJZAK D, 1990, WILDLIFE SOC B, V18, P125
CR  - Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
CR  - Batt, 2012, ARCTIC GOOSE JOINT V
CR  - Batt B. D. J., 1997, ARCTIC JOINT VENTURE
CR  - Bechet A, 2004, J WILDLIFE MANAGE, V68, P639, DOI 10.2193/0022-541X(2004)068[0639:ETSOTG]2.0.CO;2
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Boyd WS, 2000, J FIELD ORNITHOL, V71, P686, DOI 10.1648/0273-8570-71.4.686
CR  - Buckland ST, 2012, J APPL ECOL, V49, P960, DOI 10.1111/j.1365-2664.2012.02150.x
CR  - Butler MJ, 2007, J WILDLIFE MANAGE, V71, P1639, DOI 10.2193/2006-254
CR  - Chabot D, 2016, J FIELD ORNITHOL, V87, P343, DOI 10.1111/jofo.12171
CR  - Chabot D, 2015, J UNMANNED VEH SYST, V3, P137, DOI 10.1139/juvs-2015-0021
CR  - Chabot D, 2012, WATERBIRDS, V35, P170, DOI 10.1675/063.035.0119
CR  - Chretien L.-P., 2015, REMOTE SENSING SPATI, VXL, P241, DOI [10.5194/isprsarchives-XL-1-W4-241-2015, DOI 10.5194/ISPRSARCHIVES-XL-1-W4-241-2015]
CR  - Chretien LP, 2016, WILDLIFE SOC B, V40, P181, DOI 10.1002/wsb.629
CR  - Conn PB, 2014, METHODS ECOL EVOL, V5, P1280, DOI 10.1111/2041-210X.12127
CR  - Descamps S, 2011, BIRD STUDY, V58, P302, DOI 10.1080/00063657.2011.588195
CR  - Frederick PC, 2003, J FIELD ORNITHOL, V74, P281, DOI 10.1648/0273-8570-74.3.281
CR  - GILMER DS, 1988, WILDLIFE SOC B, V16, P204
CR  - Good RE, 2007, J WILDLIFE MANAGE, V71, P395, DOI 10.2193/2005-593
CR  - Groom G., 2007, P REM SENS PHOT SOC, P252
CR  - Groom G, 2013, ECOL INFORM, V14, P2, DOI 10.1016/j.ecoinf.2012.12.001
CR  - Groom G, 2011, INT J REMOTE SENS, V32, P4611, DOI 10.1080/01431161.2010.489068
CR  - Hollings T, 2018, METHODS ECOL EVOL, V9, P881, DOI 10.1111/2041-210X.12973
CR  - Kerbes R.H., 2014, ARCTIC GOOSE JOINT V
CR  - Kerbes RH, 2006, TECHNICAL REPORT SER, V447
CR  - Kingsford RT, 2009, WILDLIFE RES, V36, P29, DOI 10.1071/WR08034
CR  - Laliberte AS, 2003, WILDLIFE SOC B, V31, P362
CR  - LaRue MA, 2017, CONSERV BIOL, V31, P213, DOI 10.1111/cobi.12809
CR  - Lefebvre J, 2017, AMBIO, V46, P262, DOI 10.1007/s13280-016-0887-1
CR  - Longmore SN, 2017, INT J REMOTE SENS, V38, P2623, DOI 10.1080/01431161.2017.1280639
CR  - Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
CR  - Maire F, 2015, LECT NOTES ARTIF INT, V9457, P386, DOI 10.1007/978-3-319-26350-2_34
CR  - Marburg A, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761146
CR  - Maussang F., 2015, P MTS IEEE OC C 18 2, DOI [10.1109/OCEANS-Genova.2015.7271678, DOI 10.1109/OCEANS-GENOVA.2015.7271678]
CR  - McNeill S, 2011, INT GEOSCI REMOTE SE, P4312, DOI 10.1109/IGARSS.2011.6050185
CR  - NABCI, 2016, STAT N AM BIRDS 2016
CR  - Redding N. J., 1999, P C DIG IM COMP TECH
CR  - Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
CR  - Rosenberg KV, 2017, CONDOR, V119, P594, DOI 10.1650/CONDOR-17-57.1
CR  - Seymour AC, 2017, SCI REP-UK, V7, DOI 10.1038/srep45127
CR  - Torney CJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156342
CR  - Trathan PN, 2004, WILDLIFE SOC B, V32, P332, DOI 10.2193/0091-7648(2004)32[332:IAOCAP]2.0.CO;2
CR  - Warner T, 2011, GEOGR COMPASS, V5, P781, DOI 10.1111/j.1749-8198.2011.00451.x
CR  - Woodworth BL, 1997, AFR J ECOL, V35, P326, DOI 10.1111/j.1365-2028.1997.098-89098.x
PU  - RESILIENCE ALLIANCE
PI  - WOLFVILLE
PA  - ACADIA UNIV, BIOLOGY DEPT, WOLFVILLE, NS B0P 1X0, CANADA
DA  - JUN
PY  - 2018
VL  - 13
IS  - 1
DO  - 10.5751/ACE-01205-130115
AN  - WOS:000438899000016
N1  - Times Cited in Web of Science Core Collection:  18
Total Times Cited:  18
Cited Reference Count:  45
ER  -

TY  - JOUR
AU  - Spitz, DB
AU  - Hebblewhite, M
AU  - Stephenson, TR
TI  - 'MigrateR': extending model-driven methods for classifying and quantifying animal movement behavior
T2  - ECOGRAPHY
LA  - English
KW  - DIEL VERTICAL MIGRATION
KW  - HABITAT
KW  - SPACE
KW  - SIZE
AB  - To be useful, definitions of animal movement behavior (e.g. migration) should be quantitatively rigorous, flexible enough to accommodate variation in species biology (e.g. latitudinal vs elevational movement) and sufficiently general to allow comparison among different species. Recent studies have applied a model-driven approach to classifying and quantifying animal movement from global positioning system (GPS) location data. We improve upon these methods by 1) revising model structure to provide a simple biologically-defensible basis to reduce misclassification; 2) introducing a data-efficient tool that can be used to quantify and circumvent model sensitivity to starting location; and 3) illustrating how existing models can be adapted to describe short-distance migration, using elevational migration as an example. These improvements are included in 'migrateR', an open source R package that expands and automates model-driven classification and quantification of animal movement behavior. We demonstrate the software and these improved methods using GPS-collar location data from a long-distance migrant, elk Cervus elaphus, and a short-distance elevational migrant, Sierra Nevada bighorn sheep Ovis canadensis sierrae. We provide in-text example code and a supplementary script illustrating how default options can be revised to meet several common challenges in fitting movement models.
AD  - Oregon State Univ, Dept Fisheries & Wildlife, Corvallis, OR 97331 USAAD  - Univ Montana, Coll Forestry & Conservat, Missoula, MT 59812 USAAD  - Calif Dept Fish & Wildlife, Sierra Nevada Bighorn Sheep Recovery Program, Sacramento, CA USAC3  - Oregon State UniversityC3  - University of Montana SystemC3  - University of MontanaCR  - ALBON SD, 1992, OIKOS, V65, P502, DOI 10.2307/3545568
CR  - Bauer S, 2014, SCIENCE, V344, P54, DOI 10.1126/science.1242552
CR  - BEAMISH FWH, 1966, J FISH RES BOARD CAN, V23, P109, DOI 10.1139/f66-009
CR  - Beatty WS, 2015, J WILDLIFE MANAGE, V79, P1153, DOI 10.1002/jwmg.920
CR  - Blake S, 2013, J ANIM ECOL, V82, P310, DOI 10.1111/1365-2656.12020
CR  - Borger L, 2012, DISPERSAL ECOLOGY AND EVOLUTION, P222
CR  - Bolger DT, 2008, ECOL LETT, V11, P63
CR  - Bolker B.M, 2008, ECOLOGICAL MODELS DA
CR  - Boyle WA, 2010, P ROY SOC B-BIOL SCI, V277, P2511, DOI 10.1098/rspb.2010.0344
CR  - Bunnefeld N, 2011, J ANIM ECOL, V80, P466, DOI 10.1111/j.1365-2656.2010.01776.x
CR  - Burnham KP., 2002, MODEL SELECTION MULT
CR  - Cagnacci F, 2016, J ANIM ECOL, V85, P54, DOI 10.1111/1365-2656.12449
CR  - Cagnacci F, 2011, OIKOS, V120, P1790, DOI 10.1111/j.1600-0706.2011.19441.x
CR  - Calenge C, 2006, ECOL MODEL, V197, P516, DOI 10.1016/j.ecolmodel.2006.03.017
CR  - Dingle H, 2006, J ORNITHOL, V147, P212, DOI 10.1007/s10336-005-0052-2
CR  - Dingle H, 2007, BIOSCIENCE, V57, P113, DOI 10.1641/B570206
CR  - Eggeman SL, 2016, J ANIM ECOL, V85, P785, DOI 10.1111/1365-2656.12495
CR  - Gutierrez D, 2014, OECOLOGIA, V175, P861, DOI 10.1007/s00442-014-2952-4
CR  - Hebblewhite M., 2016, MOVEBANK DATA RESP, DOI 10.5441/001/1.k8s2g5v7
CR  - James MC, 2006, CAN J ZOOL, V84, P754, DOI 10.1139/Z06-046
CR  - Kays R, 2015, SCIENCE, V348, DOI 10.1126/science.aaa2478
CR  - Kranstauber B, 2011, ENVIRON MODELL SOFTW, V26, P834, DOI 10.1016/j.envsoft.2010.12.005
CR  - LAMPERT W, 1989, FUNCT ECOL, V3, P21, DOI 10.2307/2389671
CR  - McGuire LP, 2013, BIOL REV, V88, P767, DOI 10.1111/brv.12024
CR  - MilnerGulland EJ, 2011, ANIMAL MIGRATION: A SYNTHESIS, P1, DOI 10.1093/acprof:oso/9780199568994.001.0001
CR  - Mysterud A, 2011, OIKOS, V120, P1817, DOI 10.1111/j.1600-0706.2010.19439.x
CR  - Naidoo R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036527
CR  - Nielsen JK, 2014, MAR ECOL PROG SER, V517, P229, DOI 10.3354/meps11043
CR  - Sims DW, 2006, J ANIM ECOL, V75, P176, DOI 10.1111/j.1365-2656.2005.01033.x
CR  - Singh NJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149594
CR  - Spitz D. B, 2015, THESIS
CR  - Turchin Peter, 1998
CR  - Van Moorter B, 2016, J ANIM ECOL, V85, P21, DOI 10.1111/1365-2656.12394
CR  - Wiktander U, 2001, BIOL CONSERV, V100, P387, DOI 10.1016/S0006-3207(01)00045-3
CR  - Wilcove DS, 2008, PLOS BIOL, V6, P1361, DOI 10.1371/journal.pbio.0060188
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - JUN
PY  - 2017
VL  - 40
IS  - 6
SP  - 788
EP  - 799
DO  - 10.1111/ecog.02587
AN  - WOS:000403075500011
N1  - Times Cited in Web of Science Core Collection:  39
Total Times Cited:  39
Cited Reference Count:  35
ER  -

TY  - JOUR
AU  - Bertacchi, A
AU  - Giannini, V
AU  - Di Franco, C
AU  - Silvestri, N
TI  - Using unmanned aerial vehicles for vegetation mapping and identification of botanical species in wetlands
T2  - LANDSCAPE AND ECOLOGICAL ENGINEERING
LA  - English
KW  - UAVs
KW  - Aerial photos
KW  - Vegetation map
KW  - Wetland
KW  - Phragmites
KW  - Myriophyllum
KW  - Tuscany
KW  - RECLAIMED PEATY SOILS
KW  - AIRCRAFT SYSTEMS
KW  - HIGH-RESOLUTION
KW  - CLASSIFICATION
KW  - BIODIVERSITY
KW  - RESTORATION
KW  - IMAGERY
KW  - EUROPE
AB  - High-resolution aerial photographs have important applications in vegetation mapping, especially in environments, such as wetlands, which are not easily accessible by ground operators. Unmanned aerial vehicles (UAVs), equipped with cameras capable of taking photographs of < 1 cm pixel resolution, are promising not only for the vegetation mapping but also for the identification of plant species. This paper illustrated the results of three different flight heights (5 m = 3.5126 mm/pixel; 10 m = 7.0252 mm/pixel; 25 m = 17.5630 mm/pixel), using 12MP images and their magnification, on the identification of vegetation and botanical species in a rewetted peatland populated mainly by Phragmites australis and Myriophyllum aquaticum within the Massaciuccoli Lake basin (Northern Tuscany, Italy). Among the obtained images, we selected the best flight height for the vegetation mapping and the botanical identification of the plant species using both visual and automated image analyses. Images taken from flights at 25 m of height proved to be useful for a sufficiently detailed mapping, while those from 10 m of height were more suitable for the detection of plant microcommunities. However, the most accurate identification of the species (at the taxonomic level of genus/species) was possible only with the images taken from 5 m of height.
AD  - Univ Pisa, DAFE, Via Borghetto 80, I-56124 Pisa, ItalyAD  - Scuola Super Sant Anna, Inst Life Sci, Piazza Martiri Liberta 33, I-56127 Pisa, ItalyAD  - Scuola Super Sant Anna, TECIP, Via Moruzzi 1, I-56124 Pisa, ItalyC3  - University of PisaC3  - Scuola Superiore Sant'AnnaC3  - Scuola Superiore Sant'AnnaFU  - Consorzio di Bonifica Versilia-Massaciuccoli; Regione Toscana
FX  - This work was supported by the "Consorzio di Bonifica Versilia-Massaciuccoli" later "Consorzio di Bonifica 1 Toscana Nord" and funded by the "Regione Toscana".
CR  - Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
CR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - Bertacchi A, 2015, 2 INT C PLANT SCI 11
CR  - Biondi E, 2014, PLANT BIOSYST, V148, P318, DOI 10.1080/11263504.2014.892907
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Braun-Blanquet J., 1983, PLANT SOCIOLOGY STUD
CR  - Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343
CR  - CARPENTER SR, 1997, RESILIENCE RESTORATI
CR  - Ciccolini V, 2013, RESTORATION MEDITERR
CR  - Davies B, 2008, AGR ECOSYST ENVIRON, V125, P1, DOI 10.1016/j.agee.2007.10.006
CR  - de Groot R.S., 1992, FUNCTIONS NATURE EVA
CR  - Fitzgerald DG, 2006, FISHERIES, V31, P61, DOI 10.1577/1548-8446(2006)31[61:FHQSAV]2.0.CO;2
CR  - Fujimura Y, 2013, LANDSC ECOL ENG, V9, P305, DOI 10.1007/s11355-012-0193-4
CR  - Getzin S, 2012, METHODS ECOL EVOL, V3, P397, DOI 10.1111/j.2041-210X.2011.00158.x
CR  - Giannini V, 2018, J ENVIRON MANAGE, V208, P92, DOI 10.1016/j.jenvman.2017.12.016
CR  - Giannini V, 2017, ECOL ENG, V103, P478, DOI 10.1016/j.ecoleng.2015.11.049
CR  - Henderson FM, 2008, INT J REMOTE SENS, V29, P5809, DOI 10.1080/01431160801958405
CR  - HOWLAND WG, 1980, PHOTOGRAMM ENG REM S, V46, P87
CR  - Husson E, 2014, APPL VEG SCI, V17, P567, DOI 10.1111/avsc.12072
CR  - Ishihama F, 2012, APPL VEG SCI, V15, P383, DOI 10.1111/j.1654-109X.2012.01184.x
CR  - Kaneko K., 2014, Journal of Geographic Information System, V6, P733, DOI 10.4236/jgis.2014.66060
CR  - Keddy P.A, 2000, WETLAND ECOLOGY PRIN
CR  - Klemas V, 2013, INT J REMOTE SENS, V34, P6286, DOI 10.1080/01431161.2013.800656
CR  - Klimkowska A, 2010, PERSPECT PLANT ECOL, V12, P245, DOI 10.1016/j.ppees.2010.02.004
CR  - Klotzli F, 2001, RESTOR ECOL, V9, P209, DOI 10.1046/j.1526-100x.2001.009002209.x
CR  - Kottek M, 2006, METEOROL Z, V15, P259, DOI 10.1127/0941-2948/2006/0130
CR  - Laliberte AS, 2011, GISCI REMOTE SENS, V48, P4, DOI 10.2747/1548-1603.48.1.4
CR  - Lastrucci L., 2017, Plant Sociology, V54, P67, DOI 10.7338/pls2017541/03
CR  - Marcaccio JV, 2016, J UNMANNED VEH SYST, V4, P193, DOI 10.1139/juvs-2015-0016
CR  - Martin J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038882
CR  - Muro J, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100795
CR  - Oertli B, 2002, BIOL CONSERV, V104, P59, DOI 10.1016/S0006-3207(01)00154-9
CR  - Pellegrino E, 2015, AGR ECOSYST ENVIRON, V199, P164, DOI 10.1016/j.agee.2014.09.004
CR  - Penning WE, 2008, AQUAT ECOL, V42, P253, DOI 10.1007/s10452-008-9183-x
CR  - Rebelo LM, 2009, J ENVIRON MANAGE, V90, P2144, DOI 10.1016/j.jenvman.2007.06.027
CR  - Sandbrook C, 2015, AMBIO, V44, pS636, DOI 10.1007/s13280-015-0714-0
CR  - Schmidt KS, 2003, REMOTE SENS ENVIRON, V85, P92, DOI 10.1016/S0034-4257(02)00196-7
CR  - Shahbazi M, 2014, GISCI REMOTE SENS, V51, P339, DOI 10.1080/15481603.2014.926650
CR  - Verhoeven JTA, 2014, ECOL ENG, V66, P6, DOI 10.1016/j.ecoleng.2013.03.006
CR  - Vymazal J, 2007, SCI TOTAL ENVIRON, V380, P48, DOI 10.1016/j.scitotenv.2006.09.014
CR  - Watts AC, 2010, J WILDLIFE MANAGE, V74, P1614, DOI 10.2193/2009-425
CR  - Xie YC, 2008, J PLANT ECOL, V1, P9, DOI 10.1093/jpe/rtm005
CR  - Yabe K, 2010, LANDSC ECOL ENG, V6, P201, DOI 10.1007/s11355-009-0098-z
CR  - Zak D, 2014, ECOL ENG, V66, P82, DOI 10.1016/j.ecoleng.2013.10.003
CR  - Zedler JB, 2005, ANNU REV ENV RESOUR, V30, P39, DOI 10.1146/annurev.energy.30.050504.144248
PU  - SPRINGER JAPAN KK
PI  - TOKYO
PA  - SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005, JAPAN
DA  - APR
PY  - 2019
VL  - 15
IS  - 2
SP  - 231
EP  - 240
DO  - 10.1007/s11355-018-00368-1
AN  - WOS:000464030400012
N1  - Times Cited in Web of Science Core Collection:  8
Total Times Cited:  8
Cited Reference Count:  45
ER  -

TY  - JOUR
AU  - Putland, RL
AU  - Ranjard, L
AU  - Constantine, R
AU  - Radford, CA
TI  - A hidden Markov model approach to indicate Bryde's whale acoustics
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Acoustic detection
KW  - Cetacean
KW  - Hidden markov models
KW  - Noise mitigation
KW  - Passive acoustic monitoring
KW  - Temporal variation
KW  - GULF-OF-MEXICO
KW  - BALAENOPTERA-EDENI
KW  - HUMPBACK WHALES
KW  - MEGAPTERA-NOVAEANGLIAE
KW  - SEASONAL OCCURRENCE
KW  - NEW-ZEALAND
KW  - CALLS
KW  - SOUND
KW  - CLASSIFICATION
KW  - VOCALIZATIONS
AB  - Increasing sound in the ocean from human activity potentially threatens marine animals that use sound to communicate, detect prey, avoid predators and function within their ecosystem. The detection and classification of sound produced by marine animals, such as whales and fish, is an important component in noise mitigation strategies, while also providing valuable insights into their ecology. Traditionally, visual surveys are conducted to assess how these animals utilize a specific area, often underestimating the number of individuals as they don't spend much time at the surface. Long-term passive acoustic monitoring efforts have become more prevalent to monitor such animals. The large datasets collected can be impractical to manually process, necessitating the development of automated detection methods, which often produce mixed results owing to the broad frequency range and variable duration of many biological sounds. Here we describe a novel approach for automated detection of underwater biophonic sounds employing hidden Markov models (HMM). Acoustic data was collected at a single listening station in Hauraki Gulf, from October 2014 to April 2016. HMM detection models were developed for Bryde's whales (Balaenoptera edeni) that were used as a model organism because they are notoriously hard to study with traditional visual surveys and produce a characteristic call. Bryde's whale calls also directly overlap the sounds of anthropogenic activity, in particular the sound of vessels transiting to the busiest port in New Zealand; therefore monitoring whale calls is of utmost importance when confronting increasing sound in the ocean. Vocalizations were detected with a sensitivity of 77% and false positive rate of 23%. Bryde's whale vocalizations were detected on 11% of all recordings. Overall, there were significantly more detections during summer (n = 1716) than winter (n = 447), and significantly more during the day (n = 1991) compared to night (n = 1264). This study shows the feasibility of using HMMs on long-term acoustic datasets. The method has the potential to be used for a wide range of soniferous animals who, like the Bryde's whale, also produce unique sounds. The detection method would be particularly useful for mitigation and management strategies of species that are difficult to detect using traditional visual methods.
AD  - Univ Auckland, Inst Marine Sci, Leigh Marine Lab, POB 349, Warkworth 0941, New ZealandAD  - Australian Natl Univ, Res Sch Biol, ANU Coll Med Biol & Environm, Canberra, ACT 0200, AustraliaAD  - Univ Auckland, Sch Biol Sci, Private Bag 92019, Auckland, New ZealandC3  - University of AucklandC3  - Australian National UniversityC3  - University of AucklandFU  - Rutherford Discovery Fellowship from the Royal Society of New Zealand [RDF-U0A1302]
FX  - This research was funded by a Rutherford Discovery Fellowship from the Royal Society of New Zealand (RDF-U0A1302) to CAR, including a PhD scholarship to RLP.
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Baker C, 2016, CONSERVATION STATUS
CR  - Best PB, 2001, MAR ECOL PROG SER, V220, P277, DOI 10.3354/meps220277
CR  - Binder C., 2016, J ACOUST SOC AM, V140, P2949
CR  - Brown JC, 2009, J ACOUST SOC AM, V125, pEL221, DOI 10.1121/1.3124659
CR  - Butler J, 2017, ECOL INDIC, V77, P377, DOI 10.1016/j.ecolind.2017.02.041
CR  - Compton R, 2008, MAR POLICY, V32, P255, DOI 10.1016/j.marpol.2007.05.005
CR  - Constantine R, 2015, BIOL CONSERV, V186, P149, DOI 10.1016/j.biocon.2015.03.008
CR  - CUMMINGS WC, 1986, FISH B-NOAA, V84, P359
CR  - Dunlop RA, 2007, J ACOUST SOC AM, V122, P2893, DOI 10.1121/1.2783115
CR  - Dunlop RA, 2016, ANIM BEHAV, V111, P13, DOI 10.1016/j.anbehav.2015.10.002
CR  - Edds-Walton Peggy L., 1997, Bioacoustics, V8, P47
CR  - Erbe C., 2012, EFFECTS NOISE AQUATI
CR  - Gillespie D., 2008, P I ACOUSTICS, V30
CR  - Hatch L, 2008, ENVIRON MANAGE, V42, P735, DOI 10.1007/s00267-008-9169-4
CR  - Hawkins AD, 2017, ICES J MAR SCI, V74, P635, DOI 10.1093/icesjms/fsw205
CR  - Heimlich SL, 2005, J ACOUST SOC AM, V118, P1830, DOI 10.1121/1.1992674
CR  - Jaramillo-Legorreta A, 2017, CONSERV BIOL, V31, P183, DOI 10.1111/cobi.12789
CR  - Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
CR  - Kelly S., 2014, STATE OUR GULF 2014, P2014
CR  - Kerosky SM, 2012, DEEP-SEA RES PT I, V65, P125, DOI 10.1016/j.dsr.2012.03.013
CR  - Kogan JA, 1998, J ACOUST SOC AM, V103, P2185, DOI 10.1121/1.421364
CR  - Kozmian-Ledward L., 2014, SPATIAL ECOLOGY CETA
CR  - Marcoux M, 2017, POLAR BIOL, V40, P1127, DOI 10.1007/s00300-016-2040-9
CR  - McDonald EM, 2017, ECOL INDIC, V72, P360, DOI 10.1016/j.ecolind.2016.08.028
CR  - McDonald MA, 2006, NEW ZEAL J MAR FRESH, V40, P519, DOI 10.1080/00288330.2006.9517442
CR  - Mellinger D. K., 2004, Canadian Acoustics, V32, P55
CR  - Mellinger DK, 2007, OCEANOGRAPHY, V20, P36, DOI 10.5670/oceanog.2007.03
CR  - Mellinger DK, 2007, MAR MAMMAL SCI, V23, P856, DOI 10.1111/j.1748-7692.2007.00144.x
CR  - Merchant ND, 2016, SCI REP-UK, V6, DOI 10.1038/srep36942
CR  - Miksis-Olds JL, 2016, J ACOUST SOC AM, V139, P501, DOI 10.1121/1.4938237
CR  - Miksis-Olds JL, 2013, J ACOUST SOC AM, V134, P3464, DOI 10.1121/1.4821537
CR  - Munger L. M., 2005, Canadian Acoustics, V33, P25
CR  - MUNK WH, 1994, J ACOUST SOC AM, V96, P2330, DOI 10.1121/1.410105
CR  - Nedelec SL, 2015, MAR ECOL PROG SER, V524, P125, DOI 10.3354/meps11175
CR  - Oleson EM, 2003, MAR MAMMAL SCI, V19, P407
CR  - Oswald JN, 2011, J ACOUST SOC AM, V129, P3353, DOI 10.1121/1.3575555
CR  - Parks SE, 2016, P M AC, V27
CR  - Parks SE, 2014, SCI REP-UK, V4, DOI 10.1038/srep07508
CR  - Putland RL, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-06347-0
CR  - Radford CA, 2010, MAR ECOL PROG SER, V401, P21, DOI 10.3354/meps08451
CR  - Ranjard L., 2016, METHODS ECOL EVOL
CR  - Ranjard L, 2015, J ACOUST SOC AM, V137, P2542, DOI 10.1121/1.4919329
CR  - Ren Y, 2009, ALGORITHMS, V2, P1410, DOI 10.3390/a2041410
CR  - Rice AN, 2014, J ACOUST SOC AM, V135, P3066, DOI 10.1121/1.4870057
CR  - Risch D, 2014, MOV ECOL, V2, DOI 10.1186/s40462-014-0024-3
CR  - Roch MA, 2016, ECOL INFORM, V31, P122, DOI 10.1016/j.ecoinf.2015.12.002
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Scheifele PM, 2015, J ACOUST SOC AM, V138, pEL105, DOI 10.1121/1.4922768
CR  - Sirovic A, 2014, MAR MAMMAL SCI, V30, P399, DOI 10.1111/mms.12036
CR  - Smith JN, 2008, ANIM BEHAV, V76, P467, DOI 10.1016/j.anbehav.2008.02.013
CR  - Somervuo P, 2006, IEEE T AUDIO SPEECH, V14, P2252, DOI 10.1109/TASL.2006.872624
CR  - SPIESBERGER JL, 1990, AM NAT, V135, P107, DOI 10.1086/285035
CR  - Stafford KM, 2017, J ACOUST SOC AM, V141, P3939
CR  - Stanley J. A., 2016, P M AC, V27
CR  - TERSHY BR, 1992, J MAMMAL, V73, P477, DOI 10.2307/1382013
CR  - TINDLE CT, 1978, J ACOUST SOC AM, V64, P1178, DOI 10.1121/1.382080
CR  - TINDLE CT, 1982, J ACOUST SOC AM, V71, P1145, DOI 10.1121/1.387760
CR  - Vieira M, 2015, J ACOUST SOC AM, V138, P3941, DOI 10.1121/1.4936858
CR  - Wambergue B., 2014, REV PRACTICAL IMPLEM
CR  - Weisburn B.A., 1993, AC SPEECH SIGN PROC, V1, P269
CR  - Williamson LD, 2017, MAR ECOL PROG SER, V570, P223, DOI 10.3354/meps12118
CR  - Wiseman N, 2011, MAR MAMMAL SCI, V27, pE253, DOI 10.1111/j.1748-7692.2010.00454.x
CR  - Yack T., 2009, TESTING VALIDATION A
CR  - Young S.J., 2006, HTK BOOK VERSION 3 4
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - JAN
PY  - 2018
VL  - 84
SP  - 479
EP  - 487
DO  - 10.1016/j.ecolind.2017.09.025
AN  - WOS:000425828200049
N1  - Times Cited in Web of Science Core Collection:  24
Total Times Cited:  24
Cited Reference Count:  65
ER  -

TY  - JOUR
AU  - Ulloa, JS
AU  - Aubin, T
AU  - Llusia, D
AU  - Bouveyron, C
AU  - Sueur, J
TI  - Estimating animal acoustic diversity in tropical environments using unsupervised multiresolution analysis
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Ecoacoustic monitoring
KW  - Acoustic community
KW  - Unsupervised machine learning
KW  - Wavelets
KW  - Nocturnal soundscape
KW  - CLIMATE-CHANGE
KW  - RAIN-FOREST
KW  - BIODIVERSITY
KW  - INDEXES
KW  - MODEL
KW  - CLASSIFICATION
KW  - SOUNDSCAPE
KW  - AUDIO
KW  - ECOACOUSTICS
KW  - PERFORMANCE
AB  - Ecoacoustic monitoring has proved to be a viable approach to capture ecological data related to animal communities. While experts can manually annotate audio samples, the analysis of large datasets can be significantly facilitated by automatic pattern recognition methods. Unsupervised learning methods, which do not require labelled data, are particularly well suited to analyse poorly documented habitats, such as tropical environments. Here we propose a new method, named Multiresolution Analysis of Acoustic Diversity (MAAD), to automate the detection of relevant structure in audio data. MAAD was designed to decompose the acoustic community into few elementary components (soundtypes) based on their time-frequency attributes. First, we used the short-time Fourier transform to detect regions of interest (ROIs) in the time-frequency domain. Then, we characterised these ROIs by (1) estimating the median frequency and (2) by running a 2D wavelet analysis at multiple scales and angles. Finally, we grouped the ROIs using a model-based subspace clustering technique so that ROIs were automatically annotated and clustered into soundtypes. To test the performance of the automatic method, we applied MAAD to two distinct tropical environments in French Guiana, a lowland high rainforest and a rock savanna, and we compared manual and automatic annotations using the adjusted Rand index. The similarity between the manual and automated partitions was high and consistent, indicating that the clusters found are intelligible and can be used for further analysis. Moreover, the weight of the features estimated by the clustering process revealed important information about the structure of the acoustic communities. In particular, the median frequency had the strongest effect on modelling the clusters and on classification performance, suggesting a role in community organisation. The number of clusters found in MAAD can be regarded as an estimation of the soundtype richness in a given environment. MAAD is a comprehensive and promising method to automatically analyse passive acoustic recordings. Combining MAAD and manual analysis would maximally exploit the strengths of both human reasoning and computer algorithms. Thereby, the composition of the acoustic community could be estimated accurately, quickly and at large scale.
AD  - Sorbonne Univ, Inst Systemat Evolut Biodiversite ISYEB, Museum Natl Hist Nat, CNRS,UPMC,EPHE, 57 Rue Cuvier,CP 50, F-75005 Paris, FranceAD  - Univ Paris 11, Equipe Commun Acoust, UMR NeuroPSI 9197, CNRS, Bat 446, F-91405 Orsay, FranceAD  - Univ Paris 05, Lab MAP5, UMR CNRS 8145, Paris, FranceAD  - Sorbonne Paris Cite, Paris, FranceC3  - Centre National de la Recherche Scientifique (CNRS)C3  - Museum National d'Histoire Naturelle (MNHN)C3  - UDICE-French Research UniversitiesC3  - League of European Research Universities - LERUC3  - Sorbonne UniversiteC3  - PSL Research University ParisC3  - Ecole Pratique des Hautes Etudes (EPHE)C3  - Universite de ParisC3  - Centre National de la Recherche Scientifique (CNRS)C3  - UDICE-French Research UniversitiesC3  - League of European Research Universities - LERUC3  - Universite Paris SaclayC3  - Centre National de la Recherche Scientifique (CNRS)C3  - CNRS - National Institute for Mathematical Sciences (INSMI)C3  - UDICE-French Research UniversitiesC3  - Universite de ParisFU  - CEBA (Centre d'Etude de la Biodiversite Amazonienne); SABIOD MASTODONS Big Data CNRS MI project; Fyssen Foundation; COLCIENCIAS (Colombian government)
FX  - This research was supported by the Labex CEBA (Centre d'Etude de la Biodiversite Amazonienne) and the SABIOD MASTODONS Big Data (CNRS MI project 2012-2017). We would like to warmly thank Philippe Gaucher, Elodie Courtois and Patrick Chatelet for their help during our stay at the Nouragues research station. We specially thank Julio Pedraza who provided valuable advices on the use of high performance computing clusters to run batch process. We also would like to thank Laure Desutter-Grandcolas and Elodie Courtois for their help in identifying clusters to a species-specific acoustic signal. DLL was supported by the Fyssen Foundation (Post-doctoral Grant). JSU was supported by COLCIENCIAS (Doctoral Scholarship of the Colombian government). The authors declare no conflict of interest. We finally wish to acknowledge the valuable help of two anonymous referees for their remarks and comments on the manuscript.
CR  - AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
CR  - Baudry JP, 2012, STAT COMPUT, V22, P455, DOI 10.1007/s11222-011-9236-1
CR  - Berge L., 2012, J STAT SOFTWARE, V46
CR  - Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9
CR  - Bioacoustics Research Program, 2014, RAV PRO INT SOUND AN
CR  - Birge L, 2007, PROBAB THEORY REL, V138, P33, DOI 10.1007/s00440-006-0011-8
CR  - BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
CR  - Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009
CR  - Bouveyron C, 2015, ANN APPL STAT, V9, P1726, DOI 10.1214/15-AOAS861
CR  - Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
CR  - Bringers F., 2001, NOURAGUES DYNAMICS P
CR  - Buscaino G, 2016, SCI REP-UK, V6, DOI 10.1038/srep34230
CR  - Depraetere M, 2012, ECOL INDIC, V13, P46, DOI 10.1016/j.ecolind.2011.05.006
CR  - Deslonqueres C., 2015, PEERJ, V3, pe1393
CR  - Dong XY, 2015, ECOL INFORM, V29, P66, DOI 10.1016/j.ecoinf.2015.07.007
CR  - Dugan P, 2013, PROCEDIA COMPUT SCI, V20, P156, DOI 10.1016/j.procs.2013.09.254
CR  - Eldridge A, 2016, PEERJ, V4, DOI 10.7717/peerj.2108
CR  - Farina A, 2015, BIOACOUSTICS, V24, P269, DOI 10.1080/09524622.2015.1070282
CR  - Fletcher NH, 2014, SPRINGER HANDBOOK OF ACOUSTICS, 2ND EDITION, P821
CR  - Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131
CR  - Ruiz-Munoz JF, 2016, ECOL INFORM, V33, P75, DOI 10.1016/j.ecoinf.2016.04.001
CR  - Fuller S, 2015, ECOL INDIC, V58, P207, DOI 10.1016/j.ecolind.2015.05.057
CR  - Ganchev TD, 2015, EXPERT SYST APPL, V42, P6098, DOI 10.1016/j.eswa.2015.03.036
CR  - Gasc A, 2015, BIOL CONSERV, V191, P306, DOI 10.1016/j.biocon.2015.06.018
CR  - GERHARDT HC, 1994, ANNU REV ECOL SYST, V25, P293, DOI 10.1146/annurev.es.25.110194.001453
CR  - Gerhardt HC., 2002, ACOUSTIC COMMUNICATI
CR  - Harris SA, 2016, METHODS ECOL EVOL, V7, P713, DOI 10.1111/2041-210X.12527
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
CR  - Kendrick P., 2016, INT C SOUND VIBR ICS
CR  - Kershenbaum A, 2016, BIOL REV, V91, P13, DOI 10.1111/brv.12160
CR  - Krause B. L., 1993, SOUNDSCAPE NEWSL, V6, P4
CR  - Krause B, 2016, BIOL CONSERV, V195, P245, DOI 10.1016/j.biocon.2016.01.013
CR  - Lellouch L, 2014, METHODS ECOL EVOL, V5, P495, DOI 10.1111/2041-210X.12178
CR  - Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920
CR  - Magurran AE., 2004, MEASURING BIOL DIVER
CR  - Mallat S.G, 2009, WAVELET TOUR SIGNAL
CR  - Parks SE, 2014, ECOL INFORM, V21, P81, DOI 10.1016/j.ecoinf.2013.11.003
CR  - Pekin BK, 2012, LANDSCAPE ECOL, V27, P1513, DOI 10.1007/s10980-012-9806-4
CR  - Pereira HM, 2013, SCIENCE, V339, P277, DOI 10.1126/science.1229931
CR  - Petrou ZI, 2015, BIODIVERS CONSERV, V24, P2333, DOI 10.1007/s10531-015-0947-z
CR  - PIMM SL, 1995, SCIENCE, V269, P347, DOI 10.1126/science.269.5222.347
CR  - Potamitis I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096936
CR  - R Core Team, 2017, R LANG ENV STAT COMP
CR  - RIEDE K, 1993, AMBIO, V22, P546
CR  - Rodriguez A, 2014, ECOL INFORM, V21, P133, DOI 10.1016/j.ecoinf.2013.12.006
CR  - Sarthou C., 2001, PLANT COMMUNITIES GR, P64
CR  - Schmidt AKD, 2013, BEHAV ECOL, V24, P470, DOI 10.1093/beheco/ars187
CR  - SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
CR  - Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
CR  - Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
CR  - Sueur J, 2002, BIOL J LINN SOC, V75, P379, DOI 10.1111/j.1095-8312.2002.tb02079.x
CR  - Sueur J, 2015, BIOSEMIOTICS-NETH, V8, P493, DOI 10.1007/s12304-015-9248-x
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121
CR  - Towsey M, 2014, ECOL INFORM, V21, P1, DOI 10.1016/j.ecoinf.2014.02.002
CR  - Tukey J.W., 1977, EXPLORATORY DATA ANA
CR  - Ulloa JS, 2016, ECOL INFORM, V31, P91, DOI 10.1016/j.ecoinf.2015.11.012
CR  - Villanueva-Rivera LJ, 2014, PEERJ, V2, DOI 10.7717/peerj.496
CR  - Way MJ, 2012, CH CRC DATA MIN KNOW, pXIII
CR  - Webb AR, 2011, STAT PATTERN RECOGNI, VThird
CR  - Xie J, 2016, ECOL INFORM, V32, P134, DOI 10.1016/j.ecoinf.2016.01.007
CR  - Yu G, 2008, IEEE T SIGNAL PROCES, V56, P1830, DOI 10.1109/TSP.2007.912893
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - JUL
PY  - 2018
VL  - 90
SP  - 346
EP  - 355
DO  - 10.1016/j.ecolind.2018.03.026
AN  - WOS:000440266100036
N1  - Times Cited in Web of Science Core Collection:  17
Total Times Cited:  17
Cited Reference Count:  63
ER  -

TY  - JOUR
AU  - Andrew, ME
AU  - Shephard, JM
TI  - Semi-automated detection of eagle nests: an application of very high-resolution image data and advanced image analyses to wildlife surveys
T2  - REMOTE SENSING IN ECOLOGY AND CONSERVATION
LA  - English
KW  - eCognition
KW  - Haliaeetus leucogaster
KW  - image analysis
KW  - Maxent
KW  - nest surveys
KW  - object-based image analyses (OBIA)
KW  - white-bellied sea eagle
KW  - HALIAEETUS-LEUCOGASTER
KW  - GOOGLE EARTH
KW  - AERIAL-PHOTOGRAPHY
KW  - BALD EAGLES
KW  - SPECIES DISTRIBUTIONS
KW  - POPULATION
KW  - CONSERVATION
KW  - BAY
KW  - CLASSIFICATION
KW  - ABUNDANCE
AB  - Very high-resolution (VHR) image data, including from unmanned aerial vehicle (UAV) platforms, are increasingly acquired for wildlife surveys. Animals or structures they build (e.g. nests) can be photointerpreted from these images, however, automated detection is required for more efficient surveys. We developed semi-automated analyses to map white-bellied sea eagle (Haliaeetus leucogaster) nests in VHR aerial photographs of the Houtman Abrolhos Islands, Western Australia, an important breeding site for many seabird species. Nest detection is complicated by high environmental heterogeneity at the scale of nests (similar to 1-2 m), the presence of many features that resemble nests and the variability of nest size, shape and context. Finally, the rarity of nests limits the availability of training data. These challenges are not unique to wildlife surveys and we show how they can be overcome by an innovative integration of object-based image analyses (OBIA) and the powerful machine learning one-class classifier Maxent. Maxent classifications using features characterizing object texture, geometry and neighborhood, along with limited object color information, successfully identified over 90% of high quality nests (most weathered and unusually shaped nests were also detected, but at a slightly lower rate) and labeled <2% of objects as candidate nests. Although this overestimates the occurrence of nests, the results can be visually screened to rule out all but the most likely nests in a process that is simpler and more efficient than manual photointerpretation of the full image. Our study shows that semi-automated image analyses for wildlife surveys are achievable. Furthermore, the developed strategies have broad relevance to image processing applications that seek to detect rare features differing only subtly from a heterogeneous background, including remote sensing of archeological remains. We also highlight solutions to maximize the use of imperfect or uncalibrated image data, such as some UAV-based imagery and the growing body of VHR imagery available in Google Earth and other virtual globes.
AD  - Murdoch Univ, Sch Vet & Life Sci, Environm & Conservat Sci, Murdoch, WA, AustraliaC3  - Murdoch UniversityFU  - National Geographic Society's Committee for Research and Exploration [9545-14]; Western Australia Department of Fisheries
FX  - This research was funded by the National Geographic Society's Committee for Research and Exploration grant #9545-14. The field surveys would not have been possible without the generous support of the Western Australia Department of Fisheries. N. Dunlop (Conservation Council of Western Australia), D. Alpers, R. Phillips and A. Frost also provided valuable assistance in the field.
CR  - Abd-Elrahman A, 2005, SURVEYING LAND INFOR, V65, P37
CR  - ANTHONY RM, 1995, WILDLIFE SOC B, V23, P80
CR  - BAJZAK D, 1990, WILDLIFE SOC B, V18, P125
CR  - Barber-Meyer SM, 2007, POLAR BIOL, V30, P1565, DOI 10.1007/s00300-007-0317-8
CR  - Barbier N, 2010, GLOBAL ECOL BIOGEOGR, V19, P72, DOI 10.1111/j.1466-8238.2009.00493.x
CR  - Begall S, 2008, P NATL ACAD SCI USA, V105, P13451, DOI 10.1073/pnas.0803650105
CR  - Benshemesh JS, 1996, WILDLIFE RES, V23, P121, DOI 10.1071/WR9960121
CR  - Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Burbidge Andrew A., 2004, Corella, V28, P96
CR  - Butler D. R., 2002, GEOCARTO INT, V17, P69, DOI DOI 10.1080/10106040208542255
CR  - Cunningham DJ, 1996, WILDLIFE SOC B, V24, P345
CR  - CURNUTT JL, 1994, J WILDLIFE MANAGE, V58, P218, DOI 10.2307/3809383
CR  - Dennis T. E., 1996, Corella, V20, P93
CR  - Dennis TE, 2011, EMU, V111, P179, DOI 10.1071/MU10044
CR  - Department of Fisheries, 2013, COASTL ABR ISL
CR  - Department of Fisheries, 2003, 151 DEP FISH
CR  - Department of Fisheries, 2012, EXPL HOUTM ABR ISL
CR  - Dolbeer RA, 1997, COLON WATERBIRD, V20, P8, DOI 10.2307/1521758
CR  - Dorais A, 2011, REMOTE SENS-BASEL, V3, P1157, DOI 10.3390/rs3061157
CR  - Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x
CR  - Elith J, 2011, DIVERS DISTRIB, V17, P43, DOI 10.1111/j.1472-4642.2010.00725.x
CR  - Frederick PC, 2003, J FIELD ORNITHOL, V74, P281, DOI 10.1648/0273-8570-74.3.281
CR  - Fretwell PT, 2009, GLOBAL ECOL BIOGEOGR, V18, P543, DOI 10.1111/j.1466-8238.2009.00467.x
CR  - Fuller Phillip J., 1994, Corella, V18, P97
CR  - Funk WC, 2012, TRENDS ECOL EVOL, V27, P489, DOI 10.1016/j.tree.2012.05.012
CR  - GILMER DS, 1988, WILDLIFE SOC B, V16, P204
CR  - GRIER JW, 1981, J WILDLIFE MANAGE, V45, P83, DOI 10.2307/3807876
CR  - Groom G, 2013, ECOL INFORM, V14, P2, DOI 10.1016/j.ecoinf.2012.12.001
CR  - Groom G, 2011, INT J REMOTE SENS, V32, P4611, DOI 10.1080/01431161.2010.489068
CR  - Guo QH, 2007, GISCI REMOTE SENS, V44, P24, DOI 10.2747/1548-1603.44.1.24
CR  - HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
CR  - He YH, 2011, REMOTE SENS LETT, V2, P147, DOI 10.1080/01431161.2010.504755
CR  - Hodgson A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079556
CR  - Hughes BJ, 2011, WILDLIFE BIOL, V17, P210, DOI 10.2981/10-106
CR  - IUCN Species Survival Commission, 2001, IUCN RED LIST CAT CR
CR  - Johansen K, 2008, J SPAT SCI, V53, P43, DOI 10.1080/14498596.2008.9635134
CR  - Laba M, 2010, REMOTE SENS ENVIRON, V114, P876, DOI 10.1016/j.rse.2009.12.002
CR  - Laliberte AS, 2003, WILDLIFE SOC B, V31, P362
CR  - LaRue MA, 2011, POLAR BIOL, V34, P1727, DOI 10.1007/s00300-011-1023-0
CR  - Lasaponara R, 2016, REMOTE SENS ENVIRON, V174, P148, DOI 10.1016/j.rse.2015.12.016
CR  - Li WK, 2010, INT J REMOTE SENS, V31, P2227, DOI 10.1080/01431161003702245
CR  - Lin JY, 2014, INT J REMOTE SENS, V35, P6708, DOI 10.1080/01431161.2014.960623
CR  - Luo L, 2014, REMOTE SENS-BASEL, V6, P11956, DOI 10.3390/rs61211956
CR  - Mack B, 2014, REMOTE SENS-BASEL, V6, P8779, DOI 10.3390/rs6098779
CR  - Meekan MG, 2006, MAR ECOL PROG SER, V319, P275, DOI 10.3354/meps319275
CR  - Mejias L., 2013, P OCEANS 13 IEEE MTS
CR  - Mering C, 2010, INT J REMOTE SENS, V31, P5867, DOI 10.1080/01431161.2010.512311
CR  - Moffett KB, 2013, INT J REMOTE SENS, V34, P1332, DOI 10.1080/01431161.2012.718463
CR  - Monroe AP, 2016, J WILDLIFE MANAGE, V80, P667, DOI 10.1002/jwmg.1050
CR  - National Wildlife Refuge Alaska, 1963, J RAPTOR RES, V41, P1
CR  - Nicholson K, 2012, MAR FRESHWATER RES, V63, P1059, DOI 10.1071/MF12210
CR  - Olea PP, 2016, FRONT ECOL ENVIRON, V14, P11, DOI 10.1002/FEEOlealetter.1
CR  - Pettorelli N, 2014, J APPL ECOL, V51, P839, DOI 10.1111/1365-2664.12261
CR  - Phillips S.J., 2005, MAXENT SOFTWARE SPEC
CR  - Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026
CR  - Phillips SJ, 2008, ECOGRAPHY, V31, P161, DOI 10.1111/j.0906-7590.2008.5203.x
CR  - Phillips SJ, 2013, ECOLOGY, V94, P1409, DOI 10.1890/12-1520.1
CR  - Ploton P, 2012, ECOL APPL, V22, P993, DOI 10.1890/11-1606.1
CR  - Priddel D, 2003, WILDLIFE RES, V30, P451, DOI 10.1071/WR02046
CR  - Puttock AK, 2015, J UNMANNED VEH SYST, V3, P123, DOI 10.1139/juvs-2015-0005
CR  - Saffer V, 2014, P 5 NAT MALL FOR, P140
CR  - Sarda-Palomera F, 2012, IBIS, V154, P177, DOI 10.1111/j.1474-919X.2011.01177.x
CR  - Sauer JR, 2011, J WILDLIFE MANAGE, V75, P509, DOI 10.1002/jwmg.84
CR  - Shephard JM, 2005, CONSERV GENET, V6, P413, DOI 10.1007/s10592-005-4987-x
CR  - Shephard JM, 2005, AUSTRAL ECOL, V30, P131, DOI 10.1111/j.1442-9993.2005.01428.x
CR  - Stenzel S, 2014, INT J APPL EARTH OBS, V33, P211, DOI 10.1016/j.jag.2014.05.012
CR  - Surman C. A., 2009, Corella, V33, P81
CR  - Thompson Scott, 2015, Pacific Conservation Biology, V21, P208, DOI 10.1071/PC14919
CR  - Thurstans Shaun D., 2009, Corella, V33, P51
CR  - Thurstans Shaun D., 2009, Corella, V33, P66
CR  - Trathan PN, 2004, WILDLIFE SOC B, V32, P332, DOI 10.2193/0091-7648(2004)32[332:IAOCAP]2.0.CO;2
CR  - Trimble, 2012, ECOGNITION DEV 8 8 R
CR  - TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
CR  - Van Andel AC, 2015, AM J PRIMATOL, V77, P1122, DOI 10.1002/ajp.22446
CR  - van Gemert JC, 2015, LECT NOTES COMPUT SC, V8925, P255, DOI 10.1007/978-3-319-16178-5_17
CR  - Vermeulen C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054700
CR  - Visser V, 2014, BIOL INVASIONS, V16, P513, DOI 10.1007/s10530-013-0604-y
CR  - Waser LT, 2011, REMOTE SENS ENVIRON, V115, P76, DOI 10.1016/j.rse.2010.08.006
CR  - Watts BD, 2010, J WILDLIFE MANAGE, V74, P940, DOI 10.2193/2009-018
CR  - Watts BD, 2008, J WILDLIFE MANAGE, V72, P152, DOI 10.2193/2005-616
CR  - Westcott F, 2015, APPL GEOGR, V62, P97, DOI 10.1016/j.apgeog.2015.04.011
CR  - WHITFIELD D W A, 1974, Canadian Field-Naturalist, V88, P399
CR  - Wiersma Jason M., 2009, Corella, V33, P71
CR  - Witharana C, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050375
CR  - Yang Z, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115989
CR  - Yu L, 2012, INT J REMOTE SENS, V33, P3966, DOI 10.1080/01431161.2011.636081
CR  - Zwiefelhofer D., 2007, COMP BALD EAGLE HALI
CR  - [No title captured]
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN, NJ 07030 USA
DA  - JUN
PY  - 2017
VL  - 3
IS  - 2
SP  - 66
EP  - 80
DO  - 10.1002/rse2.38
AN  - WOS:000436010900003
N1  - Times Cited in Web of Science Core Collection:  16
Total Times Cited:  16
Cited Reference Count:  89
ER  -

TY  - JOUR
AU  - Brooker, SA
AU  - Stephens, PA
AU  - Whittingham, MJ
AU  - Willis, SG
TI  - Automated detection and classification of birdsong: An ensemble approach
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Automated detection
KW  - Bioacoustics
KW  - Birdsong
KW  - Dawn chorus
KW  - Ensemble forecasting
KW  - Survey method
KW  - FOREST BIRDS
KW  - RECORDINGS
KW  - RECORDERS
KW  - MODELS
KW  - SONG
AB  - The avian dawn chorus presents a challenging opportunity to test autonomous recording units (ARUs) and associated recogniser software in the types of complex acoustic environments frequently encountered in the natural world. To date, extracting information from acoustic surveys using readily-available signal recognition tools ('recognisers') for use in biodiversity surveys has met with limited success. Combining signal detection methods used by different recognisers could improve performance, but this approach remains untested. Here, we evaluate the ability of four commonly used and commercially- or freely-available individual recognisers to detect species, focusing on five woodland birds with widely-differing song-types. We combined the likelihood scores (of a vocalisation originating from a target species) assigned to detections made by the four recognisers to devise an ensemble approach to detecting and classifying birdsong. We then assessed the relative performance of individual recognisers and that of the ensemble models. The ensemble models out-performed the individual recognisers across all five song-types, whilst also minimising false positive error rates for all species tested. Moreover, during acoustically complex dawn choruses, with many species singing in parallel, our ensemble approach resulted in detection of 74% of singing events, on average, across the five song-types, compared to 59% when averaged across the recognisers in isolation; a marked improvement. We suggest that this ensemble approach, used with suitably trained individual recognisers, has the potential to finally open up the use of ARUs as a means of automatically detecting the occurrence of target species and identifying patterns in singing activity over time in challenging acoustic environments.
AD  - Univ Durham, Dept Biosci, South Rd, Durham DH1 3LE, EnglandAD  - Newcastle Univ, Sch Nat & Environm Sci SNES, Agr Bldg, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, EnglandC3  - Durham UniversityC3  - Newcastle University - UKFU  - Natural Environment Research Council (NERC) [NE/L002590/1]; British Trust for Ornithology (BTO)
FX  - This work was supported by the Natural Environment Research Council (NERC) [Grant ref: NE/L002590/1] in a CASE Partnership with the British Trust for Ornithology (BTO).
CR  - Abrahams C, 2018, BIRD STUDY, V65, P197, DOI 10.1080/00063657.2018.1446904
CR  - Agranat I. D., 2009, AUTOMATICALLY IDENTI, P1
CR  - Araujo MB, 2007, TRENDS ECOL EVOL, V22, P42, DOI 10.1016/j.tree.2006.09.010
CR  - Barton K, 2018, MUMIN MULTIMODEL INF, V1, P1
CR  - Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
CR  - Bibby C.J., 2000, BIRD CENSUS TECHNIQU, V2nd edn
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
CR  - Burivalova Z, 2019, SCIENCE, V363, P28, DOI 10.1126/science.aav1902
CR  - Burnham KP., 2002, MODEL SELECTION MULT
CR  - Charif R.A., 2010, RAVEN PRO 1 4 USERS
CR  - Core Team R, 2018, R LANG ENV STAT COMP
CR  - Diaz S, 2019, SUMMARY POLICYMAKERS
CR  - Duan S, 2013, P 25 INN APPL ART IN, P1519
CR  - Friard O, 2016, METHODS ECOL EVOL, V7, P1325, DOI 10.1111/2041-210X.12584
CR  - Furnas BJ, 2015, J WILDLIFE MANAGE, V79, P325, DOI 10.1002/jwmg.821
CR  - Grau J, 2015, BIOINFORMATICS, V31, P2595, DOI 10.1093/bioinformatics/btv153
CR  - Hafner S., 2018, MONITOR ACOUSTIC TEM
CR  - Hafner S. D., 2018, SHORT INTRO ACOUSTIC
CR  - Holland J, 1998, J ACOUST SOC AM, V103, P2154, DOI 10.1121/1.421361
CR  - Joshi KA, 2017, EMU, V117, P233, DOI 10.1080/01584197.2017.1298970
CR  - Katz J, 2016, BIOACOUSTICS, V25, P197, DOI 10.1080/09524622.2016.1138415
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Length R., 2019, Emmeans: Estimated Marginal Means, Aka Least-Squares Means. R Package Version 1.4.1
CR  - Luther DA, 2009, BIOL LETTERS, V5, P183, DOI 10.1098/rsbl.2008.0733
CR  - Mackenzie D.I., 2006, OCCUPANCY ESTIMATION
CR  - MCNAMARA JM, 1987, BEHAV ECOL SOCIOBIOL, V20, P399, DOI 10.1007/BF00302982
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Poesel Angelika, 2000, Etologia, V8, P1
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Rodrigues M, 1996, ANIM BEHAV, V51, P709, DOI 10.1006/anbe.1996.0074
CR  - Sanders CE, 2014, CONDOR, V116, P371, DOI 10.1650/CONDOR-13-098.1
CR  - Sebastian-Gonzalez E, 2015, ECOL EVOL, V5, P4696, DOI 10.1002/ece3.1743
CR  - Shonfield J, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00974-120114
CR  - Sidie-Slettedahl AM, 2015, WILDLIFE SOC B, V39, P626, DOI 10.1002/wsb.569
CR  - Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
CR  - Stowell D., 2011, C4DMTR0912 U LOND, P2
CR  - Swiston KA, 2009, J FIELD ORNITHOL, V80, P42, DOI 10.1111/j.1557-9263.2009.00204.x
CR  - Thiele C., 2018, CUTPOINTR DETERMINE
CR  - Turgeon PJ, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00958-120109
CR  - Wildlife Acoustics, 2011, SONG SCOP BIOAC SOFT
CR  - Wildlife Acoustics Inc., 2018, KAL PRO 5 US GUID VE
CR  - Wildlife Acoustics Inc., 2018, CLUST AN IN DEPTH 1
CR  - WILEY RH, 1978, BEHAV ECOL SOCIOBIOL, V3, P69, DOI 10.1007/BF00300047
CR  - Wimmer J, 2013, ECOL APPL, V23, P1419, DOI 10.1890/12-2088.1
CR  - Zhang VY, 2016, BIOACOUSTICS, V25, P19, DOI 10.1080/09524622.2015.1076348
CR  - Zwart MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102770
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - OCT
PY  - 2020
VL  - 117
DO  - 10.1016/j.ecolind.2020.106609
AN  - WOS:000555557300001
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  49
ER  -

TY  - JOUR
AU  - Zhang, L
AU  - Towsey, M
AU  - Zhang, JL
AU  - Roe, P
TI  - Using non-negative matrix factorisation to facilitate efficient bird species richness surveys
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Non-negative matrix factorisation
KW  - Clustering
KW  - Acoustic sampling
KW  - Bird species richness
KW  - CLASSIFICATION
KW  - IDENTIFICATION
KW  - RECORDINGS
KW  - EXTRACTION
KW  - SCALE
AB  - This paper considers computer-assisted learning of sound spectra in environmental recordings to facilitate manual bird species identification. Today, a variety of automated methods have been successfully applied for acoustic recognition of specific bird species. These methods are more effective for single targeted species detection. For in-field recordings, however, simultaneous vocalisations and unknown species usually make such methods less effective.
   In this study, we propose a non-negative matrix factorisation based method to facilitate manual bird species identification from environmental recordings. First, distinct sound spectra are extracted from each audio clip by applying non-negative matrix factorisation and clustering techniques. Based on these distinct sound spectra, a greedy algorithm is then designed to sample audio clips. Each sampled audio clip maximises the number of new spectra. People who follow this sampled sequence of audio clips should be able to identify the most species given a fixed number of audio clips. The efficiency is validated with annotated bird species per minute provided by experienced ornithologists.
AD  - Queensland Univ Technol, Brisbane, Qld, AustraliaC3  - Queensland University of Technology (QUT)CR  - Acevedo MA, 2009, ECOL INFORM, V4, P206, DOI 10.1016/j.ecoinf.2009.06.005
CR  - Bertin N, 2007, INT CONF ACOUST SPEE, P65
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Brandes TS, 2006, J ACOUST SOC AM, V120, P2950, DOI 10.1121/1.2355479
CR  - Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
CR  - Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101
CR  - Chen ZX, 2006, J ACOUST SOC AM, V120, P2974, DOI 10.1121/1.2345831
CR  - CLARK CW, 1987, ETHOLOGY, V76, P101
CR  - Eldridge A, 2016, PEERJ, V4, DOI 10.7717/peerj.2108
CR  - Fagerlund S, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/38637
CR  - Farina A., 2014, SOUNDSCAPE ECOLOGY P
CR  - Feng T, 2002, 2ND INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, PROCEEDINGS, P178, DOI 10.1109/DEVLRN.2002.1011835
CR  - Frigyesi A, 2008, CANCER INFORM, V6, P275
CR  - Harma A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P545
CR  - Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
CR  - Hutchins LN, 2008, BIOINFORMATICS, V24, P2684, DOI 10.1093/bioinformatics/btn526
CR  - Kogan JA, 1998, J ACOUST SOC AM, V103, P2185, DOI 10.1121/1.421364
CR  - Kosicki JZ, 2014, ECOL INDIC, V38, P50, DOI 10.1016/j.ecolind.2013.10.032
CR  - Kosicki JZ, 2012, ECOL RES, V27, P347, DOI 10.1007/s11284-011-0906-4
CR  - Langfelder P, 2008, BIOINFORMATICS, V24, P719, DOI 10.1093/bioinformatics/btm563
CR  - Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
CR  - MARTINDALE S, 1980, CONDOR, V82, P199, DOI 10.2307/1367478
CR  - McIlraith AL, 1997, 1997 CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, CONFERENCE PROCEEDINGS, VOLS I AND II, P63, DOI 10.1109/CCECE.1997.614790
CR  - Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Skierczynski M, 2010, BEHAVIOUR, V147, P333, DOI 10.1163/000579509X12549112908535
CR  - Smaragdis P, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P177, DOI 10.1109/aspaa.2003.1285860
CR  - Smaragdis P, 2004, LECT NOTES COMPUT SC, V3195, P494
CR  - Somervuo P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P825
CR  - Vilches E, 2006, INT C PATT RECOG, P400
CR  - Wimmer J, 2013, ECOL APPL, V23, P1419, DOI 10.1890/12-2088.1
CR  - Zhang J., 2008, COMPUT INTELL NEUROS
CR  - Zhang L, 2015, 2015 IEEE 17 INT
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - SEP
PY  - 2017
VL  - 80
SP  - 297
EP  - 302
DO  - 10.1016/j.ecolind.2017.05.017
AN  - WOS:000406436100031
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  33
ER  -

TY  - JOUR
AU  - Moallem, G
AU  - Pathirage, DD
AU  - Reznick, J
AU  - Gallagher, J
AU  - Sari-Sarraf, H
TI  - An explainable deep vision system for animal classification and detection in trail-camera images with automatic post-deployment retraining
T2  - KNOWLEDGE-BASED SYSTEMS
LA  - English
KW  - Automatic wildlife monitoring
KW  - Animal classification and detection
KW  - Data drift and retraining
KW  - Model explainability
KW  - Convolutional neural networks (CNN)
KW  - Deep learning
AB  - This paper introduces an automated vision system for animal detection in trail-camera images taken from a field under the administration of the Texas Parks and Wildlife Department. As traditional wildlife counting techniques are intrusive and labor intensive to conduct, trail-camera imaging is a comparatively non-intrusive method for capturing wildlife activity. However, given the large volume of images produced from trail-cameras, manual analysis of the images remains time-consuming and inefficient. We implemented a two-stage deep convolutional neural network pipeline to find animal-containing images in the first stage and then process these images to detect birds in the second stage. The animal classification system classifies animal images with overall 93% sensitivity and 96% specificity. The bird detection system achieves better than 93% sensitivity, 92% specificity, and 68% average Intersection-over-Union rate. The entire pipeline processes an image in less than 0.5 s as opposed to an average 30 s for a human labeler. We also addressed post-deployment issues related to data drift for the animal classification system as image features vary with seasonal changes. This system utilizes an automatic retraining algorithm to detect data drift and update the system. We introduce a novel technique for detecting drifted images and triggering the retraining procedure. Two statistical experiments are also presented to explain the prediction behavior of the animal classification system. These experiments investigate the cues that steers the system towards a particular decision. Statistical hypothesis testing demonstrates that the presence of an animal in the input image significantly contributes to the system's decisions. (C) 2021 Elsevier B.V. All rights reserved.
AD  - Texas Tech Univ, Elect & Comp Engn Dept, Lubbock, TX 79409 USAAD  - Texas Parks & Wildlife Dept, Mason, TX 76856 USAC3  - Texas Tech University SystemC3  - Texas Tech UniversityFU  - Texas Parks and Wildlife Department, USA [522285]
FX  - The authors would like to thank the members of the Applied Vision Lab at Texas Tech University for their assistance in image annotation, especially Peter Wharton, Rupa Vani Battula, Shawn Spicer, Farshad Bolouri, Colin Lynch, and Rishab Tewari. This research was funded by a grant from the Texas Parks and Wildlife Department, USA (522285).
CR  - Adefurin A, 2017, PHARMACOGENOMICS J
CR  - Beery S., 2019, ARXIV PREPRINT ARXIV
CR  - Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
CR  - Boudaoud L.B., 2019, P OCEANS 2019 MARS M, P1
CR  - Chen T., 2020, ARXIV PREPRINT ARXIV
CR  - Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
CR  - Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
CR  - Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
CR  - Hong SJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071651
CR  - Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
CR  - Hudelot C, 2018, 2018 IEEE INT C FUZZ, P1
CR  - Koh P.W., 2017, ARXIV PREPRINT ARXIV
CR  - Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
CR  - LIU G., 2018, P ECCV, P85
CR  - Liu GJ, 2017, KNOWL-BASED SYST, V123, P102, DOI 10.1016/j.knosys.2017.02.016
CR  - Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
CR  - Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
CR  - Pankajakshan A, 2020, ADV INTELL SYST COMP, V1024, P197, DOI 10.1007/978-981-32-9291-8_17
CR  - Pintor M, 2019, ARXIV PREPRINT ARXIV
CR  - Qiaosong Wang, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P146, DOI 10.1007/978-3-319-50835-1_14
CR  - Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
CR  - Ross S., 2006, 1 COURSE PROBABILITY
CR  - Samek W., 2017, ARXIV PREPRINT ARXIV
CR  - Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820
CR  - Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
CR  - Shang R., 2020, KNOWL-BASED SYST
CR  - Simons ES, 2019, ECOL EVOL, V9, P11878, DOI 10.1002/ece3.5695
CR  - Simonyan K., 2013, INT C LEARN REPR ICL
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Swinnen KRR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098881
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tang TY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020336
CR  - Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
CR  - Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
CR  - Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
CR  - Yu X, 2016, LECT NOTES COMPUT SC, V9909, P52, DOI 10.1007/978-3-319-46454-1_4
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - MAR 15
PY  - 2021
VL  - 216
DO  - 10.1016/j.knosys.2021.106815
AN  - WOS:000620980200001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  38
ER  -

TY  - JOUR
AU  - Thiffault, E
AU  - Webster, K
AU  - Lafleur, B
AU  - Wilson, S
AU  - Mansuy, N
TI  - Biophysical indicators based on spatial hierarchy for informing land reclamation: The case of the Lower Athabasca River (Alberta, Canada)
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Land reclamation
KW  - Landscape
KW  - Watershed
KW  - Landform
KW  - Ecosite
KW  - Automated classification
KW  - Ecosystem services
KW  - ASPEN SEEDLING ESTABLISHMENT
KW  - ECOLOGICAL RESTORATION
KW  - LANDSCAPE ECOLOGY
KW  - CLASSIFICATION
KW  - FOREST
KW  - RESOLUTION
KW  - ECOSYSTEMS
KW  - PATTERN
KW  - GROWTH
KW  - ISSUES
AB  - In the Lower Athabasca region of Alberta (Canada), surface mining for bitumen from oil sands creates highly disturbed environments, which need to be restored, after mine closing, to equivalent land capability in terms of biodiversity and ecosystem services. We demonstrate a method to characterize ecosystem diversity and conditions using biophysical indicators of the Lower Athabasca meant for informing land reclamation planning and monitoring by identifying and creating a typology of the main assemblages of topography, soil and forest vegetation at the watershed, landform and ecosite scales, and analysing the relationships among land units of various scales. Our results showed that watersheds could be classified into distinct groups with specific features, even for a region with a generally flat or gently rolling topography, with slope, surficial deposits and aspect as key drivers of differences. Despite the subtle topography, the moisture regime, which is linked to large-scale cycles that are dependent on the surrounding matrix, was of primary importance for driving vegetation assemblages. There was no unique and homogeneous association between topography and vegetation; the specific landforms each displayed a range of ecosites, and the same ecosites were found in different landforms. This suggests that landscapes cannot be defined in a qualitative manner but rather with quantitative indicators that express the proportion occupied by each class of ecological units within the coarser units, therefore requiring during land reclamation that sufficient care is given to create heterogeneity within a given landform in terms of soil texture and drainage so that a mosaic of ecosite conditions is created. (C) 2016 Published by Elsevier Ltd.
AD  - Univ Laval, Ctr Rech Mat Renouvelables, Dept Sci Bois & Foret, 2405 Rue Terrasse Pavillon Abitibi Price, Quebec City, PQ G1V 0A6, CanadaAD  - Nat Resources Canada, Canadian Forest Serv, Great Lakes Forestry Ctr, 1219 Queen St East, Sault Ste Marie, ON P6A 2E5, CanadaAD  - Nat Resources Canada, Canadian Forest Serv, Laurentian Forestry Ctr, Stn Sainte Foy, 1055 PEPS,POB 10380, Quebec City, PQ G1V 4C7, CanadaAD  - Univ Quebec Abitibi Temiscamingue, Inst Rech Forets, 445 Boul Univ, Quebec City, PQ J9X 5E4, CanadaC3  - Laval UniversityC3  - Natural Resources CanadaC3  - Canadian Forest ServiceC3  - Great Lakes Forestry CentreC3  - Natural Resources CanadaC3  - Canadian Forest ServiceC3  - University of QuebecC3  - University Quebec Abitibi-TemiscamingueFU  - Canadian Forest Service of Natural Resources Canada
FX  - Funding for this project provided by the Canadian Forest Service of Natural Resources Canada. The authors also wish to acknowledge anonymous reviewers on previous versions of the manuscript.
CR  - Alberta Environment, 2011, OIL SANDS LAND COV D
CR  - Alberta Environment and Sustainable Resource Development, 2013, CRITERIA INDICATORS, P163
CR  - Alberta Government, 2012, LOW ATH REG PLAN 201
CR  - Alberta Government, 2015, OIL SANDS RECL FACT
CR  - Alberta Government, 1999, CONS RECL INF LETT G
CR  - Audet P, 2015, CAN J FOREST RES, V45, P364, DOI 10.1139/cjfr-2014-0330
CR  - Augusto L, 2002, ANN FOREST SCI, V59, P233, DOI 10.1051/forest:2002020
CR  - Beaudoin A, 2014, CAN J FOREST RES, V44, P521, DOI 10.1139/cjfr-2013-0401
CR  - Beckingham J. D., 1996, 5 CAN FOR SERV NO FO
CR  - Bezdek J. C, 1981, PATTERN RECOGN, P1, DOI [10.1007/978-1-4757-0450-1_1, DOI 10.1007/978-1-4757-0450-1_1]
CR  - Bridge SRJ, 2000, J VEG SCI, V11, P57, DOI 10.2307/3236776
CR  - Bryan BA, 2006, ENVIRON MANAGE, V37, P126, DOI 10.1007/s00267-004-0058-1
CR  - Burkhard B., 2009, Landscape Online
CR  - Burkhard B, 2012, ECOL INDIC, V21, P17, DOI 10.1016/j.ecolind.2011.06.019
CR  - BURROUGH P. A., 2011, PRINCIPLES GEOGRAPHI
CR  - Burrough PA, 2000, FUZZY SET SYST, V113, P37, DOI 10.1016/S0165-0114(99)00011-1
CR  - Certini G, 2014, AMBIO, V43, P191, DOI 10.1007/s13280-013-0418-2
CR  - CONACHER AJ, 1977, GEODERMA, V18, P1
CR  - Corns I.G.W., 1986, FIELD GUIDE FOREST E
CR  - Cumulative Environmental Management Association, 2006, LAND CAP CLASS SYST
CR  - de Blois S, 2002, ECOGRAPHY, V25, P244, DOI 10.1034/j.1600-0587.2002.250212.x
CR  - de Groot WJ, 2013, FOREST ECOL MANAG, V294, P23, DOI 10.1016/j.foreco.2012.07.033
CR  - Drake J. A., 2010, P 5 INT C MIN CLOS 2, P241
CR  - Duan M, 2015, ECOL ENG, V75, P323, DOI 10.1016/j.ecoleng.2014.12.010
CR  - Duraiappah A., 2005, EC HUM WELL BEING BI
CR  - Environment Canada, 2014, CAN CLIM NORM 1981 2
CR  - Fisher P., 1998, GeoInformatica, V2, P215, DOI 10.1023/A:1009717704255
CR  - Fitterer JL, 2012, ECOL INDIC, V20, P151, DOI 10.1016/j.ecolind.2012.02.024
CR  - Fung M. Y. P., 2000, Reclamation of drastically disturbed lands, P755
CR  - Garibaldi A, 2009, J ETHNOBIOL, V29, P323, DOI 10.2993/0278-0771-29.2.323
CR  - Hannam KD, 2004, SOIL SCI SOC AM J, V68, P1735, DOI 10.2136/sssaj2004.1735
CR  - Jensen ME, 2001, J AM WATER RESOUR AS, V37, P1155, DOI 10.1111/j.1752-1688.2001.tb03629.x
CR  - Johnson EA, 2008, ANN NY ACAD SCI, V1134, P120, DOI 10.1196/annals.1439.007
CR  - Kasischke ES., 2006, GEOPHYS RES LETT, V33
CR  - Kaufman L., 2005, FINDING GROUPS DATA
CR  - KLIJN F, 1994, LANDSCAPE ECOL, V9, P89, DOI 10.1007/BF00124376
CR  - Larsen CPS, 1997, J BIOGEOGR, V24, P663, DOI 10.1111/j.1365-2699.1997.tb00076.x
CR  - Lei K, 2016, ECOL ENG, V90, P320, DOI 10.1016/j.ecoleng.2016.01.080
CR  - Lesko G., 1973, 73 ALB EARTH SCI, V73
CR  - Lindsay J., 2014, P GIS RES UK 22 ANN, V16, P18
CR  - Lindsay JB, 2005, HYDROL PROCESS, V19, P1123, DOI 10.1002/hyp.5818
CR  - Lindsay JB, 2006, COMPUT GEOSCI-UK, V32, P1192, DOI 10.1016/j.cageo.2005.11.002
CR  - Loveland TR, 2004, ENVIRON MANAGE, V34, pS1, DOI 10.1007/s00267-003-5181-x
CR  - Mackey BG, 2008, J BIOGEOGR, V35, P213, DOI 10.1111/j.1365-2699.2007.01822.x
CR  - MacMillan RA, 2000, FUZZY SET SYST, V113, P81, DOI 10.1016/S0165-0114(99)00014-7
CR  - MacMillan RA, 2007, GEODERMA, V140, P353, DOI 10.1016/j.geoderma.2007.04.027
CR  - Mansuy N, 2014, GEODERMA, V235, P59, DOI 10.1016/j.geoderma.2014.06.032
CR  - Serra JM, 2011, ENVIRON MODEL ASSESS, V16, P77, DOI 10.1007/s10666-010-9232-4
CR  - Marleau JN, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2013.2094
CR  - Mayer A, 2014, ECOL INDIC, V45, P340, DOI 10.1016/j.ecolind.2014.04.030
CR  - McNab W. H., 2015, General Technical Report - Southern Research Station, USDA Forest Service, P489
CR  - MILES J, 1985, J SOIL SCI, V36, P571, DOI 10.1111/j.1365-2389.1985.tb00359.x
CR  - Millan M. R. A., 2004, Computers, Environment and Urban Systems, V28, P175, DOI 10.1016/S0198-9715(03)00019-X
CR  - Nadeau LB, 2004, FOREST CHRON, V80, P359, DOI 10.5558/tfc80359-3
CR  - Nikodemus O, 2013, ARCH AGRON SOIL SCI, V59, P449, DOI 10.1080/03650340.2011.638290
CR  - ODEH IOA, 1992, SOIL SCI SOC AM J, V56, P505, DOI 10.2136/sssaj1992.03615995005600020027x
CR  - Omernik JM, 2004, ENVIRON MANAGE, V34, pS27, DOI 10.1007/s00267-003-5197-2
CR  - Pawlik L, 2013, EARTH-SCI REV, V126, P250, DOI 10.1016/j.earscirev.2013.08.007
CR  - Pinno B. D., 2015, Ecological Restoration, V33, P43, DOI 10.3368/er.33.1.43
CR  - Pinno B.D., 2016, J AM SOC MIN RECLAM, V5, P28, DOI [10.21000/JASMR16010028, DOI 10.21000/JASMR16010028]
CR  - Pinno BD, 2015, FORESTS, V6, P2109, DOI 10.3390/f6062109
CR  - Pinno BD, 2012, CAN J SOIL SCI, V92, P143, DOI [10.4141/CJSS2011-004, 10.4141/cjss2011-004]
CR  - Pouliot D, 2009, REMOTE SENS ENVIRON, V113, P1749, DOI 10.1016/j.rse.2009.04.008
CR  - Qualizza C., 2012, SYNTHESIS REPORT PRE
CR  - Quideau SA, 2013, BIOGEOSCIENCES, V10, P5651, DOI 10.5194/bg-10-5651-2013
CR  - ROWE JS, 1992, FOREST CHRON, V68, P222, DOI 10.5558/tfc68222-2
CR  - Samonil P, 2010, GEODERMA, V157, P65, DOI 10.1016/j.geoderma.2010.03.018
CR  - Sarle W.S., 1983, A108 SAS I INC
CR  - SAS, 2012, JMP VERS 11 0
CR  - Schneider M., 2010, LECT NOTES EARTH SCI, V115, P37, DOI [10.1007/978-3-540-75761-0_3, DOI 10.1007/978-3-540-75761-0_3]
CR  - Shackelford N, 2013, RESTOR ECOL, V21, P297, DOI 10.1111/rec.12012
CR  - Tamminga A, 2014, FORESTS, V5, P325, DOI 10.3390/f5020325
CR  - Tansley AG, 1935, ECOLOGY, V16, P284, DOI 10.2307/1930070
CR  - Troy A, 2006, ECOL ECON, V60, P435, DOI 10.1016/j.ecolecon.2006.04.007
CR  - Turchenek L., 1982, 122 AOSERP ENV RES M
CR  - TURNER MG, 1989, ANNU REV ECOL SYST, V20, P171, DOI 10.1146/annurev.es.20.110189.001131
CR  - Turner W, 2003, TRENDS ECOL EVOL, V18, P306, DOI 10.1016/S0169-5347(03)00070-3
CR  - van Asselen S, 2006, GEOMORPHOLOGY, V78, P309, DOI 10.1016/j.geomorph.2006.01.037
CR  - Webster KL, 2011, GEODERMA, V160, P457, DOI 10.1016/j.geoderma.2010.10.016
CR  - Wu JG, 2002, LANDSCAPE ECOL, V17, P355, DOI 10.1023/A:1020561630963
CR  - [No title captured]
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - JAN
PY  - 2017
VL  - 72
SP  - 173
EP  - 184
DO  - 10.1016/j.ecolind.2016.08.020
AN  - WOS:000398426200017
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  5
Cited Reference Count:  81
ER  -

TY  - JOUR
AU  - Yoh, N
AU  - Kingston, T
AU  - McArthur, E
AU  - Aylen, OE
AU  - Huang, JCC
AU  - Jinggong, ER
AU  - Khan, FAA
AU  - Lee, BPYH
AU  - Mitchell, SL
AU  - Bicknell, JE
AU  - Struebig, MJ
TI  - A machine learning framework to classify Southeast Asian echolocating bats
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Acoustic monitoring
KW  - Chiroptera
KW  - Echolocation
KW  - Southeast Asia
KW  - Machine learning
KW  - Supervised algorithm
KW  - INSECTIVOROUS BATS
KW  - IDENTIFICATION
KW  - CALLS
KW  - VESPERTILIONIDAE
KW  - EMBALLONURIDAE
KW  - CONSERVATION
KW  - RELIABILITY
KW  - CHIROPTERA
KW  - SIGNALS
KW  - TIME
AB  - Bats comprise a quarter of all mammal species, provide key ecosystem services and serve as effective bio-indicators. Automated methods for classifying echolocation calls of free-flying bats are useful for monitoring but are not widely used in the tropics. This is particularly problematic in Southeast Asia, which supports more than 388 bat species. Here, sparse reference call databases and significant overlap among species call characteristics makes the development of automated processing methods complex. To address this, we outline a semi-automated framework for classifying bat calls in Southeast Asia and demonstrate how this can reliably speed up manual data processing. We implemented the framework to develop a classifier for the bats of Borneo and tested this at a landscape in Sabah. Borneo has a relatively well-described bat fauna, including reference calls for 52% of all 81 known echolocating species on the island. We applied machine learning to classify calls into one of four call types that serve as indicators of dominant ecological ensembles: frequency-modulated (FM; forest-specialists), constant frequency (CF; forest-specialists and edge/gap foragers), quasi-constant frequency (QCF; edge/gap foragers), and frequency-modulated quasi constant frequency (FMqCF; edge/gap and open-space foragers) calls. Where possible, we further identified calls to species/sonotype. Each classification is provided with a confidence value and a recommended threshold for manual verification. Of the 245,991 calls recorded in our test landscape, 85% were correctly identified to call type and only 10% needed manual verification for three of the call types. The classifier was most successful at classifying CF calls, reducing the volume of calls to be manually verified by over 95% for three common species. The most difficult bats to classify were those with FMqCF calls, with only a 52% reduction in files. Our framework allows users to rapidly filter acoustic files for common species and isolate files of interest, cutting the total volume of data to be processed by 86%. This provides an alternative method where species-specific classifiers are not yet feasible and enables researchers to expand non-invasive monitoring of bat species. Notably, this approach incorporates aerial insectivorous ensembles that are regularly absent from field datasets despite being important components of the bat community, thus improving our capacity to monitor bats remotely in tropical landscapes.
AD  - Univ Kent, Sch Anthropol & Conservat, Durrell Inst Conservat & Ecol DICE, Canterbury, Kent, EnglandAD  - Texas Tech Univ, Dept Biol Sci, Lubbock, TX 79409 USAAD  - Southeast Asian Bat Conservat Res Unit, Lubbock, TX USAAD  - Univ Malaysia Sarawak, Fac Resource Sci & Technol, Sarawak 94300, MalaysiaAD  - Univ Otago, Dept Zool, Dunedin, Otago, New ZealandAD  - Taiwan Forestry Res Inst, Taipei, TaiwanAD  - Natl Pk Board, Wildlife Management Div, Singapore, SingaporeC3  - University of KentC3  - Texas Tech University SystemC3  - Texas Tech UniversityC3  - University of Malaysia SarawakC3  - University of OtagoFU  - Natural Environmental Research Council (NERC) EnvEast DTP scholarship [NE/L002582/1]; NERC [NE/K016407/1]; Mohamed bin Zayed species Conservation Fund [11253049]; Ministry of Higher Education Malaysia [F07/FRGS/1878/2019]; Global Biodiversity Information Facility through BIFA grant; Ministry of National Development EDGE Scholarship; US National Science Foundation [165871]; Wildlife Reserves Singapore Conservation Fund
FX  - NY was funded by a Natural Environmental Research Council (NERC) EnvEast DTP scholarship (grant number NE/L002582/1). NERC also funded the acoustic surveys in Sabah (NE/K016407/1; https://lom bok.nerc-hmtf.info/) along with the Mohamed bin Zayed species Conservation Fund (11253049). FAAK and ERJ were supported by the Ministry of Higher Education Malaysia through F07/FRGS/1878/2019. JCCH was supported by the Global Biodiversity Information Facility through BIFA grant. BPYHL was supported by a Ministry of National Development EDGE Scholarship and the Wildlife Reserves Singapore Conservation Fund. TK was funded by the US National Science Foundation (165871). We thank the Sabah Biodiversity Council, Sabah Forest Department, Yayasan Sabah, and Benta Wawasan Sdn Bhd. for research permissions in Sabah.
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Chen SF, 2009, P ROY SOC B-BIOL SCI, V276, P3901, DOI 10.1098/rspb.2009.1185
CR  - Chen X, 2020, BIOL CONSERV, V241, DOI 10.1016/j.biocon.2019.108269
CR  - Clement MJ, 2014, ECOL EVOL, V4, P3482, DOI 10.1002/ece3.1201
CR  - Denzinger A, 2013, FRONT PHYSIOL, V4, DOI 10.3389/fphys.2013.00164
CR  - FENTON MB, 1981, J MAMMAL, V62, P233, DOI 10.2307/1380701
CR  - Fisher-Phelps M, 2017, ECOL INFORM, V40, P22, DOI 10.1016/j.ecoinf.2017.05.003
CR  - Furmankiewicz J, 2009, J MAMMAL, V90, P1310, DOI 10.1644/09-MAMM-S-099R1.1
CR  - Gardner TA, 2008, ECOL LETT, V11, P139, DOI 10.1111/j.1461-0248.2007.01133.x
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Gorfol T, 2022, PEERJ, V10, DOI 10.7717/peerj.12445
CR  - Harrell FE, 2015, SPRINGER SER STAT, DOI 10.1007/978-3-319-19425-7
CR  - Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
CR  - Hughes AC, 2011, ACTA CHIROPTEROL, V13, P447, DOI 10.3161/150811011X624938
CR  - IUCN (International Union for Conservation of Nature), 2019, IUCN RED LIST THREAT
CR  - James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1
CR  - Jennings N, 2008, CAN J ZOOL, V86, P371, DOI 10.1139/Z08-009
CR  - Jones Gareth, 2009, Endangered Species Research, V8, P93, DOI 10.3354/esr00182
CR  - Jones Kate E., 2013, P213
CR  - Jung K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085279
CR  - KALKO EKV, 1993, BEHAV ECOL SOCIOBIOL, V33, P415
CR  - Kershenbaum A, 2016, BIOL REV, V91, P13, DOI 10.1111/brv.12160
CR  - Kingston T, 1999, J ZOOL, V249, P359, DOI 10.1111/j.1469-7998.1999.tb00771.x
CR  - Kingston T, 2003, J MAMMAL, V84, P205, DOI 10.1644/1545-1542(2003)084<0205:AOECIS>2.0.CO;2
CR  - Kingston T., 2016, CORE STANDARDIZED ME, P59
CR  - Kingston Tigga, 2013, P169
CR  - Kingston T, 2010, BIODIVERS CONSERV, V19, P471, DOI 10.1007/s10531-008-9458-5
CR  - Kobayashi K, 2021, ECOL INFORM, V62, DOI 10.1016/j.ecoinf.2021.101253
CR  - Kuhn Max, 2020, CRAN
CR  - Kwok R, 2019, NATURE, V567, P133, DOI 10.1038/d41586-019-00746-1
CR  - Lane DJW, 2006, BIOL CONSERV, V131, P584, DOI 10.1016/j.biocon.2006.03.005
CR  - LAWRENCE BD, 1982, J ACOUST SOC AM, V71, P585, DOI 10.1121/1.387529
CR  - Lopez-Baucells A, 2019, ECOL INFORM, V49, P45, DOI 10.1016/j.ecoinf.2018.11.004
CR  - McArthur E;, 2021, J BAT RES CONSERV, V14, P95, DOI 10.14709/BarbJ.14.1.2021.11
CR  - McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
CR  - Meyer Christoph F.J., 2016, P63
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Olden JD, 2008, Q REV BIOL, V83, P171, DOI 10.1086/587826
CR  - Park KJ, 2015, MAMM BIOL, V80, P191, DOI 10.1016/j.mambio.2014.10.004
CR  - Parsons S, 2000, J EXP BIOL, V203, P2641
CR  - Pham LK, 2021, DIVERSITY-BASEL, V13, DOI 10.3390/d13010018
CR  - Phillipps Q., 2016, PHILLIPPS FIELD GUID, V1st
CR  - Pottie SA, 2005, ACTA CHIROPTEROL, V7, P237, DOI 10.3161/1733-5329(2005)7[237:TMBFOS]2.0.CO;2
CR  - Revilla-Martin N, 2021, BIOACOUSTICS, V30, P527, DOI 10.1080/09524622.2020.1816492
CR  - Russo D, 2018, CAN J ZOOL, V96, P63, DOI 10.1139/cjz-2017-0089
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Schmieder DA, 2012, FUNCT ECOL, V26, P1043, DOI 10.1111/j.1365-2435.2012.02024.x
CR  - Schnitzler HU, 2003, TRENDS ECOL EVOL, V18, P386, DOI 10.1016/S0169-5347(03)00185-X
CR  - Schnitzler HU, 2001, BIOSCIENCE, V51, P557, DOI 10.1641/0006-3568(2001)051[0557:EBIEB]2.0.CO;2
CR  - Siemers BM, 2004, NATURE, V429, P657, DOI 10.1038/nature02547
CR  - Simmons N.B., BAT SPECIES WORLD TA
CR  - Soisook P, 2015, ACTA CHIROPTEROL, V17, P21, DOI 10.3161/15081109ACC2015.17.1.002
CR  - Struebig MJ, 2013, ADV ECOL RES, V48, P183, DOI 10.1016/B978-0-12-417199-2.00003-3
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tanshi I, 2021, FASCINAT LIFE SCI, P255, DOI 10.1007/978-3-030-54727-1_16
CR  - Torrent L, 2018, REMOTE SENS ECOL CON, V4, P339, DOI 10.1002/rse2.83
CR  - Valletta JJ, 2017, ANIM BEHAV, V124, P203, DOI 10.1016/j.anbehav.2016.12.005
CR  - Walters CL, 2013, BAT EVOLUTION ECOLOG, P479, DOI [10.1007/978-1-4614-7397-8_23, DOI 10.1007/978-1-4614-7397-8_23]
CR  - Wei L, 2008, ACTA CHIROPTEROL, V10, P51, DOI 10.3161/150811008X331081
CR  - Yoh N, 2020, DIVERSITY-BASEL, V12, DOI 10.3390/d12020060
CR  - Zamora-Gutierrez V, 2016, METHODS ECOL EVOL, V7, P1082, DOI 10.1111/2041-210X.12556
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - MAR
PY  - 2022
VL  - 136
DO  - 10.1016/j.ecolind.2022.108696
AN  - WOS:000761479300001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  61
ER  -

TY  - JOUR
AU  - Metcalf, OC
AU  - Lees, AC
AU  - Barlow, J
AU  - Marsden, SJ
AU  - Devenish, C
TI  - hardRain: An R package for quick, automated rainfall detection in ecoacoustic datasets using a threshold-based approach
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Ecoacoustics
KW  - Environmental monitoring
KW  - Bioacoustics
KW  - Soundscape ecology
KW  - Rain detection
KW  - Acoustic pre-processing
KW  - ACOUSTIC INDEXES
KW  - BIODIVERSITY
KW  - IDENTIFICATION
KW  - SOUND
AB  - The increasing demand for cost-efficient biodiversity data at large spatiotemporal scales has led to an increase in the collection of large ecoacoustic datasets. Whilst the ease of collection and storage of audio data has rapidly increased and costs fallen, methods for robust analysis of the data have not developed so quickly. Identification and classification of audio signals to species level is extremely desirable, but reliability can be highly affected by non-target noise, especially rainfall. Despite this demand, there are few easily applicable pre-processing methods available for rainfall detection for conservation practitioners and ecologists. Here, we use threshold values of two simple measures, Power Spectrum Density (amplitude) and Signal-to-Noise Ratio at two frequency bands, to differentiate between the presence and absence of heavy rainfall. We assess the effect of using different threshold values on Accuracy and Specificity. We apply the method to four datasets from both tropical and temperate regions, and find that it has up to 99% accuracy on tropical datasets (e.g. from the Brazilian Amazon), but performs less well in temperate environments. This is likely due to the intensity of rainfall in tropical forests and its falling on dense, broadleaf vegetation amplifying the sound. We show that by choosing between different threshold values, informed trade-offs can be made between Accuracy and Specificity, thus allowing the exclusion of large amounts of audio data containing rainfall in all locations without the loss of data not containing rain. We assess the impact of using different sample sizes of audio data to set threshold values, and find that 200 15 s audio files represents an optimal trade-off between effort, accuracy and specificity in most scenarios. This methodology and accompanying R package 'hardRain' is the first automated rainfall detection tool for pre-processing large acoustic datasets without the need for any additional rain gauge data.
AD  - Manchester Metropolitan Univ, Sch Sci & Environm, Dept Nat Sci, Manchester, Lancs, EnglandAD  - Cornell Univ, Cornell Lab Ornithol, Ithaca, NY USAAD  - Univ Lancaster, Lancaster Environm Ctr, Lancaster, Lancs, EnglandAD  - Univ Fed Lavras, Dept Biol, Lavras, MG, BrazilC3  - Manchester Metropolitan UniversityC3  - Cornell UniversityC3  - Lancaster UniversityC3  - Universidade Federal de LavrasFU  - ECOFOR [NE/K016431/1]; AFIRE [NE/P004512/1]; PELD-RAS [CNPq/CAPES/PELD 441659/2016-0]; Rainforest Trust; Chester Zoo; NERC [NE/K016431/1, NE/P004512/1] Funding Source: UKRI
FX  - We are very grateful for the insightful comments of Carol Bedoya who kindly provided feedback on the Manuscript. We are also grateful to J. Ferreira, E. Berenguer, L. Rossi and F. Franca for logistical field support in Brazil, R. Junaid and G. C. Aprianto in Java, M. Mcready, M. Rowcliffe, J. Ewen, E. Williams and S. Collins in New Zealand, and M. Lororio-Leturiondo and G. Abercrombie in the UK. Fieldwork in Brazil was supported by research grants ECOFOR (NE/K016431/1), and AFIRE (NE/P004512/1), PELD-RAS (CNPq/CAPES/PELD 441659/2016-0) and in Java through funding from the Rainforest Trust and Chester Zoo.
CR  - Bedoya C, 2017, ECOL INDIC, V75, P95, DOI 10.1016/j.ecolind.2016.12.018
CR  - Bioacoustics Research Program, 2010, RAV PROINT SOUND AN
CR  - Brown A, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105501
CR  - Burivalova Z, 2019, SCIENCE, V363, P28, DOI 10.1126/science.aav1902
CR  - Deichmann JL, 2018, BIOTROPICA, V50, P713, DOI 10.1111/btp.12593
CR  - Depraetere M, 2012, ECOL INDIC, V13, P46, DOI 10.1016/j.ecolind.2011.05.006
CR  - Fairbrass AJ, 2017, ECOL INDIC, V83, P169, DOI 10.1016/j.ecolind.2017.07.064
CR  - Farina A, 2018, ECOL INDIC, V85, P698, DOI 10.1016/j.ecolind.2017.10.073
CR  - Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088
CR  - Frontier Labs, 2015, BIOAC AUD REC US GUI
CR  - Gardner TA, 2008, ECOL LETT, V11, P139, DOI 10.1111/j.1461-0248.2007.01133.x
CR  - Glotin, 2016, 2016 IEEE 26 INT WOR, P1, DOI [DOI 10.1109/MLSP.2016.7738875, 10.1109/MLSP.2016.7738875]
CR  - Hampton SE, 2013, FRONT ECOL ENVIRON, V11, P156, DOI 10.1890/120103
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - McCallen E, 2019, FRONT ECOL ENVIRON, V17, P109, DOI 10.1002/fee.1993
CR  - Metcalf OC, 2019, METHODS ECOL EVOL, V10, P626, DOI 10.1111/2041-210X.13147
CR  - Peters DPC, 2014, ECOSPHERE, V5, DOI 10.1890/ES13-00359.1
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - RStudio Team, 2015, RSTUDIO INT DEV ENV
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Sueur J, 2008, BIOACOUSTICS, V18, P213, DOI 10.1080/09524622.2008.9753600
CR  - Towsey M, 2014, ECOL INFORM, V21, P110, DOI 10.1016/j.ecoinf.2013.11.007
CR  - Velez DR, 2007, GENET EPIDEMIOL, V31, P306, DOI 10.1002/gepi.20211
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - FEB
PY  - 2020
VL  - 109
DO  - 10.1016/j.ecolind.2019.105793
AN  - WOS:000500940400032
N1  - Times Cited in Web of Science Core Collection:  11
Total Times Cited:  11
Cited Reference Count:  23
ER  -

TY  - JOUR
AU  - Thangavel, S
AU  - Shokkalingam, CS
TI  - The IoT based embedded system for the detection and discrimination of animals to avoid human-wildlife conflict
T2  - JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA  - English
KW  - Animal acoustic monitoring
KW  - Animal recognition
KW  - Machine learning techniques
KW  - Internet of things (IoT)
KW  - Early warning and monitoring module
KW  - SPEECH EMOTION RECOGNITION
KW  - CLASSIFICATION
KW  - ELEPHANTS
KW  - AGE
AB  - Human-wildlife conflict (HWC) is one of the major crises in the valparai region of Anamalai Tiger Reserves (ATR). It is essential to reduce the HWC to save people from the wildlife and also to protect wildlife. In this paper, we propose an automated unsupervised system for the identification and classification of animals from their acoustic signal. The environment sound signals are captured using a microphone and the audio is stored in a.wav file and is sent to a base station through a radio frequency (RF) network. This system is processed with three steps (i) from the received audio signal initially, animal identification is done by extracting features of an animal signal using Mel frequency cepstral coefficient (MFCC) and classification of animal is performed by radial basis function (RBF) neural network, (ii) age estimation (calf/adult) is performed by autocorrelation, (iii) elephant state of mind (SOM) is detected by extracting features of an elephant acoustic signal using gammatone frequency cepstral coefficient (GFCC) and classification of various sounds of elephant are performed by support vector machine (SVM). Based on this, an early warning message which contains an animal type, age (calf/adult), elephant SOM, global positioning system (GPS) tracks its location information and all this information will be transmitted via global system for mobile communication (GSM) to the forest authorities, local communities, radio station or local channels indicating that an animal movement is near to forest border areas. The results were fed into a separate web page using the internet of thing (IoT).
AD  - Anna Univ, Univ Coll Engn, Thirukkuvalai, Nagapattinam, IndiaC3  - Anna UniversityFU  - University Grants Commission, New Delhi
FX  - My heartfelt gratitude to my mentor and my research guide Dr. Chitra Selvi Shokkalingam, Department of Electrical and Electronics Engineering, Anna University-University College of Engineering, Thirukkuvalai for her constant support and valuable guidance, and supervision. I sincerely acknowledge the University Grants Commission, New Delhi for providing me SRF (Senior Research Fellow) Fellowship under National Fellowship Scheme.
CR  - Anni DJS, 2015, ADV INTELLIGENT SYST, V337, DOI [10.1007/978-3-319-13728-5_67, DOI 10.1007/978-3-319-13728-5_67]
CR  - Anni JS, 2018, FUTURE GENER COMP SY, V83, P522, DOI 10.1016/j.future.2017.02.019
CR  - Arslan A, 2018, GAZI U J SCI, V31, P112
CR  - Ayoub B, 2016, 2016 INT C INF TECHN, P1, DOI [10.1109/IT4OD.2016.7479293, DOI 10.1109/IT4OD.2016.7479293]
CR  - Bjorck J, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P476
CR  - Borden GJ, 1994, SPEECH SCI PRIMER PH
CR  - Boussaid L, 2018, INT J SPEECH TECHNOL, V21, P29, DOI 10.1007/s10772-017-9480-7
CR  - Broersen PM., 2006, AUTOMATIC AUTOCORREL
CR  - Buchan SJ, 2020, BIOACOUSTICS, V29, P140, DOI 10.1080/09524622.2018.1563758
CR  - Clemins PJ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P484
CR  - Darras K, 2016, BIOL CONSERV, V201, P29, DOI 10.1016/j.biocon.2016.06.021
CR  - Devi KJ., 2019, J AMB INTEL HUM COMP, DOI [10.1007/s12652-019-01414-y, DOI 10.1007/S12652-019-01414-Y]
CR  - Gutierrez-Galan D, 2018, NEUROCOMPUTING, V272, P17, DOI 10.1016/j.neucom.2017.03.090
CR  - Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
CR  - Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
CR  - Kapersky E, 2013, BLACKHATONOMICS: AN INSIDE LOOK AT THE ECONOMICS OF CYBERCRIME, P45, DOI 10.1016/B978-1-59-749740-4.00004-6
CR  - Kaya H, 2017, COMPUT SPEECH LANG, V46, P268, DOI 10.1016/j.csl.2017.06.002
CR  - Keen S, 2014, ECOL INFORM, V21, P25, DOI 10.1016/j.ecoinf.2014.01.001
CR  - Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
CR  - Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004
CR  - Lenin J., 2011, ACTION PLAN MITIGATI
CR  - Leonid TT, 2021, J AMB INTEL HUM COMP, V12, P5269, DOI 10.1007/s12652-020-02005-y
CR  - Luque J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050717
CR  - Matuska S, 2014, AASRI PROC, V9, P25, DOI 10.1016/j.aasri.2014.09.006
CR  - Mustafa MB, 2018, INT J SPEECH TECHNOL, V21, P137, DOI 10.1007/s10772-018-9493-x
CR  - Nanni L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238578
CR  - Ogawa A, 2017, SPEECH COMMUN, V89, P70, DOI 10.1016/j.specom.2017.02.009
CR  - Oikarinen TP, 2018, 437004 BIORXIV
CR  - Padmanabhan J, 2015, IETE TECH REV, V32, P240, DOI 10.1080/02564602.2015.1010611
CR  - Poshitha D, 2015, P 6 ACM WORKSH REAL, DOI [10.1145/2820990.2821000, DOI 10.1145/2820990.2821000]
CR  - Prabu, 2016, INT J ADV ENG TECHNO, V7, P166
CR  - Stoeger AS, 2014, BIOACOUSTICS, V23, P231, DOI 10.1080/09524622.2014.888375
CR  - Stoeger AS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048907
CR  - Venkataraman AB, 2005, CURR SCI INDIA, V88, P1827
CR  - Viljoen JJ, 2015, BIOACOUSTICS, V24, P1, DOI 10.1080/09524622.2014.906320
CR  - Wood JD, 2005, J APPL ECOL, V42, P587, DOI 10.1111/j.1365-2664.2005.01044.x
CR  - Wu Y., 2012, ISRN APPL MATH, V2012, P1, DOI [10.5402/2012/324194, DOI 10.5402/2012/324194]
CR  - Zeppelzauer Matthias, 2015, BMC Research Notes, V8, P409, DOI 10.1186/s13104-015-1370-y
CR  - Zeppelzauer M, 2015, BIOACOUSTICS, V24, P13, DOI 10.1080/09524622.2014.906321
CR  - Zhang B, 2017, BIOMED SIGNAL PROCES, V38, P100, DOI 10.1016/j.bspc.2017.05.003
CR  - Zhao Z, 2017, ECOL INFORM, V39, P99, DOI 10.1016/j.ecoinf.2017.04.003
CR  - Zhu Y., 2018, IEEE T CIRC SYST VID, P1, DOI DOI 10.1109/TCSVT.2018.2793359
PU  - SPRINGER HEIDELBERG
PI  - HEIDELBERG
PA  - TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
DO  - 10.1007/s12652-021-03141-9
AN  - WOS:000634309900001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  42
ER  -

TY  - JOUR
AU  - Catzim, VV
AU  - Elias-Gutierrez, M
AU  - Perez-Lachaud, G
TI  - Contribution to the lady beetle fauna of the Yucatan Peninsula and integrative taxonomy for species delimitation
T2  - SYSTEMATICS AND BIODIVERSITY
LA  - English
KW  - ABGD method
KW  - barcode index number
KW  - Coccinellidae
KW  - Diomus
KW  - DNA barcodes
KW  - Mexico
KW  - tropics
KW  - COLEOPTERA-COCCINELLIDAE
KW  - DNA BARCODES
KW  - PREDACEOUS COCCINELLIDAE
KW  - GENUS
KW  - CLASSIFICATION
KW  - BIODIVERSITY
KW  - HISTORY
KW  - NORTH
AB  - Lady beetles (Coleoptera: Coccinellidae) are among the most familiar insects; many species are of economic importance, but their diversity in the tropics is poorly known. We aimed to contribute to the knowledge of the lady beetle fauna of the Yucatan Peninsula, particularly for Quintana Roo state. We used an integrative approach for species identification, comparing classical morphological identifications and quick automated methods for species delimitation using DNA barcode sequences. Through a literature review and a survey of lady beetles in gardens in Quintana Roo, we further provide an updated list of the species found on the Yucatan Peninsula. Out of the 40 species delimited in our study, 34 are new reports for the peninsula, and 36 are new for Quintana Roo state. Overall, 62 species of lady beetles are now recorded for the entire region, including three exotics: the invasive Harmonia axyridis, Chilocorus nigrita, and Delphastus catalinae. Our study also contributed to public reference libraries with 110 barcode sequences for the tropics belonging to 34 delineated species. We showed that cytochrome oxidase 1 (COI) sequences can be useful for lady beetle species delimitation and that the Automatic Barcode Gap Discovery algorithm (ABGD) was the best method, complementing the number of initially delineated morphospecies. The Barcode Index Number (BIN) approach overestimated seven putative species due to the splitting of conspecifics, while the ABGD method suggested two additional MOTUs at a prior intraspecific distance of 0.059. Combined molecular and morphological data in our study revealed one additional putative species of Diomus, initially considered a tentative colour variation. Our study exemplifies how molecular methods paired with classical taxonomy can efficiently assist in delineating species when descriptions and identification keys are unavailable and highlights the possible great richness of coccinellid species awaiting exploration and description on the Yucatan Peninsula.
AD  - El Colegio Frontera Sur, Dept Conservac Biodiversidad, Ave Centenario Km 5-5, Chetmal 77014, Quintana Roo, MexicoAD  - El Colegio Frontera Sur, Dept Ecol & Sistemat Acuat, Ave Centenario Km 5-5, Chetmal 77014, Quintana Roo, MexicoC3  - El Colegio de la Frontera Sur (ECOSUR)C3  - El Colegio de la Frontera Sur (ECOSUR)FU  - Consejo Nacional de Ciencia y Tecnologia (CONACYT, Mexico) [462338]
FX  - This work was partially supported by Consejo Nacional de Ciencia y Tecnologia (CONACYT, Mexico) under Grant number 462338
CR  - Blagoev GA, 2015, GENOME, V58, P197
CR  - Bouchard P, 2011, ZOOKEYS, P1, DOI 10.3897/zookeys.88.807
CR  - Burgos Solorio A., 2001, TOPICOS SOBRE COLEOP, P69
CR  - Catzim V.V., 2015, THESIS COLEGIO FRONT
CR  - Che LH, 2021, MOL PHYLOGENET EVOL, V156, DOI 10.1016/j.ympev.2020.107045
CR  - Ramos ASDC, 2020, REV BRAS ENTOMOL, V64, DOI [10.1590/1806-9665-RBENT-2020-0014, 10.1590/1806-9665-rbent-2020-0014]
CR  - Costello MJ, 2013, SCIENCE, V339, P413, DOI 10.1126/science.1230318
CR  - Crotch G.R., 1874, REVISION COLEOPTEROU
CR  - Dixon AFG, 1997, ENTOMOPHAGA, V42, P71, DOI 10.1007/BF02769882
CR  - Espinosa-Organista D, 2008, CAPITAL NATURAL MEXI, P33
CR  - Flores-MejYa S., 2004, ACTA U, V14, P8, DOI [https://doi.org/10.15174/au.2004.233, DOI 10.15174/AU.2004.233]
CR  - Gordon R.D., 1983, Transactions of the American Entomological Society (Philadelphia), V109, P229
CR  - GORDON RD, 1985, J NEW YORK ENTOMOL S, V93, P1
CR  - Gorham H.S., 1891, BIOL CENT AM, P150
CR  - Gorham H.S., 1894, BIOL CENT AM, P177
CR  - Gorham H.S., 1897, BIOL CENT AM, P217
CR  - Gorham H.S., 1898, BIOL CENT AM, P241
CR  - Gorham H.S., 1892, BIOL CENT AM, P161
CR  - Greenstone MH, 2011, MOL ECOL RESOUR, V11, P629, DOI 10.1111/j.1755-0998.2011.03007.x
CR  - HAGEN KS, 1962, ANNU REV ENTOMOL, V7, P289, DOI 10.1146/annurev.en.07.010162.001445
CR  - Halim M, 2017, J ASIA-PAC ENTOMOL, V20, P814, DOI 10.1016/j.aspen.2017.05.009
CR  - Hebert PDN, 2003, P ROY SOC B-BIOL SCI, V270, pS96, DOI [10.1098/rspb.2002.2218, 10.1098/rsbl.2003.0025]
CR  - Hodda M, 2011, ZOOTAXA, P63, DOI 10.11646/zootaxa.3148.1.3
CR  - Hoelmer KA, 2003, BIOCONTROL SCI TECHN, V13, P529, DOI 10.1080/0958315031000141018
CR  - Honek A., 1996, Series Entomologica (Dordrecht), V54, P33
CR  - Honek A, 2020, BIOL INVASIONS, V22, P2049, DOI 10.1007/s10530-020-02238-0
CR  - Huang WD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66874-1
CR  - Iperti G, 1999, AGR ECOSYST ENVIRON, V74, P323, DOI 10.1016/S0167-8809(99)00041-9
CR  - Nestor-Arriola JI, 2019, ZOOTAXA, V4701, P537, DOI 10.11646/zootaxa.4701.6.3
CR  - Ivanova NV, 2006, MOL ECOL NOTES, V6, P998, DOI 10.1111/j.1471-8286.2006.01428.x
CR  - Janzen DH, 2017, P NATL ACAD SCI USA, V114, P8313, DOI 10.1073/pnas.1621504114
CR  - Juarez Monroy A.C., 1986, THESIS U NACL AUTONO
CR  - Koch RL, 2003, J INSECT SCI, V3, DOI 10.1093/jis/3.1.32
CR  - Kovar I., 1996, Series Entomologica (Dordrecht), V54, P19
CR  - Lin XL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138993
CR  - Llorente-Bousquets JE, 2008, CAPITAL NATURAL MEXI, VI, P283
CR  - Lozano Contreras Monica Guadalupe, 2012, Fitosanidad, V16, P5
CR  - Lpez Pia G., 2017, BIOLOGICAS, V19, P16
CR  - Lpez-Arroyo J.I., 2008, CASOS CONTROL BIOL M, P279
CR  - Lpez-Arroyo J.I., 2003, 1 S INT CITR OAX, P12
CR  - Machkour-M'Rabet Salima, 2015, Acta Zool. Mex, V31, P512
CR  - Rodriguez-Velez JM, 2019, COLEOPTS BULL, V73, P243, DOI 10.1649/0010-065X-73.1.243
CR  - Rodriguez-Velez JM, 2019, SOUTHWEST ENTOMOL, V44, P345, DOI 10.3958/059.044.0141
CR  - Rodriguez-Velez JM, 2018, REV MEX BIODIVERS, V89, P666, DOI 10.22201/ib.20078706e.2018.3.2445
CR  - Marin J, 2010, ZOOL SCR, V39, P591, DOI 10.1111/j.1463-6409.2010.00450.x
CR  - MarYn-Jarillo A., 2008, FOLIA ENTOMOLOGICA M, V47, P21
CR  - Mitchell A, 2020, PEERJ, V8, DOI 10.7717/peerj.9348
CR  - Montes-Ortiz L, 2018, J LIMNOL, V77, P428, DOI 10.4081/jlimnol.2018.1746
CR  - Mulsant M.E., 1853, ANN SOC LINNEENNE LY, V2, P129, DOI DOI 10.5962/BHL.TITLE.60609
CR  - Mulsant M.E., 1850, ANN SCI PHYS NATUREL, V2, P1, DOI DOI 10.5962/BHL.TITLE.8953
CR  - MunguYa R.A., 2002, PROGRAMA MANEJO PULG
CR  - Nestor Arriola J.I., 2011, THESIS I ECOLOGIA ME
CR  - Obrycki JJ, 1998, ANNU REV ENTOMOL, V43, P295, DOI 10.1146/annurev.ento.43.1.295
CR  - Ortiz AS, 2017, BIODIVERS DATA J, V5, DOI 10.3897/BDJ.5.e19840
CR  - Pang H, 2009, ANN ZOOL, V59, P641, DOI 10.3161/000345409X485008
CR  - Pentinsaari M, 2017, MOL ECOL RESOUR, V17, P393, DOI 10.1111/1755-0998.12557
CR  - Poolprasert P., 2019, MALAYSIAN J APPL SCI, V4, P10
CR  - Poorani J., 2015, Entomon, V40, P235
CR  - Puillandre N, 2012, MOL ECOL, V21, P1864, DOI 10.1111/j.1365-294X.2011.05239.x
CR  - Rannala B, 2020, PHYLOGENETICS GENOMI
CR  - Ratnasingham S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066213
CR  - Roy HE, 2016, BIOL INVASIONS, V18, P997, DOI 10.1007/s10530-016-1077-6
CR  - RuYz Cancino E., 2002, ARTROPODOS TERRESTRE
CR  - Scheffers BR, 2012, TRENDS ECOL EVOL, V27, P501, DOI 10.1016/j.tree.2012.05.008
CR  - Seago AE, 2011, MOL PHYLOGENET EVOL, V60, P137, DOI 10.1016/j.ympev.2011.03.015
CR  - Slogget John J., 2012, P13
CR  - Song C, 2018, ZOOL SCR, V47, P311, DOI 10.1111/zsc.12284
CR  - Song N, 2020, INT J BIOL MACROMOL, V147, P1193, DOI 10.1016/j.ijbiomac.2019.10.089
CR  - Stork NE, 2018, ANNU REV ENTOMOL, V63, P31, DOI 10.1146/annurev-ento-020117-043348
CR  - Thomas, 2013, LADYBIRD BEETLES REC
CR  - Tyagi K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50510-8
CR  - Vandenberg N.J., 2002, AM BEETLES POLYPHAGA, VII, P371
CR  - Vandenberg NJ, 2019, ZOOTAXA, V4554, P255, DOI 10.11646/zootaxa.4554.1.9
CR  - Wallace AR., 1876, GEOGRAPHICAL DISTRIB
CR  - Wang ZL, 2019, MITOCHONDRIAL DNA A, V30, P1, DOI 10.1080/24701394.2018.1446950
CR  - Williams T, 2013, ANNU REV ENTOMOL, V58, P119, DOI 10.1146/annurev-ento-120811-153552
CR  - Zhou ZJ, 2019, BMC EVOL BIOL, V19, DOI 10.1186/s12862-019-1404-5
PU  - TAYLOR & FRANCIS LTD
PI  - ABINGDON
PA  - 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
DA  - DEC 31
PY  - 2022
VL  - 20
IS  - 1
DO  - 10.1080/14772000.2021.2017060
AN  - WOS:000752054800001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  77
ER  -

TY  - JOUR
AU  - John, E
AU  - Bunting, P
AU  - Hardy, A
AU  - Silayo, D
AU  - Masunga, E
TI  - A Forest Monitoring System for Tanzania
T2  - REMOTE SENSING
LA  - English
KW  - forest baseline
KW  - forest types
KW  - Landsat-8
KW  - change detection
KW  - deforestation
KW  - XGBoost
KW  - tropical forests
KW  - protected areas
KW  - Tanzania
KW  - LAND-USE
KW  - COMBINING SATELLITE
KW  - DEFORESTATION
KW  - ACCURACY
KW  - EARTH
AB  - Tropical forests provide essential ecosystem services related to human livelihoods. However, the distribution and condition of tropical forests are under significant pressure, causing shrinkage and risking biodiversity loss across the tropics. Tanzania is currently undergoing significant forest cover changes, but monitoring is limited, in part due to a lack of remote sensing knowledge, tools and methods. This study has demonstrated a comprehensive approach to creating a national-scale forest monitoring system using Earth Observation data to inform decision making, policy formulation, and combat biodiversity loss. A systematically wall-to-wall forest baseline was created for 2018 through the application of Landsat 8 imagery. The classification was developed using the extreme gradient boosting (XGBoost) machine-learning algorithm, and achieved an accuracy of 89% and identified 45.76% of the country's area to be covered with forest. Of those forested areas, 45% was found within nationally protected areas. Utilising an innovative methodology based on a forest habitat suitability analysis, the forest baseline was classified into forest types, with an overall accuracy of 85%. Woodlands (open and closed) were found to make up 79% of Tanzania's forests. To map changes in forest extent, an automated system for downloading and processing of the Landsat imagery was used along with the XGBoost classifiers trained to define the national forest extent, where Landsat 8 scenes were individually downloaded and processed and the identified changes summarised on an annual basis. Forest loss identified for 2019 was found to be 157,204 hectares, with an overall accuracy of 82%. These forest losses within Tanzania have already triggered ecological problems and alterations in ecosystem types and species loss. Therefore, a forest monitoring system, such as the one presented in this study, will enhance conservation programmes and support efforts to save the last remnants of Tanzania's pristine forests.
AD  - Aberystwyth Univ, Dept Geog & Earth Sci, Aberystwyth SY23 3DB, Dyfed, WalesAD  - Tanzania Forest Serv TFS Agcy, Dar Es Salaam 15472, TanzaniaC3  - Aberystwyth UniversityFU  - Commonwealth Scholarship Commission (CSC) in the UK [TZCS-2017-721]
FX  - This research was supported by the Commonwealth Scholarship Commission (CSC) in the UK with award number TZCS-2017-721.
CR  - Anande D. M., 2019, Atmospheric and Climate Sciences, V9, P421, DOI 10.4236/acs.2019.93029
CR  - Anderson K, 2017, GEO-SPAT INF SCI, V20, P77, DOI 10.1080/10095020.2017.1333230
CR  - Awty-Carroll K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232833
CR  - Awty-Carroll K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232779
CR  - Bazzaz F.A., 1998, TROPICAL FORESTS FUT, P177
CR  - Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
CR  - Brooks EB, 2014, IEEE T GEOSCI REMOTE, V52, P3316, DOI 10.1109/TGRS.2013.2272545
CR  - Bunting P., 2018, ATMOSPHERIC RADIOMET
CR  - Bunting P., 2018, EARTH OBSERVATION DA
CR  - Bunting P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101669
CR  - Bunting P, 2014, COMPUT GEOSCI-UK, V62, P216, DOI 10.1016/j.cageo.2013.08.007
CR  - Bunting P, 2013, COMPUT GEOSCI-UK, V57, P54, DOI 10.1016/j.cageo.2013.03.025
CR  - Burgess N., 2004, TERRESTRIAL ECOREGIO, P1
CR  - CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
CR  - Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213502
CR  - Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
CR  - Chuvieco E, 2002, INT J REMOTE SENS, V23, P5103, DOI 10.1080/01431160210153129
CR  - De Wasseige C., 2014, FORESTS CONGO BASIN, P21
CR  - DeVries B, 2015, REMOTE SENS ENVIRON, V161, P107, DOI 10.1016/j.rse.2015.02.012
CR  - Duveiller G, 2008, REMOTE SENS ENVIRON, V112, P1969, DOI 10.1016/j.rse.2007.07.026
CR  - Encalada AC, 2019, SCIENCE, V365, P1124, DOI 10.1126/science.aax1682
CR  - Fisher R, 2012, INT J APPL EARTH OBS, V16, P77, DOI 10.1016/j.jag.2011.12.004
CR  - Fjeldsa J, 1999, BIRD CONSERV INT, V9, P47, DOI 10.1017/S0959270900003348
CR  - Fuller DO, 2006, SINGAPORE J TROP GEO, V27, P15, DOI 10.1111/j.1467-9493.2006.00237.x
CR  - Galiatsatos N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111790
CR  - Garc?a MJL., 1991, GEOCARTO INT, V6, P31, DOI [10.1080/10106049109354290, DOI 10.1080/10106049109354290]
CR  - Ghaderpour E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12234001
CR  - Godoy FL, 2012, ENVIRON CONSERV, V39, P62, DOI 10.1017/S037689291100035X
CR  - Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1244693, 10.1126/science.1215904]
CR  - Hardy AJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081931
CR  - Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276
CR  - Hoscilo A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080929
CR  - Irons JR, 2012, REMOTE SENS ENVIRON, V122, P11, DOI 10.1016/j.rse.2011.08.026
CR  - John E, 2020, DIVERS DISTRIB, V26, P1663, DOI 10.1111/ddi.13152
CR  - Kimambo NE, 2019, FORESTS, V10, DOI 10.3390/f10080621
CR  - Lambin EF, 2003, ANNU REV ENV RESOUR, V28, P205, DOI 10.1146/annurev.energy.28.050302.105459
CR  - Li YC, 2019, FORESTS, V10, DOI 10.3390/f10121073
CR  - Malhi Y, 2014, ANNU REV ENV RESOUR, V39, P125, DOI 10.1146/annurev-environ-030713-155141
CR  - Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
CR  - Mitchard ETA, 2012, BIOGEOSCIENCES, V9, P179, DOI 10.5194/bg-9-179-2012
CR  - Mitchell AL, 2017, CARBON BAL MANAGE, V12, DOI 10.1186/s13021-017-0078-9
CR  - MNRT, 2015, NAT FOR RES MON ASS
CR  - National Bureau of Statistics (NBS) [Tanzania], 2017, NAT ENV STAT REP, P1
CR  - Neeff T, 2020, FOREST POLICY ECON, V118, DOI 10.1016/j.forpol.2020.102248
CR  - Olofsson P, 2020, REMOTE SENS ENVIRON, V236, DOI 10.1016/j.rse.2019.111492
CR  - Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
CR  - Pitkanen TP, 2020, INT J APPL EARTH OBS, V86, DOI 10.1016/j.jag.2019.102011
CR  - Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
CR  - Potapov PV, 2012, REMOTE SENS ENVIRON, V122, P106, DOI 10.1016/j.rse.2011.08.027
CR  - Reiche J, 2021, ENVIRON RES LETT, V16, DOI 10.1088/1748-9326/abd0a8
CR  - Reiche J, 2016, NAT CLIM CHANGE, V6, P120, DOI 10.1038/nclimate2919
CR  - Suarez DR, 2021, ENVIRON RES LETT, V16, DOI 10.1088/1748-9326/abe960
CR  - Rosa IMD, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10124476
CR  - Saxena R, 2018, ISPRS J PHOTOGRAMM, V144, P217, DOI 10.1016/j.isprsjprs.2018.07.002
CR  - Schuster C, 2012, INT J REMOTE SENS, V33, P5583, DOI 10.1080/01431161.2012.666812
CR  - Shepherd JD, 2003, INT J REMOTE SENS, V24, P3503, DOI 10.1080/01431160210154029
CR  - UNEP-WCMC, 2021, PROT AR PROF UN REP
CR  - Van Passel J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12081276
CR  - Verbesselt J, 2010, REMOTE SENS ENVIRON, V114, P2970, DOI 10.1016/j.rse.2010.08.003
CR  - Vermote EF, 1997, IEEE T GEOSCI REMOTE, V35, P675, DOI 10.1109/36.581987
CR  - Vesa L., 2010, NATL FORESTRY RESOUR
CR  - Willis KJ, 2013, PHILOS T R SOC B, V368, DOI 10.1098/rstb.2012.0491
CR  - Wu L, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020341
CR  - Yu L, 2012, INT J REMOTE SENS, V33, P3966, DOI 10.1080/01431161.2011.636081
CR  - Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - AUG
PY  - 2021
VL  - 13
IS  - 16
DO  - 10.3390/rs13163081
AN  - WOS:000690102900001
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  65
ER  -

TY  - CPAPER
AU  - Islam, SB
AU  - Valles, D
ED  - Charkrabarti, S
ED  - Paul, R
TI  - Identification of Wild Species in Texas from Camera-trap Images using Deep Neural Network for Conservation Monitoring
T2  - 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC)
LA  - English
CP  - 10th Annual Computing and Communication Workshop and Conference (CCWC)
KW  - DCNN
KW  - image classification
KW  - species recognition
KW  - camera traps
KW  - wildlife monitoring
AB  - Protection of endangered species requires continuous monitoring and updated information about the existence, location, and behavioral alterations in their habitat. Remotely activated camera or "camera traps" is a reliable and effective method of photo documentation of local population size, locomotion, and predator-prey relationships of wild species. However, manual data processing from a large volume of images and captured videos is extremely laborious, time-consuming, and expensive. The recent advancement of deep learning methods has shown great outcomes for object and species identification in images. This paper proposes an automated wildlife monitoring system by image classification using computer vision algorithms and machine learning techniques. The goal is to train and validate a Convolutional Neural Network (CNN) that will be able to detect Snakes, Lizards and Toads/Frogs from camera trap images. The initial experiment implies building a flexible CNN architecture with labeled images accumulated from standard benchmark datasets of different citizen science projects. After accessing satisfactory accuracy, new camera-trap imagery data (collected from Bastrop County, Texas) will be implemented to the model to detect species. The performance will be evaluated based on the accuracy of prediction within their classification. The suggested hardware and software framework will offer an efficient monitoring system, speed up wildlife investigation analysis, and formulate resource management decisions.
AD  - Texas Sate Univ, Ingram Sch Engn, San Marcos, TX 78666 USACR  - Al Bashit A, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P438, DOI 10.1109/IEMCON.2018.8615076
CR  - [Anonymous], ZOONIVERSE DATABASE
CR  - [Anonymous], IMAGENET LARGE SCALE
CR  - Bashit A. A, 2019, INT S MEAS CONTR ROB
CR  - Brownlee J, INTRO IMAGENET CHALL
CR  - Brownlee J, PREPARE DATA MACHINE
CR  - Che Yong Yeo, 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P198, DOI 10.1109/CSPA.2011.5759872
CR  - Chen GB, 2014, IEEE IMAGE PROC, P858, DOI 10.1109/ICIP.2014.7025172
CR  - Gomez A., 2016, ARXIV160306169
CR  - He ZH, 2016, IEEE CIRC SYST MAG, V16, P73, DOI 10.1109/MCAS.2015.2510200
CR  - Kays R., 2010, ARXIV10095718V1CSNI
CR  - Mech L.D., 2002, CRITIQUE WILDLIFE RA
CR  - Moreaux M, TOAD IMAGE DATA
CR  - Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
CR  - Norouzzadeh M.S., 2017, ARXIV170305830V5
CR  - Rosebrock A., 2017, DEEP LEARNING COMPUT
CR  - Sahu R, 2019, VISUAL OBJECT TRACKI, DOI [10.5772/intechopen.88437, DOI 10.5772/INTECHOPEN.88437]
CR  - Schneider S, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P321, DOI 10.1109/CRV.2018.00052
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
CR  - Yim J, 2017, P INT C DIG IM COMP, DOI 10.1109/DICTA.2017.8227427
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
CR  - Zhang WW, 2011, IEEE T IMAGE PROCESS, V20, P1696, DOI 10.1109/TIP.2010.2099126
PU  - IEEE
PI  - NEW YORK
PA  - 345 E 47TH ST, NEW YORK, NY 10017 USA
PY  - 2020
SP  - 537
EP  - 542
AN  - WOS:000668567200085
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  22
ER  -

TY  - JOUR
AU  - Rhinehart, TA
AU  - Chronister, LM
AU  - Devlin, T
AU  - Kitzes, J
TI  - Acoustic localization of terrestrial wildlife: Current practices and future opportunities
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - acoustic localization system
KW  - autonomous recording units
KW  - bioacoustics
KW  - conservation
KW  - microphone array
KW  - wildlife monitoring
KW  - ROBOT AUDITION SYSTEM
KW  - JAPANESE HOUSE BATS
KW  - MICROPHONE-ARRAY
KW  - TIME-DIFFERENCES
KW  - LOCATION SYSTEM
KW  - SAGE-GROUSE
KW  - PIPISTRELLUS-ABRAMUS
KW  - ECHOLOCATION CALLS
KW  - MOVEMENT BEHAVIOR
KW  - FLIGHT BEHAVIOR
AB  - Autonomous acoustic recorders are an increasingly popular method for low-disturbance, large-scale monitoring of sound-producing animals, such as birds, anurans, bats, and other mammals. A specialized use of autonomous recording units (ARUs) is acoustic localization, in which a vocalizing animal is located spatially, usually by quantifying the time delay of arrival of its sound at an array of time-synchronized microphones. To describe trends in the literature, identify considerations for field biologists who wish to use these systems, and suggest advancements that will improve the field of acoustic localization, we comprehensively review published applications of wildlife localization in terrestrial environments. We describe the wide variety of methods used to complete the five steps of acoustic localization: (1) define the research question, (2) obtain or build a time-synchronizing microphone array, (3) deploy the array to record sounds in the field, (4) process recordings captured in the field, and (5) determine animal location using position estimation algorithms. We find eight general purposes in ecology and animal behavior for localization systems: assessing individual animals' positions or movements, localizing multiple individuals simultaneously to study their interactions, determining animals' individual identities, quantifying sound amplitude or directionality, selecting subsets of sounds for further acoustic analysis, calculating species abundance, inferring territory boundaries or habitat use, and separating animal sounds from background noise to improve species classification. We find that the labor-intensive steps of processing recordings and estimating animal positions have not yet been automated. In the near future, we expect that increased availability of recording hardware, development of automated and open-source localization software, and improvement of automated sound classification algorithms will broaden the use of acoustic localization. With these three advances, ecologists will be better able to embrace acoustic localization, enabling low-disturbance, large-scale collection of animal position data.
AD  - Univ Pittsburgh, Dept Biol Sci, Pittsburgh, PA 15260 USAC3  - Pennsylvania Commonwealth System of Higher Education (PCSHE)C3  - University of PittsburghFU  - Microsoft [NGS-55651T-18]; National Geographic Society [NGS-55651T-18]; University of Pittsburgh
FX  - Microsoft, Grant/Award Number: NGS-55651T-18; National Geographic Society, Grant/Award Number: NGS-55651T-18; University of Pittsburgh
CR  - Ali AM, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P41, DOI 10.1109/IPSN.2007.4379663
CR  - Ali AM, 2009, J SIGNAL PROCESS SYS, V57, P415, DOI 10.1007/s11265-008-0310-7
CR  - Allen M, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P371, DOI 10.1109/IPSN.2008.45
CR  - Andrei V., 2015, J ELECT ELECT ENG, V3, P202, DOI [10.11648/j.jeee.20150306.15, DOI 10.11648/J.JEEE.20150306.15]
CR  - Araya-Salas M, 2017, ANIM BEHAV, V124, P57, DOI 10.1016/j.anbehav.2016.12.003
CR  - Araya-Salas M, 2017, METHODS ECOL EVOL, V8, P184, DOI 10.1111/2041-210X.12624
CR  - Audacity Team, 2019, AUD R FREE AUD ED RE
CR  - Bates ME, 2010, J ACOUST SOC AM, V127, P2664, DOI 10.1121/1.3308468
CR  - Beason RD, 2019, BIOACOUSTICS, V28, P381, DOI 10.1080/09524622.2018.1463293
CR  - Bircheld S. T., 2004, EUR SIGN PROC C EUSI, P4
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
CR  - Bower JL, 2005, BIOACOUSTICS, V15, P1
CR  - Brinklov S, 2010, BEHAV ECOL SOCIOBIOL, V64, P1867, DOI 10.1007/s00265-010-0998-9
CR  - Cai S., 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P210, DOI 10.1109/ChinaSIP.2013.6625330
CR  - Cai S., 2013, ACM IEEE INT C INF P, P2
CR  - Calupca T.A., 2000, J ACOUST SOC AM, V108, P2582, DOI DOI 10.1121/1.4743595
CR  - Campbell M, 2012, J FIELD ORNITHOL, V83, P391, DOI 10.1111/j.1557-9263.2012.00389.x
CR  - Celis-Murillo A, 2009, J FIELD ORNITHOL, V80, P64, DOI 10.1111/j.1557-9263.2009.00206.x
CR  - Charif R.A., 2010, RAVEN PRO 1 4 USERS
CR  - Chen C.-E., 2006, ACM IEEE INT C INF P, P8
CR  - Chen JC, 2002, IEEE T SIGNAL PROCES, V50, P1843, DOI 10.1109/TSP.2002.800420
CR  - Clark CJ, 2018, J EXP BIOL, V221, DOI 10.1242/jeb.173625
CR  - Clark Christopher W., 1996, Report of the International Whaling Commission, V46, P541
CR  - Cobos M., 2017, WIRELESS COMMUNICATI, V2017, P1
CR  - Collier T. C., 2010, THESIS
CR  - Collier TC, 2010, ETHOLOGY, V116, P1171, DOI 10.1111/j.1439-0310.2010.01830.x
CR  - Collier TC, 2010, J ACOUST SOC AM, V128, P182, DOI 10.1121/1.3425729
CR  - Dantzker MS, 1999, J EXP BIOL, V202, P2893
CR  - Darras K, 2019, ECOL APPL, V29, DOI 10.1002/eap.1954
CR  - Darras K, 2018, METHODS ECOL EVOL, V9, P1928, DOI 10.1111/2041-210X.13031
CR  - Dawson DK, 2009, J APPL ECOL, V46, P1201, DOI 10.1111/j.1365-2664.2009.01731.x
CR  - Du XD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092906
CR  - Eastman KM, 2005, ACOUST RES LETT ONL, V6, P257, DOI 10.1121/1.2046567
CR  - ETHIER JP, 2019, IBIS 1107
CR  - Falk B, 2014, J EXP BIOL, V217, P4356, DOI 10.1242/jeb.114132
CR  - Fitzsimmons LP, 2008, BEHAV ECOL, V19, P824, DOI 10.1093/beheco/arn036
CR  - Fitzsimmons LP, 2008, ANIM BEHAV, V75, P1913, DOI 10.1016/j.anbehav.2007.11.006
CR  - Foote JR, 2008, BEHAV ECOL, V19, P1192, DOI 10.1093/beheco/arn087
CR  - Foote JR, 2008, ANIM BEHAV, V76, P1227, DOI 10.1016/j.anbehav.2008.06.007
CR  - Foote JR, 2010, BEHAVIOUR, V147, P1219, DOI 10.1163/000579510X513761
CR  - Frommolt KH, 2014, ECOL INFORM, V21, P4, DOI 10.1016/j.ecoinf.2013.12.009
CR  - Fujii K, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174927
CR  - Fujioka E, 2016, P NATL ACAD SCI USA, V113, P4848, DOI 10.1073/pnas.1515091113
CR  - Fujioka E, 2014, J ACOUST SOC AM, V136, P3389, DOI 10.1121/1.4898428
CR  - Fujioka E, 2011, J ACOUST SOC AM, V129, P1081, DOI 10.1121/1.3523300
CR  - Gillette MD, 2008, IEEE SIGNAL PROC LET, V15, P1, DOI 10.1109/LSP.2007.910324
CR  - Girod L., 2006, P 4 INT C EMB NETW S, P71
CR  - Girod L. D., 2005, THESIS
CR  - Goeau H., 2018, C LABS EV FOR 2018, P12
CR  - Goerlitz HR, 2018, ECOL EVOL, V8, P5090, DOI 10.1002/ece3.4088
CR  - Goerlitz HR, 2010, CURR BIOL, V20, P1568, DOI 10.1016/j.cub.2010.07.046
CR  - Gotze S, 2016, SCI REP-UK, V6, DOI 10.1038/srep30978
CR  - Grafe TU, 1997, ANIM BEHAV, V53, P1103, DOI 10.1006/anbe.1996.0427
CR  - Grodzinski U, 2009, J ANIM ECOL, V78, P540, DOI 10.1111/j.1365-2656.2009.01526.x
CR  - Guggenberger Mario, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P203, DOI 10.1007/978-3-319-14445-0_18
CR  - Gustafsson T, 2003, IEEE T SPEECH AUDI P, V11, P791, DOI 10.1109/TSA.2003.818027
CR  - Halverson T., 2002, GLOBAL POSITIONING S
CR  - Harlow Zac, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P220, DOI 10.1109/ChinaSIP.2013.6625332
CR  - Hedley RW, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00963-120106
CR  - Hedwig D, 2018, BEHAV ECOL SOCIOBIOL, V72, DOI 10.1007/s00265-018-2451-4
CR  - Hennigar B, 2019, BEHAV ECOL, V30, P1591, DOI 10.1093/beheco/arz123
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - Holderied MW, 2006, J EXP BIOL, V209, P1816, DOI 10.1242/jeb.02194
CR  - Holderied MW, 2003, P ROY SOC B-BIOL SCI, V270, P2293, DOI 10.1098/rspb.2003.2487
CR  - Hugel T, 2017, BEHAV ECOL SOCIOBIOL, V71, DOI 10.1007/s00265-017-2398-x
CR  - Huetz C., 2012, SENSORS ECOLOGY INTE, P83
CR  - Hulgard K, 2016, J EXP BIOL, V219, P334, DOI 10.1242/jeb.128983
CR  - Hutto RL, 2009, J FIELD ORNITHOL, V80, P387, DOI 10.1111/j.1557-9263.2009.00245.x
CR  - Ing RK, 2016, ACTA CHIROPTEROL, V18, P477, DOI 10.3161/15081109ACC2016.18.2.014
CR  - Jakobsen L, 2015, P NATL ACAD SCI USA, V112, P8118, DOI 10.1073/pnas.1419943112
CR  - Jensen ME, 1999, BEHAV ECOL SOCIOBIOL, V47, P60, DOI 10.1007/s002650050650
CR  - Jones DL, 2009, J ACOUST SOC AM, V126, P895, DOI 10.1121/1.3158924
CR  - Kershenbaum A, 2019, J ACOUST SOC AM, V145, P1619, DOI 10.1121/1.5092973
CR  - Kitzes J, 2019, ENVIRON CONSERV, V46, P247, DOI 10.1017/S0376892919000146
CR  - Knight EC, 2020, BIOACOUSTICS, V29, P337, DOI 10.1080/09524622.2019.1606734
CR  - Koblitz JC, 2018, CAN J ZOOL, V96, P933, DOI 10.1139/cjz-2017-0187
CR  - Kojima R, 2017, PR INT CONF DATA SC, P395, DOI 10.1109/DSAA.2017.34
CR  - Kojima R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1287, DOI 10.1109/IROS.2016.7759213
CR  - Kounitsky P, 2015, P NATL ACAD SCI USA, V112, P6724, DOI 10.1073/pnas.1422843112
CR  - Krakauer AH, 2009, J EXP BIOL, V212, P3719, DOI 10.1242/jeb.033076
CR  - Kwan C, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/96706
CR  - Langemann U, 2000, BEHAVIOUR, V137, P451, DOI 10.1163/156853900502178
CR  - Lapierre JM, 2011, BEHAV ECOL SOCIOBIOL, V65, P2149, DOI 10.1007/s00265-011-1223-1
CR  - Lasseck M., 2018, C LABS EV FOR AV FRA, P11
CR  - Lewanzik D, 2018, FUNCT ECOL, V32, P1251, DOI 10.1111/1365-2435.13073
CR  - Lippold S, 2008, ACTA ETHOL, V11, P67, DOI 10.1007/s10211-008-0043-4
CR  - MAGYAR I, 1978, EXPERIENTIA, V34, P676, DOI 10.1007/BF01937030
CR  - Marsland S, 2019, METHODS ECOL EVOL, V10, P1189, DOI 10.1111/2041-210X.13213
CR  - Matsubayashi S, 2017, J ROBOT MECHATRON, V29, P224, DOI 10.20965/jrm.2017.p0224
CR  - McGregor PK, 1997, ETHOL ECOL EVOL, V9, P269, DOI 10.1080/08927014.1997.9522887
CR  - Mellinger DK, 2007, OCEANOGRAPHY, V20, P36, DOI 10.5670/oceanog.2007.03
CR  - Mennill DJ, 2008, CURR BIOL, V18, P1314, DOI 10.1016/j.cub.2008.07.073
CR  - Mennill DJ, 2006, J ACOUST SOC AM, V119, P2832, DOI 10.1121/1.2184988
CR  - Mennill DJ, 2012, METHODS ECOL EVOL, V3, P704, DOI 10.1111/j.2041-210X.2012.00209.x
CR  - Militello C, 2007, J ACOUST SOC AM, V121, P3595, DOI 10.1121/1.2724241
CR  - Miller Lee A., 1993, Bioacoustics, V5, P67
CR  - Motoi K, 2017, J ACOUST SOC AM, V141, pEL439, DOI 10.1121/1.4981934
CR  - Nakadai K, 2010, ADV ROBOTICS, V24, P739, DOI 10.1163/016918610X493561
CR  - Osmun AE, 2011, ETHOLOGY, V117, P385, DOI 10.1111/j.1439-0310.2011.01887.x
CR  - Papin M, 2018, FRONT ZOOL, V15, DOI 10.1186/s12983-018-0260-2
CR  - Park J, 2018, APPL ACOUST, V136, P149, DOI 10.1016/j.apacoust.2017.08.026
CR  - Patricelli GL, 2008, ANIM BEHAV, V76, P1389, DOI 10.1016/j.anbehav.2008.07.005
CR  - Patricelli GL, 2007, BEHAV ECOL SOCIOBIOL, V61, P1099, DOI 10.1007/s00265-006-0343-5
CR  - Patricelli GL, 2010, BEHAV ECOL, V21, P97, DOI 10.1093/beheco/arp155
CR  - Payne KB, 2003, AFR J ECOL, V41, P99, DOI 10.1046/j.1365-2028.2003.00421.x
CR  - Peters DPC, 2014, ECOSPHERE, V5, DOI 10.1890/ES13-00295.1
CR  - Pijanowski BC, 2011, LANDSCAPE ECOL, V26, P1213, DOI 10.1007/s10980-011-9600-8
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Priyadarshani N, 2018, ECOL EVOL, V8, P5016, DOI 10.1002/ece3.3889
CR  - Priyadarshani N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146790
CR  - Rascon C, 2017, ROBOT AUTON SYST, V96, P184, DOI 10.1016/j.robot.2017.07.011
CR  - Ratcliffe JM, 2011, J COMP PHYSIOL A, V197, P413, DOI 10.1007/s00359-011-0630-0
CR  - Rek P, 2014, ACTA ETHOL, V17, P31, DOI 10.1007/s10211-013-0155-3
CR  - ROEDER KD, 1966, J INSECT PHYSIOL, V12, P843, DOI 10.1016/0022-1910(66)90035-7
CR  - Sarradj E, 2017, APPL ACOUST, V116, P50, DOI 10.1016/j.apacoust.2016.09.015
CR  - Sarradj E, 2011, AIAA J, V49, P769, DOI 10.2514/1.J050703
CR  - Schul J, 2000, P ROY SOC B-BIOL SCI, V267, P1711, DOI 10.1098/rspb.2000.1199
CR  - Segura-Garcia J, 2015, IEEE SENS J, V15, P836, DOI 10.1109/JSEN.2014.2356342
CR  - Seibert AM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135590
CR  - Seibert AM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060752
CR  - Silva M, 2008, COMPUT ELECTRON AGR, V64, P286, DOI 10.1016/j.compag.2008.05.024
CR  - Simmons AM, 2008, J COMP PSYCHOL, V122, P274, DOI 10.1037/0735-7036.122.3.274
CR  - Simons TR, 2007, AUK, V124, P986, DOI 10.1642/0004-8038(2007)124[986:EAOTAD]2.0.CO;2
CR  - Spencer SJ, 2007, J ACOUST SOC AM, V121, P3579, DOI 10.1121/1.2734404
CR  - Spiesberger JL, 1999, J ACOUST SOC AM, V106, P837, DOI 10.1121/1.427100
CR  - Spiesberger JL, 2005, J ACOUST SOC AM, V118, P1790, DOI 10.1121/1.1992708
CR  - SPIESBERGER JL, 1990, AM NAT, V135, P107, DOI 10.1086/285035
CR  - Spiesberger JL, 2001, J ACOUST SOC AM, V109, P3076, DOI 10.1121/1.1373442
CR  - Spillmann B, 2017, BEHAV ECOL SOCIOBIOL, V71, DOI 10.1007/s00265-016-2252-6
CR  - Spillmann B, 2015, AM J PRIMATOL, V77, P767, DOI 10.1002/ajp.22398
CR  - Stepanian PM, 2016, ECOL EVOL, V6, P7039, DOI 10.1002/ece3.2447
CR  - Stevenson BC, 2015, METHODS ECOL EVOL, V6, P38, DOI 10.1111/2041-210X.12291
CR  - Stoller D., 2018, ARXIV180603185CSEESS
CR  - Sumiya M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169995
CR  - SURLYKKE A, 1993, BEHAV ECOL SOCIOBIOL, V33, P1, DOI 10.1007/BF00164341
CR  - Surlykke A, 2009, P ROY SOC B-BIOL SCI, V276, P853, DOI 10.1098/rspb.2008.1505
CR  - Surlykke A, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002036
CR  - Suzuki R, 2018, ECOL EVOL, V8, P812, DOI 10.1002/ece3.3645
CR  - Suzuki R, 2016, INTERSPEECH, P2626, DOI 10.21437/Interspeech.2016-782
CR  - Suzuki R, 2017, J ROBOT MECHATRON, V29, P213, DOI 10.20965/jrm.2017.p0213
CR  - Svaizer P, 1997, INT CONF ACOUST SPEE, P231, DOI 10.1109/ICASSP.1997.599611
CR  - Taylor CE, 2016, ARTIF LIFE ROBOT, V21, P268, DOI 10.1007/s10015-016-0295-4
CR  - Thode AM, 2006, IEEE J OCEANIC ENG, V31, P696, DOI 10.1109/JOE.2006.880431
CR  - Thompson ME, 2010, AFR J ECOL, V48, P654, DOI 10.1111/j.1365-2028.2009.01161.x
CR  - Tiemann CO, 2006, J ACOUST SOC AM, V120, P2355, DOI 10.1121/1.2335577
CR  - Trifa V. M., 2006, THESIS
CR  - Trifa V. M., 2007, 12 INT S ART LIF ROB, P4
CR  - Vallejo EE, 2009, ARTIF LIFE ROBOT, V14, P485, DOI 10.1007/s10015-009-0705-y
CR  - Van Parijs SM, 2009, MAR ECOL PROG SER, V395, P21, DOI 10.3354/meps08123
CR  - Wahlberg Magnus, 2003, Bioacoustics, V13, P233
CR  - Wang H., 2005, OPTICS PHOTONICS 200
CR  - Wang HY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-1-r5
CR  - Warren MR, 2018, J NEUROSCI METH, V297, P44, DOI 10.1016/j.jneumeth.2017.12.013
CR  - WATKINS WA, 1972, DEEP-SEA RES, V19, P691, DOI 10.1016/0011-7471(72)90061-7
CR  - Whytock RC, 2017, METHODS ECOL EVOL, V8, P308, DOI 10.1111/2041-210X.12678
CR  - Wijers M, 2021, BIOACOUSTICS, V30, P41, DOI 10.1080/09524622.2019.1685408
CR  - Wilson DR, 2014, BIOACOUSTICS, V23, P99, DOI 10.1080/09524622.2013.827588
CR  - Wilson SJ, 2018, AVIAN CONSERV ECOL, V13, DOI 10.5751/ACE-01248-130204
CR  - Woelfel M., 2009, ACOUSTICS DISTANT SP, P27
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - Yip DA, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00997-120111
CR  - Yu K, 2016, IEEE SIGNAL PROC LET, V23, P1791, DOI 10.1109/LSP.2016.2614107
CR  - Zhang J, 2014, UNMANNED SYST, V2, P249, DOI 10.1142/S2301385014400044
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - JUL
PY  - 2020
VL  - 10
IS  - 13
SP  - 6794
EP  - 6818
DO  - 10.1002/ece3.6216
AN  - WOS:000547928500001
N1  - Times Cited in Web of Science Core Collection:  11
Total Times Cited:  13
Cited Reference Count:  164
ER  -

TY  - JOUR
AU  - Maciel, EA
AU  - Arle, E
TI  - Rare7: An R package to assess the forms of rarity in a community
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Rare species
KW  - Conservation biology
KW  - Rabinowitz
KW  - Data management
KW  - SPECIES DISTRIBUTIONS
KW  - CONSERVATION PRIORITY
KW  - VULNERABILITY
KW  - EXTINCTION
KW  - ABUNDANCE
AB  - Avoiding extinction rate is a challenge for scientists and decision-makers. In turn, identifying vulnerable species is a key step towards a consistent strategic planning and programming for species conservation. Rare species are of great interest to scientists because they are more prone to extinction. Rabinowitz proposed that rarity arises from the combination of three parameters: (1) geographic range, (2) local abundance, and (3) habitat specificity. By combining these parameters, the species of a community can be classified into seven forms of rarity. Many authors report the forms of rarity as a priority species for conservation. However, almost 40 years after it was first proposed there are no tools to apply this method. To remedy this gap, we propose the Rare7 package. Here, we provide an automated application of Rabinowitz's method to assess species rarity within a community. Rare7 present some advantages such as easy-to-follow instructions, robust methods, flexibility, applicability for different taxa, and a wide scale of distribution. Using the three parameters proposed by Rabinowitz, Rare7 distinguishes between common and rare species in a community. The output provided to Rare7 is a list comprising the species names and their respective classification as common or one of the seven forms of rarity of Rabinowitz. Because rarity precedes extinction events, Rare7 can be a powerful tool to planning species conservation.
AD  - Univ Estadual Campinas, UNICAMP, Inst Biol, Rua Monteiro Lobato 255,Block M, BR-13083862 Campinas, SP, BrazilAD  - German Ctr Integrat Biodivers Res iDiv, Macroecol & Soc, Deutsch Pl 5e, D-04103 Leipzig, GermanyC3  - Universidade Estadual de CampinasFU  - CNPq (Brazilian National Council for Scientific and Technological Development); DAAD (German Academic Exchange Service) [290179/2017-3]
FX  - This work was done with funding from the CNPq (Brazilian National Council for Scientific and Technological Development) and the DAAD (German Academic Exchange Service). Grant no. 290179/2017-3.
CR  - Abbitt RJF, 2000, BIOL CONSERV, V96, P169, DOI 10.1016/S0006-3207(00)00064-1
CR  - Bracken MES, 2012, ECOL LETT, V15, P461, DOI 10.1111/j.1461-0248.2012.01758.x
CR  - Broennimann O, 2005, BOT HELV, V115, P95, DOI 10.1007/s00035-005-0713-z
CR  - Caiafa AN, 2010, BIODIVERS CONSERV, V19, P2597, DOI 10.1007/s10531-010-9861-6
CR  - Cofre H, 1999, BIOL CONSERV, V88, P53, DOI 10.1016/S0006-3207(98)00090-1
CR  - Condit R, 2013, P NATL ACAD SCI USA, V110, P5064, DOI 10.1073/pnas.1218042110
CR  - Corlett Richard T., 2016, Plant Diversity, V38, P10, DOI 10.1016/j.pld.2016.01.001
CR  - Duncan RP, 2000, ECOLOGY, V81, P3048
CR  - Elton C.S., 1927, ANIMAL ECOLOGY
CR  - Espeland EK, 2011, BIODIVERS CONSERV, V20, P963, DOI 10.1007/s10531-011-0007-2
CR  - Fattorini S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033995
CR  - Gaston KJ, 2009, J APPL ECOL, V46, P1, DOI 10.1111/j.1365-2664.2008.01596.x
CR  - Grinnell J., 1917, Auk Cambridge Mass, V34
CR  - Guo QF, 2003, OIKOS, V101, P639, DOI 10.1034/j.1600-0706.2003.12428.x
CR  - IUCN, 2012, IUCN RED LIST CAT CR, VSecond
CR  - KATTAN GH, 1992, CONSERV BIOL, V6, P64, DOI 10.1046/j.1523-1739.1992.610064.x
CR  - Krauss J, 2010, ECOL LETT, V13, P597, DOI 10.1111/j.1461-0248.2010.01457.x
CR  - Kricsfalusy VV, 2014, BIODIVERS CONSERV, V23, P39, DOI 10.1007/s10531-013-0583-4
CR  - Lim GS, 2012, SYST BIOL, V61, P165, DOI 10.1093/sysbio/syr030
CR  - Lohmus A, 2015, BIODIVERS CONSERV, V24, P3151, DOI 10.1007/s10531-015-1000-y
CR  - MACARTHUR R, 1960, AM NAT, V94, P25, DOI 10.1086/282106
CR  - Maciel EA, 2016, NAT CONSERVACAO, V14, P74, DOI 10.1016/j.ncon.2016.10.002
CR  - Maciel EA, 2016, BIODIVERS CONSERV, V25, P611, DOI 10.1007/s10531-016-1068-z
CR  - MCINTYRE S, 1992, BIOL CONSERV, V60, P31, DOI 10.1016/0006-3207(92)90796-P
CR  - McKinney Michael L., 1997, Population and Community Biology Series, V17, P110
CR  - Mehlman DW, 2004, BIOL CONSERV, V120, P383, DOI 10.1016/j.biocon.2004.03.013
CR  - Mouillot D, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001569
CR  - Munday PL, 2004, GLOBAL CHANGE BIOL, V10, P1642, DOI 10.1111/j.1365-2486.2004.00839.x
CR  - Pitman NCA, 1999, ECOLOGY, V80, P2651, DOI 10.1890/0012-9658(1999)080[2651:TSDIAU]2.0.CO;2
CR  - Price T.D., 2009, P R SOC LONDON B
CR  - RABINOWITZ D, 1984, ECOLOGY, V65, P1144, DOI 10.2307/1938322
CR  - Rabinowitz D., 1981, BIOL ASPECTS RARE PL, P205
CR  - Rey Benayas JM, 1999, CONSERV ECOL, V3, P5
CR  - Ricketts TH, 2005, P NATL ACAD SCI USA, V102, P18497, DOI 10.1073/pnas.0509060102
CR  - Saetersdal M, 1997, J BIOGEOGR, V24, P127, DOI 10.1046/j.1365-2699.1997.00096.x
CR  - Simaika JP, 2011, ECOL INDIC, V11, P370, DOI 10.1016/j.ecolind.2010.06.005
CR  - Soliveres S, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0269
CR  - Spielman D, 2004, P NATL ACAD SCI USA, V101, P15261, DOI 10.1073/pnas.0403809101
CR  - Synge H., 1980, P INT C KINGS COLL C, VXxviii, P14
CR  - Wamelink GWW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102674
CR  - Wilson K, 2005, ENVIRON MANAGE, V35, P527, DOI 10.1007/s00267-004-0095-9
CR  - Yu JP, 2000, J BIOGEOGR, V27, P131, DOI 10.1046/j.1365-2699.2000.00366.x
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - AUG
PY  - 2020
VL  - 115
DO  - 10.1016/j.ecolind.2020.106419
AN  - WOS:000560052300012
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  42
ER  -

TY  - JOUR
AU  - Perez-Granados, C
AU  - Bota, G
AU  - Giralt, D
AU  - Albarracin, J
AU  - Traba, J
TI  - COST-EFFECTIVENESS ASSESSMENT OF FIVE AUDIO RECORDING SYSTEMS FOR WILDLIFE MONITORING: DIFFERENCES BETWEEN RECORDING DISTANCES AND SINGING DIRECTION
T2  - ARDEOLA-INTERNATIONAL JOURNAL OF ORNITHOLOGY
LA  - English
KW  - acoustic monitoring
KW  - automated signal recognition
KW  - Autonomous Recording Unit
KW  - Chersophilus duponti
KW  - classification software
KW  - playback
KW  - LARK CHERSOPHILUS-DUPONTI
KW  - RECOGNITION SOFTWARE
KW  - POINT COUNTS
KW  - BIRDS
KW  - UNITS
KW  - VOCALIZATION
KW  - PERFORMANCE
KW  - SIZE
AB  - Audio recording systems coupled with automated song recognition are commonly being used for monitoring wildlife. Recorders usually differ in cost and effectiveness, and their performance may vary with source distance, wind speed and acoustic source direction, among other factors. We here assess the cost-effectiveness of five audio systems considering such factors as distance and singing direction. We developed field tests using playback of Dupont's Lark Chersophilus duponti songs from nine fixed locations at distances of 1 to 256m, played towards or away from the recorders' position. We selected this species because its very characteristic song should be easily identified by automated signal recognition software. Field tests were carried out during March 2016 in level dwarf-shrub steppe (mean height < 40cm) in NE Spain. We found large differences in effectiveness between recorders. The number of songs detected by an automated signal recognition algorithm significantly decreased with distance and when playback was angled away from the recorder position, a factor never previously tested. Finally, we give the design of a cost-effective Autonomous Recording Unit, based upon the most effective recorder. We recommend researchers working with acoustic recorders to evaluate the performance of several devices before making a selection for long-term monitoring pro-grammes, and to consider such factors such as singing direction in their analyses.
AD  - Univ Autonoma Madrid, Dept Ecol, Terr Ecol Grp TEG UAM, Madrid, SpainAD  - Fed Univ Mato Grosso UFMT, Natl Inst Sci & Technol Wetlands INAU, Computat Bioacoust Res Unit COBRA, Cuiaba, Mato Grosso, BrazilAD  - Forest Sci & Technol Ctr Catalonia CTFC, Landscape Dynam & Biodivers Programme, Biodivers & Anim Conservat Lab, Solsona, Catalonia, SpainAD  - Univ Autonoma Madrid, Ctr Invest Biodiversidad & Cambio Global CIBC UAM, Madrid, SpainC3  - Autonomous University of MadridC3  - Universidade Federal de Mato GrossoC3  - Universidade Federal de Mato Grosso do SulC3  - Autonomous University of MadridFU  - programa de Investigacion y Conservacion del zoo de Barcelona within the project "Nuevas tecnologias para viejos trabajos. Uso de grabadores automaticos para la deteccion y censo de especies raras y amenazadas. El caso de la alondra ricoti en Lleida y otra; Comunidad de Madrid; Life-Ricoti-project [LIFE15-NAT-ES-000802]; European Commission
FX  - This study was partially supported by programa de Investigacion y Conservacion del zoo de Barcelona within the project "Nuevas tecnologias para viejos trabajos. Uso de grabadores automaticos para la deteccion y censo de especies raras y amenazadas. El caso de la alondra ricoti en Lleida y otras poblaciones pequenas". The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. We wish to thank the Junta de Andalucia for the assistance provided with some equipment used. We wish to thank Manuel Rojo, Francesc Sarda-palomera and David Guixe. We are also grateful to two anonymous reviewers, Jesus M. Aviles and Ernest Garcia whose comments helped to improve the manuscript. This is a contribution to the Excellence Network Remedinal 3CM (S2013/MAE 2719), supported by the Comunidad de Madrid and the Life-Ricoti-project (LIFE15-NAT-ES-000802), supported by the European Commission.
CR  - Acevedo MA, 2006, WILDLIFE SOC B, V34, P211, DOI 10.2193/0091-7648(2006)34[211:UADRSA]2.0.CO;2
CR  - Alquezar RD, 2015, WILSON J ORNITHOL, V127, P712, DOI 10.1676/14-104.1
CR  - Bates D., 2014, J STAT SOFTW, V1406, P5823, DOI DOI 10.18637/jss.v067.i01
CR  - Beason RD, 2019, BIOACOUSTICS, V28, P381, DOI 10.1080/09524622.2018.1463293
CR  - Bibby C.J., 2000, BIRD CENSUS TECHNIQU, V2nd edn
CR  - Brandes T.S., 2005, ACOUSTIC MONITORING
CR  - Brandes TS, 2008, BIRD CONSERV INT, V18, pS163, DOI 10.1017/S0959270908000415
CR  - Catchpole CK, 2008, BIRD SONG: BIOLOGICAL THEMES AND VARIATIONS, 2ND EDITION, P1
CR  - Cyr A., 1981, Studies in Avian Biology, P327
CR  - de Oliveira AG, 2015, APPL ACOUST, V98, P34, DOI 10.1016/j.apacoust.2015.04.014
CR  - Digby A, 2013, METHODS ECOL EVOL, V4, P675, DOI 10.1111/2041-210X.12060
CR  - Drake KL, 2016, WILDLIFE SOC B, V40, P346, DOI 10.1002/wsb.658
CR  - Efford MG, 2009, ECOLOGY, V90, P2676, DOI 10.1890/08-1735.1
CR  - Fristrup KM, 2012, ACOUST TODAY, V3, P16, DOI DOI 10.1121/1.4753913
CR  - Ganchev TD, 2015, EXPERT SYST APPL, V42, P6098, DOI 10.1016/j.eswa.2015.03.036
CR  - Gil D, 2015, BEHAV ECOL, V26, P435, DOI 10.1093/beheco/aru207
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
CR  - Hutto RL, 2009, J FIELD ORNITHOL, V80, P387, DOI 10.1111/j.1557-9263.2009.00245.x
CR  - Jahn O, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169041
CR  - Kepler C.B., 1981, Studies in Avian Biology, P366
CR  - LARSEN ON, 1990, ORNIS SCAND, V21, P37, DOI 10.2307/3676376
CR  - Leach EC, 2016, EMU, V116, P305, DOI 10.1071/MU15097
CR  - Oppel S, 2014, NAT CONSERV-BULGARIA, P1, DOI 10.3897/natureconservation.7.6890
CR  - Perez-Granados C, 2018, ARDEA, V106, P139, DOI 10.5253/arde.v106i2.a6
CR  - Perez-Granados C, 2019, IBIS, V161, P901, DOI 10.1111/ibi.12728
CR  - Perez-Granados C, 2018, BIRD STUDY, V65, P338, DOI 10.1080/00063657.2018.1511682
CR  - Perez-Granados C, 2017, ARDEOLA, V64, P75, DOI 10.13157/arla.64.1.2017.sc2
CR  - Perez-Granados C, 2016, J ORNITHOL, V157, P471, DOI 10.1007/s10336-015-1310-6
CR  - R Core Team, 2017, R LANG ENV STAT COMP
CR  - Rempel RS, 2013, J FIELD ORNITHOL, V84, P86, DOI 10.1111/jofo.12008
CR  - Rempel RS, 2005, J FIELD ORNITHOL, V76, P1, DOI 10.1648/0273-8570-76.1.1
CR  - Seoane J, 2006, BIOL CONSERV, V128, P241, DOI 10.1016/j.biocon.2005.09.032
CR  - Shearin AF, 2012, WETLANDS, V32, P737, DOI 10.1007/s13157-012-0307-7
CR  - Titze IR, 2018, J ACOUST SOC AM, V143, P2813, DOI 10.1121/1.5034768
CR  - Towsey M, 2012, BIOACOUSTICS, V21, P107, DOI 10.1080/09524622.2011.648753
CR  - Turgeon PJ, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00958-120109
CR  - Venier LA, 2012, WILDLIFE SOC B, V36, P30, DOI 10.1002/wsb.88
CR  - Waddle JH, 2009, HERPETOL CONSERV BIO, V4, P384
CR  - Wildlife Acoustics, 2011, SONG SCOP US MAN BIO
CR  - Wolfgang A, 2016, NORTHEAST NAT, V23, P249
CR  - Yip DA, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00997-120111
CR  - Zwart MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102770
PU  - SOC ESPANOLA ORNITOLGIA
PI  - MADRID
PA  - MELQUIADAS BIENCINTO 34, E-28053 MADRID, SPAIN
DA  - JUL
PY  - 2019
VL  - 66
IS  - 2
SP  - 311
EP  - 325
DO  - 10.13157/arla.66.2.2019.ra4
AN  - WOS:000482707800004
N1  - Times Cited in Web of Science Core Collection:  18
Total Times Cited:  18
Cited Reference Count:  44
ER  -

TY  - JOUR
AU  - Hipiny, I
AU  - Ujir, H
AU  - Mujahid, A
AU  - Yahya, NK
TI  - Towards Automated Biometric Identification of Sea Turtles (Chelonia mydas)
T2  - JOURNAL OF ICT RESEARCH AND APPLICATIONS
LA  - English
KW  - content-based image retrieval
KW  - invariant feature descriptor
KW  - multimedia databases
KW  - template matching
KW  - visual animal biometrics
AB  - Passive biometric identification enables wildlife monitoring with minimal disturbance. Using a motion-activated camera placed at an elevated position and facing downwards, images of sea turtle carapaces were collected, each belonging to one of sixteen Chelonia mydas juveniles. Then, co-variant and robust image descriptors from these images were learned, enabling indexing and retrieval. In this paper, several classification results of sea turtle carapaces using the learned image descriptors are presented. It was found that a template-based descriptor, i.e. Histogram of Oriented Gradients (HOG) performed much better during classification than keypoint-based descriptors. For our dataset, a high-dimensional descriptor is a must because of the minimal gradient and color information in the carapace images. Using HOG, we obtained an average classification accuracy of 65%.
AD  - UNIMAS, Fac Comp Sci & Informat Technol, Jalan Datuk Mohammad Musa, Kota Samarahan 94300, Sarawak, MalaysiaAD  - UNIMAS, Fac Resource Sci & Technol, Jalan Datuk Mohammad Musa, Kota Samarahan 94300, Sarawak, MalaysiaAD  - Sabah Wildlife Dept, Danau Girang Field Ctr, Lower Kinabatangan Wildl, Sabah, MalaysiaAD  - Cardiff Univ, Lower Kinabatangan Wildl, Sabah, MalaysiaC3  - University of Malaysia SarawakC3  - University of Malaysia SarawakFU  - Universiti Malaysia Sarawak through the following Small Grant Scheme (SGS) [F08(S160)/1171/2014(25)]
FX  - This work was supported by Universiti Malaysia Sarawak through the following Small Grant Scheme (SGS) grant: F08(S160)/1171/2014(25).
CR  - Balazs G.H., 1982, Marine Turtle Newsletter, P11
CR  - Balazs G. H., 2000, NMFSSEFSC443 NOAA
CR  - Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
CR  - Bellini Claudio, 2001, Herpetological Review, V32, P172
CR  - Bolle R. M, 2000, IEEE C COMP VIS PATT
CR  - BOULENGER GA, 1890, FAUNA BRIT INDIA REP
CR  - Burghardt T., 2007, 6 INT PENG C IPC07 H
CR  - Burghardt T., 2010, VISUAL OBSERVATION A, P17
CR  - Dabarera R., 2010, 5 INT C INF AUT SUST
CR  - Dalal N., 2005, 9 EUR C COMP VIS SAN
CR  - Hassanien A. E, 2017, INT C ADV INT SYST I
CR  - Hipiny I, 2012, CSTR12003 U BRIST
CR  - Hipiny I, 2013, THESIS
CR  - Li WY, 2017, COMPUT ELECTRON AGR, V142, P622, DOI 10.1016/j.compag.2017.10.029
CR  - LIMPUS CJ, 1992, WILDLIFE RES, V19, P457, DOI 10.1071/WR9920457
CR  - Loos A., 2012, 19 INT C SYST SIGN I
CR  - Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
CR  - McDonald Donna L., 1996, Chelonian Conservation and Biology, V2, P148
CR  - Monteiro F. C, 2016, INT C IM AN REC
CR  - Mrosovsky N., 1982, Marine Turtle Newsletter, P11
CR  - Puzicha J., 2001, ADV NEURAL INFORM PR
CR  - Reisser Julia, 2008, Endangered Species Research, V5, P73, DOI 10.3354/esr00113
CR  - Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
CR  - Ting R. R, 2016, NURHARTINI BIDS FARE
CR  - Ujir H, 2014, I S INTELL SIG PROC, P196, DOI 10.1109/ISPACS.2014.7024451
CR  - Ujir H, 2014, LECT NOTES ELECTR EN, V291, P245, DOI 10.1007/978-981-4585-42-2_29
CR  - van Dam Robert P., 1999, Chelonian Conservation and Biology, V3, P225
CR  - Wyneken J., 2001, ANATOMY SEA TURTLES
PU  - ITB JOURNAL PUBL
PI  - BANDUNG
PA  - LPPM ITB, ITB RECTORATE BUILDING, 5TH FLR, JALAN TAMANSARI 64, BANDUNG, 40116, INDONESIA
PY  - 2018
VL  - 12
IS  - 3
SP  - 256
EP  - 266
DO  - 10.5614/itbj.ict.res.appl.2018.12.3.4
AN  - WOS:000457435200004
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  28
ER  -

TY  - JOUR
AU  - Clapham, M
AU  - Miller, E
AU  - Nguyen, M
AU  - Darimont, CT
TI  - Automated facial recognition for wildlife that lack unique markings: A deep learning approach for brown bears
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - deep learning
KW  - face recognition
KW  - grizzly bear
KW  - individual ID
KW  - machine learning
KW  - wildlife monitoring
KW  - CAMERA TRAPS
KW  - REIDENTIFICATION
KW  - INDIVIDUALS
KW  - NETWORKS
AB  - Emerging technologies support a new era of applied wildlife research, generating data on scales from individuals to populations. Computer vision methods can process large datasets generated through image-based techniques by automating the detection and identification of species and individuals. With the exception of primates, however, there are no objective visual methods of individual identification for species that lack unique and consistent body markings. We apply deep learning approaches of facial recognition using object detection, landmark detection, a similarity comparison network, and an support vector machine-based classifier to identify individuals in a representative species, the brown bear Ursus arctos. Our open-source application, BearID, detects a bear's face in an image, rotates and extracts the face, creates an "embedding" for the face, and uses the embedding to classify the individual. We trained and tested the application using labeled images of 132 known individuals collected from British Columbia, Canada, and Alaska, USA. Based on 4,674 images, with an 80/20% split for training and testing, respectively, we achieved a facial detection (ability to find a face) average precision of 0.98 and an individual classification (ability to identify the individual) accuracy of 83.9%. BearID and its annotated source code provide a replicable methodology for applying deep learning methods of facial recognition applicable to many other species that lack distinguishing markings. Further analyses of performance should focus on the influence of certain parameters on recognition accuracy, such as age and body size. Combining BearID with camera trapping could facilitate fine-scale behavioral research such as individual spatiotemporal activity patterns, and a cost-effective method of population monitoring through mark-recapture studies, with implications for species and landscape conservation and management. Applications to practical conservation include identifying problem individuals in human-wildlife conflicts, and evaluating the intrapopulation variation in efficacy of conservation strategies, such as wildlife crossings.
AD  - BearID Project, Sooke, BC, CanadaAD  - Univ Victoria, Dept Geog, 3800 Finnerty Rd, Victoria, BC V8P 5C2, CanadaAD  - Raincoast Conservat Fdn, Bella Bella, BC, CanadaC3  - University of VictoriaFU  - Natural Sciences and Engineering Research Council of Canada [CRDPJ 523329-18]
FX  - Natural Sciences and Engineering Research Council of Canada, Grant/Award Number: CRDPJ 523329-18
CR  - Arts K, 2015, AMBIO, V44, pS661, DOI 10.1007/s13280-015-0705-1
CR  - Brust CA, 2017, IEEE INT CONF COMP V, P2820, DOI 10.1109/ICCVW.2017.333
CR  - Chen P, 2020, ECOL EVOL, V10, P3561, DOI 10.1002/ece3.6152
CR  - Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Clapham M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035404
CR  - Clutton-Brock T, 2010, TRENDS ECOL EVOL, V25, P562, DOI 10.1016/j.tree.2010.08.002
CR  - Crouse D, 2017, BMC ZOOL, V2, DOI 10.1186/s40850-016-0011-9
CR  - Dalal N., 2005, IEEE COMPUTER SOC C, P886, DOI 10.1109/CVPR.2005.177
CR  - Deb D., 2018, ARXIV180408790
CR  - Dexter CE, 2018, AUST MAMMAL, V40, P67, DOI 10.1071/AM16043
CR  - Ernst A, 2011, 8 IEEE INT C ADV VID, P279, DOI [10.1109/avss.2011.6027337, DOI 10.1109/AVSS.2011.6027337]
CR  - Freytag A, 2016, LECT NOTES COMPUT SC, V9796, P51, DOI 10.1007/978-3-319-45886-1_5
CR  - HAN B, 2018, ADV NEUR IN, V31
CR  - Hertel AG, 2017, BEHAV ECOL, V28, P1524, DOI 10.1093/beheco/arx122
CR  - Hilderbrand GV, 1999, CAN J ZOOL, V77, P132, DOI 10.1139/cjz-77-1-132
CR  - Huang G. B., 2007, LABELED FACES WILD D
CR  - Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
CR  - King D. E., 2015, 150200046 ARXIV
CR  - King DE, 2009, J MACH LEARN RES, V10, P1755
CR  - Kingsley MCS, 1983, INT C BEARS, V5, P174, DOI [DOI 10.2307/3872535, 10.2307/3872535]
CR  - Kuhl HS, 2013, TRENDS ECOL EVOL, V28, P432, DOI 10.1016/j.tree.2013.02.013
CR  - Loos A, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P116, DOI 10.1109/ISM.2012.30
CR  - Miao ZQ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44565-w
CR  - Moreira TP, 2017, MULTIMED TOOLS APPL, V76, P15325, DOI 10.1007/s11042-016-3824-1
CR  - Rashmi P., 2017, INT J RECENT TRENDS, V3, P207, DOI [10.23883/IJRTER.2017.3215.TXUQG, DOI 10.23883/IJRTER.2017.3215.TXUQG]
CR  - Rowcliffe JM, 2008, J APPL ECOL, V45, P1228, DOI 10.1111/j.1365-2664.2008.01473.x
CR  - Schneider S, 2020, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW50321.2020.9096925
CR  - Schneider S, 2019, METHODS ECOL EVOL, V10, P461, DOI 10.1111/2041-210X.13133
CR  - Schofield D, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0736
CR  - Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
CR  - Steenweg R, 2017, FRONT ECOL ENVIRON, V15, P26, DOI 10.1002/fee.1448
CR  - Swan GJF, 2017, TRENDS ECOL EVOL, V32, P518, DOI 10.1016/j.tree.2017.03.011
CR  - Wearn OR, 2019, NAT MACH INTELL, V1, P72, DOI 10.1038/s42256-019-0022-7
CR  - Weinstein BG, 2018, J ANIM ECOL, V87, P533, DOI 10.1111/1365-2656.12780
CR  - Weinstein BG, 2015, METHODS ECOL EVOL, V6, P357, DOI 10.1111/2041-210X.12320
CR  - Witham CL, 2018, J NEUROSCI METH, V300, P157, DOI 10.1016/j.jneumeth.2017.07.020
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - DEC
PY  - 2020
VL  - 10
IS  - 23
SP  - 12883
EP  - 12892
DO  - 10.1002/ece3.6840
AN  - WOS:000585885000001
N1  - Times Cited in Web of Science Core Collection:  14
Total Times Cited:  14
Cited Reference Count:  37
ER  -

TY  - JOUR
AU  - Overton, C
AU  - Casazza, M
AU  - Bretz, J
AU  - McDuie, F
AU  - Matchett, E
AU  - Mackell, D
AU  - Lorenz, A
AU  - Mott, A
AU  - Herzog, M
AU  - Ackerman, J
TI  - Machine learned daily life history classification using low frequency tracking data and automated modelling pipelines: application to North American waterfowl
T2  - MOVEMENT ECOLOGY
LA  - English
KW  - Animal behavior
KW  - Daily activity
KW  - Life history state
KW  - Global positioning system
KW  - Supervised machine learning
KW  - Classification
KW  - Automated model pipeline
KW  - Biologging
KW  - Waterfowl
KW  - Anatidae
KW  - Telemetry
KW  - Daily activity routine
KW  - REAL-TIME
KW  - GPS
KW  - RESOLUTION
KW  - TELEMETRY
KW  - MIGRATION
KW  - BEHAVIOR
KW  - CONSERVATION
KW  - ECOLOGY
AB  - Background Identifying animal behaviors, life history states, and movement patterns is a prerequisite for many animal behavior analyses and effective management of wildlife and habitats. Most approaches classify short-term movement patterns with high frequency location or accelerometry data. However, patterns reflecting life history across longer time scales can have greater relevance to species biology or management needs, especially when available in near real-time. Given limitations in collecting and using such data to accurately classify complex behaviors in the long-term, we used hourly GPS data from 5 waterfowl species to produce daily activity classifications with machine-learned models using "automated modelling pipelines". Methods Automated pipelines are computer-generated code that complete many tasks including feature engineering, multi-framework model development, training, validation, and hyperparameter tuning to produce daily classifications from eight activity patterns reflecting waterfowl life history or movement states. We developed several input features for modeling grouped into three broad categories, hereafter "feature sets": GPS locations, habitat information, and movement history. Each feature set used different data sources or data collected across different time intervals to develop the "features" (independent variables) used in models. Results Automated modelling pipelines rapidly developed easily reproducible data preprocessing and analysis steps, identification and optimization of the best performing model and provided outputs for interpreting feature importance. Unequal expression of life history states caused unbalanced classes, so we evaluated feature set importance using a weighted F1-score to balance model recall and precision among individual classes. Although the best model using the least restrictive feature set (only 24 hourly relocations in a day) produced effective classifications (weighted F1 = 0.887), models using all feature sets performed substantially better (weighted F1 = 0.95), particularly for rarer but demographically more impactful life history states (i.e., nesting). Conclusions Automated pipelines generated models producing highly accurate classifications of complex daily activity patterns using relatively low frequency GPS and incorporating more classes than previous GPS studies. Near real-time classification is possible which is ideal for time-sensitive needs such as identifying reproduction. Including habitat and longer sequences of spatial information produced more accurate classifications but incurred slight delays in processing.
AD  - US Geol Survey, Western Ecol Res Ctr, Dixon Field Stn, Dixon, CA 95620 USAAD  - US Geol Survey, Cloud Hosting Solut, Bozeman, MT USAAD  - San Jose State Univ Res Fdn, Moss Landing Labs, San Jose, CA USAC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - California State University SystemC3  - San Jose State UniversityFU  - USGS Western Ecological Research Center; USGS Cloud Hosting Services; California Department of Water Resources, Suisun Marsh Branch
FX  - This study was primarily funded by the USGS Western Ecological Research Center and USGS Cloud Hosting Services. Wildlife telemetry data used in this was project was obtained under grant with California Department of Water Resources, Suisun Marsh Branch.
CR  - Abrahms B, 2017, MOV ECOL, V5, DOI 10.1186/s40462-017-0104-2
CR  - Altizer S, 2011, SCIENCE, V331, P296, DOI 10.1126/science.1194694
CR  - Brown DD, 2012, WILDLIFE SOC B, V36, P139, DOI 10.1002/wsb.111
CR  - Capoccia S., 2020, MT BUR MINES GEOL, V121, P13
CR  - Casazza ML, 2020, ANIM BEHAV, V164, P163, DOI 10.1016/j.anbehav.2020.04.013
CR  - Chakravarty P, 2019, METHODS ECOL EVOL, V10, P802, DOI 10.1111/2041-210X.13172
CR  - Chen T, 2016, P78594, DOI 10.1145/2939672.2939785
CR  - Croston R, 2020, ECOL EVOL, V10, P2513, DOI 10.1002/ece3.6078
CR  - Das P, 2020, P 4 INT WORKSHOP DAT, P17, DOI [10.1145/3399579.3399870, DOI 10.1145/3399579.3399870]
CR  - Du Y, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040354
CR  - Edelhoff H, 2016, MOV ECOL, V4, DOI 10.1186/s40462-016-0086-5
CR  - Fu LM, 2021, PROCEEDINGS OF EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING (EASE 2021), P40, DOI 10.1145/3463274.3463325
CR  - Gardy JL, 2018, NAT REV GENET, V19, P9, DOI 10.1038/nrg.2017.88
CR  - Getz WM, 2008, P NATL ACAD SCI USA, V105, P19066, DOI 10.1073/pnas.0801732105
CR  - Getz WM., 2019, ECOLOGY, DOI [10.1101/819763, DOI 10.1101/819763]
CR  - Glass TW, 2020, ECOL INFORM, V60, DOI 10.1016/j.ecoinf.2020.101152
CR  - Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
CR  - Gurarie E, 2016, J ANIM ECOL, V85, P69, DOI 10.1111/1365-2656.12379
CR  - Harel R, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0397
CR  - Hounslow JL, 2019, J EXP MAR BIOL ECOL, V512, P22, DOI 10.1016/j.jembe.2018.12.003
CR  - Iwana BK, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254841
CR  - Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
CR  - Kays R, 2015, SCIENCE, V348, DOI 10.1126/science.aaa2478
CR  - Kohl JD., 2019, THESIS U CALIFORNIA
CR  - Ladds MA., 2017, ANIM BIOTELEM, V5, P8, DOI [10.1186/s40317-017-0123-1, DOI 10.1186/S40317-017-0123-1]
CR  - Mahoney PJ, 2017, METHODS ECOL EVOL, V8, P174, DOI 10.1111/2041-210X.12658
CR  - McDuie F, 2021, J ENVIRON MANAGE, V297, DOI 10.1016/j.jenvman.2021.113170
CR  - McDuie F, 2019, MOV ECOL, V7, DOI 10.1186/s40462-019-0146-8
CR  - McGowan J, 2017, J APPL ECOL, V54, P423, DOI 10.1111/1365-2664.12755
CR  - MilnerGulland EJ, 2011, ANIMAL MIGRATION: A SYNTHESIS, P1, DOI 10.1093/acprof:oso/9780199568994.001.0001
CR  - Nathan R, 2008, P NATL ACAD SCI USA, V105, P19052, DOI 10.1073/pnas.0800375105
CR  - Olivetti S, 2021, METHODS ECOL EVOL, V12, P1186, DOI [10.1111/2041-210X.13604, 10.5061/DRYAD.2547D7WQ4]
CR  - Overton CUS., 2022, SCIENCEBASE, DOI [10.5066/P9XBZKZ8, DOI 10.5066/P9XBZKZ8]
CR  - Owen-Smith N, 2010, PHILOS T R SOC B, V365, P2267, DOI 10.1098/rstb.2010.0095
CR  - Park Y-S, 2016, DEV ENV MODELLING IN, P12340
CR  - Peterson SH, 2019, ECOL EVOL, V9, P5490, DOI 10.1002/ece3.5146
CR  - Picardi S, 2020, MOV ECOL, V8, DOI 10.1186/s40462-020-00201-1
CR  - R Core Team, 2019, R LANG ENV STAT COMP
CR  - Rajalashmi K, 2021, IOP C SERIES MAT SCI
CR  - Roever CL, 2014, DIVERS DISTRIB, V20, P322, DOI 10.1111/ddi.12164
CR  - Sarker S, 2021, P INT JOINT C ADV CO, P46984, DOI [10.1007/978-981-16-0586-4_38, DOI 10.1007/978-981-16-0586-4_38]
CR  - Schafer TLJ, 2020, J AGR BIOL ENVIR ST, V25, P365, DOI 10.1007/s13253-020-00399-y
CR  - Sergio F, 2019, J APPL ECOL, V56, P562, DOI 10.1111/1365-2664.13294
CR  - Shamoun-Baranes J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037997
CR  - Stanley TR, 2000, ECOLOGY, V81, P2048, DOI 10.2307/177292
CR  - Wall J, 2014, ECOL APPL, V24, P593, DOI 10.1890/13-1971.1
CR  - Walter SE, 1997, J WILDLIFE MANAGE, V61, P768, DOI 10.2307/3802183
CR  - Watsa M, 2020, SCIENCE, V369, P145, DOI 10.1126/science.abc0017
CR  - Weegman MD, 2017, CURR ZOOL, V63, P667, DOI 10.1093/cz/zox056
CR  - Wittemyer G, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2018.0046
CR  - Yang X, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113741
CR  - YARRIS GS, 1994, CONDOR, V96, P36, DOI 10.2307/1369061
PU  - BMC
PI  - LONDON
PA  - CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
DA  - MAY 16
PY  - 2022
VL  - 10
IS  - 1
DO  - 10.1186/s40462-022-00324-7
AN  - WOS:000796491400001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  52
ER  -

TY  - JOUR
AU  - Lacharite, M
AU  - Brown, CJ
AU  - Gazzola, V
TI  - Multisource multibeam backscatter data: developing a strategy for the production of benthic habitat maps using semi-automated seafloor classification methods
T2  - MARINE GEOPHYSICAL RESEARCH
LA  - English
KW  - Multibeam echosounder
KW  - Backscatter
KW  - Habitat mapping
KW  - Benthoscape
KW  - Atlantic Canada
KW  - SCALE PARAMETER
KW  - IMAGE-ANALYSIS
KW  - GRAIN-SIZE
KW  - MARINE
KW  - SONAR
KW  - SEGMENTATION
KW  - MANAGEMENT
AB  - The establishment of multibeam echosounders (MBES) as a mainstream tool in ocean mapping has facilitated integrative approaches towards nautical charting, benthic habitat mapping, and seafloor geotechnical surveys. The bathymetric and backscatter information generated by MBES enables marine scientists to present highly accurate bathymetric data with a spatial resolution closely matching that of terrestrial mapping, and can generate customized thematic seafloor maps to meet multiple ocean management needs. However, when a variety of MBES systems are used, the creation of objective habitat maps can be hindered by the lack of backscatter calibration, due for example, to system-specific settings, yielding relative rather than absolute values. Here, we describe an approach using object-based image analysis to combine 4 non-overlapping and uncalibrated (backscatter) MBES coverages to form a seamless habitat map on St. Anns Bank (Atlantic Canada), a marine protected area hosting a diversity of benthic habitats. The benthoscape map was produced by analysing each coverage independently with supervised classification (k-nearest neighbor) of image-objects based on a common suite of 7 benthoscapes (determined with 4214 ground-truthing photographs at 61 stations, and characterized with backscatter, bathymetry, and bathymetric position index). Manual re-classification based on uncertainty in membership values to individual classes-especially at the boundaries between coverages-was used to build the final benthoscape map. Given the costs and scarcity of MBES surveys in offshore marine ecosystems-particularly in large ecosystems in need of adequate conservation strategies, such as in Canadian waters-developing approaches to synthesize multiple datasets to meet management needs is warranted.
AD  - Nova Scotia Community Coll, Appl Res, Waterfront Campus,80 Mawiomi Pl, Dartmouth, NS B2Y 0A5, CanadaFU  - DFO Academic Research Contribution Program [F5299-140076]; NSERC Canadian Healthy Oceans Network; Department of Fisheries and Oceans Canada; INREST (Port of Sept-Iles) [NETGP 468437-14, 1.2.5]; INREST (City of Sept-Iles) [NETGP 468437-14, 1.2.5]
FX  - The authors would like to thank Derek Fenton, Tanya Koropatnick and other colleagues in the Oceans and Coastal Management Division of Fisheries and Oceans, Canada (DFO) at the Bedford Institute of Oceanography for support and suggestions to this research project. Financial support for the research was through DFO Academic Research Contribution Program entitled Developing Methods for Benthic Habitat Mapping of MPAs in Atlantic Canada (project agreement #F5299-140076), and the NSERC Canadian Healthy Oceans Network and its partners: Department of Fisheries and Oceans Canada and INREST (representing the Port of Sept-Iles and City of Sept-Iles; NETGP 468437-14, Project 1.2.5).
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Brown CJ, 2008, ESTUAR COAST SHELF S, V78, P203, DOI 10.1016/j.ecss.2007.11.026
CR  - Brown CJ, 2012, J SEA RES, V72, P1, DOI 10.1016/j.seares.2012.04.009
CR  - Brown CJ, 2011, ESTUAR COAST SHELF S, V92, P502, DOI 10.1016/j.ecss.2011.02.007
CR  - Calvert J, 2015, ICES J MAR SCI, V72, P1498, DOI 10.1093/icesjms/fsu223
CR  - Cogan CB, 2009, ICES J MAR SCI, V66, P2033, DOI 10.1093/icesjms/fsp214
CR  - Collier JS, 2005, MAR GEOL, V214, P431, DOI 10.1016/j.margeo.2004.11.011
CR  - Copeland A, 2013, J COAST CONSERV, V17, P225, DOI 10.1007/s11852-011-0172-1
CR  - DFO, 2012, 3012034 DFO CAN SCI
CR  - Diesing M, 2014, CONT SHELF RES, V84, P107, DOI 10.1016/j.csr.2014.05.004
CR  - Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
CR  - Gavazzi GM, 2016, ESTUAR COAST SHELF S, V170, P45, DOI 10.1016/j.ecss.2015.12.014
CR  - Gordon Jr D.C., 2007, MAPPING SEAFLOOR HAB, P29
CR  - Hillman JIT, 2018, MAR GEOPHYS RES, V39, P205, DOI 10.1007/s11001-016-9297-9
CR  - Hogg OT, 2016, SCI REP-UK, V6, DOI 10.1038/srep33163
CR  - Huvenne VAI, 2002, MAR GEOL, V189, P323, DOI 10.1016/S0025-3227(02)00420-6
CR  - Ismail K, 2015, MAR GEOL, V362, P17, DOI 10.1016/j.margeo.2015.01.006
CR  - Jordan A, 2005, AQUAT CONSERV, V15, P51, DOI 10.1002/aqc.657
CR  - Kenny AJ, 2003, ICES J MAR SCI, V60, P411, DOI 10.1016/S1054-3139(03)00006-7
CR  - Lucieer V, 2009, MAR GEOL, V264, P230, DOI 10.1016/j.margeo.2009.06.006
CR  - Lucieer VL, 2008, INT J REMOTE SENS, V29, P905, DOI 10.1080/01431160701311309
CR  - Lucieer V, 2013, ESTUAR COAST SHELF S, V117, P94, DOI 10.1016/j.ecss.2012.11.001
CR  - Lucieer V, 2011, CONT SHELF RES, V31, P1236, DOI 10.1016/j.csr.2011.04.016
CR  - Lurton X., 2015, BACKSCATTER MEASUREM
CR  - McGonigle C, 2014, ESTUAR COAST SHELF S, V147, P123, DOI 10.1016/j.ecss.2014.05.025
CR  - McGonigle C, 2010, MAR GEOD, V33, P16, DOI 10.1080/01490410903530273
CR  - Ming DP, 2015, ISPRS J PHOTOGRAMM, V106, P28, DOI 10.1016/j.isprsjprs.2015.04.010
CR  - Neves BM, 2014, DEEP-SEA RES PT II, V99, P169, DOI 10.1016/j.dsr2.2013.05.026
CR  - Pickrill R.A., 2007, MAPPING SEAFLOOR HAB, V47, P483
CR  - Pickrill RA, 2003, OCEAN COAST MANAGE, V46, P601, DOI 10.1016/S0964-5691(03)00037-1
CR  - Roff JC, 2003, AQUAT CONSERV, V13, P77, DOI 10.1002/aqc.525
CR  - Stephens D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093950
CR  - Young M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116200
CR  - Zajac RN, 2003, LIMNOL OCEANOGR, V48, P829, DOI 10.4319/lo.2003.48.2.0829
PU  - SPRINGER
PI  - DORDRECHT
PA  - VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
DA  - JUN
PY  - 2018
VL  - 39
IS  - 1-2
SP  - 307
EP  - 322
DO  - 10.1007/s11001-017-9331-6
AN  - WOS:000430016500019
N1  - Times Cited in Web of Science Core Collection:  38
Total Times Cited:  38
Cited Reference Count:  34
ER  -

TY  - JOUR
AU  - Hahn-Klimroth, M
AU  - Kapetanopoulos, T
AU  - Gubert, J
AU  - Dierkes, PW
TI  - Deep learning-based pose estimation for African ungulates in zoos
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - animal behavior states
KW  - automated monitoring
KW  - convolutional neural networks
KW  - deep learning tools
KW  - ecology of savannah animals
KW  - image classification
KW  - BEHAVIOR
AB  - The description and analysis of animal behavior over long periods of time is one of the most important challenges in ecology. However, most of these studies are limited due to the time and cost required by human observers. The collection of data via video recordings allows observation periods to be extended. However, their evaluation by human observers is very time-consuming. Progress in automated evaluation, using suitable deep learning methods, seems to be a forward-looking approach to analyze even large amounts of video data in an adequate time frame.
   In this study, we present a multistep convolutional neural network system for detecting three typical stances of African ungulates in zoo enclosures which works with high accuracy. An important aspect of our approach is the introduction of model averaging and postprocessing rules to make the system robust to outliers.
   Our trained system achieves an in-domain classification accuracy of >0.92, which is improved to >0.96 by a postprocessing step. In addition, the whole system performs even well in an out-of-domain classification task with two unknown types, achieving an average accuracy of 0.93. We provide our system at so that interested users can train their own models to classify images and conduct behavioral studies of wildlife.
   The use of a multistep convolutional neural network for fast and accurate classification of wildlife behavior facilitates the evaluation of large amounts of image data in ecological studies and reduces the effort of manual analysis of images to a high degree. Our system also shows that postprocessing rules are a suitable way to make species-specific adjustments and substantially increase the accuracy of the description of single behavioral phases (number, duration). The results in the out-of-domain classification strongly suggest that our system is robust and achieves a high degree of accuracy even for new species, so that other settings (e.g., field studies) can be considered.
AD  - Goethe Univ, Dept Comp Sci & Math, 10 Robert Mayer St, D-60325 Frankfurt, GermanyAD  - Goethe Univ, Fac Biol Sci Biosci Educ & Zoo Biol, Frankfurt, GermanyC3  - Goethe University FrankfurtC3  - Goethe University FrankfurtFU  - von Opel Hessische Zoostiftung
FX  - von Opel Hessische Zoostiftung
CR  - Abdulla W., 2017, MASK R CNN OBJECT DE
CR  - Andrews W., P BRIT MACH VIS C SW, V60, P1, DOI [10.5244/c.29.60, DOI 10.5244/C.29.60]
CR  - Beery S., 2018, P EUR C COMP VIS ECC
CR  - Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED
CR  - Bradski G, 2000, DR DOBBS J, V25, P120
CR  - Burger AL, 2020, APPL ANIM BEHAV SCI, V229, DOI 10.1016/j.applanim.2020.105012
CR  - Chakravarty P, 2020, METHODS ECOL EVOL, V11, P1639, DOI 10.1111/2041-210X.13491
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
CR  - Dell AI, 2014, TRENDS ECOL EVOL, V29, P417, DOI 10.1016/j.tree.2014.05.004
CR  - Eikelboom JAJ, 2019, METHODS ECOL EVOL, V10, P1875, DOI [10.1111/2041-210X.13277, 10.4121/UUID:BA99A206-3E5A-4673-B830-B5C866445B8C]
CR  - Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
CR  - Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
CR  - Ferreira AC, 2020, METHODS ECOL EVOL, V11, P1072, DOI 10.1111/2041-210X.13436
CR  - Graving JM, 2019, ELIFE, V8, DOI 10.7554/eLife.47994
CR  - He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
CR  - Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
CR  - Kabra M, 2013, NAT METHODS, V10, P64, DOI [10.1038/NMETH.2281, 10.1038/nmeth.2281]
CR  - Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
CR  - Kingma DP, 2015, COMPUTER SCI, P1
CR  - Kogler J, 2020, J ZOO AQUAR RES, V8, P124
CR  - Li C, 2019, PROC CVPR IEEE, P7864, DOI 10.1109/CVPR.2019.00806
CR  - Lima SL, 2005, ANIM BEHAV, V70, P723, DOI 10.1016/j.anbehav.2005.01.008
CR  - Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
CR  - Mathis MW, 2020, CURR OPIN NEUROBIOL, V60, P1, DOI 10.1016/j.conb.2019.10.008
CR  - Melzheimer J, 2020, P NATL ACAD SCI USA, V117, P33325, DOI 10.1073/pnas.2002487117
CR  - Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
CR  - Norouzzadeh MS, 2021, METHODS ECOL EVOL, V12, P150, DOI 10.1111/2041-210X.13504
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Pedersen GR, 2004, J EQUINE VET SCI, V24, P153, DOI 10.1016/j.jevs.2004.03.013
CR  - Porto SMC, 2013, BIOSYST ENG, V115, P184, DOI 10.1016/j.biosystemseng.2013.03.002
CR  - Quionero-Candela J., 2009, DATASET SHIFT MACHIN, DOI [10.5555/1462129, DOI 10.5555/1462129]
CR  - Rast W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227317
CR  - Recht B, 2019, PR MACH LEARN RES, V97
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - RYDER OA, 1995, BIODIVERS CONSERV, V4, P671, DOI 10.1007/BF00222522
CR  - Schneider S, 2020, ECOL EVOL, V10, P3503, DOI 10.1002/ece3.6147
CR  - Simonyan K., 2014, ADV NEURAL INFORM PR, P568
CR  - Stanton LA, 2015, APPL ANIM BEHAV SCI, V173, P3, DOI 10.1016/j.applanim.2015.04.001
CR  - Stern U, 2015, SCI REP-UK, V5, DOI 10.1038/srep14351
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tan M., 2020, EFFICIENTDET SCALABL, P10778, DOI [10.1109/CVPR42600.2020.01079, DOI 10.1109/CVPR42600.2020.01079]
CR  - Tan MX, 2019, PR MACH LEARN RES, V97
CR  - Teitelbaum CS, 2015, ECOL LETT, V18, P545, DOI 10.1111/ele.12435
CR  - Ternman E, 2014, APPL ANIM BEHAV SCI, V160, P12, DOI 10.1016/j.applanim.2014.08.014
CR  - Touvron H., 2020, FIXING TRAIN TEST RE
CR  - Valletta JJ, 2017, ANIM BEHAV, V124, P203, DOI 10.1016/j.anbehav.2016.12.005
CR  - Weinstein BG, 2018, METHODS ECOL EVOL, V9, P1435, DOI 10.1111/2041-210X.13011
CR  - Xie Q., 2019, SELF TRAINING NOISY
CR  - Yakubovskiy P., 2019, EFFICIENTNET
CR  - Yosinski J, 2014, ADV NEUR IN, V27
CR  - Zepelin H., 2005, PRINCIPLES PRACTICE, P91, DOI DOI 10.1016/B0-72-160797-7/50015-X
CR  - Zhao YX, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00501-x
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - JUN
PY  - 2021
VL  - 11
IS  - 11
SP  - 6015
EP  - 6032
DO  - 10.1002/ece3.7367
AN  - WOS:000646574600001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  54
ER  -

TY  - JOUR
AU  - Hollings, T
AU  - Burgman, M
AU  - van Andel, M
AU  - Gilbert, M
AU  - Robinson, T
AU  - Robinson, A
TI  - How do you find the green sheep? A critical review of the use of remotely sensed imagery to detect and count animals
T2  - METHODS IN ECOLOGY AND EVOLUTION
LA  - English
KW  - agriculture
KW  - animals
KW  - detection
KW  - population survey
KW  - remote sensing
KW  - satellite imagery
KW  - wildlife
KW  - RESOLUTION SATELLITE IMAGERY
KW  - AERIAL
KW  - ABUNDANCE
KW  - COLONIES
KW  - CLASSIFICATION
KW  - CONSERVATION
KW  - KNOWLEDGE
KW  - PENGUINS
KW  - SCIENCE
KW  - SYSTEM
AB  - 1. Animal abundance data are essential for endangered species conservation, tracking invasive species spread, biosecurity, agricultural applications and wildlife monitoring; however, obtaining abundance data are a perennial challenge. Recent improvements in the resolution of remotely sensed imagery, and image-processing tools and software have facilitated improvement of methods for the detection of individual, generally large-bodied animals. The potential to monitor and survey populations from remotely sensed imagery is an exciting new development in animal ecology.
   2. We review the methods used to analyse remotely sensed imagery for their potential to estimate the abundance of wild and domestic animal populations by directly detecting, identifying and counting individuals.
   3.Despite many illustrative studies using a variety of methods for detecting animals from remotely sensed imagery, it remains problematic in many situations. Studies that demonstrated reasonably high accuracy using automated and semi-automated techniques have been undertaken on small spatial scales relative to the geographical range of the species of interest and/or in homogenous environments such as sea ice. The major limitations are the relatively low accuracy of automated detection techniques across large spatial extents, false detections and the cost of high-resolution data.
   4. Future developments in the analysis of remotely sensed data for population surveys will improve detection capabilities, including the advancement of algorithms, the crossover of software and technology from other disciplines, and improved availability, accessibility, cost and resolution of data.
AD  - Univ Melbourne, Sch Biosci, Ctr Excellence Biosecur Risk Anal, Melbourne, Vic, AustraliaAD  - Imperial Coll London, Ctr Environm Policy, London, EnglandAD  - Minist Primary Ind, Wellington, New ZealandAD  - Univ Libre Bruxelles, Spatial Epidemiol Lab, Brussels, BelgiumAD  - Fonds Natl Rech Sci, Brussels, BelgiumAD  - Food & Agr Org United Nations, Rome, ItalyC3  - University of MelbourneC3  - League of European Research Universities - LERUC3  - Imperial College LondonC3  - Universite Libre de BruxellesC3  - Fonds de la Recherche Scientifique - FNRSC3  - Food & Agriculture Organization of the United Nations (FAO)FU  - New Zealand Ministry for Primary Industries (MPI); Centre of Excellence for Biosecurity Risk Analysis (CEBRA)
FX  - The authors thank the Centre of Excellence for Biosecurity Risk Analysis (CEBRA) and the New Zealand Ministry for Primary Industries (MPI) for funding this research. We also thank the three anonymous reviewers whose valuable comments considerably improved our manuscript.
CR  - Abileah R., 2002, US NAVY J UNDERWATER, V52, P709
CR  - Aerometrex, 2016, SERV DIG AER PHOT CA
CR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - Barber-Meyer SM, 2007, POLAR BIOL, V30, P1565, DOI 10.1007/s00300-007-0317-8
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Bortolot ZJ, 2009, BIOSYST ENG, V102, P379, DOI 10.1016/j.biosystemseng.2009.01.005
CR  - Burgman MA., 2015, TRUSTING JUDGEMENTS
CR  - Chretien LP, 2016, WILDLIFE SOC B, V40, P181, DOI 10.1002/wsb.629
CR  - Conn PB, 2014, METHODS ECOL EVOL, V5, P1280, DOI 10.1111/2041-210X.12127
CR  - Cunningham DJ, 1996, WILDLIFE SOC B, V24, P345
CR  - Descamps S, 2011, BIRD STUDY, V58, P302, DOI 10.1080/00063657.2011.588195
CR  - Deuter M, 2016, 20 THINGS THEY DONT
CR  - Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
CR  - Fredborg M, 2015, BMC MICROBIOL, V15, DOI 10.1186/s12866-015-0583-5
CR  - Fretwell PT, 2015, REMOTE SENS ENVIRON, V156, P448, DOI 10.1016/j.rse.2014.10.011
CR  - Fretwell PT, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088655
CR  - Fretwell PT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033751
CR  - Groom G, 2013, ECOL INFORM, V14, P2, DOI 10.1016/j.ecoinf.2012.12.001
CR  - Groom G, 2011, INT J REMOTE SENS, V32, P4611, DOI 10.1080/01431161.2010.489068
CR  - Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
CR  - Jachmann H, 2002, J APPL ECOL, V39, P841, DOI 10.1046/j.1365-2664.2002.00752.x
CR  - KADLEC JA, 1968, J WILDLIFE MANAGE, V32, P287, DOI 10.2307/3798973
CR  - Ke YH, 2010, REMOTE SENS ENVIRON, V114, P1141, DOI 10.1016/j.rse.2010.01.002
CR  - Laliberte AS, 2003, WILDLIFE SOC B, V31, P362
CR  - Landinfo Worldwide Mapping LLC, 2017, BUYING SAT IM PRIC I
CR  - LaRue MA, 2014, POLAR BIOL, V37, P507, DOI 10.1007/s00300-014-1451-8
CR  - LaRue MA, 2017, CONSERV BIOL, V31, P213, DOI 10.1111/cobi.12809
CR  - LaRue MA, 2015, WILDLIFE SOC B, V39, P772, DOI 10.1002/wsb.596
CR  - LaRue MA, 2011, POLAR BIOL, V34, P1727, DOI 10.1007/s00300-011-1023-0
CR  - Leonard R.M., 1974, Wildlife Soc Bull, V2, P191
CR  - LOFFLER E, 1980, REMOTE SENS ENVIRON, V9, P47, DOI 10.1016/0034-4257(80)90046-2
CR  - Lynch HJ, 2012, POLAR BIOL, V35, P963, DOI 10.1007/s00300-011-1138-3
CR  - Martin TG, 2012, CONSERV BIOL, V26, P29, DOI 10.1111/j.1523-1739.2011.01806.x
CR  - McBride M. F., 2012, IS SUCH KNOWLEDGE GA, P11
CR  - McMahon CR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092613
CR  - McNeill S, 2011, INT GEOSCI REMOTE SE, P4312, DOI 10.1109/IGARSS.2011.6050185
CR  - Mejias L., 2013, AUTOMATED MARINE MAM, P1
CR  - Oishi Y, 2014, INT J REMOTE SENS, V35, P1374, DOI 10.1080/01431161.2013.876516
CR  - Papadopoulou CA, 2014, FUTURE INTERNET, V6, P109, DOI 10.3390/fi6010109
CR  - Pena-Barragan JM, 2011, REMOTE SENS ENVIRON, V115, P1301, DOI 10.1016/j.rse.2011.01.009
CR  - Pettorelli N, 2014, J APPL ECOL, V51, P839, DOI 10.1111/1365-2664.12261
CR  - Puchkov E., 2016, J COMPUTER COMMUNICA, V4, P8
CR  - Robinson TP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096084
CR  - SAMUEL MD, 1987, J WILDLIFE MANAGE, V51, P622, DOI 10.2307/3801280
CR  - Sbalzarini IF, 2005, J STRUCT BIOL, V151, P182, DOI 10.1016/j.jsb.2005.06.002
CR  - Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/nmeth.2019, 10.1038/NMETH.2019]
CR  - SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
CR  - Stapleton S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101513
CR  - Terletzky P.A., 2016, J SIGNAL INFORM PROC, V7, P123, DOI [10.4236/jsip.2016.73013, DOI 10.4236/JSIP.2016.73013]
CR  - Terletzky P. A, 2013, THESIS
CR  - Terletzky P, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085239
CR  - Terletzky P, 2012, GISCI REMOTE SENS, V49, P597, DOI 10.2747/1548-1603.49.4.597
CR  - Trathan PN, 2004, WILDLIFE SOC B, V32, P332, DOI 10.2193/0091-7648(2004)32[332:IAOCAP]2.0.CO;2
CR  - TRIVEDI MM, 1982, PHOTOGRAMM ENG REM S, V48, P1879
CR  - Turner W, 2003, TRENDS ECOL EVOL, V18, P306, DOI 10.1016/S0169-5347(03)00070-3
CR  - Velasco M., 2009, THESIS
CR  - Williams M, 1998, POLAR RES, V17, P15, DOI 10.1111/j.1751-8369.1998.tb00256.x
CR  - Wyatt C. L., 1985, P 18 INT S REM SENS, P1475
CR  - Yang Z., 2012, THESIS
CR  - Yang Z, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115989
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - APR
PY  - 2018
VL  - 9
IS  - 4
SP  - 881
EP  - 892
DO  - 10.1111/2041-210X.12973
AN  - WOS:000429421800007
N1  - Times Cited in Web of Science Core Collection:  42
Total Times Cited:  43
Cited Reference Count:  60
ER  -

TY  - JOUR
AU  - Delisle, ZJ
AU  - Flaherty, EA
AU  - Nobbe, MR
AU  - Wzientek, CM
AU  - Swihart, RK
TI  - Next-Generation Camera Trapping: Systematic Review of Historic Trends Suggests Keys to Expanded Research Applications in Ecology and Conservation
T2  - FRONTIERS IN ECOLOGY AND EVOLUTION
LA  - English
KW  - camera trap
KW  - diversity
KW  - ecoregions
KW  - image classification
KW  - occupancy
KW  - population attributes
KW  - technological diffusion
KW  - wildlife
KW  - ESTIMATING ANIMAL DENSITY
KW  - ACTIVITY PATTERNS
KW  - TRAPS
KW  - DISTANCE
KW  - PREY
KW  - BIODIVERSITY
KW  - OCCUPANCY
KW  - LANDSCAPE
KW  - RICHNESS
KW  - CANOPY
AB  - Camera trapping is an effective non-invasive method for collecting data on wildlife species to address questions of ecological and conservation interest. We reviewed 2,167 camera trap (CT) articles from 1994 to 2020. Through the lens of technological diffusion, we assessed trends in: (1) CT adoption measured by published research output, (2) topic, taxonomic, and geographic diversification and composition of CT applications, and (3) sampling effort, spatial extent, and temporal duration of CT studies. Annual publications of CT articles have grown 81-fold since 1994, increasing at a rate of 1.26 (SE = 0.068) per year since 2005, but with decelerating growth since 2017. Topic, taxonomic, and geographic richness of CT studies increased to encompass 100% of topics, 59.4% of ecoregions, and 6.4% of terrestrial vertebrates. However, declines in per article rates of accretion and plateaus in Shannon's H for topics and major taxa studied suggest upper limits to further diversification of CT research as currently practiced. Notable compositional changes of topics included a decrease in capture-recapture, recent decrease in spatial-capture-recapture, and increases in occupancy, interspecific interactions, and automated image classification. Mammals were the dominant taxon studied; within mammalian orders carnivores exhibited a unimodal peak whereas primates, rodents and lagomorphs steadily increased. Among biogeographic realms we observed decreases in Oceania and Nearctic, increases in Afrotropic and Palearctic, and unimodal peaks for Indomalayan and Neotropic. Camera days, temporal extent, and area sampled increased, with much greater rates for the 0.90 quantile of CT studies compared to the median. Next-generation CT studies are poised to expand knowledge valuable to wildlife ecology and conservation by posing previously infeasible questions at unprecedented spatiotemporal scales, on a greater array of species, and in a wider variety of environments. Converting potential into broad-based application will require transferable models of automated image classification, and data sharing among users across multiple platforms in a coordinated manner. Further taxonomic diversification likely will require technological modifications that permit more efficient sampling of smaller species and adoption of recent improvements in modeling of unmarked populations. Environmental diversification can benefit from engineering solutions that expand ease of CT sampling in traditionally challenging sites.
AD  - Purdue Univ, Dept Forestry & Nat Resources, W Lafayette, IN 47907 USAC3  - Purdue University SystemC3  - Purdue UniversityC3  - Purdue University West Lafayette CampusFU  - Indiana DNR grant [W-48-R-02]; Purdue University; USDA National Institute of Food and Agriculture, Hatch Project [1019737]
FX  - Funding was provided by Indiana DNR grant W-48-R-02 and by Purdue University. Support for EF provided by the USDA National Institute of Food and Agriculture, Hatch Project #1019737.
CR  - Ahmed A, 2019, ECOL INFORM, V52, P57, DOI 10.1016/j.ecoinf.2019.05.006
CR  - Ahumada JA, 2020, ENVIRON CONSERV, V47, P1, DOI 10.1017/S0376892919000298
CR  - Apps P, 2018, AFR J ECOL, V56, P710, DOI 10.1111/aje.12573
CR  - Atkin DJ, 2015, MASS COMMUN SOC, V18, P623, DOI 10.1080/15205436.2015.1066014
CR  - Augustine B, 2019, ECOSPHERE, V10, DOI 10.1002/ecs2.2627
CR  - Bischof R, 2014, J ZOOL, V293, P40, DOI 10.1111/jzo.12100
CR  - Blackburn Tim M., 1998, Diversity and Distributions, V4, P121, DOI 10.1046/j.1365-2699.1998.00015.x
CR  - BLACKBURN TM, 1994, OIKOS, V70, P127, DOI 10.2307/3545707
CR  - Burnham K.P., 2002, MODEL SELECTION MULT, V2nd, DOI 10.1007/b97636
CR  - Burton AC, 2015, J APPL ECOL, V52, P675, DOI 10.1111/1365-2664.12432
CR  - Cappelle N, 2019, AM J PRIMATOL, V81, DOI 10.1002/ajp.22962
CR  - Chan BPL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72641-z
CR  - Chandler RB, 2013, ANN APPL STAT, V7, P936, DOI 10.1214/12-AOAS610
CR  - Chapman Frank, 1927, NATL GEOGRAPHIC MAGA, V52, p[341, 342]
CR  - Chler R., 2020, R PACKAGE UNMARKED M
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Conway A.M., 2020, BIORXIV, V1, DOI [10.1101/2020.06.29.177261, DOI 10.1101/2020.06.29.177261]
CR  - Cusack JJ, 2017, OIKOS, V126, P812, DOI 10.1111/oik.03403
CR  - Cutler TL, 1999, WILDLIFE SOC B, V27, P571
CR  - Delibes-Mateos M, 2014, MAMM BIOL, V79, P393, DOI 10.1016/j.mambio.2014.04.006
CR  - Dinerstein E, 2017, BIOSCIENCE, V67, P534, DOI 10.1093/biosci/bix014
CR  - Dunn P.K., 1996, J COMPUT GRAPH STAT, V5, P236, DOI DOI 10.2307/1390802
CR  - Egri O., 2019, Distance Estimation Using Multi-Camera Device, Patent No. [10192312 B2, 10192312]
CR  - Falzon G, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10010058
CR  - Fasiolo M., 2020, R PACKAGE QGAM SMOOT
CR  - Forrester T, 2016, BIODIVERS DATA J, V4, DOI 10.3897/BDJ.4.e10197
CR  - Frey S, 2017, REMOTE SENS ECOL CON, V3, P123, DOI 10.1002/rse2.60
CR  - Gilbert NA, 2021, CONSERV BIOL, V35, P88, DOI 10.1111/cobi.13517
CR  - Glover-Kapfer P, 2019, REMOTE SENS ECOL CON, V5, P209, DOI 10.1002/rse2.106
CR  - Godoy-Guinao J, 2018, ECOSPHERE, V9, DOI 10.1002/ecs2.2424
CR  - Green AM, 2020, FRONT ECOL EVOL, V8, DOI 10.3389/fevo.2020.563477
CR  - Green SE, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10010132
CR  - Gregory T, 2014, METHODS ECOL EVOL, V5, P443, DOI 10.1111/2041-210X.12177
CR  - Heiniger J, 2018, WILDLIFE RES, V45, P578, DOI 10.1071/WR18078
CR  - Hepler SA, 2021, ENVIRONMETRICS, V32, DOI 10.1002/env.2657
CR  - Hofmeester TR, 2019, ECOL EVOL, V9, P2320, DOI 10.1002/ece3.4878
CR  - Hofmeester TR, 2017, REMOTE SENS ECOL CON, V3, P81, DOI 10.1002/rse2.25
CR  - HOPE ACA, 1968, J ROY STAT SOC B, V30, P582
CR  - Howe EJ, 2019, METHODS ECOL EVOL, V10, P38, DOI 10.1111/2041-210X.13082
CR  - Howe EJ, 2017, METHODS ECOL EVOL, V8, P1558, DOI 10.1111/2041-210X.12790
CR  - Kays R, 2020, DIVERS DISTRIB, V26, P644, DOI 10.1111/ddi.12993
CR  - Kays R, 2020, METHODS ECOL EVOL, V11, P700, DOI 10.1111/2041-210X.13370
CR  - Keim JL, 2019, J ANIM ECOL, V88, P690, DOI 10.1111/1365-2656.12960
CR  - Kellner KF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111436
CR  - Kery M., 2015, APPL HIERARCHICAL MO
CR  - Kery M., 2017, R PACKAGE AHMBOOK FU
CR  - Kitzes J, 2019, ENVIRON CONSERV, V46, P247, DOI 10.1017/S0376892919000146
CR  - Macaulay LT, 2020, J WILDLIFE MANAGE, V84, P301, DOI 10.1002/jwmg.21803
CR  - Magsamen-Conrad K, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106456
CR  - MANTEL N, 1982, Biometrical Journal, V24, P579, DOI 10.1002/bimj.4710240607
CR  - Maronde L, 2020, ECOL EVOL, V10, P13968, DOI 10.1002/ece3.6990
CR  - Mccallum J, 2013, MAMMAL REV, V43, P196, DOI 10.1111/j.1365-2907.2012.00216.x
CR  - McCleery RA, 2014, WILDLIFE SOC B, V38, P887, DOI 10.1002/wsb.447
CR  - McIntyre T, 2020, WILDLIFE RES, V47, P177, DOI 10.1071/WR19040
CR  - McShea WJ, 2016, LANDSCAPE ECOL, V31, P55, DOI 10.1007/s10980-015-0262-9
CR  - Meek PD, 2014, BIODIVERS CONSERV, V23, P2321, DOI 10.1007/s10531-014-0712-8
CR  - Meek PD, 2015, AUST MAMMAL, V37, P13, DOI 10.1071/AM14023
CR  - Miao ZQ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44565-w
CR  - MILLER RG, 1974, BIOMETRIKA, V61, P1
CR  - Mills CA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146142
CR  - Moeller AK, 2018, ECOSPHERE, V9, DOI 10.1002/ecs2.2331
CR  - Moll RJ, 2020, WILDLIFE RES, V47, P158, DOI 10.1071/WR19004
CR  - Mos J, 2020, MAMMAL RES, V65, P843, DOI 10.1007/s13364-020-00513-y
CR  - Nakashima Y, 2020, BIOL CONSERV, V241, DOI 10.1016/j.biocon.2019.108381
CR  - Nakashima Y, 2018, J APPL ECOL, V55, P735, DOI 10.1111/1365-2664.13059
CR  - Nekaris KAI, 2020, DIVERSITY-BASEL, V12, DOI 10.3390/d12100399
CR  - Ngoprasert D, 2019, GLOB ECOL CONSERV, V20, DOI 10.1016/j.gecco.2019.e00792
CR  - Niedballa J, 2016, METHODS ECOL EVOL, V7, P1457, DOI 10.1111/2041-210X.12600
CR  - Norouzzadeh MS, 2021, METHODS ECOL EVOL, V12, P150, DOI 10.1111/2041-210X.13504
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - OConnell AF, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, P1, DOI 10.1007/978-4-431-99495-4
CR  - Ortmann CR, 2021, J ZOOL, V313, P202, DOI 10.1111/jzo.12849
CR  - Palmer MS, 2017, ECOL LETT, V20, P1364, DOI 10.1111/ele.12832
CR  - Parsons AW, 2017, J MAMMAL, V98, P1547, DOI 10.1093/jmammal/gyx128
CR  - Pollock KH, 2002, ENVIRONMETRICS, V13, P105, DOI 10.1002/env.514
CR  - R Development Core Team, 2020, R FDN STAT COMP
CR  - Rice RE, 2017, HUM COMMUN RES, V43, P531, DOI 10.1111/hcre.12119
CR  - Rich LN, 2017, GLOBAL ECOL BIOGEOGR, V26, P918, DOI 10.1111/geb.12600
CR  - Rivas-Romero JA, 2015, SOUTHWEST NAT, V60, P366, DOI 10.1894/0038-4909-60.4.366
CR  - Rogers E. M, 1983, DIFFUSION INNOVATION, V3rd
CR  - Rovero F, 2013, HYSTRIX, V24, P148, DOI 10.4404/hystrix-24.2-6316
CR  - Rowcliffe JM, 2008, ANIM CONSERV, V11, P185, DOI 10.1111/j.1469-1795.2008.00180.x
CR  - Rowcliffe JM, 2008, J APPL ECOL, V45, P1228, DOI 10.1111/j.1365-2664.2008.01473.x
CR  - Rowcliffe JM, 2014, METHODS ECOL EVOL, V5, P1170, DOI 10.1111/2041-210X.12278
CR  - Rowcliffe M., 2019, R PACKAGE ACTIVITY A
CR  - Royle J.A, 2020, APPL HIERARCHICAL MO
CR  - Salman A, 2020, ICES J MAR SCI, V77, P1295, DOI 10.1093/icesjms/fsz025
CR  - Sarkar J., 1998, J ECON SURV, V12, P131, DOI 10.1111/1467-6419.00051
CR  - Schneider F.D., 2020, R PACKAGE TRAITDATAF
CR  - Schneider S, 2020, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW50321.2020.9096925
CR  - Schneider S, 2020, ECOL EVOL, V10, P3503, DOI 10.1002/ece3.6147
CR  - Smith JA, 2020, J ANIM ECOL, V89, P1997, DOI 10.1111/1365-2656.13264
CR  - Soininen EM, 2015, REMOTE SENS ECOL CON, V1, P29, DOI 10.1002/rse2.2
CR  - Sollmann R, 2018, AFR J ECOL, V56, P740, DOI 10.1111/aje.12557
CR  - Spellerberg IF, 2003, GLOBAL ECOL BIOGEOGR, V12, P177, DOI 10.1046/j.1466-822X.2003.00015.x
CR  - Steenweg R, 2019, ECOSPHERE, V10, DOI 10.1002/ecs2.2639
CR  - Steenweg R, 2018, ECOLOGY, V99, P172, DOI 10.1002/ecy.2054
CR  - Steenweg R, 2017, FRONT ECOL ENVIRON, V15, P26, DOI 10.1002/fee.1448
CR  - Struthers DP, 2015, FISHERIES, V40, P502, DOI 10.1080/03632415.2015.1082472
CR  - Sundaram DM, 2020, NEURAL PROCESS LETT, V52, P727, DOI 10.1007/s11063-020-10246-3
CR  - Suzuki KK, 2019, MAMMALIA, V83, P372, DOI 10.1515/mammalia-2018-0055
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Swihart RK, 2020, WILDLIFE SOC B, V44, P77, DOI 10.1002/wsb.1037
CR  - Tabak MA, 2020, ECOL EVOL, V10, P10374, DOI 10.1002/ece3.6692
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tennant EN, 2020, WILDLIFE SOC B, V44, P610, DOI 10.1002/wsb.1103
CR  - Thau D., 2019, BIODIVERS INF SCI ST, V3, DOI [10.3897/biss.3.38233, DOI 10.3897/BISS.3.38233]
CR  - Wang Y, 2012, METHODS ECOL EVOL, V3, P471, DOI 10.1111/j.2041-210X.2012.00190.x
CR  - Warton DI, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181790
CR  - Wearn OR, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181748
CR  - Wilson DE, 2005, MAMMAL SPECIES WORLD
CR  - Wood S.N., 2017, GEN ADDITIVE MODELS, DOI 10.1201/9781315370279
CR  - Wood Simon, 2021, CRAN
CR  - Wood SN, 2003, J ROY STAT SOC B, V65, P95, DOI 10.1111/1467-9868.00374
CR  - Yoshioka A, 2020, PEERJ, V8, DOI 10.7717/peerj.9681
PU  - FRONTIERS MEDIA SA
PI  - LAUSANNE
PA  - AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
DA  - FEB 26
PY  - 2021
VL  - 9
DO  - 10.3389/fevo.2021.617996
AN  - WOS:000631073400001
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  115
ER  -

TY  - JOUR
AU  - Clapham, M
AU  - Miller, E
AU  - Nguyen, M
AU  - Van Horn, RC
TI  - Multispecies facial detection for individual identification of wildlife: a case study across ursids
T2  - MAMMALIAN BIOLOGY
LA  - English
KW  - Bears
KW  - Deep learning
KW  - Face recognition
KW  - Individual ID
KW  - Machine learning
KW  - Ursidae
KW  - CAPTURE-RECAPTURE
KW  - ANDEAN BEARS
KW  - PHOTOGRAPHS
KW  - DENSITY
AB  - To address biodiversity decline in the era of big data, replicable methods of data processing are needed. Automated methods of individual identification (ID) via computer vision are valuable in conservation research and wildlife management. Rapid and systematic methods of image processing and analysis are fundamental to an ever-growing need for effective conservation research and practice. Bears (ursids) are an interesting test system for examining computer vision techniques for wildlife, as they have variable facial morphology, variable presence of individual markings, and are challenging to research and monitor. We leveraged existing imagery of bears living under human care to develop a multispecies bear face detector, a critical part of individual ID pipelines. We compared its performance across species and on a pre-existing wild brown bear Ursus arctos dataset (BearID), to examine the robustness of convolutional neural networks trained on animals under human care. Using the multispecies bear face detector and retrained sub-applications of BearID, we prototyped an end-to-end individual ID pipeline for the declining Andean bear Tremarctos ornatus. Our multispecies face detector had an average precision of 0.91-1.00 across all eight bear species, was transferable to images of wild brown bears (AP = 0.93), and correctly identified individual Andean bears in 86% of test images. These preliminary results indicate that a multispecies-trained network can detect faces of a single species sufficiently to achieve high-performance individual classification, which could speed-up the transferability and application of automated individual ID to a wider range of taxa.
AD  - Univ Victoria, Dept Geog, 3800 Finnerty Rd, Victoria, BC V8P 5C2, CanadaAD  - BearID Project, Sooke, BC, CanadaAD  - San Diego Zoo Wildlife Alliance, San Diego, CA USAC3  - University of VictoriaFU  - Microsoft AI for Earth program; Natural Sciences and Engineering Research Council of Canada [CRDPJ 523329-18, ALLRP 559534-20]; San Diego Zoo Wildlife Alliance; Google for Nonprofits; Knight Inlet Lodge; Wild Bear Lodge
FX  - Cloud computing (Microsoft Azure) credits for this project were granted by Microsoft AI for Earth program. MC is supported by the Natural Sciences and Engineering Research Council of Canada (CRDPJ 523329-18; ALLRP 559534-20), in combination with industry partners (Knight Inlet Lodge and Wild Bear Lodge) and Nanwakolas Council. RCVH is supported by the San Diego Zoo Wildlife Alliance. Google for Nonprofits funded Google Workspace which helped to facilitate this collaborative project.
CR  - Ahumada JA, 2020, ENVIRON CONSERV, V47, P1, DOI 10.1017/S0376892919000298
CR  - Appleton RD, 2018, J ZOOL, V305, P196, DOI 10.1111/jzo.12553
CR  - Araujo G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53718-w
CR  - Beery S, 2019, ARXIV190405916
CR  - Beery S, 2019, ARXIV190706772
CR  - Beery S, 2018, LECT NOTES COMPUT SC, V11220, P472, DOI 10.1007/978-3-030-01270-0_28
CR  - Berger-Wolf T.Y., 2017, ARXIV PREPRINT ARXIV
CR  - Brust CA, 2017, IEEE INT CONF COMP V, P2820, DOI 10.1109/ICCVW.2017.333
CR  - Buehler P, 2019, ECOL INFORM, V50, P191, DOI 10.1016/j.ecoinf.2019.02.003
CR  - Chen P, 2020, ECOL EVOL, V10, P3561, DOI 10.1002/ece3.6152
CR  - Choo YR, 2020, GLOB ECOL CONSERV, V24, DOI 10.1016/j.gecco.2020.e01294
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Clapham M, 2020, ECOL EVOL, V10, P12883, DOI 10.1002/ece3.6840
CR  - Crall JP, 2013, IEEE WORK APP COMP, P230, DOI 10.1109/WACV.2013.6475023
CR  - Dalal N., 2005, IEEE COMPUTER SOC C, P886, DOI 10.1109/CVPR.2005.177
CR  - Deb D, 2018, INT CONF BIOMETR THE
CR  - Dharaiya N, 2020, IUCN RED LIST THREAT, DOI [10.2305/IUCN.UK.2020-1.RLTS.T13143A166519315.en, DOI 10.2305/IUCN.UK.2020-1.RLTS.T13143A166519315.EN]
CR  - Dirzo R, 2014, SCIENCE, V345, P401, DOI 10.1126/science.1251817
CR  - Ditria EM, 2020, FRONT MAR SCI, V7, DOI 10.3389/fmars.2020.00429
CR  - Freytag A, 2016, LECT NOTES COMPUT SC, V9796, P51, DOI 10.1007/978-3-319-45886-1_5
CR  - Garshelis D, 2020, IUCN RED LIST THREAT, DOI [10.2305/IUCN.UK.2020-3.RLTS.T22824A166528664.en, DOI 10.2305/IUCN.UK.2020-3.RLTS.T22824A166528664.EN]
CR  - Guo ST, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101412
CR  - Higashide D, 2012, J ZOOL, V288, P199, DOI 10.1111/j.1469-7998.2012.00942.x
CR  - Hughes B, 2017, INT J COMPUT VISION, V122, P542, DOI 10.1007/s11263-016-0961-y
CR  - Johansson O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63367-z
CR  - Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
CR  - Kelly MJ, 2008, NORTHEAST NAT, V15, P249, DOI 10.1656/1092-6194(2008)15[249:CTOCTS]2.0.CO;2
CR  - Khan MH, 2020, PROC CVPR IEEE, P6937, DOI 10.1109/CVPR42600.2020.00697
CR  - King D. E., 2015, ARXIV PREPRINT ARXIV
CR  - King DE, 2009, J MACH LEARN RES, V10, P1755
CR  - Korschens M, 2018, ARXIV181204418
CR  - Kutschera VE, 2014, MOL BIOL EVOL, V31, P2004, DOI 10.1093/molbev/msu186
CR  - Lahoz-Monfort JJ, 2019, BIOSCIENCE, V69, P823, DOI 10.1093/biosci/biz090
CR  - Loos A, 2018, EUR SIGNAL PR CONF, P1805, DOI 10.23919/EUSIPCO.2018.8553439
CR  - Loos A, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-49
CR  - Miele V, 007377 BIORXIV, V2020, DOI [10.1101/2020.03.25.007377, DOI 10.1101/2020.03.25.007377]
CR  - Molina S, 2017, URSUS, V28, P117, DOI 10.2192/URSU-D-16-00030.1
CR  - Morrell N, 2021, GLOB ECOL CONSERV, V26, DOI 10.1016/j.gecco.2021.e01473
CR  - Ngoprasert D, 2012, URSUS, V23, P117, DOI 10.2192/URSUS-D-11-00009.1
CR  - Nipko RB, 2020, WILDLIFE SOC B, V44, P424, DOI 10.1002/wsb.1086
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Penteriani V., 2020, BEARS OF THE WORLD, DOI [10.1017/9781108692571, DOI 10.1017/9781108692571]
CR  - Penteriani V, 2020, URSUS, V31, DOI 10.2192/URSUS-D-19-00027.1
CR  - Ramsey AB, 2019, WILDLIFE RES, V46, P326, DOI 10.1071/WR18049
CR  - Ravoor PC, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100289
CR  - Reyes Adriana, 2017, Therya, V8, P83, DOI 10.12933/therya-17-453
CR  - Rodríguez Daniel, 2020, Pap. Avulsos Zool., V60, pe20206030, DOI 10.11606/1807-0205/2020.60.30
CR  - Schneider S, 2020, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW50321.2020.9096925
CR  - Schneider S, 2019, METHODS ECOL EVOL, V10, P461, DOI 10.1111/2041-210X.13133
CR  - Schofield D, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0736
CR  - Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
CR  - Scotson L, 2017, IUCN RED LIST THREAT, V2017, DOI [10.2305/IUCN.UK.2017-3.RLTS. T9760A45033547.en, DOI 10.2305/IUCN.UK.2017-3.RLTS.T9760A45033547.EN, 10.2305/IUCN.UK.2017-3.RLTS.T9760A45033547.en]
CR  - Shimozuru M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176251
CR  - Steenweg R, 2017, FRONT ECOL ENVIRON, V15, P26, DOI 10.1002/fee.1448
CR  - Van Horn RC, 2015, PEERJ, V3, DOI 10.7717/peerj.1042
CR  - Van Horn RC, 2014, WILDLIFE BIOL, V20, P291, DOI 10.2981/wlb.00023
CR  - Velez-Liendo X, 2017, IUCN RED LIST THREAT, DOI [10.2305/IUCN.UK.2017-3.RLTS.T22066A45034047.en, DOI 10.2305/IUCN.UK.2017-3.RLTS.T22066A45034047.EN]
CR  - Weinstein BG, 2018, J ANIM ECOL, V87, P533, DOI 10.1111/1365-2656.12780
CR  - Yoshizaki J, 2009, ECOLOGY, V90, P3, DOI 10.1890/08-0304.1
CR  - Zheng X, 2016, J ZOOL, V300, P247, DOI 10.1111/jzo.12377
PU  - SPRINGER HEIDELBERG
PI  - HEIDELBERG
PA  - TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
DO  - 10.1007/s42991-021-00168-5
AN  - WOS:000782162400001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  60
ER  -

TY  - JOUR
AU  - Eldridge, A
AU  - Guyot, P
AU  - Moscoso, P
AU  - Johnston, A
AU  - Eyre-Walker, Y
AU  - Peck, M
TI  - Sounding out ecoacoustic metrics: Avian species richness is predicted by acoustic indices in temperate but not tropical habitats
T2  - ECOLOGICAL INDICATORS
LA  - English
KW  - Biodiversity monitoring
KW  - Remote sensing
KW  - Ecoacoustics
KW  - Acoustic indices
KW  - Species richness
KW  - MEASURING BIODIVERSITY
KW  - SOUNDSCAPE ECOLOGY
KW  - RECORDINGS
KW  - LANDSCAPE
KW  - COMMUNITY
KW  - BIOACOUSTICS
AB  - Affordable, autonomous recording devices facilitate large scale acoustic monitoring and Rapid Acoustic Survey is emerging as a cost-effective approach to ecological monitoring; the success of the approach rests on the development of computational methods by which biodiversity metrics can be automatically derived from remotely collected audio data. Dozens of indices have been proposed to date, but systematic validation against classical, in situ diversity measures are lacking. This study conducted the most comprehensive comparative evaluation to date of the relationship between avian species diversity and a suite of acoustic indices. Acoustic surveys were carried out across habitat gradients in temperate and tropical biomes. Baseline avian species richness and subjective multi-taxa biophonic density estimates were established through aural counting by expert ornithologists. 26 acoustic indices were calculated and compared to observed variations in species diversity. Five acoustic diversity indices (Bioacoustic Index, Acoustic Diversity Index, Acoustic Evenness Index, Acoustic Entropy, and the Normalised Difference Sound Index) were assessed as well as three simple acoustic descriptors (Root-mean-square, Spectral centroid and Zero-crossing rate). Highly significant correlations, of up to 65%, between acoustic indices and avian species richness were observed across temperate habitats, supporting the use of automated acoustic indices in biodiversity monitoring where a single vocal taxon dominates. Significant, weaker correlations were observed in neotropical habitats which host multiple non-avian vocalizing species. Multivariate classification analyses demonstrated that each habitat has a very distinct soundscape and that AIs track observed differences in habitat-dependent community composition. Multivariate analyses of the relative predictive power of AIs show that compound indices are more powerful predictors of avian species richness than any single index and simple descriptors are significant contributors to avian diversity prediction in multi-taxa tropical environments. Our results support the use of community level acoustic indices as a proxy for species richness and point to the potential for tracking subtler habitat-dependent changes in community composition. Recommendations for the design of compound indices for multi-taxa community composition appraisal are put forward, with consideration for the requirements of next generation, low power remote monitoring networks.
AD  - Univ Sussex, Dept Mus, Sch Media Film & Mus, Brighton, E Sussex, EnglandAD  - Univ Sussex, Sch Life Sci, Evolut Behav & Environm, Brighton, E Sussex, EnglandAD  - Univ Toulouse, Inst Rech Informat Toulouse, Toulouse, FranceAD  - Univ Cambridge, Dept Zool, Conservat Sci Grp, Cambridge, EnglandAD  - Cornell Univ, Cornell Lab Ornithol, Ithaca, NY 14850 USAC3  - University of SussexC3  - University of SussexC3  - Universite de ToulouseC3  - Universite Federale Toulouse Midi-Pyrenees (ComUE)C3  - Universite Toulouse III - Paul SabatierC3  - Institut National Polytechnique de ToulouseC3  - Universite Toulouse 1 CapitoleC3  - Universite de Toulouse - Jean JauresC3  - Centre National de la Recherche Scientifique (CNRS)C3  - League of European Research Universities - LERUC3  - University of CambridgeC3  - Cornell UniversityFU  - Leverhulme Trust [RPG-2014-403]
FX  - Joseph Cooper and Manuel Sanchez for avian species identification in UK and Ecuador respectively, Penny Green and Jorge Noe Morales for verification. For support in field surveys Claire Reboah, Josep Navarro, Galo Conde, Wagner Encarnacion and Raul Nieto. For access to UK field sites, all at Plashett Park Wood, especially Mike Cameron, all at Knepp Wildland Estate, especially Penny Green and for access to Tesoro Escondido, Citlalli Morelos, the community of Tesoro Escondido and the Cambugan Foundation. Thanks for anonymous reviewers for swift and productive feedback on an earlier version of this manuscript. This work was funded by Leverhulme Trust Research Project Grant RPG-2014-403.
CR  - Alquezar RD, 2015, WILSON J ORNITHOL, V127, P712, DOI 10.1676/14-104.1
CR  - Bertucci F, 2016, SCI REP-UK, V6, DOI 10.1038/srep33326
CR  - Betts MG, 2017, NATURE, V547, P441, DOI 10.1038/nature23285
CR  - Boelman NT, 2007, ECOL APPL, V17, P2137, DOI 10.1890/07-0004.1
CR  - Bormpoudakis D, 2013, LANDSCAPE ECOL, V28, P495, DOI 10.1007/s10980-013-9849-1
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Buckland ST, 2005, PHILOS T R SOC B, V360, P243, DOI 10.1098/rstb.2004.1589
CR  - Buxton RT, 2016, ECOL EVOL, V6, P4697, DOI 10.1002/ece3.2242
CR  - Chillo V, 2011, ECOSYSTEMS, V14, P1168, DOI 10.1007/s10021-011-9475-1
CR  - Crooks KR, 2017, P NATL ACAD SCI USA, V114, P7635, DOI 10.1073/pnas.1705769114
CR  - Darras K. F. A, 2017, 117119 BIORXIV
CR  - Depraetere M, 2012, ECOL INDIC, V13, P46, DOI 10.1016/j.ecolind.2011.05.006
CR  - Devos P., 2016, INTERNOISE NOISE CON, V253, P3631
CR  - Dunn C, 1994, PLANT SCI B, V40, P119
CR  - Eldridge A, 2016, PEERJ, V4, DOI 10.7717/peerj.2108
CR  - Eyre T., 2015, BIOCONDITION CONDITI
CR  - Fairbrass AJ, 2017, ECOL INDIC, V83, P169, DOI 10.1016/j.ecolind.2017.07.064
CR  - Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
CR  - Fuller S, 2015, ECOL INDIC, V58, P207, DOI 10.1016/j.ecolind.2015.05.057
CR  - Gage S. H, 2017, ROLE SOUND TERRESTRI, V31
CR  - Gage S.H., 2001, J ACOUST SOC AM, V109, DOI [10.1121/1.4744597, DOI 10.1121/1.4744597]
CR  - Gasc A, 2013, ECOL INDIC, V25, P279, DOI 10.1016/j.ecolind.2012.10.009
CR  - Gasc A, 2017, AUK, V134, P215, DOI 10.1642/AUK-16-124.1
CR  - Gini C, 1971, J AM STAT ASSOC, V66, P534, DOI [10.1080/01621459.1971.10482297, DOI 10.1080/01621459.1971.10482297]
CR  - Gouyon Fabien, 2002, USE ZERO CROSSING RA
CR  - Guyot P, 2016, INTERSPEECH, P2602, DOI 10.21437/Interspeech.2016-361
CR  - Harris SA, 2016, METHODS ECOL EVOL, V7, P713, DOI 10.1111/2041-210X.12527
CR  - IPCC, 2013, SUMMARY POLICYMAKERS
CR  - Ishwaran H, 2010, J AM STAT ASSOC, V105, P205, DOI 10.1198/jasa.2009.tm08622
CR  - Jost L, 2006, OIKOS, V113, P363, DOI 10.1111/j.2006.0030-1299.14714.x
CR  - Kasten EP, 2012, ECOL INFORM, V12, P50, DOI 10.1016/j.ecoinf.2012.08.001
CR  - Magurran A.E., 2011, BIOL DIVERSITY FRONT
CR  - Magurran AE., 2004, MEASURING BIOL DIVER
CR  - Mammides C, 2017, ECOL INDIC, V82, P470, DOI 10.1016/j.ecolind.2017.07.017
CR  - MITTERMEIER RA, 1993, RAPID ASSESSMENT PRO
CR  - Napoletano B., 2004, THESIS
CR  - Newbold T, 2015, NATURE, V520, P45, DOI 10.1038/nature14324
CR  - Pavoine S, 2011, BIOL REV, V86, P792, DOI 10.1111/j.1469-185X.2010.00171.x
CR  - Peeters G., 2004, LARGE SET AUDIO FEAT
CR  - Phillips YF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193345
CR  - Pieretti N, 2011, ECOL INDIC, V11, P868, DOI 10.1016/j.ecolind.2010.11.005
CR  - Pijanowski BC, 2011, BIOSCIENCE, V61, P203, DOI 10.1525/bio.2011.61.3.6
CR  - Reid JL, 2012, BIOTROPICA, V44, P350, DOI 10.1111/j.1744-7429.2011.00814.x
CR  - Rodriguez A, 2014, ECOL INFORM, V21, P133, DOI 10.1016/j.ecoinf.2013.12.006
CR  - Santini L, 2016, BIOL CONSERV, DOI [10.1016/j.biocon.2016.08.024, DOI 10.1016/J..BIOCON.2016.08.024]
CR  - Sinsch U, 2012, AFR ZOOL, V47, P60, DOI 10.3377/004.047.0122
CR  - Sueur J, 2002, BIOL J LINN SOC, V75, P379, DOI 10.1111/j.1095-8312.2002.tb02079.x
CR  - Sueur J, 2015, BIOSEMIOTICS-NETH, V8, P493, DOI 10.1007/s12304-015-9248-x
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Sueur J, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0004065
CR  - Towsey M, 2014, ECOL INFORM, V21, P110, DOI 10.1016/j.ecoinf.2013.11.007
CR  - TURNER MG, 1989, ANNU REV ECOL SYST, V20, P171, DOI 10.1146/annurev.es.20.110189.001131
CR  - Villanueva-Rivera LJ, 2011, LANDSCAPE ECOL, V26, P1233, DOI 10.1007/s10980-011-9636-9
CR  - WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
CR  - Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
CR  - Wimmer J, 2013, ECOL APPL, V23, P1419, DOI 10.1890/12-2088.1
CR  - Xie J, 2016, APPL ACOUST, V113, P193, DOI 10.1016/j.apacoust.2016.06.029
CR  - Zotos K, 2005, ARXIVNLIN0505007
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - DEC
PY  - 2018
VL  - 95
SP  - 939
EP  - 952
DO  - 10.1016/j.ecolind.2018.06.012
AN  - WOS:000456907400092
N1  - Times Cited in Web of Science Core Collection:  44
Total Times Cited:  48
Cited Reference Count:  58
ER  -

TY  - JOUR
AU  - Chen, X
AU  - Zhao, J
AU  - Chen, YH
AU  - Zhou, W
AU  - Hughes, AC
TI  - Automatic standardized processing and identification of tropical bat calls using deep learning approaches
T2  - BIOLOGICAL CONSERVATION
LA  - English
KW  - Bats
KW  - Bioacoustics
KW  - Automated monitoring
KW  - Algorithms
KW  - Deep learning
KW  - Neural network
KW  - Automatic processing
KW  - Biodiversity metrics
KW  - Machine learning
KW  - Calls
KW  - Echolocation
KW  - Monitoring protocol
KW  - ECHOLOCATION CALLS
KW  - SIGNALS
KW  - CHIROPTERA
KW  - DIVERGENCE
KW  - OCCUPANCY
KW  - DIVERSITY
KW  - FREQUENCY
KW  - PATTERNS
KW  - SOUND
KW  - TOOL
AB  - Consistent and comparable metrics to automatically monitor biodiversity across the landscape remain a gold-standard for biodiversity research, yet such approaches have frequently been limited to a very small selection of species for which visual approaches (e.g., camera traps) make continuous monitoring possible. Acoustic-based methods have been widely applied in the monitoring of bats and some other taxa across extended spatial scales, but are have yet to be applied to diverse tropical communities.
   In this study, we developed a software program "Waveman" and prepared a reference library using over 880 audio-files from 36 Asian bat species. The software incorporated a novel network "BatNet" and a re-checking strategy (ReChk) to maximize accuracy. In Waveman, BatNet outperforms three other published networks: CNNFULL, VggNet and ResNet_v2, with over 90% overall accuracy and 0.94 AUC on the ROC plot. The classification accuracy rates for all 36 species are at least 86% when analysed in combination. Moreover, our library preparation and ReChk greatly improved the sensitivity and reduced the false positive rate, when tested with 15 species for which more detailed and situationally diverse records were available. Finally, BatNet was successfully used to identify Hipposideros larvatus and Rhinolophus siamensis from three different environments. We hope this pipeline is useful tool to process bioacoustic data accurately, effectively and automatically, therefore allowing for greater standardization and comparability for researchers to understand bat activities across space and time and therefore provide a consistent tool for monitoring biodiversity for management and conservation.
AD  - Chinese Acad Sci, Ctr Integrat Conservat, Xishuangbanna Trop Bot Garden, Menglun 666303, Peoples R ChinaAD  - Yunnan Univ, Software Sch, Kunming 650500, Yunnan, Peoples R ChinaC3  - Chinese Academy of SciencesC3  - Xishuangbanna Tropical Botanical Garden, CASC3  - Yunnan UniversityFU  - Chinese National Natural Science Foundation [U1602265]; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA20050202]; High-End Foreign Experts Program of Yunnan Province [Y9YN021B01]; CAS 135 program [2017XTBG-T03]
FX  - Supported by Chinese National Natural Science Foundation (Grant #: U1602265, Mapping Karst Biodiversity in Yunnan). Supported by the Strategic Priority Research Program of the Chinese Academy of Sciences (Grant No. XDA20050202). Supported by the High-End Foreign Experts Program of Yunnan Province (Grant #: Y9YN021B01, Yunnan Bioacoustic monitoring program). Supported by the CAS 135 program (No. 2017XTBG-T03).
CR  - ALTES RA, 1970, J ACOUST SOC AM, V48, P1014, DOI 10.1121/1.1912222
CR  - Astaras C, 2017, FRONT ECOL ENVIRON, V15, P233, DOI 10.1002/fee.1495
CR  - Baker E, 2015, DATABASE-OXFORD, DOI 10.1093/database/bav054
CR  - Barratt EM, 1997, NATURE, V387, P138, DOI 10.1038/387138b0
CR  - Benson DA, 2015, NUCLEIC ACIDS RES, V43, pD30, DOI 10.1093/nar/gku1216
CR  - Boonman A, 2005, J COMP PHYSIOL A, V191, P13, DOI 10.1007/s00359-004-0566-8
CR  - Cardinale BJ, 2018, BIOL CONSERV, V219, P175, DOI 10.1016/j.biocon.2017.12.021
CR  - Christin S., 2018, APPL DEEP LEARNING E
CR  - Clement MJ, 2014, J APPL ECOL, V51, P1460, DOI 10.1111/1365-2664.12303
CR  - Core Team R., 2019, R LANG ENV STAT COMP
CR  - Gager Y, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150780
CR  - Gasc A, 2013, ECOL INDIC, V25, P279, DOI 10.1016/j.ecolind.2012.10.009
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - Hughes AC, 2012, GLOBAL CHANGE BIOL, V18, P1854, DOI 10.1111/j.1365-2486.2012.02641.x
CR  - Hughes AC, 2011, ACTA CHIROPTEROL, V13, P447, DOI 10.3161/150811011X624938
CR  - Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
CR  - Ioffe S., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2
CR  - Jacobs DS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187769
CR  - Jiang TL, 2010, ETHOLOGY, V116, P691, DOI 10.1111/j.1439-0310.2010.01785.x
CR  - Kembel SW, 2010, BIOINFORMATICS, V26, P1463, DOI 10.1093/bioinformatics/btq166
CR  - Kingston T, 2004, NATURE, V429, P654, DOI 10.1038/nature02487
CR  - Kiskin I, 2020, NEURAL COMPUT APPL, V32, P915, DOI 10.1007/s00521-018-3626-7
CR  - Mac Aodha O, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005995
CR  - Mao XG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056786
CR  - Marques A, 2014, BASIC APPL ECOL, V15, P633, DOI 10.1016/j.baae.2014.09.004
CR  - Meagher JP, 2018, STATISTICAL DATA SCIENCE, P111
CR  - Meyer CFJ, 2010, BIOL CONSERV, V143, P2797, DOI 10.1016/j.biocon.2010.07.029
CR  - Newey S, 2015, AMBIO, V44, pS624, DOI 10.1007/s13280-015-0713-1
CR  - Parsons S, 2000, J EXP BIOL, V203, P2641
CR  - Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
CR  - Pennell MW, 2014, BIOINFORMATICS, V30, P2216, DOI 10.1093/bioinformatics/btu181
CR  - Proenca V, 2017, BIOL CONSERV, V213, P256, DOI 10.1016/j.biocon.2016.07.014
CR  - Rich LN, 2017, GLOBAL ECOL BIOGEOGR, V26, P918, DOI 10.1111/geb.12600
CR  - Russo D, 2002, J ZOOL, V258, P91, DOI 10.1017/S0952836902001231
CR  - Russo D, 2018, CAN J ZOOL, V96, P63, DOI 10.1139/cjz-2017-0089
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Rydell J, 2017, ECOL INDIC, V78, P416, DOI 10.1016/j.ecolind.2017.03.023
CR  - Silberman N., 2017, TF SLIM LIGHTWEIGHT
CR  - Simonyan K., 2015, P INT C LEARN REPR I
CR  - Stamatakis A, 2014, BIOINFORMATICS, V30, P1312, DOI 10.1093/bioinformatics/btu033
CR  - Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
CR  - Thabah A, 2006, BIOL J LINN SOC, V88, P119, DOI 10.1111/j.1095-8312.2006.00602.x
CR  - Trolle M, 2003, J MAMMAL, V84, P607, DOI 10.1644/1545-1542(2003)084<0607:EOODIT>2.0.CO;2
CR  - Walters Charlotte L., 2013, P479
CR  - Wilkins MR, 2013, TRENDS ECOL EVOL, V28, P156, DOI 10.1016/j.tree.2012.10.002
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
CR  - ZINGG P.E., 2019, REV SUISSE ZOOL, P263
PU  - ELSEVIER SCI LTD
PI  - OXFORD
PA  - THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
DA  - JAN
PY  - 2020
VL  - 241
DO  - 10.1016/j.biocon.2019.108269
AN  - WOS:000518695100048
N1  - Times Cited in Web of Science Core Collection:  11
Total Times Cited:  12
Cited Reference Count:  47
ER  -

TY  - BOOK
AU  - Carranza-Rojas, J
AU  - Joly, A
AU  - Goeau, H
AU  - Mata-Montero, E
AU  - Bonnet, P
ED  - Joly, A
ED  - Vrochidis, S
ED  - Karatzas, K
ED  - Karppinen, A
ED  - Bonnet, P
TI  - Automated Identification of Herbarium Specimens at Different Taxonomic Levels
T2  - MULTIMEDIA TOOLS AND APPLICATIONS FOR ENVIRONMENTAL & BIODIVERSITY INFORMATICS
LA  - English
KW  - CLASSIFICATION
AB  - The estimated number of flowering plant species on Earth is around 400,000. In order to classify all known species via automated image-based approaches, current datasets of plant images will have to become considerably larger. To achieve this, some authors have explored the possibility of using herbarium sheet images. As the plant datasets grow and start reaching the tens of thousands of classes, unbalanced datasets become a hard problem. This causes models to be inaccurate for certain species due to intra- and inter-specific similarities. Additionally, automatic plant identification is intrinsically hierarchical. In order to tackle this problem of unbalanced datasets, we need ways to classify and calculate the loss of the model by taking into account the taxonomy, for example, by grouping species at higher taxon levels. In this research we compare several architectures for automatic plant identification, taking into account the plant taxonomy to classify not only at the species level, but also at higher levels, such as genus and family.
AD  - Costa Rica Inst Technol, Sch Comp, Cartago, Costa RicaAD  - Inria ZENITH Team, Montpellier, FranceAD  - CIRAD, UMR AMAP, Montpellier, FranceAD  - Univ Montpellier, AMAP, CIRAD, CNRS,INRA,IRD, Montpellier, FranceC3  - Instituto Tecnologico de Costa RicaC3  - CIRADC3  - Centre National de la Recherche Scientifique (CNRS)C3  - Institut de Recherche pour le Developpement (IRD)C3  - Universite de MontpellierC3  - Centre National de la Recherche Scientifique (CNRS)C3  - CIRADC3  - INRAEC3  - Institut de Recherche pour le Developpement (IRD)C3  - Universite de MontpellierCR  - Bebber DP, 2010, P NATL ACAD SCI USA, V107, P22169, DOI 10.1073/pnas.1011841108
CR  - Carranza-Rojas J, 2017, BMC EVOL BIOL, V17, P1, DOI 10.1186/s12862-017-1014-z
CR  - CarranzaRojas J., 2017, BIODIVERSITY INFORM, V1
CR  - Dieleman S, 2015, LASAGNE 1 RELEASE
CR  - Goeau H., 2015, CLEF2015 WORK NOT TO
CR  - Goodfellow I, 2014, MULTIDIGIT NUMBER RE
CR  - Ioffe S., 2015, ABS150203167 CORR
CR  - Joly A., 2016, LIFECLEF 2016 MULTIM, P286
CR  - Joly A, 2016, MULTIMEDIA SYST, V22, P751, DOI 10.1007/s00530-015-0462-9
CR  - Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
CR  - MataMontero E., 2016, AUTOMATED PLANT SPEC, P26, DOI DOI 10.1007/978-3319-444475_3
CR  - Matsunaga A, 2013, P IEEE INT C E-SCI, P78, DOI 10.1109/eScience.2013.48
CR  - Page LM, 2015, BIOSCIENCE, V65, P841, DOI 10.1093/biosci/biv104
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - Shahbaba B, 2007, BAYESIAN ANAL, V2, P221, DOI 10.1214/07-BA209
CR  - Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
CR  - Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
CR  - Theano Development Team, 2016, ABS160502688 ARXIV T
CR  - Wu FH, 2005, LECT NOTES ARTIF INT, V3607, P313
CR  - Yan Z., 2015, ICCV 15 P IEEE 15 IN
PU  - SPRINGER
PI  - NEW YORK
PA  - 233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES
PY  - 2018
SP  - 151
EP  - 167
DO  - 10.1007/978-3-319-76445-0_9
DO  - 10.1007/978-3-319-76445-0
AN  - WOS:000449980400010
N1  - Times Cited in Web of Science Core Collection:  10
Total Times Cited:  10
Cited Reference Count:  20
ER  -

TY  - JOUR
AU  - Hastie, GD
AU  - Wu, GM
AU  - Moss, S
AU  - Jepp, P
AU  - MacAulay, J
AU  - Lee, A
AU  - Sparling, CE
AU  - Evers, C
AU  - Gillespie, D
TI  - Automated detection and tracking of marine mammals: A novel sonar tool for monitoring effects of marine industry
T2  - AQUATIC CONSERVATION-MARINE AND FRESHWATER ECOSYSTEMS
LA  - English
KW  - behaviour
KW  - mammals
KW  - monitoring
KW  - new techniques
KW  - ocean
KW  - renewable energy
KW  - HARBOR SEALS
KW  - WHALES
KW  - DYNAMICS
AB  - Many marine industries may pose acute risks to marine wildlife. For example, tidal turbines have the potential to injure or kill marine mammals through collisions with turbine blades. However, the quantification of collision risk is currently limited by a lack of suitable technologies to collect long-term data on marine mammal behaviour around tidal turbines. Sonar provides a potential means of tracking marine mammals around tidal turbines. However, its effectiveness for long-term data collection is hindered by the large data volumes and the need for manual validation of detections. Therefore, the aim here was to develop and test automated classification algorithms for marine mammals in sonar data. Data on the movements of harbour seals were collected in a tidally energetic environment using a high-frequency multibeam sonar on a custom designed seabed-mounted platform. The study area was monitored by observers to provide visual validation of seals and other targets detected by the sonar. Sixty-five confirmed seals and 96 other targets were detected by the sonar. Movement and shape parameters associated with each target were extracted and used to develop a series of classification algorithms. Kernel support vector machines were used to classify targets (seal vs. nonseal) and cross-validation analyses were carried out to quantify classifier efficiency. The best-fit kernel support vector machine correctly classified all the confirmed seals but misclassified a small percentage of non-seal targets (similar to 8%) as seals. Shape and non-spectral movement parameters were considered to be the most important in achieving successful classification. Results indicate that sonar is an effective method for detecting and tracking seals in tidal environments, and the automated classification approach developed here provides a key tool that could be applied to collecting long-term behavioural data around anthropogenic activities such as tidal turbines.
AD  - Univ St Andrews, Sea Mammal Res Unit, Scottish Oceans Inst, St Andrews KY16 8LB, Fife, ScotlandAD  - Helmholtz Ctr Environm Res, DEVELOP, Permoserstr 15, Leipzig, GermanyAD  - Tritech Int Ltd, Peregrine Rd,Westhill Business Pk, Westhill, Aberdeen, ScotlandAD  - SMRU Consulting Hong Kong, 1802 One Midtown,11 Hoi Shing Rd, Hong Kong, Peoples R ChinaAD  - SMRU Consulting Europe, New Technol Ctr, St Andrews, Fife, ScotlandAD  - Fisheries & Oceans Canada, Bedford Inst Oceanog, 1 Challenger Dr, Dartmouth, NS, CanadaC3  - University of St AndrewsC3  - Helmholtz AssociationC3  - Helmholtz Center for Environmental Research (UFZ)C3  - Fisheries & Oceans CanadaFU  - Department of Energy and Climate Change; Scottish Government [USA/010/14]; Natural Environment Research Council [NE/R014639/1, SMRU1001]; NERC [NE/R014639/1] Funding Source: UKRI
FX  - Department of Energy and Climate Change; Scottish Government, Grant/Award Number: Project no. USA/010/14; Natural Environment Research Council, Grant/Award Numbers: NE/R014639/1 and SMRU1001
CR  - Abe S., 2006, SUPPORT VECTOR MACHI
CR  - Benoit-Bird K., 2003, J ACOUST SOC AM, V114, P2300
CR  - Benoit-Bird KJ, 2003, BEHAV ECOL SOCIOBIOL, V53, P364, DOI 10.1007/s00265-003-0585-4
CR  - Chappell O.P., 1996, Report of the International Whaling Commission, V46, P587
CR  - Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
CR  - Cryer JD, 2008, SPRINGER TEXTS STAT, P1
CR  - Doksaeter L, 2009, ICES J MAR SCI, V66, P1029, DOI 10.1093/icesjms/fsp130
CR  - Findlay CR, 2018, MAR POLLUT BULL, V135, P1042, DOI 10.1016/j.marpolbul.2018.08.042
CR  - FISHER FH, 1977, J ACOUST SOC AM, V62, P558, DOI 10.1121/1.381574
CR  - Fox J., 2011, R COMPANION APPL REG, V2nd ed.
CR  - Gillespie D, 2008, P I ACOUST, V30, P67
CR  - Goddijn-Murphy L, 2013, J ATMOS OCEAN TECH, V30, P96, DOI 10.1175/JTECH-D-11-00223.1
CR  - Gonzalez-Socoloske Daniel, 2009, Endangered Species Research, V8, P249, DOI 10.3354/esr00232
CR  - Graham IM, 2011, ANIM CONSERV, V14, P587, DOI 10.1111/j.1469-1795.2011.00469.x
CR  - Hardin J., 2003, GEN ESTIMATING EQUAT
CR  - Hastie G.D., 2012, URN12D328 SMRU LTD D
CR  - Hastie GD, 2019, AQUAT CONSERV, V29, P564, DOI 10.1002/aqc.3017
CR  - Hastie GD, 2018, J APPL ECOL, V55, P684, DOI 10.1111/1365-2664.12981
CR  - Hastie GD, 2016, BEHAV ECOL SOCIOBIOL, V70, P2161, DOI 10.1007/s00265-016-2219-7
CR  - Hastie GD, 2014, HUMANIT SEA, P127, DOI 10.1007/978-94-017-8002-5_10
CR  - Hastie T., 2009, ELEMENTS STAT LEARNI, P520
CR  - Joslin J, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083633
CR  - Law George, 2013, International Journal of Computer Theory and Engineering, V5, P503, DOI 10.7763/IJCTE.2013.V5.738
CR  - Nottestad L, 2002, POLAR BIOL, V25, P939, DOI 10.1007/s00300-002-0437-0
CR  - Nottestad L, 2002, ICES J MAR SCI, V59, P393, DOI 10.1006/jmsc.2001.1172
CR  - Nowacek DP, 2007, MAMMAL REV, V37, P81, DOI 10.1111/j.1365-2907.2007.00104.x
CR  - Ona E, 1996, ICES J MAR SCI, V53, P677, DOI 10.1006/jmsc.1996.0087
CR  - onzalez-Socoloske D., 2012, OPEN REMOTE SENS J, V5, P1, DOI 10.2174/1875413901205010001
CR  - Parsons MJG, 2017, ACOUST AUST, V45, P41, DOI 10.1007/s40857-016-0076-1
CR  - Pyc CD, 2016, MAR MAMMAL SCI, V32, P202, DOI 10.1111/mms.12250
CR  - Quick NJ, 2004, AQUACULTURE, V230, P169, DOI 10.1016/S0044-8486(03)00428-9
CR  - Read AJ, 2006, CONSERV BIOL, V20, P163, DOI 10.1111/j.1523-1739.2006.00338.x
CR  - Ridoux V, 1997, MAR MAMMAL SCI, V13, P196, DOI 10.1111/j.1748-7692.1997.tb00627.x
CR  - Smith HD, 2000, OCEAN COAST MANAGE, V43, P11, DOI 10.1016/S0964-5691(00)00028-4
CR  - Team RC, 2012, R LANG ENV STAT COMP
CR  - van der Hoop J, 2017, ECOL EVOL, V7, P92, DOI 10.1002/ece3.2615
CR  - Vanderlaan ASM, 2007, MAR MAMMAL SCI, V23, P144, DOI 10.1111/j.1748-7692.2006.00098.x
CR  - Viehman HA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176405
CR  - Williamson BJ, 2017, IEEE J OCEANIC ENG, V42, P948, DOI 10.1109/JOE.2016.2637179
CR  - Williamson BJ, 2016, IEEE J OCEANIC ENG, V41, P67, DOI 10.1109/JOE.2015.2410851
CR  - Wilson B, 2007, COLLISION RISKS MARI
CR  - Wilson B, 2013, ENDANGER SPECIES RES, V22, P125, DOI 10.3354/esr00538
CR  - Yang ZR, 2004, BRIEF BIOINFORM, V5, P328, DOI 10.1093/bib/5.4.328
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - SEP
PY  - 2019
VL  - 29
SP  - 119
EP  - 130
DO  - 10.1002/aqc.3103
AN  - WOS:000484997200009
N1  - Times Cited in Web of Science Core Collection:  11
Total Times Cited:  11
Cited Reference Count:  43
ER  -

TY  - JOUR
AU  - Karasov, O
AU  - Heremans, S
AU  - Kulvik, M
AU  - Domnich, A
AU  - Chervanyov, I
TI  - On How Crowdsourced Data and Landscape Organisation Metrics Can Facilitate the Mapping of Cultural Ecosystem Services: An Estonian Case Study
T2  - LAND
LA  - English
KW  - cultural ecosystem services
KW  - automated image recognition
KW  - natural language processing
KW  - topic modelling
KW  - landscape coherence
KW  - colour harmony
KW  - SOCIAL MEDIA DATA
KW  - AESTHETIC VALUE
KW  - VALUES
KW  - SUSTAINABILITY
KW  - INDICATORS
KW  - MANAGEMENT
KW  - VALUATION
KW  - RESOURCE
KW  - AREAS
AB  - Social media continues to grow, permanently capturing our digital footprint in the form of texts, photographs, and videos, thereby reflecting our daily lives. Therefore, recent studies are increasingly recognising passively crowdsourced geotagged photographs retrieved from location-based social media as suitable data for quantitative mapping and assessment of cultural ecosystem service (CES) flow. In this study, we attempt to improve CES mapping from geotagged photographs by combining natural language processing, i.e., topic modelling and automated machine learning classification. Our study focuses on three main groups of CESs that are abundant in outdoor social media data: landscape watching, active outdoor recreation, and wildlife watching. Moreover, by means of a comparative viewshed analysis, we compare the geographic information system- and remote sensing-based landscape organisation metrics related to landscape coherence and colour harmony. We observed the spatial distribution of CESs in Estonia and confirmed that colour harmony indices are more strongly associated with landscape watching and outdoor recreation, while landscape coherence is more associated with wildlife watching. Both CES use and values of landscape organisation indices are land cover-specific. The suggested methodology can significantly improve the state-of-the-art with regard to CES mapping from geotagged photographs, and it is therefore particularly relevant for monitoring landscape sustainability.
AD  - Estonian Univ Life Sci, Inst Agr & Environm Sci, EE-51006 Tartu, EstoniaAD  - Res Inst Nat & Forest INBO, B-1000 Brussels, BelgiumAD  - Univ Tartu, Inst Comp Sci, EE-51009 Tartu, EstoniaAD  - Kharkov Natl Univ, Sch Geol Geog Recreat & Tourism, Phys Geog & Cartog Dept, UA-61022 Kharkiv, UkraineC3  - Estonian University of Life SciencesC3  - Research Institute for Nature & ForestC3  - University of TartuC3  - Ministry of Education & Science of UkraineC3  - VN Karazin Kharkiv National UniversityFU  - European Social Fund's Dora Plus Programme; ALTER-Net mobility fund; IMAGINE project (ERANET BIODIVERSA 3)
FX  - This research was funded by the European Social Fund's Dora Plus Programme, the ALTER-Net mobility fund, and the IMAGINE project (ERANET BIODIVERSA 3). The APC was partly funded by the IMAGINE project (ERANET BIODIVERSA 3).
CR  - Antrop M, 2017, LANDSC SER, V23, P81, DOI 10.1007/978-94-024-1183-6_5
CR  - Bachi L, 2020, TOURISM MANAGE, V77, DOI 10.1016/j.tourman.2019.104017
CR  - Burkhard B., 2018, One Ecosystem, V3, pe29153
CR  - Calcagni F, 2019, SUSTAIN SCI, V14, P1309, DOI 10.1007/s11625-019-00672-1
CR  - Cao Y, 2013, INT J SUST DEV WORLD, V20, P349, DOI 10.1080/13504509.2013.773266
CR  - Conrad O, 2015, GEOSCI MODEL DEV, V8, P1991, DOI 10.5194/gmd-8-1991-2015
CR  - Costanza R, 1997, NATURE, V387, P253, DOI 10.1038/387253a0
CR  - Demsar J, 2013, J MACH LEARN RES, V14, P2349
CR  - Diaz S, 2015, CURR OPIN ENV SUST, V14, P1, DOI 10.1016/j.cosust.2014.11.002
CR  - Dickinson DC, 2017, ECOSYST SERV, V25, P179, DOI 10.1016/j.ecoser.2017.04.014
CR  - Dunford R, 2018, ECOSYST SERV, V29, P499, DOI 10.1016/j.ecoser.2017.10.014
CR  - Dunkel A, 2015, LANDSCAPE URBAN PLAN, V142, P173, DOI 10.1016/j.landurbplan.2015.02.022
CR  - Figueroa-Alfaro RW, 2017, J ENVIRON PLANN MAN, V60, P266, DOI 10.1080/09640568.2016.1151772
CR  - Finlayson M., 2005, MILLENNIUM ECOSYSTEM
CR  - Ghermandi A, 2019, GLOBAL ENVIRON CHANG, V55, P36, DOI 10.1016/j.gloenvcha.2019.02.003
CR  - Gosal AS, 2019, ECOSYST SERV, V38, DOI 10.1016/j.ecoser.2019.100958
CR  - Haines-Young R., 2018, COMMON INT CLASSIFIC, V53
CR  - Hall-Beyer M., 2017, GLCM TEXTURE TUTORIA, DOI 10.13140/RG.2.2.12424.21767
CR  - HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
CR  - Hausmann A, 2018, CONSERV LETT, V11, DOI 10.1111/conl.12343
CR  - Hermes J, 2018, ECOSYST SERV, V31, P289, DOI 10.1016/j.ecoser.2018.04.011
CR  - Jacobs S, 2016, ECOSYST SERV, V22, P213, DOI 10.1016/j.ecoser.2016.11.007
CR  - Kaplan R, 1989, EXPERIENCE NATURE PS, P1208
CR  - Karasov O, 2021, GEOJOURNAL, V86, P529, DOI 10.1007/s10708-019-10058-6
CR  - Karasov O, 2020, ECOL INDIC, V111, DOI 10.1016/j.ecolind.2019.105973
CR  - Karasov O, 2019, GEOJOURNAL, V84, P1057, DOI 10.1007/s10708-018-9908-x
CR  - Kemp S., KEPIOS TEAM DIGITAL
CR  - Kim Y, 2019, TOURISM MANAGE, V72, P249, DOI 10.1016/j.tourman.2018.12.005
CR  - Kopperoinen L, 2017, MAPPING ECOSYSTEM SERVICES, P197
CR  - La Rosa D, 2016, ECOL INDIC, V61, P74, DOI 10.1016/j.ecolind.2015.04.028
CR  - Langemeyer J, 2018, LAND USE POLICY, V77, P542, DOI 10.1016/j.landusepol.2018.05.049
CR  - Lee H, 2019, ECOL INDIC, V96, P505, DOI 10.1016/j.ecolind.2018.08.035
CR  - Lutsenko E. V., 2002, Proceedings 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002), P268, DOI 10.1109/ICAIS.2002.1048109
CR  - Mancini F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200565
CR  - Pastur GM, 2016, LANDSCAPE ECOL, V31, P383, DOI 10.1007/s10980-015-0254-9
CR  - Milcu AI, 2013, ECOL SOC, V18, DOI 10.5751/ES-05790-180344
CR  - Musacchio LR, 2013, LANDSCAPE ECOL, V28, P995, DOI 10.1007/s10980-013-9909-6
CR  - Oteros-Rozas E, 2018, ECOL INDIC, V94, P74, DOI 10.1016/j.ecolind.2017.02.009
CR  - Ou LC, 2018, COLOR RES APPL, V43, P736, DOI 10.1002/col.22243
CR  - Pascual U, 2017, CURR OPIN ENV SUST, V26-27, P7, DOI 10.1016/j.cosust.2016.12.006
CR  - Plieninger T, 2015, CURR OPIN ENV SUST, V14, P28, DOI 10.1016/j.cosust.2015.02.006
CR  - Potschin MB, 2011, PROG PHYS GEOG, V35, P575, DOI 10.1177/0309133311423172
CR  - Richards DR, 2018, ECOSYST SERV, V31, P318, DOI 10.1016/j.ecoser.2017.09.004
CR  - Sahraoui Y, 2018, T GIS, V22, P1310, DOI 10.1111/tgis.12457
CR  - Saint-Marc P., 1971, SOCIALIZATION ENV
CR  - Santos-Martin F., 2018, One Ecosystem, V3, pe26719, DOI 10.3897/oneeco.3.e26719
CR  - Schloss KB, 2011, ATTEN PERCEPT PSYCHO, V73, P551, DOI 10.3758/s13414-010-0027-0
CR  - Sharp R., 2018, NATURAL CAPITAL PROJ
CR  - Statistics Estonia, MAJ ENT US INF COMM
CR  - Sullivan RG, 2016, ENVIRON PRAC, V18, P166, DOI 10.1017/S1466046616000260
CR  - Tenerelli P, 2016, ECOL INDIC, V64, P237, DOI 10.1016/j.ecolind.2015.12.042
CR  - Tenkanen H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18007-4
CR  - Tew ER, 2019, PEOPLE NAT, V1, P70, DOI 10.1002/pan3.14
CR  - Tieskens KF, 2018, LANDSCAPE URBAN PLAN, V177, P128, DOI 10.1016/j.landurbplan.2018.05.002
CR  - Van Berkel DB, 2018, ECOSYST SERV, V31, P326, DOI 10.1016/j.ecoser.2018.03.022
CR  - van Zanten BT, 2016, P NATL ACAD SCI USA, V113, P12974, DOI 10.1073/pnas.1614158113
CR  - Wood SA, 2013, SCI REP-UK, V3, DOI 10.1038/srep02976
CR  - Wu JG, 2013, LANDSCAPE ECOL, V28, P999, DOI 10.1007/s10980-013-9894-9
CR  - Yoshimura N, 2017, ECOSYST SERV, V24, P68, DOI 10.1016/j.ecoser.2017.02.009
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - MAY
PY  - 2020
VL  - 9
IS  - 5
DO  - 10.3390/land9050158
AN  - WOS:000542144200010
N1  - Times Cited in Web of Science Core Collection:  9
Total Times Cited:  9
Cited Reference Count:  59
ER  -

TY  - CPAPER
AU  - Moller, T
AU  - Nilssen, I
AU  - Nattkemper, TW
A1  - IEEE
TI  - Active learning for the classification of species in underwater images from a fixed observatory
T2  - 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW 2017)
LA  - English
CP  - 16th IEEE International Conference on Computer Vision (ICCV)
AB  - Vision based wildlife monitoring is an important task in the field of environmental monitoring. Wildlife monitoring activities often create large collections of data needing computational approaches to (semi-) automated detection and annotation of objects in the images/video. In this work, we consider the special case of marine wildlife monitoring using camera equipped fixed observatories. In such cases where a-priori knowledge about which species to find is limited, a standard computer vision approach, employing supervised learning, will not be applicable for detecting and classifying species (or events) in the images.
   In a recently proposed unsupervised learning method, image patches are extracted from a time series of underwater images that feature moving species (like starfish, etc). The patches are automatically grouped into clusters with similar morphology and a so called relevance score is assigned to each of the clusters describing the likeliness that it contains patches showing unusual changes. However, due to the unsupervised fashion (i) the categories don't have labels and (ii) do not reflect the species distribution satisfactory.
   In this paper, we propose an active learning method that builds upon these results and can be used to assign taxonomic categories to single patches based on a set of human expert annotations making use of the cluster structure and relevance scores. The evaluation shows that compared to traditional sampling strategies our approach uses significantly less manual labels to train a classifier. We are confident that the results are relevant for non-marine contexts as well.
AD  - Bielefeld Univ, Biodata Min Grp, D-33615 Bielefeld, GermanyAD  - Statoil ASA, Res & Technol, N-7005 Trondheim, NorwayC3  - University of BielefeldC3  - EquinorFU  - Statoil ASA, Research and Technology, Norway
FX  - Financial support was given by Statoil ASA, Research and Technology, Norway
CR  - Bloomberg D., COLOR QUANTIZATION U
CR  - Chen GB, 2014, IEEE IMAGE PROC, P858, DOI 10.1109/ICIP.2014.7025172
CR  - CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
CR  - Godo O. R., 2014, MARINE TECHNOLOGY SO, V48
CR  - Huang PX, 2015, MACH VISION APPL, V26, P89, DOI 10.1007/s00138-014-0641-2
CR  - Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
CR  - Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
CR  - Kawabata K., 2014, INT J DISTRIBUTED SE, V10
CR  - Knerr S, 1990, SINGLE LAYER LEARNIN, P41, DOI [10.1007/978-3-642-76153-9_5, DOI 10.1007/978-3-642-76153-9_5]
CR  - Moller T, 2016, 2016 ICPR 2ND WORKSHOP ON COMPUTER VISION FOR ANALYSIS OF UNDERWATER IMAGERY (CVAUI 2016), P13, DOI [10.1109/CVAUI.2016.15, 10.1109/CVAUI.2016.015]
CR  - Moller T., 2016, INT C PATT REC ICPR
CR  - Nguyen HT, 2004, P 21 INT C MACH LEAR, P79, DOI [10.1145/1015330.1015349, DOI 10.1145/1015330.1015349]
CR  - Norouzzadeh Mohammad Sadegh, 2017, CORR
CR  - O. N. Canada, 2014, NEPTUNE NE PAC
CR  - Osterloff J., 2016, METHODS OCEANOGRAPHY
CR  - Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P43
CR  - Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
CR  - Settles B., 2010, U WISCONSIN MADISON, V52, P55
CR  - Vardaro MF, 2013, LIMNOL OCEANOGR-METH, V11, P304, DOI 10.4319/lom.2013.11.304
PU  - IEEE
PI  - NEW YORK
PA  - 345 E 47TH ST, NEW YORK, NY 10017 USA
PY  - 2017
SP  - 2891
EP  - 2897
DO  - 10.1109/ICCVW.2017.341
AN  - WOS:000425239602113
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  19
ER  -

TY  - JOUR
AU  - Giese, L
AU  - Melzheimer, J
AU  - Bockmuhl, D
AU  - Wasiolka, B
AU  - Rast, W
AU  - Berger, A
AU  - Wachter, B
TI  - Using Machine Learning for Remote Behaviour Classification-Verifying Acceleration Data to Infer Feeding Events in Free-Ranging Cheetahs
T2  - SENSORS
LA  - English
KW  - accelerometry
KW  - automated behaviour classification
KW  - Acinonyx jubatus
KW  - cheetah
KW  - GPS clusters
KW  - supervised machine learning
KW  - TRIAXIAL ACCELEROMETER
KW  - ECOLOGY
KW  - ANIMALS
KW  - PREY
AB  - Behavioural studies of elusive wildlife species are challenging but important when they are threatened and involved in human-wildlife conflicts. Accelerometers (ACCs) and supervised machine learning algorithms (MLAs) are valuable tools to remotely determine behaviours. Here we used five captive cheetahs in Namibia to test the applicability of ACC data in identifying six behaviours by using six MLAs on data we ground-truthed by direct observations. We included two ensemble learning approaches and a probability threshold to improve prediction accuracy. We used the model to then identify the behaviours in four free-ranging cheetah males. Feeding behaviours identified by the model and matched with corresponding GPS clusters were verified with previously identified kill sites in the field. The MLAs and the two ensemble learning approaches in the captive cheetahs achieved precision (recall) ranging from 80.1% to 100.0% (87.3% to 99.2%) for resting, walking and trotting/running behaviour, from 74.4% to 81.6% (54.8% and 82.4%) for feeding behaviour and from 0.0% to 97.1% (0.0% and 56.2%) for drinking and grooming behaviour. The model application to the ACC data of the free-ranging cheetahs successfully identified all nine kill sites and 17 of the 18 feeding events of the two brother groups. We demonstrated that our behavioural model reliably detects feeding events of free-ranging cheetahs. This has useful applications for the determination of cheetah kill sites and helping to mitigate human-cheetah conflicts.
AD  - Leibniz Inst Zoo & Wildlife Res, Alfred Kowalke Str 17, D-10315 Berlin, GermanyC3  - Leibniz Institut fur Zoo und WildtierforschungFU  - Ministry of Environment, Forestry and Tourism (MEFT) in Namibia
FX  - We thank the Ministry of Environment, Forestry and Tourism (MEFT) in Namibia for permission and support to conduct this study and Christian Schmitt and family from the Okambara Elephant Lodge for allowing us to conduct the study on the captive cheetahs on their farm. We also thank Heribert Hofer for stimulating discussions.
CR  - Bidder OR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088609
CR  - Blecha KA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138915
CR  - Block BA, 2011, NATURE, V475, P86, DOI 10.1038/nature10082
CR  - Blumstein DT, 2004, CONSERV BIOL, V18, P1175, DOI 10.1111/j.1523-1739.2004.00587.x
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Brewster LR, 2018, MAR BIOL, V165, DOI 10.1007/s00227-018-3318-y
CR  - Brown DR, 2013, APL MATER, V1, DOI 10.1063/1.4827595
CR  - Brownscombe JW, 2014, MAR ECOL PROG SER, V505, P241, DOI 10.3354/meps10786
CR  - Buchholz R, 2007, TRENDS ECOL EVOL, V22, P401, DOI 10.1016/j.tree.2007.06.002
CR  - Cagnacci F, 2010, PHILOS T R SOC B, V365, P2157, DOI 10.1098/rstb.2010.0107
CR  - Campbell HA, 2013, J EXP BIOL, V216, P4501, DOI 10.1242/jeb.089805
CR  - Caro T.M., 1994, CHEETAHS SERENGETI P
CR  - Crofoot MC, 2010, ANIM BEHAV, V80, P475, DOI 10.1016/j.anbehav.2010.06.006
CR  - Durant S., 2015, SPECIES, DOI [10.2305/IUCN.UK.2015-4.RLTS.T219A50649567.en, DOI 10.2305/IUCN.UK.2015-4.RLTS.T219A50649567.EN]
CR  - Durant SM, 2017, P NATL ACAD SCI USA, V114, P528, DOI 10.1073/pnas.1611122114
CR  - e-obs GmbH System Manual, 2014, GPS ACC TAGS
CR  - Frohlich M, 2012, S AFR J WILDL RES, V42, P104, DOI 10.3957/056.042.0208
CR  - Gese EM, 2016, WILDLIFE RES, V43, P130, DOI 10.1071/WR15196
CR  - Graf PM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136751
CR  - Grunewalder S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049120
CR  - Hayward MW, 2006, J ZOOL, V270, P615, DOI 10.1111/j.1469-7998.2006.00184.x
CR  - Hetem RS, 2019, INTEGR ZOOL, V14, P30, DOI 10.1111/1749-4877.12341
CR  - Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
CR  - Joubert S.C.J., 2014, GAME RANCH MANAGEMEN, V5th, P384
CR  - Kays R, 2015, SCIENCE, V348, DOI 10.1126/science.aaa2478
CR  - Korner P, 2016, ANIM BEHAV, V115, P69, DOI 10.1016/j.anbehav.2016.02.026
CR  - Lamb CT, 2020, P NATL ACAD SCI USA, V117, P17876, DOI 10.1073/pnas.1922097117
CR  - Liaw A, 2002, FOREST@, V2, P18, DOI DOI 10.1177/154405910408300516
CR  - Macdonald DW, 2016, ANIM BEHAV, V120, P197, DOI 10.1016/j.anbehav.2016.06.013
CR  - Marker LL, 2003, CONSERV BIOL, V17, P1290, DOI 10.1046/j.1523-1739.2003.02077.x
CR  - Martiskainen P, 2009, APPL ANIM BEHAV SCI, V119, P32, DOI 10.1016/j.applanim.2009.03.005
CR  - McClune DW., 2014, ANIM BIOTELEM, V2, P1
CR  - Melzheimer J, 2020, P NATL ACAD SCI USA, V117, P33325, DOI 10.1073/pnas.2002487117
CR  - Melzheimer J, 2018, ECOSPHERE, V9, DOI 10.1002/ecs2.2308
CR  - Menges V., 2015, CONSERV ENV NAMIB, P23
CR  - Meyer D., 2021
CR  - Mills M.G.L., 2017, KALAHRI CHEETAHS ADA, V1st
CR  - Mills MGL, 2004, WILDLIFE BIOL, V10, P177, DOI 10.2981/wlb.2004.024
CR  - Moreau M, 2009, APPL ANIM BEHAV SCI, V119, P158, DOI 10.1016/j.applanim.2009.04.008
CR  - Nathan R, 2012, J EXP BIOL, V215, P986, DOI 10.1242/jeb.058602
CR  - Painter M.S., 2016, ANIM BIOTELEM, V4, P20, DOI 10.1186/s40317-016-0113-8
CR  - R.Core Team, 2018, R LANG ENV STAT COMP, DOI DOI 10.1007/978-3-540-74686-7
CR  - Rast W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227317
CR  - Resheff YS, 2014, MOV ECOL, V2, DOI 10.1186/s40462-014-0027-0
CR  - Sakamoto KQ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005379
CR  - Scantlebury DM, 2014, SCIENCE, V346, P79, DOI 10.1126/science.1256424
CR  - Schliep K., 2016
CR  - Shepard Emily L. C., 2010, Endangered Species Research, V10, P47, DOI 10.3354/esr00084
CR  - Sliwa A, 2004, MAMM BIOL, V69, P96, DOI 10.1078/1616-5047-00124
CR  - Smith JA, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2014.2711
CR  - Soltis Joseph, 2012, Endangered Species Research, V18, P255, DOI 10.3354/esr00452
CR  - Stein AB, 2015, AFR J WILDL RES, V45, P247, DOI 10.3957/056.045.0247
CR  - Storch I., 2017, ANIMAL BIOTELEMETRY, V5, P10, DOI [10.1186/s40317-017-0125-z, DOI 10.1186/S40317-017-0125-Z]
CR  - Sur M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174785
CR  - Suraci JP, 2019, ECOLOGY, V100, DOI 10.1002/ecy.2644
CR  - Sutherland WJ, 1998, ANIM BEHAV, V56, P801, DOI 10.1006/anbe.1998.0896
CR  - Swaisgood RR, 2007, APPL ANIM BEHAV SCI, V102, P139, DOI 10.1016/j.applanim.2006.05.027
CR  - Therneau T., 2019
CR  - Van Rossum G., 2009, PYTHON 3 REFERENCE M
CR  - Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
CR  - Viviant M, 2010, POLAR BIOL, V33, P713, DOI 10.1007/s00300-009-0750-y
CR  - Wachter B, 2018, BIODIVER WORL CONS, P121, DOI 10.1016/B978-0-12-804088-1.00009-5
CR  - Wang YW, 2015, MOV ECOL, V3, DOI 10.1186/s40462-015-0030-0
CR  - Watanabe S, 2005, APPL ANIM BEHAV SCI, V94, P117, DOI 10.1016/j.applanim.2005.01.010
CR  - Weise FJ, 2019, FRONT ECOL EVOL, V6, DOI 10.3389/fevo.2018.00242
CR  - Weise FJ, 2017, PEERJ, V5, DOI 10.7717/peerj.4096
CR  - Whitney Nicholas M., 2010, Endangered Species Research, V10, P71, DOI 10.3354/esr00247
CR  - Williams HJ., 2015, ANIM BIOTELEM, DOI [10.1186/s40317-015-0077-0, DOI 10.1186/S40317-015-0077-0]
CR  - Wilson ADM, 2015, CONSERV BIOL, V29, P1065, DOI 10.1111/cobi.12486
CR  - Wilson E.O, 2012, FOREWORD BEHAV GUIDE, V20th
CR  - Wilson JW, 2013, BIOL LETTERS, V9, DOI 10.1098/rsbl.2013.0620
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - AUG
PY  - 2021
VL  - 21
IS  - 16
DO  - 10.3390/s21165426
AN  - WOS:000689877400001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  71
ER  -

TY  - JOUR
AU  - Aryal, B
AU  - Escarzaga, SM
AU  - Zesati, SVA
AU  - Velez-Reyes, M
AU  - Fuentes, O
AU  - Tweedie, C
TI  - Semi-Automated Semantic Segmentation of Arctic Shorelines Using Very High-Resolution Airborne Imagery, Spectral Indices and Weakly Supervised Machine Learning Approaches
T2  - REMOTE SENSING
LA  - English
KW  - land water segmentation
KW  - remote sensing
KW  - deep learning
KW  - sparse labels
KW  - BEAUFORT SEA
KW  - WATER-BODY
KW  - EXTRACTION
KW  - CLASSIFICATION
KW  - COASTLINE
KW  - FEATURES
KW  - EROSION
KW  - NDWI
KW  - ICE
KW  - NETWORKS
AB  - Precise coastal shoreline mapping is essential for monitoring changes in erosion rates, surface hydrology, and ecosystem structure and function. Monitoring water bodies in the Arctic National Wildlife Refuge (ANWR) is of high importance, especially considering the potential for oil and natural gas exploration in the region. In this work, we propose a modified variant of the Deep Neural Network based U-Net Architecture for the automated mapping of 4 Band Orthorectified NOAA Airborne Imagery using sparsely labeled training data and compare it to the performance of traditional Machine Learning (ML) based approaches-namely, random forest, xgboost-and spectral water indices-Normalized Difference Water Index (NDWI), and Normalized Difference Surface Water Index (NDSWI)-to support shoreline mapping of Arctic coastlines. We conclude that it is possible to modify the U-Net model to accept sparse labels as input and the results are comparable to other ML methods (an Intersection-over-Union (IoU) of 94.86% using U-Net vs. an IoU of 95.05% using the best performing method).
AD  - Univ Texas El Paso, Computat Sci Program, 500 W Univ Ave, El Paso, TX 79968 USAAD  - Univ Texas El Paso, Environm Sci & Engn Program, 500 W Univ Ave, El Paso, TX 79968 USAAD  - Univ Texas El Paso, Coll Engn Elect & Comp Engn, 500 W Univ Ave, El Paso, TX 79968 USAAD  - Univ Texas El Paso, Dept Comp Sci, 500 W Univ Ave, El Paso, TX 79968 USAC3  - University of Texas SystemC3  - University of Texas El PasoC3  - University of Texas SystemC3  - University of Texas El PasoC3  - University of Texas SystemC3  - University of Texas El PasoC3  - University of Texas SystemC3  - University of Texas El PasoFU  - National Oceanic and Atmospheric Administration; Office of Education Educational Partnership Program [NA16SEC4810008]; NSF LTER award [1656026]; NASA [NNX17AC58A, 80NSSC21K1164]; NSF ITEX-AON [1836861]
FX  - Miguel Velez-Reyes, Craig Tweedie, and Stephen Escarzaga were partially supported by the National Oceanic and Atmospheric Administration, Office of Education Educational Partnership Program award number NA16SEC4810008 and by the NSF LTER award number: 1656026. Sergio Vargas Zesati was partially supported by NASA award numbers NNX17AC58A and 80NSSC21K1164 and NSF ITEX-AON award number: 1836861. The content of the paper is solely the responsibility of the award recipient and do not necessarily represent the official views of the U.S. Department of Commerce, National Oceanic and Atmospheric Administration.
CR  - Abolt CJ, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0423-9
CR  - Al Mansoori S., 2016, INT J CURR ENG TECHN, V6, P1245
CR  - Alonso I, 2018, IEEE INT C INT ROBOT, P5785, DOI 10.1109/IROS.2018.8594185
CR  - Alonso I, 2017, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2017.339
CR  - Banks S, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121206
CR  - Baraka S., 2020, ARXIV201205013
CR  - Barnhart KR, 2014, CRYOSPHERE, V8, P1777, DOI 10.5194/tc-8-1777-2014
CR  - Bayram B, 2017, ISPRS ANN PHOTO REM, V4-4, P141, DOI 10.5194/isprs-annals-IV-4-W4-141-2017
CR  - Bhuiyan MA, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120137
CR  - Boak EH, 2005, J COASTAL RES, V21, P688, DOI 10.2112/03-0071.1
CR  - Board Space Studies and National Academies of Sciences Engineering and Medicine, 2019, THRIV OUR CHANG PLAN
CR  - BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
CR  - Chen F, 2017, IEEE J-STARS, V10, P4002, DOI 10.1109/JSTARS.2017.2705718
CR  - Chen T., 2015, XGBOOST EXTREME GRAD, P1, DOI DOI 10.1145/2939672
CR  - Chen Y, 2018, WATER-SUI, V10, DOI 10.3390/w10050585
CR  - Cheng DC, 2017, IEEE J-STARS, V10, P5769, DOI 10.1109/JSTARS.2017.2747599
CR  - Choung YJ, 2017, J SENSORS, V2017, DOI 10.1155/2017/8245204
CR  - Cooley SW, 2019, GEOPHYS RES LETT, V46, P2111, DOI 10.1029/2018GL081584
CR  - Costantino D, 2020, GEOGR TECH, V15, P171, DOI 10.21163/GT_2020.152.17
CR  - DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
CR  - Dickens K., 2019, SMU DATA SCI REV, V2, P4
CR  - Dixon B, 2008, INT J REMOTE SENS, V29, P1185, DOI 10.1080/01431160701294661
CR  - Dunton, 2018, FOOD WEBS, V15, DOI [10.1016/j.fooweb.2018.e00081, DOI 10.1016/J.FOOWEB.2018.E00081]
CR  - Dunton KH, 2012, ESTUAR COAST, V35, P416, DOI 10.1007/s12237-012-9475-1
CR  - Farquharson LM, 2018, MAR GEOL, V404, P71, DOI 10.1016/j.margeo.2018.07.007
CR  - Forbes D. L., 2011, STATE ARCTIC COAST 2
CR  - Fritz M, 2017, NAT CLIM CHANGE, V7, P6, DOI 10.1038/nclimate3188
CR  - Gatto L.W., 1980, COASTAL ENV BATHYMET
CR  - Ghoneim E, 2015, GEOMORPHOLOGY, V228, P1, DOI 10.1016/j.geomorph.2014.08.021
CR  - Godre A., 2019, SUAS BASED MULTISPEC
CR  - Goswami S, 2011, J GEOPHYS RES-BIOGEO, V116, DOI 10.1029/2010JG001346
CR  - Gunther F, 2013, BIOGEOSCIENCES, V10, P4297, DOI 10.5194/bg-10-4297-2013
CR  - Heim B, 2014, BIOGEOSCIENCES, V11, P4191, DOI 10.5194/bg-11-4191-2014
CR  - Hernes P., 2014, AGU FALL M, V2014
CR  - Hu YF, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122053
CR  - Huang WL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050797
CR  - Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
CR  - IBA W, 1992, MACHINE LEARNING /, P233
CR  - Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
CR  - Jones BM, 2018, ENVIRON RES LETT, V13, DOI 10.1088/1748-9326/aae471
CR  - Jones BM, 2008, ARCTIC, V61, P361
CR  - Jorgenson MT, 2005, GEO-MAR LETT, V25, P69, DOI 10.1007/s00367-004-0188-8
CR  - Kalkan K, 2013, INT ARCH PHOTOGRAMM, V40-7-W2, P125, DOI 10.5194/isprsarchives-XL-7-W2-125-2013
CR  - Kinsman N., 2015, P COASTAL SEDIMENTS
CR  - Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
CR  - Kyzivat ED, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182163
CR  - Lantuit H, 2008, GEOMORPHOLOGY, V95, P84, DOI 10.1016/j.geomorph.2006.07.040
CR  - Lantuit H, 2012, ESTUAR COAST, V35, P383, DOI 10.1007/s12237-010-9362-6
CR  - Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
CR  - Liu W, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010056
CR  - Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
CR  - Lu X, 2020, J HYDROL, V584, DOI 10.1016/j.jhydrol.2020.124689
CR  - Ma SF, 2019, ECOL INDIC, V98, P68, DOI 10.1016/j.ecolind.2018.10.049
CR  - Maglione P, 2014, EUR J REMOTE SENS, V47, P685, DOI 10.5721/EuJRS20144739
CR  - Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
CR  - Main-Knorn M, 2017, PROC SPIE, V10427, DOI 10.1117/12.2278218
CR  - MARSHALL GJ, 1994, REMOTE SENS ENVIRON, V50, P149, DOI 10.1016/0034-4257(94)90041-8
CR  - McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
CR  - McFeeters SK, 2013, REMOTE SENS-BASEL, V5, P3544, DOI 10.3390/rs5073544
CR  - Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
CR  - Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
CR  - Nazeer M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050749
CR  - Nitze I, 2020, CRYOSPHERE, V14, P4279, DOI 10.5194/tc-14-4279-2020
CR  - Obu J, 2016, POLAR RES, V35, DOI 10.3402/polar.v35.30313
CR  - OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
CR  - Osin V., 2017, ARXIV170606169
CR  - OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
CR  - Ozturk D, 2015, OCEAN COAST MANAGE, V118, P290, DOI 10.1016/j.ocecoaman.2015.03.009
CR  - Park SJ, 2019, J COASTAL RES, P228, DOI 10.2112/SI90-028.1
CR  - Paszke A, 2019, ADV NEUR IN, V32
CR  - PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800
CR  - Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
CR  - Ping CL, 2011, J GEOPHYS RES-BIOGEO, V116, DOI 10.1029/2010JG001588
CR  - Randazzo G, 2020, GEOSCIENCES, V10, DOI 10.3390/geosciences10050172
CR  - Richmond B.M, 2015, NATL ASSESSMENT SHOR
CR  - Richter-Menge J., 2019, REPORT CARD
CR  - RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2
CR  - Robinson C, 2020, AAAI CONF ARTIF INTE, V34, P2509
CR  - Ronneberger O., 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
CR  - ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326
CR  - Ruisanchez I, 2021, TALANTA, V222, DOI 10.1016/j.talanta.2020.121564
CR  - RYAN TW, 1991, PHOTOGRAMM ENG REM S, V57, P947
CR  - Sekovski I, 2014, INT J REMOTE SENS, V35, P3556, DOI 10.1080/01431161.2014.907939
CR  - Song SR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020397
CR  - Sorensen T., 1948, BIOL SKRIFTER, V5
CR  - Streletskiy DA, 2017, PERMAFROST PERIGLAC, V28, P566, DOI 10.1002/ppp.1918
CR  - Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
CR  - Turetsky MR, 2019, NATURE, V569, P32, DOI 10.1038/d41586-019-01313-4
CR  - Tweedie C., 2012, P 10 INT C PERM SAL
CR  - Vos K, 2019, ENVIRON MODELL SOFTW, V122, DOI 10.1016/j.envsoft.2019.104528
CR  - Wang S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020207
CR  - Winsvold SH, 2016, IEEE J-STARS, V9, P3698, DOI 10.1109/JSTARS.2016.2527063
CR  - Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
CR  - Yang L, 2015, INT J INNOV COMPUT I, V11, P1913
CR  - Yu L, 2017, INT J COMPUT INTELL, V16, DOI 10.1142/S1469026817500018
CR  - Zhang WX, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091487
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - NOV
PY  - 2021
VL  - 13
IS  - 22
DO  - 10.3390/rs13224572
AN  - WOS:000726226900001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  96
ER  -

TY  - JOUR
AU  - Shepley, A
AU  - Falzon, G
AU  - Meek, P
AU  - Kwan, P
TI  - Automated location invariant animal detection in camera trap images using publicly available data sources
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - animal identification
KW  - artificial intelligence
KW  - camera trap images
KW  - camera trapping
KW  - deep convolutional neural networks
KW  - deep learning
KW  - infusion
KW  - location invariance
KW  - wildlife ecology
KW  - wildlife monitoring
AB  - A time-consuming challenge faced by camera trap practitioners is the extraction of meaningful data from images to inform ecological management. An increasingly popular solution is automated image classification software. However, most solutions are not sufficiently robust to be deployed on a large scale due to lack of location invariance when transferring models between sites. This prevents optimal use of ecological data resulting in significant expenditure of time and resources to annotate and retrain deep learning models.
   We present a method ecologists can use to develop optimized location invariant camera trap object detectors by (a) evaluating publicly available image datasets characterized by high intradataset variability in training deep learning models for camera trap object detection and (b) using small subsets of camera trap images to optimize models for high accuracy domain-specific applications.
   We collected and annotated three datasets of images of striped hyena, rhinoceros, and pigs, from the image-sharing websites FlickR and iNaturalist (FiN), to train three object detection models. We compared the performance of these models to that of three models trained on the Wildlife Conservation Society and Camera CATalogue datasets, when tested on out-of-sample Snapshot Serengeti datasets. We then increased FiN model robustness by infusing small subsets of camera trap images into training.
   In all experiments, the mean Average Precision (mAP) of the FiN trained models was significantly higher (82.33%-88.59%) than that achieved by the models trained only on camera trap datasets (38.5%-66.74%). Infusion further improved mAP by 1.78%-32.08%.
   Ecologists can use FiN images for training deep learning object detection solutions for camera trap image processing to develop location invariant, robust, out-of-the-box software. Models can be further optimized by infusion of 5%-10% camera trap images into training data. This would allow AI technologies to be deployed on a large scale in ecological applications. Datasets and code related to this study are open source and available on this repository: .
AD  - Univ New England, Sch Sci & Technol, Armidale, NSW, AustraliaAD  - Flinders Univ S Australia, Coll Sci & Engn, Adelaide, SA, AustraliaAD  - NSW Dept Primary Ind, Vertebrate Pest Res Unit, Coffs Harbour, NSW, AustraliaAD  - Univ New England, Sch Environm & Rural Sci, Armidale, NSW, AustraliaAD  - Melbourne Inst Technol, Sch IT & Engn, Melbourne, Vic, AustraliaC3  - University of New EnglandC3  - Flinders University South AustraliaC3  - NSW Department of Primary IndustriesC3  - University of New EnglandFU  - University of New England; Australian Department of Agriculture and Water Resources; NSW Department of Primary Industries; NSW Environmental Trust; Centre for Invasive Animals Solutions
FX  - Centre for Invasive Animals Solutions; University of New England; Australian Department of Agriculture and Water Resources; NSW Department of Primary Industries; NSW Environmental Trust
CR  - Aradhya H.V.R., 2018, 2018 INT C COMM SIGN
CR  - Christensen JH, 2018, 2018 IEEE/OES AUTONOMOUS UNDERWATER VEHICLE WORKSHOP (AUV)
CR  - Christin S, 2019, METHODS ECOL EVOL, V10, P1632, DOI 10.1111/2041-210X.13256
CR  - Clune, 2017, P NATL ACAD SCI USA, V115
CR  - Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
CR  - Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
CR  - Falzon G, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10010058
CR  - Falzon G, 2014, CAMERA TRAPPING: WILDLIFE MANAGEMENT AND RESEARCH, P299
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Glover-Kapfer P, 2019, REMOTE SENS ECOL CON, V5, P209, DOI 10.1002/rse2.106
CR  - Villa AG, 2017, ECOL INFORM, V41, P24, DOI 10.1016/j.ecoinf.2017.07.004
CR  - Kellenberger B, 2017, JOINT URB REMOTE SEN
CR  - Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
CR  - Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
CR  - Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
CR  - Maurice, 2019, SURV STAT PANG CAM T
CR  - Meek PD, 2015, AUST MAMMAL, V37, P13, DOI 10.1071/AM14023
CR  - Miao ZQ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44565-w
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - O'Connell AF, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, P191, DOI 10.1007/978-4-431-99495-4_11
CR  - Perona, 2018, RECOGNITION TERRA IN
CR  - Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
CR  - Ren SQ, 2015, ADV NEUR IN, V28
CR  - Rodin CD, 2018, IEEE IJCNN
CR  - Rovero F., 2016, CAMERA TRAPPING WILD
CR  - Schneider S, 2019, METHODS ECOL EVOL, V10, P461, DOI 10.1111/2041-210X.13133
CR  - Schneider S, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P321, DOI 10.1109/CRV.2018.00052
CR  - Shahinfar S, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101085
CR  - Singh P., 2020, 2020 IEEE SW S IM AN
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Swinnen KRR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098881
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tambe M., 2020, 2020 IEEE WINT C APP
CR  - Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
CR  - Vedaldi, 2017, LEARNING MULTIPLE VI, P506
CR  - Wang G., 2017, 2017 IEEE WINT C APP
CR  - Wang X., 2019, 2019 IEEE CVF C COMP
CR  - Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
CR  - Wearn O.R., 2017, WWF CONSERVATION TEC, DOI DOI 10.13140/RG.2.2.23409.17767
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
CR  - Xu BB, 2020, INT J REMOTE SENS, V41, P8121, DOI 10.1080/01431161.2020.1734245
CR  - Yang XY, 2019, IEEE INT CONF COMP V, P255, DOI 10.1109/ICCVW.2019.00034
CR  - Young S, 2018, ECOL EVOL, V8, P9947, DOI 10.1002/ece3.4464
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
CR  - Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
CR  - Zisserman, 2007, DATASET ISSUES OBJEC, V4170, P29
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - MAY
PY  - 2021
VL  - 11
IS  - 9
SP  - 4494
EP  - 4506
DO  - 10.1002/ece3.7344
AN  - WOS:000626984400001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  48
ER  -

TY  - JOUR
AU  - Carl, C
AU  - Schonfeld, F
AU  - Profft, I
AU  - Klamm, A
AU  - Landgraf, D
TI  - Automated detection of European wild mammal species in camera trap images with an existing and pre-trained computer vision model
T2  - EUROPEAN JOURNAL OF WILDLIFE RESEARCH
LA  - English
KW  - Computer vision
KW  - Image analysis
KW  - Camera trap
KW  - Pre-trained model
KW  - Wild mammal species
AB  - The use of camera traps is a nonintrusive monitoring method to obtain valuable information about the appearance and behavior of wild animals. However, each study generates thousands of pictures and extracting information remains mostly an expensive, time-consuming manual task. Nevertheless, image recognition and analyzing technologies combined with machine learning algorithms, particularly deep learning models, improve and speed up the analysis process. Therefore, we tested the usability of a pre-trained deep learning model available on the TensorFlow hub-FasterRCNN+InceptionResNet V2 network applied to images of ten different European wild mammal species such as wild boar (Sus scrofa), roe deer (Capreolus capreolus), or red fox (Vulpes vulpes) in color as well as black and white infrared images. We found that the detection rate of the correct region of interest (region of the animal) was 94%. The classification accuracy was 71% for the correct species' name as mammals and 93% for the correct species or higher taxonomic ranks such as "carnivore" as order. In 7% of cases, the classification was incorrect as the wrong species' name was classified. In this technical note, we have shown the potential of an existing and pre-trained image classification model for wildlife animal detection, classification, and analysis. A specific training of the model on European wild mammal species could further increase the detection and classification accuracy of the models. Analysis of camera trap images could thus become considerably faster, less expensive, and more efficient.
AD  - Univ Appl Sci Erfurt, Forestry & Ecosyst Management, Leipziger Str 77, D-99085 Erfurt, GermanyAD  - ThuringenForst AoR, Forstliches Forsch & Kompetenzzentrum, Jagerstr 1, D-99867 Gotha, GermanyAD  - Natl Pk Verwaltung Hainich, Bei Marktkirche 9, D-99947 Bad Langensalza, GermanyFU  - University of Applied Sciences Erfurt
FX  - This research was supported by the University of Applied Sciences Erfurt (FHE).
CR  - Abadi M., 2015, TensorFlow: large-scale machine learning on heterogeneous systems
CR  - Banupriya N., 2020, J CRIT REV, V7, P434
CR  - Beery S., 2019, ARXIV190405986
CR  - Bowkett AE, 2008, AFR J ECOL, V46, P479, DOI 10.1111/j.1365-2028.2007.00881.x
CR  - Casaer J, 2019, BIODIVERSITY INFORM
CR  - Figueroa K, 2014, LECT NOTES COMPUT SC, V8827, P940, DOI 10.1007/978-3-319-12568-8_114
CR  - Google LLC, 2019, OP IM DAT V4 CC 4 0
CR  - Google LLC Colaboratory, 2019, WELC COL
CR  - Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
CR  - Hui Jonathan, 2018, OBJECT DETECTION SPE
CR  - Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
CR  - Inik o, 2018, J NEW RESULTS SCI, V7, P9
CR  - Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
CR  - Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
CR  - LILA BC, 2019, LAB INF LIB AL BIOL
CR  - Lundh F, 2016, PILLOW PYTHON IMAGIN
CR  - Miao ZQ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44565-w
CR  - Nationalparkverwaltung Hainich FFK Gotha, 2019, SCHW HAIN
CR  - Newey S, 2015, AMBIO, V44, pS624, DOI 10.1007/s13280-015-0713-1
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Oliphant T.E., 2006, A GUIDE TO NUMPY, P85
CR  - Python Software Foundation, 2019, PYTH STAND LIBR TEMP
CR  - Python Software Foundation, 2019, PYTH STAND LIB IO CO
CR  - Python Software Foundation, 2019, PYTH STAND LIB URLL
CR  - Python Software Foundation, 2019, PYTH STAND LIB TIM T
CR  - Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
CR  - Silveira L, 2003, BIOL CONSERV, V114, P351, DOI 10.1016/S0006-3207(03)00063-6
CR  - Weingarth K, 2011, GRENZUBERSCHREITENDE
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
PU  - SPRINGER
PI  - NEW YORK
PA  - ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
DA  - JUL 14
PY  - 2020
VL  - 66
IS  - 4
DO  - 10.1007/s10344-020-01404-y
AN  - WOS:000547883800001
N1  - Times Cited in Web of Science Core Collection:  5
Total Times Cited:  5
Cited Reference Count:  29
ER  -

TY  - CPAPER
AU  - Evans, BC
AU  - Tucker, A
AU  - Wearn, OR
AU  - Carbone, C
ED  - Koprinska, I
ED  - Kamp, M
ED  - Appice, A
ED  - Loglisci, C
ED  - Antonie, L
ED  - Zimmermann, A
ED  - Guidotti, R
ED  - Ozgobek, O
TI  - Reasoning About Neural Network Activations: An Application in Spatial Animal Behaviour from Camera Trap Classifications
T2  - ECML PKDD 2020 WORKSHOPS
LA  - English
CP  - European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)
KW  - Animal behavior
KW  - Convolutional Neural Networks
KW  - Bayesian networks
KW  - Activation based reasoning
AB  - Camera traps are a vital tool for ecologists to enable them to monitor wildlife over large areas in order to determine population changes, habitat, and behaviour. As a result, camera-trap datasets are rapidly growing in size. Recent advancements in Artificial Neural Networks (ANN) have emerged in image recognition and detection tasks which are now being applied to automate camera-trap labelling. An ANN designed for species detection will output a set of activations, representing the observation of a particular species (an individual class) at a particular location and time and are often used as a way to calculate population sizes in different regions. Here we go one step further and explore how we can combine ANNs with probabilistic graphical models to reason about animal behaviour using the ANN outputs over different geographical locations. By using the output activations from ANNs as data along with the trap's associated spatial coordinates, we build spatial Bayesian networks to explore species behaviours (how they move and distribute themselves) and interactions (how they distribute in relation to other species). This combination of probabilistic reasoning and deep learning offers many advantages for large camera trap projects as well as potential for other remote sensing datasets that require automated labelling.
AD  - Brunel Univ London, Uxbridge UB8 3PH, Middx, EnglandAD  - Zool Soc London, Inst Zool, London NW1 4RY, EnglandC3  - Brunel UniversityC3  - Zoological Society of LondonFU  - NERC (The Natural Environment Research Council)
FX  - Benjamin C. Evans work is funded by NERC (The Natural Environment Research Council).
CR  - Beery S, 2019, ARXIV190706772
CR  - Devlin J, 2019, ARXIV181004805 CS, V1
CR  - Franco C, 2016, ENVIRON MODELL SOFTW, V80, P132, DOI 10.1016/j.envsoft.2016.02.029
CR  - Glover-Kapfer P, 2019, REMOTE SENS ECOL CON, V5, P209, DOI 10.1002/rse2.106
CR  - Maldonado AD, 2019, ENVIRON MODELL SOFTW, V118, P281, DOI 10.1016/j.envsoft.2019.04.011
CR  - Oord Avd, 2016, ARXIV160903499
CR  - Rowcliffe JM, 2008, ANIM CONSERV, V11, P185, DOI 10.1111/j.1469-1795.2008.00180.x
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - SPIRTES P, 1993, CAUSATION PREDICTION
CR  - Trifonova N, 2015, ECOL INFORM, V30, P142, DOI 10.1016/j.ecoinf.2015.10.003
CR  - Uusitalo L, 2007, ECOL MODEL, V203, P312, DOI 10.1016/j.ecolmodel.2006.11.033
CR  - Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
PU  - SPRINGER INTERNATIONAL PUBLISHING AG
PI  - CHAM
PA  - GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
PY  - 2020
VL  - 1323
SP  - 26
EP  - 37
DO  - 10.1007/978-3-030-65965-3_2
AN  - WOS:000724139600002
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  12
ER  -

TY  - CPAPER
AU  - Nepovinnykh, E
AU  - Eerola, T
AU  - Kalviainen, H
AU  - Radchenko, G
ED  - BlancTalon, J
ED  - Helbert, D
ED  - Philips, W
ED  - Popescu, D
ED  - Scheunders, P
TI  - Identification of Saimaa Ringed Seal Individuals Using Transfer Learning
T2  - ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS, ACIVS 2018
LA  - English
CP  - 19th International Conference on Advanced Concepts for Intelligent Vision Systems (ACIVS)
KW  - Animal biometrics
KW  - Saimaa ringed seals
KW  - Convolutional neural networks
KW  - Transfer learning
KW  - Identification
KW  - Image segmentation
AB  - The conservation efforts of the endangered Saimaa ringed seal depend on the ability to reliably estimate the population size and to track individuals. Wildlife photoidentification has been successfully utilized in monitoring for various species. Traditionally, the collected images have been analyzed by biologists. However, due to the rapid increase in the amount of image data, there is a demand for automated methods. Ringed seals have pelage patterns that are unique to each seal enabling the individual identification. In this work, two methods of Saimaa ringed seal identification based on transfer learning are proposed. The first method involves retraining of an existing convolutional neural network (CNN). The second method uses the CNN trained for image classification to extract features which are then used to train a Support Vector Machine (SVM) classifier. Both approaches show over 90% identification accuracy on challenging image data, the SVM based method being slightly better.
AD  - Lappeenranta Univ Technol, Sch Engn Sci, Dept Computat & Proc Engn, Machine Vis & Pattern Recognit Lab, Lappeenranta, FinlandAD  - South Ural State Univ, Sch Elect Engn & Comp Sci, Chelyabinsk, RussiaC3  - Lappeenranta University of TechnologyC3  - South Ural State UniversityCR  - Albu A. B., 2008, P ICPR WORKSH AN INS
CR  - Allwein EL, 2001, J MACH LEARN RES, V1, P113, DOI 10.1162/15324430152733133
CR  - Anderson C. L., 2007, THESIS
CR  - Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
CR  - Auttila M, 2014, ANN ZOOL FENN, V51, P526, DOI 10.5735/086.051.0601
CR  - Bendik NF, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059424
CR  - Chehrsimin T, 2018, IET COMPUT VIS, V12, P146, DOI 10.1049/iet-cvi.2017.0082
CR  - Crall JP, 2013, IEEE WORK APP COMP, P230, DOI 10.1109/WACV.2013.6475023
CR  - Guschanski K, 2009, BIOL CONSERV, V142, P290, DOI 10.1016/j.biocon.2008.10.024
CR  - Halloran KM, 2015, AFR J ECOL, V53, P147, DOI 10.1111/aje.12145
CR  - Hoque S., 2011, INT J BIOSCIENCE BIO, V3, P45
CR  - Koivuniemi M, 2016, ENDANGER SPECIES RES, V30, P29, DOI 10.3354/esr00723
CR  - Kovacs KM, 2012, MAR MAMMAL SCI, V28, P414, DOI 10.1111/j.1748-7692.2011.00479.x
CR  - Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
CR  - Kuhl HS, 2013, TRENDS ECOL EVOL, V28, P432, DOI 10.1016/j.tree.2013.02.013
CR  - Nepovinnykh E, 2017, THESIS
CR  - Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
CR  - Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
CR  - Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
CR  - Zhelezniakov A, 2015, LECT NOTES COMPUT SC, V9475, P227, DOI 10.1007/978-3-319-27863-6_21
PU  - SPRINGER INTERNATIONAL PUBLISHING AG
PI  - CHAM
PA  - GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
PY  - 2018
VL  - 11182
SP  - 211
EP  - 222
DO  - 10.1007/978-3-030-01449-0_18
AN  - WOS:000476892400018
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  20
ER  -

TY  - JOUR
AU  - Ruff, ZJ
AU  - Lesmeister, DB
AU  - Ducha, LS
AU  - Padmaraju, BK
AU  - Sullivan, CM
TI  - Automated identification of avian vocalizations with deep convolutional neural networks
T2  - REMOTE SENSING IN ECOLOGY AND CONSERVATION
LA  - English
KW  - Acoustic monitoring
KW  - avian vocalization
KW  - Bioacoustics
KW  - machine learning
KW  - neural networks
KW  - spotted owls
KW  - BARRED OWLS
KW  - CONSERVATION
KW  - FOREST
AB  - Passive acoustic monitoring is an emerging approach to wildlife monitoring that leverages recent improvements in automated recording units and other technologies. A central challenge of this approach is the task of locating and identifying target species vocalizations in large volumes of audio data. To address this issue, we developed an efficient data processing pipeline using a deep convolutional neural network (CNN) to automate the detection of owl vocalizations in spectrograms generated from unprocessed field recordings. While the project was initially focused on spotted and barred owls, we also trained the network to recognize northern saw-whet owl, great horned owl, northern pygmy-owl, and western screech-owl. Although classification performance varies across species, initial results are promising. Recall, or the proportion of calls in the dataset that are detected and correctly identified, ranged from 63.1% for barred owl to 91.5% for spotted owl based on raw network output. Precision, the rate of true positives among apparent detections, ranged from 0.4% for spotted owl to 77.1% for northern saw-whet owl based on raw output. In limited tests, the CNN performed as well as or better than human technicians at detecting owl calls. Our model output is suitable for developing species encounter histories for occupancy models and other analyses. We believe our approach is sufficiently general to support long-term, large-scale monitoring of a broad range of species beyond our target species list, including birds, mammals, and others.
AD  - US Forest Serv, Pacific Northwest Res Stn, USDA, Corvallis, OR 97331 USAAD  - Oregon State Univ, Dept Fisheries & Wildlife, Corvallis, OR 97331 USAAD  - Oregon Cooperat Fish & Wildlife Res Unit, Corvallis, OR USAAD  - Oregon State Univ, Ctr Genome Res & Biocomp, Corvallis, OR 97331 USAC3  - United States Department of Agriculture (USDA)C3  - United States Forest ServiceC3  - Oregon State UniversityC3  - Oregon State UniversityFU  - USDA Forest Service; USDI Bureau of Land Management
FX  - The authors thank C. Cardillo, M. Corr, D. Culp, T. Garrido, E. Guzman, A. Ingrassia, D. Jacobsma, E. Johnston, R. Justice, K. McLaughlin, P. Papajcik, and W. Swank for field assistance in collecting data and C. Cardillo, D. Culp, Z. Farrand, R. Justice, A. Munes, and S. Pruett for validating CNN output and locating additional training data. Three anonymous reviewers provided valuable insights and feedback which have greatly improved the manuscript. Funding and logistical support were provided by USDA Forest Service and USDI Bureau of Land Management. The Center for Genome Research and Biocomputing, Oregon State University provided C. Sullivan salary and biocomputing infrastructure support. This work was partially supported through a Research Participation Program administered by Oak Ridge Institute for Science and Education (ORISE) and hosted by US Forest Service, Pacific Northwest Research Station. The findings and conclusions in this publication are those of the authors and should not be construed to represent any official USDA or U.S. Government determination or policy. The use of trade or firm names in this publication is for reader information and does not imply endorsement by the U.S. Department of Agriculture of any product or service.
CR  - Abadi Martin, 2015, TENSORFLOW LARGE SCA
CR  - Alonso JB, 2017, EXPERT SYST APPL, V72, P83, DOI 10.1016/j.eswa.2016.12.019
CR  - Artuso C., 2013, BIRDS N AM
CR  - Brown JC, 2007, J ACOUST SOC AM, V122, P1201, DOI 10.1121/1.2747198
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Cannings R. J., 2017, BIRDS N AM, DOI 10.2173/bna.wesowl1.03
CR  - Chambert T, 2018, METHODS ECOL EVOL, V9, P560, DOI 10.1111/2041-210X.12910
CR  - Dugger KM, 2016, CONDOR, V118, P57, DOI 10.1650/CONDOR-15-24.1
CR  - Figueira L, 2015, BIOL CONSERV, V184, P27, DOI 10.1016/j.biocon.2014.12.020
CR  - FORSMAN ED, 1984, J WILDLIFE MANAGE, P5
CR  - Ganchev T, 2007, BIOACOUSTICS, V16, P281, DOI 10.1080/09524622.2007.9753582
CR  - Gutierrez RJ, 2007, BIOL INVASIONS, V9, P181, DOI 10.1007/s10530-006-9025-5
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Holt D. W., 2000, BIRDS N AM, DOI [10.2173/bna.494, DOI 10.2173/BNA.494]
CR  - Kahl S., 2017, LARGE SCALE BIRD SOU
CR  - Kingma D., 2015, ADAM METHOD STOCHAST
CR  - Knight EC, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-01114-120214
CR  - Krizhevsky A., 2012, ADV NEURAL INFORM PR
CR  - LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
CR  - Lesmeister Damon B., 2018, U S Forest Service Pacific Northwest Research Station General Technical Report PNW-GTR, V1, P245
CR  - Luo W., 2019, J ACOUST SOC AM, V145, P7
CR  - MacKenzie D.I., 2018, OCCUPANCY ESTIMATION, V2nd
CR  - Mazur K. M, 2000, BIRDS N AM, DOI [10.2173/bna.508, DOI 10.2173/BNA.508]
CR  - Nvidia, 2019, NVIDIA DRIVE AUT VEH
CR  - Odom KJ, 2010, CONDOR, V112, P549, DOI 10.1525/cond.2010.090163
CR  - Priyadarshani N, 2018, J AVIAN BIOL, V49, DOI 10.1111/jav.01447
CR  - Rasmussen J.L., 2008, BIRDS N AM, DOI [10.2173/bna.42., DOI 10.2173/BNA.42]
CR  - Russo D, 2003, ECOGRAPHY, V26, P197, DOI 10.1034/j.1600-0587.2003.03422.x
CR  - Shonfield J, 2018, J RAPTOR RES, V52, P42, DOI 10.3356/JRR-17-52.1
CR  - Somervuo P, 2019, BIOACOUSTICS, V28, P257, DOI 10.1080/09524622.2018.1431958
CR  - Taigman Y., 2014, DEEPFACE CLOSING GAP
CR  - Trifa VM, 2008, J ACOUST SOC AM, V123, P2424, DOI 10.1121/1.2839017
CR  - U. S. Department of Agriculture [USDA] Forest Service and U. S. Department of Interior [USDI] Bureau of Land Management, 1994, FIN SUPPL ENV IMP ST
CR  - U. S. Fish and Wildlife Service, 1990, FED REGISTER, V55, P26114
CR  - Wiens JD, 2014, WILDLIFE MONOGR, V185, P1, DOI 10.1002/wmon.1009
CR  - Wood CM, 2019, ECOL INDIC, V98, P492, DOI 10.1016/j.ecolind.2018.11.018
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN, NJ 07030 USA
DA  - MAR
PY  - 2020
VL  - 6
IS  - 1
SP  - 79
EP  - 92
DO  - 10.1002/rse2.125
AN  - WOS:000519756100006
N1  - Times Cited in Web of Science Core Collection:  16
Total Times Cited:  17
Cited Reference Count:  37
ER  -

TY  - JOUR
AU  - Enwright, NM
AU  - Wang, L
AU  - Borchert, SM
AU  - Day, RH
AU  - Feher, LC
AU  - Osland, MJ
TI  - Advancing barrier island habitat mapping using landscape position information
T2  - PROGRESS IN PHYSICAL GEOGRAPHY-EARTH AND ENVIRONMENT
LA  - English
KW  - Barrier island
KW  - dune
KW  - wetland
KW  - habitat mapping
KW  - remote sensing
KW  - GEOBIA
KW  - uncertainty
KW  - lidar
KW  - intertidal
KW  - supratidal
KW  - SEA-LEVEL RISE
KW  - LAND-COVER
KW  - AIRBORNE LIDAR
KW  - ACCURACY ASSESSMENT
KW  - IMAGE-ANALYSIS
KW  - COASTAL DUNES
KW  - CLASSIFICATION
KW  - VEGETATION
KW  - DYNAMICS
KW  - MISSISSIPPI
AB  - Barrier islands are dynamic ecosystems that change gradually from coastal processes, including currents and tides, and rapidly from episodic events, such as storms. These islands provide many important ecosystem services, including storm protection and erosion control to the mainland, habitat for fish and wildlife, and tourism. Habitat maps, developed by scientists, provide a critical tool for monitoring changes to these dynamic ecosystems. Barrier island monitoring often requires custom habitat maps due to several factors, including island size and the classification of unique geomorphology-based habitats, such as beach, dune, and barrier flats. In this study, we reviewed barrier-island-specific habitat mapping efforts and highlighted common habitat class types, source data, and mapping approaches. We also developed a framework for mapping geomorphology-based barrier island habitats using a rule-based, geographic object-based image analysis approach, which included the use of field data, tide data, high-resolution orthophotography, and lidar data. This framework integrates several barrier island mapping advancements with regard to the use of landscape position information for automated dune extraction and the use of Monte Carlo analyses for the treatment of elevation uncertainty for elevation-dependent habitats. Specifically, we used the uncertainty analyses to refine automated dune delineation based on elevation relative to extreme storm water levels and to increase the accuracy of intertidal and supratidal/upland habitat delineation. We found that dune extraction results were enhanced when elevation relative to storm water levels and visual interpretation were also applied. This framework could also be applied to beach-dune systems found along a mainland.
AD  - US Geol Survey, Lafayette, LA USAAD  - Louisiana State Univ, Baton Rouge, LA 70803 USAAD  - Borchert Consulting, Lafayette, LA USAC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - Louisiana State University SystemC3  - Louisiana State UniversityFU  - National Fish and Wildlife Foundation Gulf Environmental Benefit Fund [45719]
FX  - The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This effort supported a component of a larger collaborative effort between the US Army Corps of Engineers, the State of Alabama, and the USGS, funded by the National Fish and Wildlife Foundation Gulf Environmental Benefit Fund (project ID: 45719) to investigate viable, sustainable restoration options that protect and restore the natural resources of Dauphin Island, Alabama.
CR  - Acosta A, 2005, APPL VEG SCI, V8, P133, DOI 10.1111/j.1654-109X.2005.tb00638.x
CR  - Acosta A, 2003, INF BOT ITAL, V35, P21
CR  - Alizad K, 2016, EARTHS FUTURE, V4, P483, DOI 10.1002/2016EF000385
CR  - Anderson CP, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070602
CR  - ASPRS, 2015, PHOTOGRAMM ENG REMOT, V81, pA1, DOI [10.14358/PERS.81.3.A1-A26, DOI 10.14358/PERS.81.3.A1-A26]
CR  - Bachmann CM, 2002, IEEE T GEOSCI REMOTE, V40, P2313, DOI 10.1109/TGRS.2002.804834
CR  - Ball GH., 1965, 699616 NTIS AD STAND
CR  - Barbier EB, 2011, ECOL MONOGR, V81, P169, DOI 10.1890/10-1510.1
CR  - Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
CR  - Brock JC, 2009, J COASTAL RES, V25, P1, DOI [10.2112/SI53-001.1, 10.2112/S153-001.1]
CR  - Brownett JM, 2017, J COAST CONSERV, V21, P643, DOI 10.1007/s11852-017-0504-x
CR  - Buffington KJ, 2016, REMOTE SENS ENVIRON, V186, P616, DOI 10.1016/j.rse.2016.09.020
CR  - Campbell A, 2018, IEEE T GEOSCI REMOTE, P1
CR  - Campbell A, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020131
CR  - Chust G, 2008, ESTUAR COAST SHELF S, V78, P633, DOI 10.1016/j.ecss.2008.02.003
CR  - COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
CR  - Congalton RG, 2009, ASSESSING ACCURACY R
CR  - Cooper HM, 2013, CLIMATIC CHANGE, V121, P635, DOI 10.1007/s10584-013-0987-x
CR  - Cowardin LM, 1979, CLASSIFICATION WETLA, P134
CR  - De Reu J, 2013, GEOMORPHOLOGY, V186, P39, DOI 10.1016/j.geomorph.2012.12.015
CR  - Dobson JE, 1995, NOAA COASTAL CHANGE, P92
CR  - Dronova I, 2015, REMOTE SENS-BASEL, V7, P6380, DOI 10.3390/rs70506380
CR  - Enwright NM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010005
CR  - Enwright NM, 2018, LOUISIANA BARRIER IS
CR  - Enwright NM, 2017, 20171083 US GEOL SUR, P17
CR  - Feagin RA, 2010, J COASTAL RES, V26, P987, DOI 10.2112/09-1185.1
CR  - Fearnley S, 2009, LOUISIANA BARRIER 1, V5, P11
CR  - Feranec J, 2014, PROG PHYS GEOG, V38, P301, DOI 10.1177/0309133314532001
CR  - Gao J, 2004, PHOTOGRAMM ENG REM S, V70, P1241, DOI 10.14358/PERS.70.11.1241
CR  - GIBSON DJ, 1992, J COASTAL RES, V8, P943
CR  - Gieder KD, 2014, ECOL MODEL, V276, P38, DOI 10.1016/j.ecolmodel.2014.01.005
CR  - Guy KK, 2015, 20151179 US GEOL SUR, P3
CR  - Halls JN, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071109
CR  - Hansen J, 2016, ATMOS CHEM PHYS, V16, P3761, DOI 10.5194/acp-16-3761-2016
CR  - Hantson W, 2012, APPL VEG SCI, V15, P536, DOI 10.1111/j.1654-109X.2012.01194.x
CR  - Heumann BW, 2011, REMOTE SENS-BASEL, V3, P2440, DOI 10.3390/rs3112440
CR  - Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
CR  - Hudak AT, 2009, REMOTE SENS-BASEL, V1, P934, DOI 10.3390/rs1040934
CR  - Hugenholtz CH, 2012, EARTH-SCI REV, V111, P319, DOI 10.1016/j.earscirev.2011.11.006
CR  - HUNTER GJ, 1995, PHOTOGRAMM ENG REM S, V61, P529
CR  - Jaakkola A, 2010, ISPRS J PHOTOGRAMM, V65, P514, DOI 10.1016/j.isprsjprs.2010.08.002
CR  - Jeter GW, 2015, GEOCARTO INT, V31, P1
CR  - Katselidis KA, 2014, J EXP MAR BIOL ECOL, V450, P47, DOI 10.1016/j.jembe.2013.10.017
CR  - Kidwell DM, 2017, EARTHS FUTURE, V5, P2, DOI 10.1002/2016EF000493
CR  - Kindinger JL, 2013, 20131083 US GEOL SUR, P86
CR  - Knutson TR, 2010, NAT GEOSCI, V3, P157, DOI 10.1038/NGEO779
CR  - Lea C, 2010, THEMATIC ACCURACY AS, P116
CR  - Leatherman SP, 1979, BARRIER ISLAND HDB
CR  - Lin Y, 2011, IEEE GEOSCI REMOTE S, V8, P426, DOI 10.1109/LGRS.2010.2079913
CR  - Liu HX, 2007, J COASTAL RES, V23, P1359, DOI 10.2112/05-0580.1
CR  - Lucas KL, 2013, GEOMORPHOLOGY, V199, P129, DOI 10.1016/j.geomorph.2012.11.010
CR  - Lucas KL, 2010, J COASTAL RES, V26, P1142, DOI 10.2112/JCOASTRES-D-09-00018.1
CR  - Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
CR  - McBride R.A., 2013, TREATISE GEOMORPHOLO, P166, DOI [10.1016/B978-0-12-374739-6.00279-7, DOI 10.1016/B978-0-12-374739-6.00279-7]
CR  - McCarthy MJ, 2014, ISPRS INT J GEO-INF, V3, P297, DOI 10.3390/ijgi3010297
CR  - Medeiros S, 2015, REMOTE SENS-BASEL, V7, P3507, DOI 10.3390/rs70403507
CR  - Meng XL, 2010, REMOTE SENS-BASEL, V2, P833, DOI 10.3390/rs2030833
CR  - Meng XL, 2009, PHOTOGRAMM ENG REM S, V75, P437, DOI 10.14358/PERS.75.4.437
CR  - Monge JA, 2016, PHYS GEOGR, V37, P452, DOI 10.1080/02723646.2016.1230041
CR  - Morton RA, 2008, J COASTAL RES, V24, P1587, DOI 10.2112/07-0953.1
CR  - Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
CR  - NOAA, 2013, EXTR WAT LEV 8735180
CR  - O'Neil-Dunne J, 2014, REMOTE SENS-BASEL, V6, P12837, DOI 10.3390/rs61212837
CR  - OERTEL GF, 1985, MAR GEOL, V63, P1, DOI 10.1016/0025-3227(85)90077-5
CR  - Otvos EG, 2008, J COASTAL RES, V24, P463, DOI 10.2112/06-0820.1
CR  - Pilkey O.H., 2014, THE LAST BEACH
CR  - Plant NG, 2016, EARTHS FUTURE, V4, P143, DOI 10.1002/2015EF000331
CR  - Sallenger AH, 2000, J COASTAL RES, V16, P890
CR  - Schmidt KA, 2011, J COASTAL RES, V27, P116, DOI 10.2112/JCOASTRES-D-10-00188.1
CR  - Stockdon HF, 2012, 20121084 US GEOL SUR, P51
CR  - Stoker JM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090767
CR  - STRAHLER AH, 1980, REMOTE SENS ENVIRON, V10, P135, DOI 10.1016/0034-4257(80)90011-5
CR  - Sturdivant EJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101020
CR  - Stutz ML, 2011, J COASTAL RES, V27, P207, DOI 10.2112/09-1190.1
CR  - Su J, 2006, PHOTOGRAMM ENG REMOT, V72, p[11, 1265], DOI DOI 10.14358/PERS.72.11.1265
CR  - Timm BC, 2012, REMOTE SENS ENVIRON, V127, P106, DOI 10.1016/j.rse.2012.08.033
CR  - Trimble, 2016, TRIMBL ECOGNITION DE
CR  - Wang YQ, 2007, MAR GEOD, V30, P77, DOI 10.1080/01490410701296226
CR  - Wechsler SP, 2006, PHOTOGRAMM ENG REM S, V72, P1081, DOI 10.14358/PERS.72.9.1081
CR  - Weiss A., 2001, ESRI US C SAN DIEG C
CR  - Wernette P, 2018, J COASTAL RES, V34, P1460, DOI 10.2112/JCOASTRES-D-17-00082.1
CR  - Wernette P, 2016, GEOMORPHOLOGY, V262, P1, DOI 10.1016/j.geomorph.2016.02.024
CR  - Woodcock CE, 2000, INT J GEOGR INF SCI, V14, P153, DOI 10.1080/136588100240895
CR  - Young DR, 2011, ECOSPHERE, V2, DOI 10.1890/ES10-00186.1
CR  - Yu Q, 2006, PHOTOGRAMM ENG REM S, V72, P799, DOI 10.14358/PERS.72.7.799
CR  - Zervas C, 2013, 067 NOAA NOS COOPS, P200
CR  - Zhang CY, 2015, ISPRS J PHOTOGRAMM, V104, P213, DOI 10.1016/j.isprsjprs.2014.06.005
CR  - Zhang CY, 2013, GISCI REMOTE SENS, V50, P562, DOI 10.1080/15481603.2013.836807
CR  - Zinnert JC, 2017, BIOSCIENCE, V67, P38, DOI 10.1093/biosci/biw154
CR  - Zinnert JC, 2016, ECOSYSTEMS, V19, P685, DOI 10.1007/s10021-016-9961-6
CR  - Zinnert JC, 2011, GEOCARTO INT, V26, P595, DOI 10.1080/10106049.2011.621031
PU  - SAGE PUBLICATIONS LTD
PI  - LONDON
PA  - 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
DA  - JUN
PY  - 2019
VL  - 43
IS  - 3
SP  - 425
EP  - 450
DO  - 10.1177/0309133319839922
AN  - WOS:000469873500009
N1  - Times Cited in Web of Science Core Collection:  7
Total Times Cited:  7
Cited Reference Count:  91
ER  -

TY  - JOUR
AU  - Kabiri, K
TI  - Mapping coastal ecosystems and features using a low-cost standard drone: case study, Nayband Bay, Persian gulf, Iran
T2  - JOURNAL OF COASTAL CONSERVATION
LA  - English
KW  - Coastal mapping
KW  - Photogrammetry
KW  - Coastal habitats
KW  - Unmanned aerial vehicle (UAV)
KW  - AERIAL-PHOTOGRAPHY
KW  - ISLAND
AB  - A low-cost standard drone (DJI (TM) Phantom 4 Pro) has been employed to map the ecosystems and features in coastal areas in the northern Persian Gulf. The Pix4Dcapture (R) mobile application was selected as a user friendly and simple app to perform an automated and customized drone flight over the selected study area in Nayband Bay, Bushehr province. The flight altitude was selected to be 100 m with 80% overlap for images, which led to the imaging of an area similar to 22 ha (413 x 525 m) in similar to 13 min (from takeoff to landing the drone). Agisoft (TM) Metashape PC software was then used to create the orthophoto mosaic from 213 taken photos. Consequently, the ground sampling distance (GSD) of the created orthophoto mosaic was similar to 3 cm which means it was possible to visually identify the features on the images with a size of 30 cm and more. The orthophoto mosaic was then converted to a topological GIS-based map (in the format of ESRI (TM) shapefile) by a 2-step procedure including a supervised image classification method coupled with manual editing with an on-screen visual editing method. The final results demonstrated that the overall accuracy of the classified mosaic raster map was 87.6% where the kappa(Kappa coefficient) was 0.84. The results also showed that the applied methodology in this study can be used to differentiate the coastal ecosystems and features such as mangrove forests, vegetations, sandy beaches, and deep and shallow water bodies. As a comparison with alternative methods, the cost of implementing drone-based methodology was lower than field surveying and covers a larger area in less time.
AD  - INIOAS, Iranian Natl Inst Oceanog & Atmospher Sci, Dept Marine Remote Sensing, Tehran, IranFU  - Iranian National Institute for Oceanography and Atmospheric Science [INIOAS397-011-06-09-01]
FX  - This research was supported by the Iranian National Institute for Oceanography and Atmospheric Science [grant no. INIOAS397-011-06-09-01]. Dr. A. Maghsoodloo is acknowledged for his kind supports of this study. The author also wishes to thank Mr. H. Bazyar in Bushehr for his contribution to the field observations in Nayband Bay.
CR  - Bendell LI, 2011, J COAST CONSERV, V15, P417, DOI 10.1007/s11852-010-0101-8
CR  - Duffy J, 2019, THESIS U EXETER
CR  - Duffy JP, 2018, ESTUAR COAST SHELF S, V200, P169, DOI 10.1016/j.ecss.2017.11.001
CR  - Feygels V, 2018, PROC SPIE, V10778, DOI 10.1117/12.2324749
CR  - Fourqurean JW, 2012, NAT GEOSCI, V5, P505, DOI 10.1038/ngeo1477
CR  - Green E., 2000, REMOTE SENSING HDB T
CR  - Kabiri K, 2020, EARTH SCI INFORM, V13, P1265, DOI 10.1007/s12145-020-00507-z
CR  - Kabiri K, 2018, MAR POLLUT BULL, V129, P266, DOI 10.1016/j.marpolbul.2018.02.045
CR  - Kabiri K, 2014, J COAST CONSERV, V18, P691, DOI 10.1007/s11852-014-0345-9
CR  - Klemas V, 2011, J COASTAL RES, V27, P2, DOI 10.2112/JCOASTRES-D-10-00103.1
CR  - Nandy S, 2011, J COAST CONSERV, V15, P123, DOI 10.1007/s11852-010-0126-z
CR  - Perez-Alberti A, 2019, ENCY COASTAL SCI
CR  - Rodriguez W, 2016, GLOB ECOL CONSERV, V7, P245, DOI 10.1016/j.gecco.2016.07.005
CR  - Ruwaimana M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200288
CR  - Seifert E, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101252
CR  - TUELL G, 2010, ALGORITHMS TECHNOLOG, V7695
CR  - Ventura D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091331
CR  - Ventura D, 2016, ESTUAR COAST SHELF S, V171, P85, DOI 10.1016/j.ecss.2016.01.030
CR  - Woodget AS, 2017, WIRES WATER, V4, DOI 10.1002/wat2.1222
CR  - Wozencraft J, 2005, MAR TECHNOL SOC J, V39, P27, DOI 10.4031/002533205787442440
CR  - Zimudzi E, 2019, GEOCARTO INT, V34, P1648, DOI 10.1080/10106049.2018.1497093
PU  - SPRINGER
PI  - NEW YORK
PA  - ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
DA  - SEP 27
PY  - 2020
VL  - 24
IS  - 5
DO  - 10.1007/s11852-020-00780-6
AN  - WOS:000572738700001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  21
ER  -

TY  - JOUR
AU  - Shahinfar, S
AU  - Meek, P
AU  - Falzon, G
TI  - "How many images do I need?" Understanding how sample size per class affects deep learning model performance metrics for balanced designs in autonomous wildlife monitoring
T2  - ECOLOGICAL INFORMATICS
LA  - English
KW  - Camera traps
KW  - Deep learning
KW  - Ecological informatics
KW  - Generalised additive models
KW  - Learning curves
KW  - Predictive modelling
KW  - Wildlife
AB  - Deep learning (DL) algorithms are the state of the art in automated classification of wildlife camera trap images. The challenge is that the ecologist cannot know in advance how many images per species they need to collect for model training in order to achieve their desired classification accuracy. In fact there is limited empirical evidence in the context of camera trapping to demonstrate that increasing sample size will lead to improved accuracy.
   In this study we explore in depth the issues of deep learning model performance for progressively increasing per class (species) sample sizes. We also provide ecologists with an approximation formula to estimate how many images per animal species they need for certain accuracy level a priori. This will help ecologists for optimal allocation of resources, work and efficient study design.
   In order to investigate the effect of number of training images; seven training sets with 10, 20, 50, 150, 500, 1000 images per class were designed. Six deep learning architectures namely ResNet-18, ResNet-50, ResNet-152, DnsNet-121, DnsNet-161, and DnsNet-201 were trained and tested on a common exclusive testing set of 250 images per class. The whole experiment was repeated on three similar datasets from Australia, Africa and North America and the results were compared. Simple regression equations for use by practitioners to approximate model performance metrics are provided. Generalizes additive models (GAM) are shown to be effective in modelling DL performance metrics based on the number of training images per class, tuning scheme and dataset.
   Overall, our trained models classified images with 0.94 accuracy (ACC), 0.73 precision (PRC), 0.72 true positive rate (TPR), and 0.03 false positive rate (FPR). Variation in model performance metrics among datasets, species and deep learning architectures exist and are shown distinctively in the discussion section. The ordinary least squares regression models explained 57%, 54%, 52%, and 34% of expected variation of ACC, PRC, TPR, and FPR according to number of images available for training. Generalised additive models explained 77%, 69%, 70%, and 53% of deviance for ACC, PRC, TPR, and FPR respectively.
   Predictive models were developed linking number of training images per class, model, dataset to performance metrics. The ordinary least squares regression and Generalised additive models developed provides a practical toolbox to estimate model performance with respect to different numbers of training images.
AD  - Univ New England, Sch Sci & Technol, Armidale, NSW, AustraliaAD  - Agr Victoria, AgriBio Ctr, Dept Jobs Precincts & Reg, Bundoora, Vic, AustraliaAD  - NSW Dept Primary Ind, POB 530, Coffs Harbour, NSW, AustraliaAD  - Univ New England, Sch Environm & Rural Sci, Armidale, NSW, AustraliaC3  - University of New EnglandC3  - NSW Department of Primary IndustriesC3  - University of New EnglandFU  - Australian Government Department of Agriculture and Water Resources
FX  - Funding for this project was provided by the Australian Government Department of Agriculture and Water Resources through the e-Technology Hub - Utilising Technology to Improve Pest Management Effectiveness and Enhance Welfare Outcomes project.
CR  - Barz B., 2020, IEEE WINT C APPL COM
CR  - Beery S., 2018, EUR C COMP VIS
CR  - Beery S., 2020, IEEE WINT C APPL COM
CR  - Cho J., 2016, MUCH DATA IS NEEDED
CR  - Clare JDJ, 2019, ECOL APPL, V29, DOI 10.1002/eap.1849
CR  - Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
CR  - Falzon G, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10010058
CR  - Falzon G, 2014, CAMERA TRAPPING: WILDLIFE MANAGEMENT AND RESEARCH, P299
CR  - Villa AG, 2017, ECOL INFORM, V41, P24, DOI 10.1016/j.ecoinf.2017.07.004
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Hastie T., 1986, STAT SCI, V1, DOI 10.1214/ss/1177013604
CR  - Hastie T.J., 1990, GEN ADDITIVE MODELS, DOI DOI 10.1214/SS/1177013604
CR  - He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
CR  - Hinton G., 2014, DISTILLING KNOWLEDGE
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - Kellenberger B, 2018, REMOTE SENS ENVIRON, V216, P139, DOI 10.1016/j.rse.2018.06.028
CR  - Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI [10.1145/3065386, DOI 10.1145/3065386]
CR  - Meek Paul D., 2020, Australian Zoologist, V40, P392, DOI 10.7882/AZ.2019.035
CR  - Meek PD, 2015, AUST MAMMAL, V37, P1, DOI 10.1071/AM14021
CR  - Moskvyak O., 2019, ARXIV PREPRINT ARXIV
CR  - Nazir S., 2017, PLOS ONE, V12, DOI [10.1371/journal.pone.4., DOI 10.1371/JOURNAL.PONE.4]
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
CR  - Paszke Adam, 2017, NIPS W
CR  - Patterson J., 2017, DEEP LEARNING
CR  - Rovero F, 2013, HYSTRIX, V24, P148, DOI 10.4404/hystrix-24.2-6316
CR  - Scotson L, 2017, REMOTE SENS ECOL CON, V3, P158, DOI 10.1002/rse2.54
CR  - Smith L.N., 2018, ABS180309820 ARXIV
CR  - Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
CR  - Swann DE, 2014, CAMERA TRAPPING: WILDLIFE MANAGEMENT AND RESEARCH, P3
CR  - Swanson A, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.26
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tack JLP, 2016, ECOL INFORM, V36, P145, DOI 10.1016/j.ecoinf.2016.11.003
CR  - Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
CR  - Wisconsin Department of Natural Resources W, 2019, SNAPSH WISC VOL BAS
CR  - Wood S. N, 2017, GEN ADDITIVE MODELS
CR  - Wood SN, 2016, J AM STAT ASSOC, V111, P1548, DOI 10.1080/01621459.2016.1180986
CR  - Wood SN, 2011, J R STAT SOC B, V73, P3, DOI 10.1111/j.1467-9868.2010.00749.x
CR  - Xu W, 2018, DESTECH TRANS COMP, P186
CR  - Yosinski J, 2014, ADV NEUR IN, V27
CR  - Zoph Barret, 2019, ARXIV PREPRINT ARXIV
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - MAY
PY  - 2020
VL  - 57
DO  - 10.1016/j.ecoinf.2020.101085
AN  - WOS:000528216500014
N1  - Times Cited in Web of Science Core Collection:  18
Total Times Cited:  18
Cited Reference Count:  42
ER  -

TY  - JOUR
AU  - Chiloane, C
AU  - Dube, T
AU  - Shoko, C
TI  - Monitoring and assessment of the seasonal and inter-annual pan inundation dynamics in the Kgalagadi Transfrontier Park, Southern Africa
T2  - PHYSICS AND CHEMISTRY OF THE EARTH
LA  - English
KW  - Endorheic pans
KW  - Livelihoods
KW  - MNDWI
KW  - Remote sensing
KW  - Surface water availability
KW  - Water resources management
KW  - Wildlife/livestock conservation
KW  - HWANGE NATIONAL-PARK
KW  - WATER INDEX NDWI
KW  - CLASSIFICATION
KW  - AVAILABILITY
KW  - HERBIVORES
KW  - VEGETATION
KW  - RAINFALL
KW  - FEATURES
KW  - DELTA
KW  - CAPE
AB  - In arid regions, pans form a critical water source that supports local communities, livestock, and wildlife, with readily available water resources. However, these waterbodies are unevenly distributed across the landscape and highly ephemeral and this influences their ability to provide water, especially in remote and water scarce areas. In addition, it remains difficult, impractical, and costly to monitor their variability using traditional hydrometric networks. In this regard, their contribution as water sources remains uncertain. The availability of spatially explicit data, with improved sensor design characteristics such as Landsat-8 enables the monitoring of their surface water extent over space and time. This study therefore, for the first time investigated the potential of using Landsat-8 in detecting and monitoring the spatial and temporal dynamics of pan inundation in the water scarce region of Kgalagadi in Southern Africa between 2016 and 2018. This was achieved by testing the performance of multiple indices, namely; the Normalised Difference Water Index (NDWI), Modified Normalised Difference Water Index (MNDWI), Automated Water Extraction Index for Shadow (AWEIsh), Water Ratio Index (WRI) and Land Surface Water Index (LSWI). Overall, the results have shown the potential of remote sensing data to monitor pan inundation. The MNDWI produced the highest overall classification accuracy of 84.91% comparatively. The MNDWI was then used for monitoring and assessing pan inundation dynamics over different seasons between 2016 and 2018. During the study period, pan inundation varied significantly (alpha = 0.05) for different seasons. Nevertheless, 2017 had the largest surface water extent covering 23 195.8 m(2), during the wet season and 17 913.3 m(2) in the dry season. On the other hand, 2018 showed the smallest spatial coverage of 13 076 m(2) for the wet season and 6032.587 m(2) during the dry season. The observed spatial variability in pan inundation was attributed to rainfall and temperature variability. The study thus revealed the utility of remotely sensed data sets in providing a more robust approach for monitoring seasonal and inter-annual pan inundation variations in semi-arid environments of Southern Africa. This information is important for water management decision making, specifically for water-limited areas, to conserve these water sources to ensure their sustainability in supporting local communities, livestock and wildlife population.
AD  - Univ Western Cape, Dept Earth Sci, Private Bag X17, ZA-7535 Bellville, South AfricaAD  - Univ Witwatersrand, Sch Geog Archaeol & Environm Studies, Div Geog, Private Bag 3, ZA-2050 Johannesburg, South AfricaC3  - University of the Western CapeC3  - University of WitwatersrandCR  - Ashraf S, 2019, CLIMATIC CHANGE, V152, P379, DOI 10.1007/s10584-018-2336-6
CR  - Balazs B, 2018, HYDROLOG SCI J, V63, P269, DOI 10.1080/02626667.2018.1425802
CR  - Bezuidenhout Hugo, 2009, Koedoe, V51, P0, DOI 10.4102/koedoe.v51i1.695
CR  - Bhaga T., J PHYS CHEM EARTH
CR  - Buma WG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072082
CR  - Chamaille-Jammes S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153639
CR  - Chen J, 2009, J HYDROL, V373, P184, DOI 10.1016/j.jhydrol.2009.04.021
CR  - de Klerk AR, 2012, WATER SA, V38, P663, DOI 10.4314/wsa.v38i5.3
CR  - deKlerk A.R., 2016, REV DEPRESSIONAL WET, DOI [10.13140/RG.2.2.28486.06723., DOI 10.13140/RG.2.2.28486.06723]
CR  - Du Y, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040354
CR  - Dube T, 2015, ISPRS J PHOTOGRAMM, V101, P36, DOI 10.1016/j.isprsjprs.2014.11.001
CR  - El-Asmar HM, 2013, EGYPT J REMOTE SENS, V16, P119, DOI 10.1016/j.ejrs.2013.04.004
CR  - Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
CR  - Gautam VK, 2015, AQUAT PR, V4, P739, DOI 10.1016/j.aqpro.2015.02.095
CR  - GOUDIE AS, 1991, PROG PHYS GEOG, V15, P221, DOI 10.1177/030913339101500301
CR  - Hutson JM, 2016, PALAEOGEOGR PALAEOCL, V441, P936, DOI 10.1016/j.palaeo.2015.10.050
CR  - Ji LY, 2015, WATER-SUI, V7, P794, DOI 10.3390/w7020794
CR  - Kaplan G, 2017, ISPRS ANN PHOTO REM, V4-4, P271, DOI 10.5194/isprs-annals-IV-4-W4-271-2017
CR  - Kraaij T, 2006, J ARID ENVIRON, V64, P174, DOI 10.1016/j.jaridenv.2005.04.009
CR  - LANCASTER IN, 1978, GEOGR J, V144, P81, DOI 10.2307/634651
CR  - Luis KMA, 2019, MAR POLLUT BULL, V145, P96, DOI 10.1016/j.marpolbul.2019.04.078
CR  - Malek K, 2018, J HYDROL, V561, P444, DOI 10.1016/j.jhydrol.2017.11.046
CR  - Masocha M, 2018, PHYS CHEM EARTH, V106, P63, DOI 10.1016/j.pce.2018.05.005
CR  - McCulloch G, 2000, WATERBIRDS, V23, p[64, 68], DOI DOI 10.2307/1522148
CR  - McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
CR  - Mialhe F, 2008, WATER RESOUR RES, V44, DOI 10.1029/2007WR006065
CR  - Milton SJ, 1995, ENVIRON MONIT ASSESS, V37, P245, DOI 10.1007/BF00546893
CR  - Nhiwatiwa T, 2017, PHYS CHEM EARTH, V97, P37, DOI 10.1016/j.pce.2016.11.003
CR  - Parris R., 1979, S AFRICAN J WILDLIFE, V3, P1
CR  - Sakamoto T, 2007, REMOTE SENS ENVIRON, V109, P295, DOI 10.1016/j.rse.2007.01.011
CR  - Seaton D, 2020, ISPRS J PHOTOGRAMM, V167, P375, DOI 10.1016/j.isprsjprs.2020.07.018
CR  - Shen L., 2010, P 18 INT C GEOINF BE, P1, DOI [10.1109/GEOINFORMATICS.2010.5567762, DOI 10.1109/GEOINFORMATICS.2010.5567762]
CR  - South African National Parks, 2008, KAL GEMSB NAT PARK P
CR  - Thondhlana G, 2011, ENVIRON RES LETT, V6, DOI 10.1088/1748-9326/6/2/024009
CR  - Toming K, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080640
CR  - Valeix M, 2011, J TROP ECOL, V27, P163, DOI 10.1017/S0266467410000647
CR  - Weiqi He, 2008, Frontiers of Environmental Science and Engineering in China, V2, P163, DOI 10.1007/s11783-008-0027-7
CR  - Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
CR  - Zengeya FM, 2013, INT J APPL EARTH OBS, V21, P513, DOI 10.1016/j.jag.2012.07.008
PU  - PERGAMON-ELSEVIER SCIENCE LTD
PI  - OXFORD
PA  - THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
DA  - OCT
PY  - 2020
VL  - 118
DO  - 10.1016/j.pce.2020.102905
AN  - WOS:000575782800009
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  39
ER  -

TY  - JOUR
AU  - Gibb, R
AU  - Browning, E
AU  - Glover-Kapfer, P
AU  - Jones, KE
TI  - Emerging opportunities and challenges for passive acoustics in ecological assessment and monitoring
T2  - METHODS IN ECOLOGY AND EVOLUTION
LA  - English
KW  - acoustic indices
KW  - bioacoustics
KW  - biodiversity monitoring
KW  - deep learning
KW  - ecoacoustics
KW  - ecological monitoring
KW  - machine learning
KW  - passive acoustic monitoring
KW  - IMPERFECT DETECTION
KW  - DENSITY-ESTIMATION
KW  - BIODIVERSITY
KW  - INDEXES
KW  - CONSERVATION
KW  - POPULATION
KW  - IMPACT
KW  - CLASSIFICATION
KW  - IDENTIFICATION
KW  - COMMUNITIES
AB  - High-throughput environmental sensing technologies are increasingly central to global monitoring of the ecological impacts of human activities. In particular, the recent boom in passive acoustic sensors has provided efficient, noninvasive, and taxonomically broad means to study wildlife populations and communities, and monitor their responses to environmental change. However, until recently, technological costs and constraints have largely confined research in passive acoustic monitoring (PAM) to a handful of taxonomic groups (e.g., bats, cetaceans, birds), often in relatively small-scale, proof-of-concept studies. The arrival of low-cost, open-source sensors is now rapidly expanding access to PAM technologies, making it vital to evaluate where these tools can contribute to broader efforts in ecology and biodiversity research. Here, we synthesise and critically assess the current emerging opportunities and challenges for PAM for ecological assessment and monitoring of both species populations and communities. We show that terrestrial and marine PAM applications are advancing rapidly, facilitated by emerging sensor hardware, the application of machine learning innovations to automated wildlife call identification, and work towards developing acoustic biodiversity indicators. However, the broader scope of PAM research remains constrained by limited availability of reference sound libraries and open-source audio processing tools, especially for the tropics, and lack of clarity around the accuracy, transferability and limitations of many analytical methods. In order to improve possibilities for PAM globally, we emphasise the need for collaborative work to develop standardised survey and analysis protocols, publicly archived sound libraries, multiyear audio datasets, and a more robust theoretical and analytical framework for monitoring vocalising animal communities.
AD  - UCL, Dept Genet Evolut & Environm, Ctr Biodivers & Environm Res, London, EnglandAD  - Zool Soc London, Inst Zool, London, EnglandAD  - Living Planet Ctr, WWF UK, Woking, Surrey, EnglandAD  - Flora & Fauna Int, David Attenborough Bldg, Cambridge, EnglandC3  - University of LondonC3  - University College LondonC3  - Zoological Society of LondonC3  - World Wildlife FundFU  - Engineering and Physical Sciences Research Council [EP/K503745/1]; World Wildlife Fund; Natural Environment Research Council [NE/P016677/1]; NERC [NE/P016677/1] Funding Source: UKRI
FX  - Engineering and Physical Sciences Research Council, Grant/Award Number: EP/K503745/1; World Wildlife Fund; Natural Environment Research Council, Grant/Award Number: NE/P016677/1
CR  - Adams AM, 2012, METHODS ECOL EVOL, V3, P992, DOI 10.1111/j.2041-210X.2012.00244.x
CR  - Aide TM, 2013, PEERJ, V1, DOI 10.7717/peerj.103
CR  - Astaras C, 2017, FRONT ECOL ENVIRON, V15, P233, DOI 10.1002/fee.1495
CR  - Banner KM, 2018, ECOL EVOL, V8, P6144, DOI 10.1002/ece3.4162
CR  - Bas Y., 2017, J OPEN RES SOFTWARE, V5, DOI [10.5334/jors.154, DOI 10.5334/JORS.154]
CR  - Baumgartner MF, 2013, J ACOUST SOC AM, V134, P1814, DOI 10.1121/1.4816406
CR  - Baumgartner MF, 2011, J ACOUST SOC AM, V129, P2889, DOI 10.1121/1.3562166
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Border JA, 2017, LANDSCAPE URBAN PLAN, V162, P44, DOI 10.1016/j.landurbplan.2017.02.005
CR  - Bradbury Jack W., 1998, pi
CR  - Braulik G, 2017, MAR POLLUT BULL, V125, P360, DOI 10.1016/j.marpolbul.2017.09.036
CR  - Bush A, 2017, NAT ECOL EVOL, V1, DOI 10.1038/s41559-017-0176
CR  - Buxton RT, 2017, SCIENCE, V356, P531, DOI 10.1126/science.aah4783
CR  - Campos-Cerqueira M, 2016, METHODS ECOL EVOL, V7, P1340, DOI 10.1111/2041-210X.12599
CR  - Cardinale BJ, 2012, NATURE, V486, P59, DOI 10.1038/nature11148
CR  - Clink DJ, 2017, INT J PRIMATOL, V38, P656, DOI 10.1007/s10764-017-9972-y
CR  - Darras K, 2016, BIOL CONSERV, V201, P29, DOI 10.1016/j.biocon.2016.06.021
CR  - Davis GE, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13359-3
CR  - de Torrez ECB, 2017, PEERJ, V5, DOI 10.7717/peerj.3940
CR  - Digby A, 2013, METHODS ECOL EVOL, V4, P675, DOI 10.1111/2041-210X.12060
CR  - Duncan, 2013, PROC, P208
CR  - Eldridge A, 2016, PEERJ, V4, DOI 10.7717/peerj.2108
CR  - Fairbrass AJ, 2018, METHODS ECOL EVOL, DOI [10.1101/248708, DOI 10.1101/248708]
CR  - Fairbrass AJ, 2017, ECOL INDIC, V83, P169, DOI 10.1016/j.ecolind.2017.07.064
CR  - Farcas A, 2016, ENVIRON IMPACT ASSES, V57, P114, DOI 10.1016/j.eiar.2015.11.012
CR  - Farina A, 2016, BIOSYSTEMS, V147, P11, DOI 10.1016/j.biosystems.2016.05.011
CR  - Fischer FP, 1997, ECOL APPL, V7, P909, DOI 10.1890/1051-0761(1997)007[0909:QAOGQA]2.0.CO;2
CR  - Froidevaux JSP, 2014, ECOL EVOL, V4, P4690, DOI 10.1002/ece3.1296
CR  - Gasc A, 2015, BIOL CONSERV, V191, P306, DOI 10.1016/j.biocon.2015.06.018
CR  - Gasc A, 2013, ECOL INDIC, V25, P279, DOI 10.1016/j.ecolind.2012.10.009
CR  - Gillespie D., 2009, J ACOUST SOC AM, V125, P2547, DOI [10.1121/1.4808713, DOI 10.1121/1.4808713, 10.1121/1]
CR  - Glotin, 2016, 2016 IEEE 26 INT WOR, P1, DOI [DOI 10.1109/MLSP.2016.7738875, 10.1109/MLSP.2016.7738875]
CR  - Glover-Kapfer P., 2017, WWF CONSERV TECHNOL, V1, P75
CR  - Goeau H., 2016, CLEF C LABS EV FOR, V1609, P440
CR  - Gregory R. D., 2004, BIRD CENSUS SURVEY T, DOI [10.1093/acprof:oso/9780198520863.001.0001, DOI 10.1093/ACPR0F:OSO/9780198520863.001.0001]
CR  - Hariharan B., 2016, ARXIV160602819
CR  - Harris SA, 2016, METHODS ECOL EVOL, V7, P713, DOI 10.1111/2041-210X.12527
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Hill AP, 2018, METHODS ECOL EVOL, V9, P1199, DOI 10.1111/2041-210X.12955
CR  - Honrado JP, 2016, J APPL ECOL, V53, P1299, DOI 10.1111/1365-2664.12777
CR  - Isaac NJB, 2014, METHODS ECOL EVOL, V5, P1052, DOI 10.1111/2041-210X.12254
CR  - Jaramillo-Legorreta A, 2017, CONSERV BIOL, V31, P183, DOI 10.1111/cobi.12789
CR  - Johnson MP, 2003, IEEE J OCEANIC ENG, V28, P3, DOI 10.1109/JOE.2002.808212
CR  - Jones Kate E., 2013, P213
CR  - Kaewtip K, 2016, J ACOUST SOC AM, V140, P3691, DOI 10.1121/1.4966592
CR  - Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
CR  - Kasten EP, 2012, ECOL INFORM, V12, P50, DOI 10.1016/j.ecoinf.2012.08.001
CR  - Kershenbaum A, 2016, BIOL REV, V91, P13, DOI 10.1111/brv.12160
CR  - Kery M, 2008, COMMUNITY ECOL, V9, P207, DOI 10.1556/ComEc.9.2008.2.10
CR  - King SL, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0053
CR  - Klingbeil BT, 2015, PEERJ, V3, DOI 10.7717/peerj.973
CR  - Krause J., 2016, UNREASONABLE EFFECTI
CR  - Lehmann GUC, 2014, J INSECT CONSERV, V18, P909, DOI 10.1007/s10841-014-9700-2
CR  - Lellouch L, 2014, METHODS ECOL EVOL, V5, P495, DOI 10.1111/2041-210X.12178
CR  - Linhart P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177206
CR  - Lucas TCD, 2015, METHODS ECOL EVOL, V6, P500, DOI 10.1111/2041-210X.12346
CR  - Lukic Y., 2016, P 26 IEEE INT WORKSH, P1, DOI [10.1109/MLSP.2016.7738816, DOI 10.1109/MLSP.2016.7738816]
CR  - Mac Aodha O, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005995
CR  - Mac Aodha O, 2014, INT C PATT RECOG, P9, DOI 10.1109/ICPR.2014.12
CR  - Marinexplore, 2013, MAR CORN U WHAL DET
CR  - Marques TA, 2013, BIOL REV, V88, P287, DOI 10.1111/brv.12001
CR  - McWilliam JN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15838-z
CR  - McWilliam JN, 2013, J EXP MAR BIOL ECOL, V446, P166, DOI 10.1016/j.jembe.2013.05.012
CR  - Mellinger DK, 2006, APPL ACOUST, V67, P1226, DOI 10.1016/j.apacoust.2006.06.002
CR  - Merchant ND, 2015, METHODS ECOL EVOL, V6, P257, DOI 10.1111/2041-210X.12330
CR  - Muda L., 2010, ARXIV10034083
CR  - Mukundarajan H, 2017, ELIFE, V6, DOI 10.7554/eLife.27854
CR  - Nedelec SL, 2015, MAR ECOL PROG SER, V524, P125, DOI 10.3354/meps11175
CR  - Newson SE, 2017, METHODS ECOL EVOL, V8, P1051, DOI 10.1111/2041-210X.12720
CR  - Newson SE, 2015, BIOL CONSERV, V191, P38, DOI 10.1016/j.biocon.2015.06.009
CR  - Norouzzadeh M, 2017, ARXIV170305830, V115
CR  - Nowacek DP, 2016, ANIM BEHAV, V120, P235, DOI 10.1016/j.anbehav.2016.07.019
CR  - Penone C, 2013, CONSERV BIOL, V27, P979, DOI 10.1111/cobi.12083
CR  - Petruskova T, 2016, METHODS ECOL EVOL, V7, P274, DOI 10.1111/2041-210X.12496
CR  - Pieretti N, 2011, ECOL INDIC, V11, P868, DOI 10.1016/j.ecolind.2010.11.005
CR  - Pijanowski BC, 2011, LANDSCAPE ECOL, V26, P1213, DOI 10.1007/s10980-011-9600-8
CR  - Pirotta E, 2015, BIOL CONSERV, V181, P82, DOI 10.1016/j.biocon.2014.11.003
CR  - Prat Y, 2016, SCI REP-UK, V6, DOI 10.1038/srep39419
CR  - Proppe DS, 2013, GLOBAL CHANGE BIOL, V19, P1075, DOI 10.1111/gcb.12098
CR  - RIEDE K, 1993, AMBIO, V22, P546
CR  - Roch MA, 2016, ECOL INFORM, V31, P122, DOI 10.1016/j.ecoinf.2015.12.002
CR  - Root-Gutteridge H, 2014, BIOACOUSTICS, V23, P55, DOI 10.1080/09524622.2013.817317
CR  - Ruiz-Gutierrez V, 2016, METHODS ECOL EVOL, V7, P900, DOI 10.1111/2041-210X.12542
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - Salamon J., 2016, ABS160804363 CORR, DOI 10.21437/interspeech.2016805
CR  - Salamon J, 2015, INT CONF ACOUST SPEE, P171, DOI 10.1109/ICASSP.2015.7177954
CR  - Sayigh L., 2016, WATKINS MARINE MAMMA, DOI [10.1121/2.0000358, DOI 10.1121/2.0000358]
CR  - Sethi SS, 2018, METHODS ECOL EVOL, V9, P2383, DOI 10.1111/2041-210X.13089
CR  - Simpson SD, 2008, ANIM BEHAV, V75, P1861, DOI 10.1016/j.anbehav.2007.11.004
CR  - Sousa-Lima RS, 2013, AQUAT MAMM, V39, P23, DOI 10.1578/AM.39.1.2013.23
CR  - Staaterman E, 2017, MAR ECOL PROG SER, V575, P207, DOI 10.3354/meps12188
CR  - Stathopoulos V, 2018, J R STAT SOC C-APPL, V67, P165, DOI 10.1111/rssc.12217
CR  - Stevenson BC, 2015, METHODS ECOL EVOL, V6, P38, DOI 10.1111/2041-210X.12291
CR  - Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
CR  - Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
CR  - Sueur J, 2014, ACTA ACUST UNITED AC, V100, P772, DOI 10.3813/AAA.918757
CR  - Sueur J, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0004065
CR  - Thompson ME, 2010, AFR J ECOL, V48, P224, DOI 10.1111/j.1365-2028.2009.01106.x
CR  - Tobias JA, 2014, P NATL ACAD SCI USA, V111, P1020, DOI 10.1073/pnas.1314337111
CR  - Van Parijs SM, 2015, MAR TECHNOL SOC J, V49, P70, DOI 10.4031/MTSJ.49.2.16
CR  - Van Parijs SM, 2009, MAR ECOL PROG SER, V395, P21, DOI 10.3354/meps08123
CR  - Walters CL, 2012, J APPL ECOL, V49, P1064, DOI 10.1111/j.1365-2664.2012.02182.x
CR  - Walters CL, 2013, BAT EVOLUTION ECOLOG, P479, DOI [10.1007/978-1-4614-7397-8_23, DOI 10.1007/978-1-4614-7397-8_23]
CR  - Ward JA, 2012, MAR MAMMAL SCI, V28, pE444, DOI 10.1111/j.1748-7692.2011.00560.x
CR  - Whytock RC, 2017, METHODS ECOL EVOL, V8, P308, DOI 10.1111/2041-210X.12678
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - Zamora-Gutierrez V, 2016, METHODS ECOL EVOL, V7, P1082, DOI 10.1111/2041-210X.12556
CR  - Zilli D, 2014, J ARTIF INTELL RES, V51, P805, DOI 10.1613/jair.4434
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - FEB
PY  - 2019
VL  - 10
IS  - 2
SP  - 169
EP  - 185
DO  - 10.1111/2041-210X.13101
AN  - WOS:000459020800002
N1  - Times Cited in Web of Science Core Collection:  134
Total Times Cited:  139
Cited Reference Count:  108
ER  -

TY  - CPAPER
AU  - Koh, PW
AU  - Sagawa, S
AU  - Marklund, H
AU  - Xie, SM
AU  - Zhang, M
AU  - Balsubramani, A
AU  - Hu, WH
AU  - Yasunaga, M
AU  - Phillips, RL
AU  - Gao, I
AU  - Lee, T
AU  - David, E
AU  - Stavness, I
AU  - Guo, W
AU  - Earnshaw, BA
AU  - Haque, IS
AU  - Beery, S
AU  - Leskovec, J
AU  - Kundaje, A
AU  - Pierson, E
AU  - Levine, S
AU  - Finn, C
AU  - Liang, P
ED  - Meila, M
ED  - Zhang, T
TI  - WILDS: A Benchmark of in-the-Wild Distribution Shifts
T2  - INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 139
LA  - English
CP  - International Conference on Machine Learning (ICML)
KW  - RACIAL DISPARITIES
KW  - DOMAIN ADAPTATION
KW  - CLASSIFICATION
KW  - ART
KW  - SYSTEMS
KW  - IMAGERY
KW  - CANCER
KW  - HEALTH
KW  - DRIFT
AB  - Distribution shifts-where the training distribution differs from the test distribution-can substantially degrade the accuracy of machine learning (ML) systems deployed in the wild. Despite their ubiquity in the real-world deployments, these distribution shifts are under-represented in the datasets widely used in the ML community today. To address this gap, we present WILDS, a curated benchmark of 10 datasets reflecting a diverse range of distribution shifts that naturally arise in real-world applications, such as shifts across hospitals for tumor identification; across camera traps for wildlife monitoring; and across time and location in satellite imaging and poverty mapping. On each dataset, we show that standard training yields substantially lower out-of-distribution than in-distribution performance. This gap remains even with models trained by existing methods for tackling distribution shifts, underscoring the need for new methods for training models that are more robust to the types of distribution shifts that arise in practice. To facilitate method development, we provide an opensource package that automates dataset loading, contains default model architectures and hyperparameters, and standardizes evaluations. The full paper, code, and leaderboards are available at https://wilds.stanford.edu.
AD  - Stanford, Stanford, CA 94305 USAAD  - Univ Calif Berkeley, Berkeley, CA USAAD  - Cornell, Ithaca, NY USAAD  - INRAE, Paris, FranceAD  - USask, Saskatoon, SK, CanadaAD  - UTokyo, Tokyo, JapanAD  - Recursion, Cambridge, MA USAAD  - CALTECH, Pasadena, CA 91125 USAAD  - Microsoft Res, Redmond, WA USAC3  - Stanford UniversityC3  - University of California SystemC3  - University of California BerkeleyC3  - INRAEC3  - University of SaskatchewanC3  - California Institute of TechnologyC3  - MicrosoftFU  - Open Philanthropy Project Award; NSF [OAC-1835598, OAC-1934578, CCF-1918940, IIS-2030477, 1805310]; Herbert Kunzel Stanford Graduate Fellowship; Dr. Tech. Marcus Wallenberg Foundation for Education in International Industrial Entrepreneurship; CIFAR; Google; NDSEG Graduate Fellowships; Funai Overseas Scholarship; Masason Foundation Fellowship; NSF Graduate Research Fellowship; DARPA [N660011924033]; ARO [W911NF-16-1-0342, W911NF-16-1-0171]; Stanford Data Science Initiative; Wu Tsai Neurosciences Institute; Chan Zuckerberg Biohub; Amazon; JPMorgan Chase; Docomo; Hitachi; JD.com; KDDI; NVIDIA; Dell; Toshiba; UnitedHealth Group
FX  - This project was funded by an Open Philanthropy Project Award and NSF Award Grant No. 1805310. Shiori Sagawa was supported by the Herbert Kunzel Stanford Graduate Fellowship. Henrik Marklund was supported by the Dr. Tech. Marcus Wallenberg Foundation for Education in International Industrial Entrepreneurship, CIFAR, and Google. Sang Michael Xie and Marvin Zhang were supported by NDSEG Graduate Fellowships. Weihua Hu was supported by the Funai Overseas Scholarship and the Masason Foundation Fellowship. Sara Beery was supported by an NSF Graduate Research Fellowship and is a PIMCO Fellow in Data Science. Jure Leskovec is a Chan Zuckerberg Biohub investigator. Chelsea Finn is a CIFAR Fellow in the Learning in Machines and Brains Program.
FX  - We also gratefully acknowledge the support of DARPA under Nos. N660011924033 (MCS); ARO under Nos. W911NF-16-1-0342 (MURI), W911NF-16-1-0171 (DURIP); NSF under Nos. OAC-1835598 (CINES), OAC-1934578 (HDR), CCF-1918940 (Expeditions), IIS-2030477 (RAPID); Stanford Data Science Initiative, Wu Tsai Neurosciences Institute, Chan Zuckerberg Biohub, Amazon, JPMorgan Chase, Docomo, Hitachi, JD.com, KDDI, NVIDIA, Dell, Toshiba, and UnitedHealth Group.
CR  - Abelson B., 2014, INT C KNOWL DISC DAT
CR  - Adragna R., 2020, ARXIV201106485
CR  - Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
CR  - Aguet F, 2020, SCIENCE, V369, P1318, DOI 10.1126/science.aaz1776
CR  - Ahadi A, 2015, P 11 ANN INT C INT C, P121, DOI DOI 10.1145/2787622.2787717
CR  - Ahumada JA, 2020, ENVIRON CONSERV, V47, P1, DOI 10.1017/S0376892919000298
CR  - Aich S, 2018, IEEE WINT CONF APPL, P323, DOI 10.1109/WACV.2018.00042
CR  - AlBadawy E., 2018, MED PHYS, V45
CR  - Alexandari AM, 2020, PR MACH LEARN RES, V119
CR  - Allamanis M., 2017, CORR ABS170507867
CR  - Allamanis M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P38, DOI 10.1145/2786805.2786849
CR  - AMORIM LA, 2018, ASS COMPUTATIONAL LI, P229, DOI DOI 10.1109/WSCAD.2018.00043
CR  - Angwin J., 2016, PROPUBLICA
CR  - [Anonymous], 2020, BBC
CR  - [Anonymous], 2016, NY TIMES
CR  - [Anonymous], 2019, ARXIV191007113
CR  - Ardila R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4218
CR  - Arjovsky M., 2019, ARXIV190702893
CR  - Asuncion Arthur, 2007, UCI MACHINE LEARNING
CR  - Attene-Ramos MS, 2013, DRUG DISCOV TODAY, V18, P716, DOI 10.1016/j.drudis.2013.05.015
CR  - Atwood James, 2020, NEURIPS 18 COMPETITI, P155
CR  - Avsec Z., 2019, BIORXIV
CR  - Ayalew Tewodros W., 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P330, DOI 10.1007/978-3-030-65414-6_23
CR  - Azizzadenesheli, 2019, INT C LEARN REPR ICL
CR  - Badgeley MA, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0105-1
CR  - Balaji Y., 2018, NEURIPS, P998
CR  - Bandi P, 2019, IEEE T MED IMAGING, V38, P550, DOI 10.1109/TMI.2018.2867350
CR  - Barbu A, 2019, ADV NEUR IN, V32
CR  - Bartlett PL, 2008, J MACH LEARN RES, V9, P1823
CR  - Baumann T, 2019, LANG RESOUR EVAL, V53, P303, DOI 10.1007/s10579-017-9410-y
CR  - Beck AH, 2011, SCI TRANSL MED, V3, DOI 10.1126/scitranslmed.3002564
CR  - Becke AD, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4869598
CR  - Beede E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376718
CR  - Beery Sara, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13072, DOI 10.1109/CVPR42600.2020.01309
CR  - Beery S., 2020, ARXIV200410340
CR  - Beery S, 2019, ARXIV190706772
CR  - Beery S, 2018, LECT NOTES COMPUT SC, V11220, P472, DOI 10.1007/978-3-030-01270-0_28
CR  - Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
CR  - Bellamy D., 2020, ARXIV201001149
CR  - Bellemare MG, 2020, NATURE, V588, P77, DOI 10.1038/s41586-020-2939-8
CR  - Bender E.M., 2018, T ASS COMPUTATIONAL, V6, P587, DOI [DOI 10.1162/TACL_A_00041, 10.1162/tacl_a_00041]
CR  - BenTaieb A, 2018, IEEE T MED IMAGING, V37, P792, DOI 10.1109/TMI.2017.2781228
CR  - Berman G., 2018, ETHICAL CONSIDERATIO
CR  - Berndl M., 2017, IMPROVING PHENOTYPIC, DOI DOI 10.1101/161422
CR  - Beyene AA, 2015, KNOWL INF SYST, V44, P177, DOI 10.1007/s10115-014-0756-9
CR  - Blanchard G., 2011, ADV NEURAL INFORM PR, V24, P2178
CR  - Blitzer J., 2007, P 45 ANN M ASS COMP
CR  - Blodgett S.L., 2016, P 2016 C EMP METH NA, P1119, DOI DOI 10.18653/V1/D16-1120
CR  - Blodgett SL, 2017, ARXIV PREPRINT ARXIV
CR  - Blumenstock J, 2015, SCIENCE, V350, P1073, DOI 10.1126/science.aac4420
CR  - Bohacek RS, 1996, MED RES REV, V16, P3, DOI 10.1002/(SICI)1098-1128(199601)16:1<3::AID-MED1>3.3.CO;2-D
CR  - Borkan D., 2019, ARXIV190302088
CR  - Borkan D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P491, DOI 10.1145/3308560.3317593
CR  - Bottou L, 2013, J MACH LEARN RES, V14, P3207
CR  - Boutros M, 2015, CELL, V163, P1314, DOI 10.1016/j.cell.2015.11.007
CR  - Bray MA, 2016, NAT PROTOC, V11, P1757, DOI 10.1038/nprot.2016.105
CR  - Brendel W., 2018, ARXIV PREPRINT ARXIV, P1
CR  - Broach JR, 1996, NATURE, V384, P14
CR  - Broussard M., 2020, NY TIMES
CR  - Bruch M., 2009, EUR SOFTW ENG C ACM
CR  - Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
CR  - Bug D, 2017, LECT NOTES COMPUT SC, V10553, P135, DOI 10.1007/978-3-319-67558-9_16
CR  - Bunel R., 2018, ICLR
CR  - Buolamwini J., 2018, 1 C FAIRNESS ACCOUNT, V81, P1
CR  - BURKE L, 2016, LANCET GLOB HEALTH, V4, DOI DOI 10.3389/FCELL.2016.00103
CR  - Byrd J, 2019, PR MACH LEARN RES, V97
CR  - Caicedo JC, 2018, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2018.00970
CR  - Caicedo JC, 2017, NAT METHODS, V14, P849, DOI [10.1038/nmeth.4397, 10.1038/NMETH.4397]
CR  - Caldas S., 2018, ARXIV PREPRINT ARXIV
CR  - Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1
CR  - Cao K., 2020, ARXIV200615766
CR  - Cao KD, 2019, ADV NEUR IN, V32
CR  - Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233
CR  - Chanussot L., 2020, ARXIV201009990
CR  - Chen I.Y., 2020, ARXIV PREPRINT ARXIV
CR  - Chen Irene Y, 2019, AMA J Ethics, V21, pE167, DOI 10.1001/amajethics.2019.167
CR  - Chen Vincent S, 2019, Adv Neural Inf Process Syst, V32, P9392
CR  - Ching T, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0387
CR  - Christie G., 2018, COMPUTER VISION PATT
CR  - Chung JS, 2018, INTERSPEECH, P1086
CR  - Clark J. H., 2020, ARXIV200305002
CR  - Codella N., 2019, ARXIV PREPRINT ARXIV
CR  - Conneau A., 2018, P 2018 C EMP METH NA
CR  - Consortium H., 2019, NATURE, V574
CR  - Corbett-Davies S., 2018, ARXIV180800023
CR  - Corbett-Davies S, 2016, WASHINGTON POST 1017
CR  - Corbett-Davies S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797, DOI 10.1145/3097983.3098095
CR  - CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358
CR  - Courtiol P, 2019, NAT MED, V25, P1519, DOI 10.1038/s41591-019-0583-3
CR  - Croce F., 2020, ARXIV201009670
CR  - Crunchant AS, 2020, METHODS ECOL EVOL, V11, P542, DOI 10.1111/2041-210X.13362
CR  - Cuccarese M. F., 2020, BIORXIV
CR  - Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
CR  - D'Amour A, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P525, DOI 10.1145/3351095.3372878
CR  - Dai DX, 2018, IEEE INT C INTELL TR, P3819, DOI 10.1109/ITSC.2018.8569387
CR  - DAmour A., 2020, UNDERSPECIFICATION P
CR  - David E., 2021, GLOBAL WHEAT HEAD DA
CR  - David E, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/3521852
CR  - David S.B., 2006, NIPS, P137
CR  - Davis SE, 2017, J AM MED INFORM ASSN, V24, P1052, DOI 10.1093/jamia/ocx030
CR  - DeGrave Alex J, 2020, medRxiv, DOI 10.1101/2020.09.13.20193565
CR  - Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8
CR  - DEVKOTA P, 2018, EMPIRICAL METHODS NA, P2799
CR  - Dietterich T., 2019, P INT C LEARN REPR I
CR  - DigitalGlobe N., 2016, SPAC
CR  - Dill KA, 2012, SCIENCE, V338, P1042, DOI 10.1126/science.1219021
CR  - Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729
CR  - Djolonga Josip, 2020, ARXIV200708558
CR  - Dodge S.F., P 2017 26 INT C COMP, P1, DOI [10.1109/ICCCN.2017.8038465, DOI 10.1109/ICCCN.2017.8038465]
CR  - Dou Q., 2019, ADV NEURAL INF PROCE, V32, P6450
CR  - Dreccer MF, 2019, PLANT SCI, V282, P73, DOI 10.1016/j.plantsci.2018.06.008
CR  - Dressel J, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao5580
CR  - Duchi J., 2021, ANN STAT
CR  - Duchi John, 2020, ARXIV200713982
CR  - Dunham I, 2012, NATURE, V489, P57, DOI 10.1038/nature11247
CR  - Dwork C., 2012, P 3 INNOVATIONS THEO, P214, DOI DOI 10.1145/2090236.2090255
CR  - Echeverri CJ, 2006, NAT REV GENET, V7, P373, DOI 10.1038/nrg1836
CR  - Elvidge C. D., 2009, COMPUTERS GEOSCIENCE, V35
CR  - Eraslan G, 2019, NAT REV GENET, V20, P389, DOI 10.1038/s41576-019-0122-6
CR  - Espey J., 2015, SUSTAINABLE DEV SOLU
CR  - Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
CR  - FAN QC, 2018, ADV NEURAL INFORM PR, P3539
CR  - Fan Z, 2018, IEEE J-STARS, V11, P876, DOI 10.1109/JSTARS.2018.2793849
CR  - Fang C, 2013, IEEE I CONF COMP VIS, P1657, DOI 10.1109/ICCV.2013.208
CR  - Feng J., 2019, ARXIV190605473
CR  - Filmer D., 2011, DEMOGRAPHY, V49
CR  - Franks C., 2015, INT C SOFTW ENG ICSE
CR  - Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
CR  - Futoma J, 2020, LANCET DIGIT HEALTH, V2, pE489, DOI 10.1016/S2589-7500(20)30186-2
CR  - Gal Y, 2016, PR MACH LEARN RES, V48
CR  - Ganin Y., 2015, PR MACH LEARN RES, P1180
CR  - Ganin Y, 2016, J MACH LEARN RES, V17
CR  - Garg S., 2020, ARXIV200307554
CR  - Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
CR  - Geifman Y., 2018, INT C LEARN REPR ICL
CR  - Geifman Y, 2019, PR MACH LEARN RES, V97
CR  - Geifman Yonatan, 2017, ADV NEURAL INFORM PR
CR  - Geirhos Robert, 2020, Nature Machine Intelligence, V2, P665, DOI 10.1038/s42256-020-00257-z
CR  - Geirhos R., 2018, P NIPS MONTR QC CAN, V31, P7538
CR  - Gelman A, 2007, J AM STAT ASSOC, V102, P813, DOI 10.1198/016214506000001040
CR  - Geva Mor, 2019, P 2019 C EMP METH NA, P1161, DOI [10.18653/v1/D19-1107, DOI 10.18653/V1/D19-1107]
CR  - GILMER J, 2017, INT C MACH LEARN ICM, V70
CR  - Godinez W. J., 2018, BIORXIV
CR  - Goel K., 2020, ARXIV200806775
CR  - Goel S, 2016, ANN APPL STAT, V10, P365, DOI 10.1214/15-AOAS897
CR  - Gogoll D, 2020, IEEE INT C INT ROBOT, P2636, DOI 10.1109/IROS45743.2020.9341277
CR  - Goh WWB, 2017, TRENDS BIOTECHNOL, V35, P498, DOI 10.1016/j.tibtech.2017.02.012
CR  - Goodfellow I. J., 2015, ICLR, P1
CR  - Graetz N, 2018, NATURE, V555, P48, DOI 10.1038/nature25761
CR  - Grooten M., 2020, LIVING PLANET REPORT
CR  - Gu S., 2017, 2017 IEEE INT C ROB, P3389, DOI [10.1109/ICRA.2017.7989385, DOI 10.1109/ICRA.2017.7989385]
CR  - Gulrajani I., 2020, ARXIV200701434
CR  - Guo J, 2018, ARXIV180902256, DOI [10.18653/v1/D18-1498, DOI 10.18653/V1/D18-1498]
CR  - Gupta A., 2018, ADV NEURAL INFORM PR, P5302
CR  - Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
CR  - Han X., 2020, ARXIV201003154
CR  - Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060
CR  - Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1244693, 10.1126/science.1215904]
CR  - Harrill Joshua, 2019, Current Opinion in Toxicology, V15, P64, DOI 10.1016/j.cotox.2019.05.004
CR  - Hashimoto TB, 2018, PR MACH LEARN RES, V80
CR  - He K, 2016, ARXIV160305027, DOI DOI 10.1109/CVPR.2016.90
CR  - He Y, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107383
CR  - Heinze-Deml C., 2017, ARXIV171011469
CR  - Hellendoorn VJ, 2019, PROC INT CONF SOFTW, P960, DOI 10.1109/ICSE.2019.00101
CR  - Henderson BE, 2012, NAT REV CANCER, V12, P648, DOI 10.1038/nrc3341
CR  - Hendrycks D., 2017, 5 INT C LEARN REPR I
CR  - Hendrycks D., 2020, ARXIV200616241, p2020a
CR  - Hendrycks D., 2020, ARXIV191111132
CR  - Hendrycks D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2744
CR  - Ho JWK, 2014, NATURE, V512, P449, DOI 10.1038/nature13415
CR  - Hoffman J, 2018, PR MACH LEARN RES, V80
CR  - Hovy D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P591
CR  - Hu JJ, 2020, PR MACH LEARN RES, V119
CR  - Hu W., 2020, ARXIV200500687
CR  - Hu WH, 2018, PR MACH LEARN RES, V80
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - Hughes JP, 2011, BRIT J PHARMACOL, V162, P1239, DOI 10.1111/j.1476-5381.2010.01127.x
CR  - Husain H., 2019, ARXIV190909436
CR  - Isaac W., 2016, SIGNIFICANCE, V13, P14, DOI DOI 10.1111/J.1740-9713.2016.00960.X
CR  - Jaganathan K, 2019, CELL, V176, P535, DOI 10.1016/j.cell.2018.12.015
CR  - Jean N., 2018, ADV NEURAL INFORM PR
CR  - Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
CR  - Jin W., 2020, ARXIV200603908
CR  - Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
CR  - Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
CR  - Jones E., 2021, INT C LEARN REPR ICL, P2021
CR  - Jorgensen A., 2015, P WORKSH NOIS US GEN, P9, DOI 10.18653/ v1/W15- 4302
CR  - Jumper J., 2020, 14 CRITICAL ASSESSME
CR  - Kahn G., 2020, ARXIV200205700
CR  - Kallus N., 2018, ARXIV180602887CSSTAT
CR  - Kamath A., 2020, ASS COMPUTATIONAL LI
CR  - Katona Z., 2018, MIAM BEH FIN C
CR  - Kaushik D., 2019, INT C LEARN REPR ICL
CR  - Kearns M, 2018, PR MACH LEARN RES, V80
CR  - Keilwagen J, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-018-1614-y
CR  - Kelley DR, 2016, GENOME RES, V26, P990, DOI 10.1101/gr.200535.115
CR  - Kim J. H., 2016, INCORPORATING SPATIA
CR  - Kim N., 2020, ARXIV201005465
CR  - Kim S, 2016, NUCLEIC ACIDS RES, V44, pD1202, DOI 10.1093/nar/gkv951
CR  - Kingma DP, 2014, ARXIV PREPRINT ARXIV
CR  - Koenecke A, 2020, P NATL ACAD SCI USA, V117, P7684, DOI 10.1073/pnas.1915768117
CR  - Koh PW, 2020, PR MACH LEARN RES, V119
CR  - Kompa B., 2020, ARXIV201003039
CR  - Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
CR  - Kulal S, 2019, ADV NEUR IN, V32
CR  - Kulkarni C, 2015, UNDERST INNOV, P131, DOI 10.1007/978-3-319-06823-7_9
CR  - Kulkarni Chinmay E, 2014, P 1 ACM C LEARN SCAL, P99, DOI DOI 10.1145/2556325.2566238
CR  - Kumar A., 2020, INT C MACH LEARN ICM
CR  - Kundaje A, 2015, NATURE, V518, P317, DOI 10.1038/nature14248
CR  - Kuznichov D., 2019, P IEEE CVF C COMP VI
CR  - Lake B, 2018, PR MACH LEARN RES, V80
CR  - Lakshminarayanan B., 2017, P ADV NEUR INF PROC, V30, P6402, DOI DOI 10.5555/3295222.3295387
CR  - Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
CR  - Landrum G., 2006, RDKIT OPEN SOURCE CH
CR  - LANGMEAD B, 2010, NAT REV GENET, V11, DOI DOI 10.1186/GB-2010-11-8-R83
CR  - Larrazabal AJ, 2020, P NATL ACAD SCI USA, V117, P12592, DOI 10.1073/pnas.1919012117
CR  - Latessa E.J, 2010, FED PROBAT, V74, P16
CR  - Lau RYK, 2014, DECIS SUPPORT SYST, V65, P80, DOI 10.1016/j.dss.2014.05.005
CR  - LeCun Y., 1998, MNIST DATABASE HANDW
CR  - Leonetti MD, 2019, BIORXIV
CR  - Li D., 2018, ASS ADV ARTIFICIAL I
CR  - Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
CR  - Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566
CR  - Li HY, 2019, GENOME RES, V29, P281, DOI 10.1101/gr.237156.118
CR  - Li J., 2017, ICLR
CR  - Li T.T., 2019, ARXIV190510497
CR  - Li Y, 2018, LECT NOTES COMPUT SC, V11219, P647, DOI 10.1007/978-3-030-01267-0_38
CR  - Liang Shiyu, 2018, INT C LEARN REPR ICL
CR  - Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920
CR  - Lin ZY, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz0652
CR  - Liu LT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6196
CR  - Liu Y, 2017, COMMUN MATH BIOL NEU, DOI 10.1080/10408398.2017.1329704
CR  - Ljosa V, 2012, NAT METHODS, V9, P637, DOI 10.1038/nmeth.2083
CR  - Long MS, 2015, PR MACH LEARN RES, V37, P97
CR  - Loshchilov I., 2019, P ICLR
CR  - Lu S., 2021, ARXIV210204664
CR  - Lum K., 2019, MEASURES FAIRNESS NE, P21
CR  - Lyu J, 2019, NATURE, V566, P224, DOI 10.1038/s41586-019-0917-9
CR  - Macarron R, 2011, NAT REV DRUG DISCOV, V10, P188, DOI 10.1038/nrd3368
CR  - Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
CR  - Madec S, 2019, AGR FOREST METEOROL, V264, P225, DOI 10.1016/j.agrformet.2018.10.013
CR  - Malloy BA, 2017, INT SYMP EMP SOFTWAR, P314, DOI 10.1109/ESEM.2017.45
CR  - Mansour Y, 2009, NEURAL INF PROCESS S, P1041
CR  - Marcus M. P., 1993, COMPUT LINGUIST, DOI DOI 10.21236/ADA273556
CR  - McCloskey K., 2020, J MED CHEM
CR  - McCoy R Thomas, 2019, ARXIV191102969
CR  - McCoy RT, 2019, ARXIV190201007
CR  - McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
CR  - Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
CR  - Meinshausen N, 2015, ANN STAT, V43, P1801, DOI 10.1214/15-AOS1325
CR  - Miller J., 2020, P 37 INT C MACH LEAR, P6905
CR  - Mirowski P, 2017, P 5 INT C LEARN REPR
CR  - Moore JE, 2020, NATURE, V583, P699, DOI 10.1038/s41586-020-2493-4
CR  - MOULT J, 1995, PROTEINS, V23, pR2, DOI 10.1002/prot.340230303
CR  - Nekoto W., 2020, FINDINGS EMPIRICAL M
CR  - Nestor B., 2019, ARXIV190800690
CR  - Netzer Yuval, 2011, NEURIPS WORKSH
CR  - Nguyen A. T., 2015, INT C SOFTW ENG ICSE
CR  - Ni Jianmo, 2019, P 2019 C EMPIRICAL M, P188
CR  - Nita M., 2010, P 32 ACM IEEE INT C, V1, P205
CR  - Noor A., 2008, POPULATION HLTH METR, V6
CR  - Nygaard V, 2016, BIOSTATISTICS, V17, P29, DOI 10.1093/biostatistics/kxv027
CR  - Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
CR  - Oren Y., 2019, EMPIRICAL METHODS NA
CR  - Osgood-Zimmerman A., 2018, NATURE, V555
CR  - Ovadia Y, 2019, ADV NEUR IN, V32
CR  - Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
CR  - Parham J., 2017, AAAI SPRING S TECHN
CR  - Parker HS, 2012, STAT APPL GENET MOL, V11, DOI 10.1515/1544-6115.1766
CR  - Patro GK, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1194, DOI 10.1145/3366423.3380196
CR  - Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
CR  - Peng XC, 2018, IEEE COMPUT SOC CONF, P2102, DOI 10.1109/CVPRW.2018.00271
CR  - Peng XB, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
CR  - Perelman L, 2014, ASSESS WRIT, V21, P104, DOI 10.1016/j.asw.2014.05.001
CR  - Peters J., 2016, J ROYAL STAT SOC B, V78
CR  - Phillips N. A., 2020, ARXIV200706199
CR  - Piech C., 2013, ED DATA MINING
CR  - Pierson E., 2018, ARXIV170208536CSSTAT
CR  - Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026
CR  - Pipal KA, 2012, N AM J FISH MANAGE, V32, P880, DOI 10.1080/02755947.2012.697096
CR  - Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7
CR  - Proksch S., 2016, 2016 31 IEEE ACM INT
CR  - Proksch S, 2015, ACM T SOFTW ENG METH, V25, DOI 10.1145/2744200
CR  - Quang D, 2019, METHODS, V166, P40, DOI 10.1016/j.ymeth.2019.03.020
CR  - Quinonero-Candela J, 2009, NEURAL INF PROCESS S, pXI
CR  - Raychev V., 2016, ACM SIGPLAN NOTICES
CR  - Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI [10.1145/2594291.2594321, 10.1145/2666356.2594321]
CR  - Re C., 2019, ARXIV190905372
CR  - Recht B, 2019, PR MACH LEARN RES, V97
CR  - Reiner R. C., 2018, NEW ENGLAND J MED, V379
CR  - Reker D., 2020, DRUG DISCOVERY TODAY
CR  - Ren SQ, 2015, ADV NEUR IN, V28
CR  - Reynolds M, 2020, PLANT SCI, V295, DOI 10.1016/j.plantsci.2019.110396
CR  - Ribeiro Marco Tulio, 2020, ARXIV PREPRINT ARXIV
CR  - Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
CR  - Rigaki M, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P70, DOI 10.1109/SPW.2018.00019
CR  - Robbes R., 2008, INT C AUT SOFTW ENG
CR  - Rolf E., 2020, ARTIFICIAL INTELLIGE
CR  - ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352
CR  - Rosenfeld A., 2018, ARXIV180803305
CR  - Sadegh Norouzzadeh M., 2019, ARXIV PREPRINT ARXIV
CR  - Sadeghi F, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII
CR  - Sadeghi-Tehran P, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0253-8
CR  - SAEED U, 2017, ELIFE, V6, DOI DOI 10.1186/S40035-017-0076-6
CR  - Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
CR  - Saerens M, 2002, NEURAL COMPUT, V14, P21, DOI 10.1162/089976602753284446
CR  - Sagawa S, 2020, PROCEEDINGS OF THE 3, V119, P8346
CR  - Sagawa S, 2020, INT C LEARN REPR
CR  - Sahn D. E., 2003, REV INCOME WEALTH, V49
CR  - Santurkar Shibani, 2020, BREEDS BENCHMARKS SU
CR  - Sap Maarten, 2019, ASS COMPUTATIONAL LI
CR  - Schneider S., 2020, ARXIV200712808
CR  - Seyyed-Kalantari L., 2020, ARXIV200300827
CR  - Shakoor N, 2017, CURR OPIN PLANT BIOL, V38, P184, DOI 10.1016/j.pbi.2017.05.006
CR  - Shankar S., 2017, ADV NEUR INF PROC SY
CR  - Shankar Vaishaal, 2019, ARXIV190602168
CR  - Shapiro A, 2014, LECT STOCHASTIC PROG
CR  - Shen J., 2018, ASS ADV ARTIFICIAL I
CR  - Shermis MD, 2014, ASSESS WRIT, V20, P53, DOI 10.1016/j.asw.2013.04.001
CR  - Shetty R, 2019, PROC CVPR IEEE, P8210, DOI 10.1109/CVPR.2019.00841
CR  - Shi J., 2017, P INT C LEARN REPR W
CR  - Shi Y, 2016, PLOS ONE, V11, P1, DOI DOI 10.1371/J0URNAL.P0NE.0157259
CR  - Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
CR  - Shin R., 2019, INT C LEARN REPR ICL
CR  - Shiu Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-57549-y
CR  - Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197
CR  - Slack D., 2019, ARXIV190809092CSSTAT
CR  - Smola, 2018, ARXIV PREPRINT ARXIV
CR  - Sohoni N., 2020, ADV NEURAL INFORM PR
CR  - Soneson C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100335
CR  - Srivastava D., 2020, BIOCH BIOPHYSICA ACT, V1863
CR  - SRIVASTAVA M, 2020, INT C MACH LEARN, P109
CR  - Sterling T, 2015, J CHEM INF MODEL, V55, P2324, DOI 10.1021/acs.jcim.5b00559
CR  - Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
CR  - Subbaswamy A., 2020, ARXIV201015100
CR  - Sun BC, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2058
CR  - Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
CR  - Sun P., 2020, C COMP VIS PATT REC
CR  - Sun Y., 2020, INT C MACH LEARN PML, P9229
CR  - Svyatkovskiy A, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2727, DOI 10.1145/3292500.3330699
CR  - Swinney DC, 2011, NAT REV DRUG DISCOV, V10, P507, DOI 10.1038/nrd3480
CR  - Tabak G, 2020, PEERJ, V8, DOI 10.7717/peerj.8594
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Taghipour K., 2016, P 2016 C EMP METH NA, P1882, DOI [10.18653/v1/D16-1193, DOI 10.18653/V1/D16-1193]
CR  - Taori R., 2020, ARXIV200700644, P2020
CR  - Tatman R., 2017, P 1 WORKSH ETH NAT L, P53
CR  - Taylor J., 2019, INT C LEARN REPR ICL
CR  - Taylor MJ, 2021, J AM SOC MASS SPECTR, V32, P872, DOI 10.1021/jasms.0c00439
CR  - Tellez D, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101544
CR  - Tellez D, 2018, IEEE T MED IMAGING, V37, P2126, DOI 10.1109/TMI.2018.2820199
CR  - Temel D, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P137, DOI 10.1109/ICMLA.2018.00028
CR  - Thorp KR, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111682
CR  - Tiecke T.G.L., 2017, MAPPING WORLD POPULA, DOI DOI 10.1596/33700
CR  - Tobin J., 2017, IEEE RSJ INT C INT R
CR  - Toda Y, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9237136
CR  - Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
CR  - Tuschl T, 2001, CHEMBIOCHEM, V2, P239, DOI 10.1002/1439-7633(20010401)2:4<239::AID-CBIC239>3.0.CO;2-R
CR  - Tzeng E., 2014, ABS14123474 CORR
CR  - Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
CR  - Ubbens Jordan R., 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P391, DOI 10.1007/978-3-030-65414-6_27
CR  - Uzkent B., 2020, COMPUTER VISION PATT
CR  - Vasic M., 2019, INT C LEARN REPR ICL
CR  - Vatnehol S, 2018, ICES J MAR SCI, V75, P1803, DOI 10.1093/icesjms/fsy029
CR  - Veeling BS, 2018, LECT NOTES COMPUT SC, V11071, P210, DOI 10.1007/978-3-030-00934-2_24
CR  - Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
CR  - Veta M, 2019, MED IMAGE ANAL, V54, P111, DOI 10.1016/j.media.2019.02.012
CR  - Veta M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161286
CR  - Volpi R., 2018, ADV NEURAL INFORM PR, P5334
CR  - Wang A, 2018, ARXIV PREPRINT ARXIV, P353, DOI 10.18653/v1/W18-5446
CR  - Wang A., 2019, ADV NEURAL INFORM PR
CR  - Wang D., 2020, ARXIV PREPRINT ARXIV
CR  - Wang H., 2019, ADV NEURAL INFORM PR
CR  - Wang S., 2020, REMOTE SENSING, V12
CR  - Wang SL, 2017, IEEE I CONF COMP VIS, P3028, DOI 10.1109/ICCV.2017.327
CR  - Ward D, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103009
CR  - Wearn O.R., 2017, WWF CONSERVATION TEC, DOI DOI 10.13140/RG.2.2.23409.17767
CR  - Weinberger S, 2015, SPEECH ACCENT ARCHIV
CR  - Weinstein BG, 2018, J ANIM ECOL, V87, P533, DOI 10.1111/1365-2656.12780
CR  - Weinstein J. N., 2013, NATURE GENETICS, V45
CR  - West R., 2014, T ASSOC COMPUT LING, V2, P297
CR  - Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900
CR  - Williams JJ, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P379, DOI 10.1145/2876034.2876042
CR  - Wilson B., 2019, ARXIV190211097
CR  - Wolf T., 2019, ARXIV PREPRINT ARXIV
CR  - Wolf T., 2019, ARXIV191001108
CR  - Wong H.Y.F., 2019, RADIOLOGY, V27, DOI [DOI 10.1148/RADIOL.2020201160, 10.1148/radiol.2020201160]
CR  - Worrall DE, 2017, PROC CVPR IEEE, P7168, DOI 10.1109/CVPR.2017.758
CR  - Wu M., 2020, INT C ED DAT MIN
CR  - Wu MK, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P782
CR  - Wu YF, 2019, PR MACH LEARN RES, V97
CR  - Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
CR  - Wulfmeier M, 2018, IEEE INT CONF ROBOT, P4489
CR  - Xiao K., 2020, ARXIV200609994
CR  - Xie M., 2016, ASS ADV ARTIFICIAL I
CR  - Xie S. M., 2020, IN N OUT PRETRAINING
CR  - Xiong HP, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0537-2
CR  - Xu K., 2018, POWERFUL GRAPH NEURA
CR  - Yang Y., 2019, C ROB LEARN CORL
CR  - Yang Y., 2010, GEOGRAPHIC INFORM SY
CR  - Yasunaga M., 2020, INT C MACH LEARN ICM
CR  - Yeh C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16185-w
CR  - You J., 2017, ASS ADV ARTIFICIAL I
CR  - Yu F., 2020, C COMP VIS PATT REC
CR  - Zafar M. B., 2017, ARXIV170700010CSSTAT
CR  - Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
CR  - ZHANG L, 2013, INT C MACH LEARN, P819
CR  - Zhang Marvin, 2020, ARXIV200702931
CR  - Zhang Y., 2019, P N AM CHAPT ASS COM, P1298
CR  - Zhao J., 2018, N AM ASS COMPUTATION
CR  - Zhou J, 2015, NAT METHODS, V12, P931, DOI [10.1038/NMETH.3547, 10.1038/nmeth.3547]
CR  - Zhou X., 2020, ARXIV200413606
CR  - Zhou YX, 2014, NATURE, V509, P487, DOI 10.1038/nature13166
CR  - Zitnick C.L., 2020, ARXIV201009435
PU  - JMLR-JOURNAL MACHINE LEARNING RESEARCH
PI  - SAN DIEGO
PA  - 1269 LAW ST, SAN DIEGO, CA, UNITED STATES
PY  - 2021
VL  - 139
AN  - WOS:000683104605062
N1  - Times Cited in Web of Science Core Collection:  12
Total Times Cited:  12
Cited Reference Count:  413
ER  -

TY  - JOUR
AU  - Campos, IB
AU  - Landers, TJ
AU  - Lee, KD
AU  - Lee, WG
AU  - Friesen, MR
AU  - Gaskett, AC
AU  - Ranjard, L
TI  - Assemblage of Focal Species Recognizers-AFSR: A technique for decreasing false indications of presence from acoustic automatic identification in a multiple species context
T2  - PLOS ONE
LA  - English
KW  - VOCAL ACTIVITY
KW  - SEABIRD
KW  - CLASSIFICATION
KW  - BIODIVERSITY
KW  - CALLS
AB  - Passive acoustic monitoring (PAM) coupled with automated species identification is a promising tool for species monitoring and conservation worldwide. However, high false indications of presence are still an important limitation and a crucial factor for acceptance of these techniques in wildlife surveys. Here we present the Assemblage of Focal Species Recognizers-AFSR, a novel approach for decreasing false positives and increasing models' precision in multispecies contexts. AFSR focusses on decreasing false positives by excluding unreliable sound file segments that are prone to misidentification. We used MatlabHTK, a hidden Markov models interface for bioacoustics analyses, for illustrating AFSR technique by comparing two approaches, 1) a multispecies recognizer where all species are identified simultaneously, and 2) an assemblage of focal species recognizers (AFSR), where several recognizers that each prioritise a single focal species are then summarised into a single output, according to a set of rules designed to exclude unreliable segments. Both approaches (the multispecies recognizer and AFSR) used the same sound files training dataset, but different processing workflow. We applied these recognisers to PAM recordings from a remote island colony with five seabird species and compared their outputs with manual species identifications. False positives and precision improved for all the five species when using AFSR, achieving remarkable 0% false positives and 100% precision for three of five seabird species, and < 6% false positives, and > 90% precision for the other two species. AFSR' output was also used to generate daily calling activity patterns for each species. Instead of attempting to withdraw useful information from every fragment in a sound recording, AFSR prioritises more trustworthy information from sections with better quality data. AFSR can be applied to automated species identification from multispecies PAM recordings worldwide.
AD  - Univ Auckland, Ctr Biodivers & Biosecur, Sch Biol Sci, Auckland, New ZealandAD  - Serra do Cipo Natl Pk, Chico Mendes Inst Biodivers Conservat, Serra Do Cipo, MG, BrazilAD  - Auckland Council, Res & Evaluat Unit, Auckland, New ZealandAD  - Landcare Res, Dunedin, New ZealandAD  - Australian Natl Univ, Res Sch Biol, ANU Coll Med Biol & Environm, Canberra, ACT, AustraliaC3  - University of AucklandC3  - Landcare Research - New ZealandC3  - Australian National UniversityFU  - CNPq-Brazil
FX  - IBC received a Science Without Borders PhD scholarship funded by CNPq-Brazil. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
CR  - Aide T. M., 2013, PEERJ, V1, P1
CR  - Andreassen T, 2014, ECOL INFORM, V21, P13, DOI 10.1016/j.ecoinf.2013.12.010
CR  - Bellingham PJ, 2010, NEW ZEAL J ECOL, V34, P115
CR  - Borker AL, 2014, CONSERV BIOL, V28, P1100, DOI 10.1111/cobi.12264
CR  - Buxton RT, 2012, J FIELD ORNITHOL, V83, P47, DOI 10.1111/j.1557-9263.2011.00355.x
CR  - Cragg Jenna L., 2015, Marine Ornithology, V43, P151
CR  - Deichmann JL, 2017, ECOL INDIC, V74, P39, DOI 10.1016/j.ecolind.2016.11.002
CR  - Eaton J.W., 2014, GNU OCTAVE VERSION 3
CR  - Gage S.H., 2001, J ACOUST SOC AM, V109, DOI [10.1121/1.4744597, DOI 10.1121/1.4744597]
CR  - Howald G, 2007, CONSERV BIOL, V21, P1258, DOI 10.1111/j.1523-1739.2007.00755.x
CR  - Ismar S.M.H., 2014, NOTORNIS, V61, P188
CR  - Jennings N, 2008, CAN J ZOOL, V86, P371, DOI 10.1139/Z08-009
CR  - Landers Todd J., 2011, Notornis, V58, P81
CR  - Mulder C.P., 2011, SEABIRD ISLANDS ECOL
CR  - Newson SE, 2015, BIOL CONSERV, V191, P38, DOI 10.1016/j.biocon.2015.06.009
CR  - Palacios V, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153858
CR  - Putland RL, 2018, ECOL INDIC, V84, P479, DOI 10.1016/j.ecolind.2017.09.025
CR  - Ranjard L, 2017, BEHAV ECOL, V28, P1085, DOI 10.1093/beheco/arx072
CR  - Ranjard L, 2017, METHODS ECOL EVOL, V8, P615, DOI 10.1111/2041-210X.12688
CR  - Ranjard L, 2015, J ACOUST SOC AM, V137, P2542, DOI 10.1121/1.4919329
CR  - Rocha LHS, 2015, BIOACOUSTICS, V24, P185, DOI 10.1080/09524622.2015.1019361
CR  - Ross E. L., 2002, Notornis, V49, P153
CR  - Sanders CE, 2014, CONDOR, V116, P371, DOI 10.1650/CONDOR-13-098.1
CR  - Stowell D, 2017, IEEE-ACM T AUDIO SPE, V25, P1193, DOI 10.1109/TASLP.2017.2690565
CR  - Warham J., 1990, PETRELS THEIR ECOLOG
CR  - Wrege PH, 2017, METHODS ECOL EVOL, V8, P1292, DOI 10.1111/2041-210X.12730
CR  - Xie J, 2016, LECT NOTES COMPUT SC, V9680, P222, DOI 10.1007/978-3-319-33618-3_23
CR  - Young SJ, 2006, HTK BOOK
CR  - Zilli D, 2014, J ARTIF INTELL RES, V51, P805, DOI 10.1613/jair.4434
CR  - Zwart MC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102770
PU  - PUBLIC LIBRARY SCIENCE
PI  - SAN FRANCISCO
PA  - 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
DA  - DEC 5
PY  - 2019
VL  - 14
IS  - 12
DO  - 10.1371/journal.pone.0212727
AN  - WOS:000534009700001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  30
ER  -

TY  - JOUR
AU  - Jia, L
AU  - Tian, Y
AU  - Zhang, JG
TI  - Domain-Aware Neural Architecture Search for Classifying Animals in Camera Trap Images
T2  - ANIMALS
LA  - English
KW  - camera trap images
KW  - convolutional neural network
KW  - neural architecture search
AB  - Simple Summary Camera traps acquire visual data in a non-disturbing and round-the-clock manner, so they are popular for ecological researchers observing wildlife. Each camera trap may record thousands of images of diverse species and bring about millions of images that need to be classified. Many methods have been proposed to classify camera trap images, but almost all methods rely on very deep convolutional neural networks that require intensive computational resources. Such resources may be unavailable and become formidable in cases where the surveillance area is large or becomes greatly expanded. We turn our attention to camera traps organized as groups, where each group produces images that are processed by the edge device with lightweight networks tailored for images produced by the group. To achieve this goal, we propose a method to automatically design networks deployable for edge devices with respect to given images. With the proposed method, researchers without any experience in designing neural networks can develop networks applicable for edge devices. Thus, camera trap images can be processed in a distributed manner through edge devices, lowering the costs of transferring and processing data accumulated at camera traps. Camera traps provide a feasible way for ecological researchers to observe wildlife, and they often produce millions of images of diverse species requiring classification. This classification can be automated via edge devices installed with convolutional neural networks, but networks may need to be customized per device because edge devices are highly heterogeneous and resource-limited. This can be addressed by a neural architecture search capable of automatically designing networks. However, search methods are usually developed based on benchmark datasets differing widely from camera trap images in many aspects including data distributions and aspect ratios. Therefore, we designed a novel search method conducted directly on camera trap images with lowered resolutions and maintained aspect ratios; the search is guided by a loss function whose hyper parameter is theoretically derived for finding lightweight networks. The search was applied to two datasets and led to lightweight networks tested on an edge device named NVIDIA Jetson X2. The resulting accuracies were competitive in comparison. Conclusively, researchers without knowledge of designing networks can obtain networks optimized for edge devices and thus establish or expand surveillance areas in a cost-effective way.
AD  - Beijing Forestry Univ, Sch Technol, Beijing 100083, Peoples R ChinaAD  - Changzhou Univ, Sch Microelect & Control Engn, Changzhou 213164, Peoples R ChinaC3  - Beijing Forestry UniversityC3  - Changzhou UniversityCR  - Bergstra J, 2012, J MACH LEARN RES, V13, P281
CR  - Castelblanco L.P., 2017, P 9 INT C MACH VIS N, P1
CR  - Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
CR  - Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
CR  - Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
CR  - Dong XT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3023706
CR  - Elias Andy Rosales, 2017, 2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI), P247, DOI 10.1145/3054977.3054986
CR  - Falkner S., 2018, P 35 INT C MACH LEAR, P1
CR  - Follmann P., 2018, Pattern Recognition and Image Analysis, V28, P605, DOI 10.1134/S1054661818040107
CR  - Villa AG, 2017, ECOL INFORM, V41, P24, DOI 10.1016/j.ecoinf.2017.07.004
CR  - Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - Ioffe S, 2015, PR MACH LEARN RES, V37, P448
CR  - Jaafra Y, 2019, IMAGE VISION COMPUT, V89, P57, DOI 10.1016/j.imavis.2019.06.005
CR  - Janzen M, 2017, ENVIRON MONIT ASSESS, V189, DOI 10.1007/s10661-017-6206-x
CR  - Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
CR  - Krizhevsky A, 2009, LEARNING MULTIPLE LA
CR  - Li XL, 2018, SPRINGERBRIEF MATH, P1, DOI [10.1109/ICDCS.2018.00011, 10.1007/978-3-319-89617-5_1]
CR  - Li YH, 2018, CHIN CONTR CONF, P9021, DOI 10.23919/ChiCC.2018.8483963
CR  - Lin M, 2014, ICLR, P1
CR  - Loshchilov I., 2017, P INT C LEARN REPR
CR  - Miao ZQ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44565-w
CR  - Moore HA, 2020, WILDLIFE RES, V47, P326, DOI 10.1071/WR19159
CR  - Nair V., 2010, P 27 INT C MACH LEAR
CR  - Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
CR  - Norouzzadeh MS, 2021, METHODS ECOL EVOL, V12, P150, DOI 10.1111/2041-210X.13504
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - Novotny D., 2016, P BRIT MACH VIS C YO, P115
CR  - Pham H., 2018, P INT C MACH LEARN S, P4095
CR  - Randler C, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10112178
CR  - Real E, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4780
CR  - Reddi S. J., 2018, P INT C LEARN REPR I, P1
CR  - Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
CR  - Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
CR  - Schneider S, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P321, DOI 10.1109/CRV.2018.00052
CR  - Shang Y, 2005, ELECTRICAL ENGINEERING HANDBOOK, P367, DOI 10.1016/B978-012170960-0/50031-1
CR  - Sutskever I., 2013, INT C MACH LEARN ICM, DOI [DOI 10.1007/S00287-015-0911-Z, 10.5555/3042817.3043064]
CR  - Tabak MA, 2020, ECOL EVOL, V10, P10374, DOI 10.1002/ece3.6692
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Tan MX, 2019, PR MACH LEARN RES, V97
CR  - Tekeli U, 2019, TURK J ELECTR ENG CO, V27, P2395, DOI 10.3906/elk-1808-130
CR  - Ulker B, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P48, DOI 10.1145/3378678.3391882
CR  - Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
CR  - Wei WD, 2020, ECOL INFORM, V55, DOI 10.1016/j.ecoinf.2019.101021
CR  - Whytock RC, 2021, METHODS ECOL EVOL, V12, P1080, DOI 10.1111/2041-210X.13576
CR  - WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1023/A:1022672621406
CR  - Xie S., 2017, P IEEE C COMP VIS PA, P1063
CR  - Xing YX, 2018, 2018 IEEE INTERNATIONAL SYMPOSIUM ON LOCAL AND METROPOLITAN AREA NETWORKS (LANMAN), P13, DOI 10.1109/LANMAN.2018.8475056
CR  - Yates R.C., 1974, CURVES THEIR PROPERT, V1st, P237
CR  - Yousif H, 2019, ECOL EVOL, V9, P1578, DOI 10.1002/ece3.4747
CR  - Zagoruyko S., 2016, BMVC
CR  - Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
CR  - Zhong Z., 2019, THESIS U CHINESE ACA
CR  - Zhou Y, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1713, DOI 10.1109/ITOEC49072.2020.9141847
CR  - Zhu CB, 2017, IEEE INT CONF COMP V, P2860, DOI 10.1109/ICCVW.2017.337
CR  - Zoph B., 2017, INT C LEARNING REPRE, P1
CR  - Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
CR  - Zualkernan IA, 2020, 2020 IEEE GLOBAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERNET OF THINGS (GCAIOT), P111, DOI 10.1109/GCAIOT51063.2020.9345858
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - FEB
PY  - 2022
VL  - 12
IS  - 4
DO  - 10.3390/ani12040437
AN  - WOS:000766440300001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  58
ER  -

TY  - JOUR
AU  - Schneider, S
AU  - Greenberg, S
AU  - Taylor, GW
AU  - Kremer, SC
TI  - Three critical factors affecting automated image species recognition performance for camera traps
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - camera traps
KW  - computer vision
KW  - convolutional networks
KW  - deep learning
KW  - density estimation
KW  - monitoring
KW  - population dynamics
KW  - species classification
KW  - K-FOLD
KW  - REIDENTIFICATION
KW  - IDENTIFICATION
KW  - CAPABILITIES
AB  - Ecological camera traps are increasingly used by wildlife biologists to unobtrusively monitor an ecosystems animal population. However, manual inspection of the images produced is expensive, laborious, and time-consuming. The success of deep learning systems using camera trap images has been previously explored in preliminary stages. These studies, however, are lacking in their practicality. They are primarily focused on extremely large datasets, often millions of images, and there is little to no focus on performance when tasked with species identification in new locations not seen during training. Our goal was to test the capabilities of deep learning systems trained on camera trap images using modestly sized training data, compare performance when considering unseen background locations, and quantify the gradient of lower bound performance to provide a guideline of data requirements in correspondence to performance expectations. We use a dataset provided by Parks Canada containing 47,279 images collected from 36 unique geographic locations across multiple environments. Images represent 55 animal species and human activity with high-class imbalance. We trained, tested, and compared the capabilities of six deep learning computer vision networks using transfer learning and image augmentation: DenseNet201, Inception-ResNet-V3, InceptionV3, NASNetMobile, MobileNetV2, and Xception. We compare overall performance on "trained" locations where DenseNet201 performed best with 95.6% top-1 accuracy showing promise for deep learning methods for smaller scale research efforts. Using trained locations, classifications with <500 images had low and highly variable recall of 0.750 +/- 0.329, while classifications with over 1,000 images had a high and stable recall of 0.971 +/- 0.0137. Models tasked with classifying species from untrained locations were less accurate, with DenseNet201 performing best with 68.7% top-1 accuracy. Finally, we provide an open repository where ecologists can insert their image data to train and test custom species detection models for their desired ecological domain.
AD  - Univ Guelph, Sch Comp Sci, Guelph, ON, CanadaAD  - Univ Calgary, Dept Comp Sci, Calgary, AB, CanadaAD  - Univ Guelph, Sch Engn, Vector Inst Artificial Intelligence, Guelph, ON, CanadaC3  - University of GuelphC3  - University of CalgaryC3  - University of GuelphCR  - Amodei D, 2016, PR MACH LEARN RES, V48
CR  - BALFOORT HW, 1992, J PLANKTON RES, V14, P575, DOI 10.1093/plankt/14.4.575
CR  - Beery S., 2019, ARXIV191203538
CR  - Beery S., 2019, ARXIV190405986
CR  - Bengio Y, 2004, J MACH LEARN RES, V5, P1089
CR  - Burton AC, 2015, J APPL ECOL, V52, P675, DOI 10.1111/1365-2664.12432
CR  - Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
CR  - CHAO A, 1989, BIOMETRICS, V45, P427, DOI 10.2307/2531487
CR  - Chen GB, 2014, IEEE IMAGE PROC, P858, DOI 10.1109/ICIP.2014.7025172
CR  - Csurka Gabriela, 2017, ADV COMPUTER VISION
CR  - Deb D., 2018, ARXIV180408790
CR  - Eraslan G, 2019, NAT REV GENET, V20, P389, DOI 10.1038/s41576-019-0122-6
CR  - Fukushima K., 1979, ELECTR COMMUN JPN, V62, P11
CR  - Gomez Alexander, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P747, DOI 10.1007/978-3-319-50835-1_67
CR  - Gomez A., 2016, ARXIV160306169
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
CR  - Greenberg S, 2019, ECOL EVOL, V9, P13706, DOI 10.1002/ece3.5767
CR  - GYSEL LESLIE W., 1956, JOUR WILDLIFE MANAGEMENT, V20, P451, DOI 10.2307/3797161
CR  - He K, 2016, ARXIV160305027, DOI DOI 10.1109/CVPR.2016.90
CR  - He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
CR  - Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
CR  - HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
CR  - Howard A.G., 2013, ARXIV13125402
CR  - Jaderberg M, 2015, ARXIV PREPRINT ARXIV
CR  - JEFFRIES HP, 1984, MAR BIOL, V78, P329, DOI 10.1007/BF00393019
CR  - KARANTH KU, 1995, BIOL CONSERV, V71, P333, DOI 10.1016/0006-3207(94)00057-W
CR  - Kingma DP, 2014, ARXIV PREPRINT ARXIV
CR  - Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI [10.1145/3065386, DOI 10.1145/3065386]
CR  - Meek P.D., 2013, Wildlife Biology in Practice, V9, P7
CR  - Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115
CR  - O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
CR  - Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
CR  - Redmon Joseph, 2016, YOU ONLY LOOK ONCE U, DOI DOI 10.1109/CVPR.2016.91
CR  - Ren SQ, 2015, ADV NEUR IN, V28
CR  - ROBSON D. S., 1964, TRANS AMER FISH SOC, V93, P215, DOI 10.1577/1548-8659(1964)93[215:SSIPME]2.0.CO;2
CR  - Rowcliffe JM, 2008, ANIM CONSERV, V11, P185, DOI 10.1111/j.1469-1795.2008.00180.x
CR  - Sadegh Norouzzadeh M., 2019, ARXIV PREPRINT ARXIV
CR  - Schneider S, 2020, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW50321.2020.9096925
CR  - Schneider S, 2019, METHODS ECOL EVOL, V10, P461, DOI 10.1111/2041-210X.13133
CR  - Schneider S, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P321, DOI 10.1109/CRV.2018.00052
CR  - SIMPSON R, 1991, IEEE CONFERENCE ON NEURAL NETWORKS FOR OCEAN ENGINEERING, P223, DOI 10.1109/ICNN.1991.163354
CR  - Szegedy C., 2015, 2015 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2015.7298594
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
CR  - Willi M, 2019, METHODS ECOL EVOL, V10, P80, DOI 10.1111/2041-210X.13099
CR  - Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
CR  - Zhu X., 2009, SYNTHESIS LECT ARTIF, V3, P1, DOI 10.2200/S00196ED1V01Y200906AIM006
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - APR
PY  - 2020
VL  - 10
IS  - 7
SP  - 3503
EP  - 3517
DO  - 10.1002/ece3.6147
AN  - WOS:000524417200029
N1  - Times Cited in Web of Science Core Collection:  29
Total Times Cited:  29
Cited Reference Count:  48
ER  -

TY  - JOUR
AU  - Rush, GP
AU  - Clarke, LE
AU  - Stone, M
AU  - Wood, MJ
TI  - Can drones count gulls? Minimal disturbance and semiautomated image processing with an unmanned aerial vehicle for colony-nesting seabirds
T2  - ECOLOGY AND EVOLUTION
LA  - English
KW  - aerial survey
KW  - image classification
KW  - Laridae
KW  - monitoring seabird
KW  - population ecology
KW  - STRUCTURE-FROM-MOTION
KW  - WILDLIFE
KW  - BIRDS
AB  - Accurate counts of wild populations are essential to monitor change through time, but some techniques demand specialist surveyors and may result in unacceptable disturbance or inaccurate counts. Recent technological developments in unmanned aerial vehicles (UAVs) offer great potential for a range of survey and monitoring approaches. They literally offer a bird's-eye view, but this increased power of observation presents the challenge of translating large amounts of imagery into accurate survey data. Seabirds, in particular, present the particular challenges of nesting in large, often inaccessible colonies that are difficult to view for ground observers, which are commonly susceptible to disturbance. We develop a protocol for carrying out UAV surveys of a breeding seabird colony (Lesser Black-backed Gulls, Larus fuscus) and subsequent image processing to provide a semiautomated classification for counting the number of birds. Behavioral analysis of the gull colonies demonstrated that minimal disturbance occurred during UAV survey flights at an altitude of 15 m above ground level, which provided high-resolution imagery for analysis. A protocol of best practice was developed using the expertise from both a UAV perspective and that of a dedicated observer. A GIS-based semiautomated classification process successfully counted the gulls, with a mean agreement of 98% and a correlation of 99% with manual counts of imagery. We also propose a method to differentiate between the different gull species captured by our survey. Our UAV survey and analysis approach provide accurate counts (when comparing manual vs. semi-automated counts taken from the UAV imagery) of a wild seabird population with minimal disturbance, with the potential to expand this to include species differentiation. The continued development of analytical and survey tools whilst minimizing the disturbance to wild populations is both key to unlocking the future of the rapid advances in UAV technology for ecological survey.
AD  - Univ Gloucestershire, Sch Nat & Social Sci, Cheltenham, Glos, EnglandAD  - Univ York, Dept Environm & Geog, York, N Yorkshire, EnglandC3  - University of GloucestershireC3  - University of York - UKFU  - Environmental Dynamics and Governance Group at the University of Gloucestershire
FX  - The authors would like to thank the wardens of Skokholm Island (Giselle Eagle and Richard Brown) for their invaluable support in the field and with logistics, for assisting in the observation of behavioral disturbance, and for their insightful feedback on the study. Ethical approval and permissions for the study were granted by Islands Conservation Advisory Committee of the Wildlife Trust for South and West Wales and Natural Resources Wales. We thank Will Carpenter for training on use of the UAV. The project was funded by the Environmental Dynamics and Governance Group at the University of Gloucestershire. We would also like to thank the two anonymous reviewers whose comments helped to improve the final version of the manuscript.
CR  - Agisoft, 2016, AG PHOTOSCAN US MAN
CR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - Bibby C.J., 2000, BIRD CENSUS TECHNIQU, V2nd edn
CR  - Brisson-Curadeau E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18202-3
CR  - Brown R., 2016, SKOKHOLM SEABIRD REP
CR  - Carney KM, 1999, WATERBIRDS, V22, P68, DOI 10.2307/1521995
CR  - Chabot D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122588
CR  - Coulson JC, 2015, BIRD STUDY, V62, P170, DOI 10.1080/00063657.2015.1013523
CR  - Cramp S., 1974, SEABIRDS BRITAIN IRE
CR  - Eaton M. A., 2013, STATE UK BIRDS 2013
CR  - Fonstad MA, 2013, EARTH SURF PROC LAND, V38, P421, DOI 10.1002/esp.3366
CR  - Foody GM, 2006, REMOTE SENS ENVIRON, V103, P179, DOI 10.1016/j.rse.2006.04.001
CR  - Fretwell PT, 2017, IBIS, V159, P481, DOI 10.1111/ibi.12482
CR  - Fretwell PT, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0085285, 10.1371/journal.pone.0088655]
CR  - Fretwell PT, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033751
CR  - Furness R.W., 1993, P86
CR  - Giese M, 1996, BIOL CONSERV, V75, P157, DOI 10.1016/0006-3207(95)00060-7
CR  - Grenzdorffer GJ, 2013, INT ARCH PHOTOGRAMM, P169
CR  - Hodgson JC, 2018, METHODS ECOL EVOL, V9, P1160, DOI 10.1111/2041-210X.12974
CR  - Hodgson JC, 2016, CURR BIOL, V26, pR404, DOI 10.1016/j.cub.2016.04.001
CR  - Hodgson JC, 2016, SCI REP-UK, V6, DOI 10.1038/srep22574
CR  - Jones GP, 2006, WILDLIFE SOC B, V34, P750, DOI 10.2193/0091-7648(2006)34[750:AAOSUA]2.0.CO;2
CR  - Kerlinger P., 2013, WILDLIFE RECREATIONI
CR  - Lillesand T., 2015, REMOTE SENSING IMAGE
CR  - Liu XY, 2007, GEOINFORMATICA, V11, P37, DOI 10.1007/s10707-006-0005-9
CR  - Lloyd C., 1991, STATUS SEABIRDS BRIT
CR  - Loarie S. R., 2007, TRENDS ECOL EVOL, V56, P211
CR  - McEvoy JF, 2016, PEERJ, V4, DOI 10.7717/peerj.1831
CR  - Mitchell P.I., 2004, SEABIRD POPULATIONS
CR  - Mulero-Pazmany M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178448
CR  - Nager RG, 2016, WATERBIRDS, V39, P15, DOI 10.1675/063.039.sp108
CR  - Sarda-Palomera F, 2012, IBIS, V154, P177, DOI 10.1111/j.1474-919X.2011.01177.x
CR  - Schlacher TA, 2013, ESTUAR COAST SHELF S, V118, P31, DOI 10.1016/j.ecss.2012.12.016
CR  - Siebert S, 2014, AUTOMAT CONSTR, V41, P1, DOI 10.1016/j.autcon.2014.01.004
CR  - Thompson G. V. F., 2007, NATURAL HIST SKOKHOL
CR  - Vas E, 2015, BIOL LETTERS, V11, DOI 10.1098/rsbl.2014.0754
CR  - Walsh P.M., 1995, SEABIRD MONITORING H
CR  - Weimerskirch H, 2018, POLAR BIOL, V41, P259, DOI 10.1007/s00300-017-2187-z
CR  - Woodget AS, 2015, EARTH SURF PROC LAND, V40, P47, DOI 10.1002/esp.3613
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - DEC
PY  - 2018
VL  - 8
IS  - 24
SP  - 12322
EP  - 12334
DO  - 10.1002/ece3.4495
AN  - WOS:000454523500004
N1  - Times Cited in Web of Science Core Collection:  31
Total Times Cited:  33
Cited Reference Count:  39
ER  -

TY  - JOUR
AU  - Gaughan, AE
AU  - Kolarik, NE
AU  - Stevens, FR
AU  - Pricope, NG
AU  - Cassidy, L
AU  - Salerno, J
AU  - Bailey, KM
AU  - Drake, M
AU  - Woodward, K
AU  - Hartter, J
TI  - Using Very-High-Resolution Multispectral Classification to Estimate Savanna Fractional Vegetation Components
T2  - REMOTE SENSING
LA  - English
KW  - savannas
KW  - vegetation composition
KW  - Africa
KW  - random forest classifier
KW  - vegetation structure
KW  - unoccupied aerial systems
KW  - ACCURACY ASSESSMENT
KW  - LAND-COVER
KW  - VARIABILITY
KW  - DYNAMICS
KW  - IMAGERY
KW  - FOREST
KW  - PIXEL
AB  - Characterizing compositional and structural aspects of vegetation is critical to effectively assessing land function. When priorities are placed on ecological integrity, remotely sensed estimates of fractional vegetation components (FVCs) are useful for measuring landscape-level habitat structure and function. In this study, we address whether FVC estimates, stratified by dominant vegetation type, vary with different classification approaches applied to very-high-resolution small unoccupied aerial system (UAS)-derived imagery. Using Parrot Sequoia imagery, flown on a DJI Mavic Pro micro-quadcopter, we compare pixel- and segment-based random forest classifiers alongside a vegetation height-threshold model for characterizing the FVC in a southern African dryland savanna. Results show differences in agreement between each classification method, with the most disagreement in shrub-dominated sites. When compared to vegetation classes chosen by visual identification, the pixel-based random forest classifier had the highest overall agreement and was the only classifier not to differ significantly from the hand-delineated FVC estimation. However, when separating out woody biomass components of tree and shrub, the vegetation height-threshold performed better than both random-forest approaches. These findings underscore the utility and challenges represented by very-high-resolution multispectral UAS-derived data (~10 cm ground resolution) and their uses to estimate FVC. Semi-automated approaches statistically differ from by-hand estimation in most cases; however, we present insights for approaches that are applicable across varying vegetation types and structural conditions. Importantly, characterization of savanna land function cannot rely only on a "greenness" measure but also requires a structural vegetation component. Underscoring these insights is that the spatial heterogeneity of vegetation structure on the landscape broadly informs land management, from land allocation, wildlife habitat use, natural resource collection, and as an indicator of overall ecosystem function.
AD  - Univ Louisville, Dept Geog & Environm Sci, Louisville, KY 40292 USAAD  - Boise State Univ, Human Environm Syst Res Ctr, 1910 Univ Dr, Boise, ID 83725 USAAD  - Univ N Carolina, Dept Earth & Ocean Sci, Wilmington, NC 28403 USAAD  - Univ Botswana, Okavango Res Inst, Maun 285, BotswanaAD  - Colorado State Univ, Dept Human Dimens Nat Resources, Grad Degree Program Ecol, Ft Collins, CO 80523 USAAD  - Univ Colorado, Dept Environm Studies, Boulder, CO 80303 USAC3  - University of LouisvilleC3  - Boise State UniversityC3  - University of North CarolinaC3  - University of North Carolina WilmingtonC3  - University of BotswanaC3  - Colorado State UniversityC3  - University of Colorado SystemC3  - University of Colorado BoulderCR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - Archer SR, 2017, SPRINGER SER ENV MAN, P25, DOI 10.1007/978-3-319-46709-2_2
CR  - Asner G., 2010, ECOSYSTEM FUNCTION S, P195, DOI DOI 10.1201/B10275
CR  - Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
CR  - Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - Brandt M, 2020, NATURE, V587, P78, DOI 10.1038/s41586-020-2824-5
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
CR  - Bruzzone L, 2014, REMOTE SENS DIGIT IM, V18, P127, DOI 10.1007/978-94-007-7969-3_9
CR  - BUCKLAND ST, 1993, J APPL ECOL, V30, P478, DOI 10.2307/2404188
CR  - Chadwick KD, 2020, METHODS ECOL EVOL, V11, P1492, DOI 10.1111/2041-210X.13463
CR  - Chadwick KD, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020087
CR  - Chenari A, 2017, INT ARCH PHOTOGRAMM, V42-4, P43, DOI 10.5194/isprs-archives-XLII-4-W4-43-2017
CR  - Cherlet M., 2018, WORLD ATLAS DESERTIF
CR  - COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
CR  - Elliott KC, 2019, IEEE GEOSC REM SEN M, V7, P106, DOI 10.1109/MGRS.2018.2876451
CR  - Farwell LS, 2021, REMOTE SENS ENVIRON, V253, DOI [10.1016/i.rse.2020.112175, 10.1016/j.rse.2020.112175]
CR  - Feng S, 2013, ATMOS CHEM PHYS, V13, P10081, DOI 10.5194/acp-13-10081-2013
CR  - Fisher JT, 2014, APPL VEG SCI, V17, P172, DOI 10.1111/avsc.12048
CR  - Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
CR  - Gamon J.A., 2007, FUNCTIONAL PLANT ECO
CR  - Gaughan AE, 2012, J ARID ENVIRON, V82, P19, DOI 10.1016/j.jaridenv.2012.02.007
CR  - Granzig T, 2021, INT J APPL EARTH OBS, V96, DOI 10.1016/j.jag.2020.102281
CR  - Hardin PJ, 2019, GISCI REMOTE SENS, V56, P309, DOI 10.1080/15481603.2018.1510088
CR  - HOLDRIDGE LR, 1947, SCIENCE, V105, P367, DOI 10.1126/science.105.2727.367
CR  - Jawak S.D., 2015, ADV REMOTE SENS, V4, P177, DOI [DOI 10.4236/ARS.2015.43015, 10.4236/ars.2015.43015]
CR  - Kedia AC, 2021, DRONES-BASEL, V5, DOI 10.3390/drones5010019
CR  - Kolarik NE, 2020, ISPRS J PHOTOGRAMM, V164, P84, DOI 10.1016/j.isprsjprs.2020.04.011
CR  - Liu DS, 2010, REMOTE SENS LETT, V1, P187, DOI 10.1080/01431161003743173
CR  - Liu JG, 2007, SCIENCE, V317, P1513, DOI 10.1126/science.1144004
CR  - Lu B, 2017, ISPRS J PHOTOGRAMM, V128, P73, DOI 10.1016/j.isprsjprs.2017.03.011
CR  - Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
CR  - Melville B, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3010005
CR  - Melville B, 2019, INT J APPL EARTH OBS, V78, P14, DOI 10.1016/j.jag.2019.01.013
CR  - Mishra NB, 2014, INT J REMOTE SENS, V35, P2082, DOI 10.1080/01431161.2014.885666
CR  - Munyati C, 2013, J ARID ENVIRON, V94, P121, DOI 10.1016/j.jaridenv.2013.02.010
CR  - Padua L., 2019, PROG ARTIF INTELL, V11804, P248
CR  - Pontius RG, 2014, INT J REMOTE SENS, V35, P7543, DOI 10.1080/2150704X.2014.969814
CR  - Pricope NG, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3030063
CR  - Pricope NG, 2015, LAND-BASEL, V4, P627, DOI 10.3390/land4030627
CR  - R.Core Team, 2018, R LANG ENV STAT COMP, DOI DOI 10.1007/978-3-540-74686-7
CR  - Rasanen A, 2019, REMOTE SENS ENVIRON, V230, DOI 10.1016/j.rse.2019.05.026
CR  - Riva F, 2021, AMBIO, V50, P1089, DOI 10.1007/s13280-020-01434-5
CR  - Sala OE, 2014, J ECOL, V102, P1357, DOI 10.1111/1365-2745.12326
CR  - Salerno J, 2018, AM SCI, V106, P34
CR  - Scholes RJ, 2002, J VEG SCI, V13, P419, DOI 10.1111/j.1654-1103.2002.tb02066.x
CR  - Scholtz R, 2014, ECOSPHERE, V5, DOI 10.1890/ES14-00034.1
CR  - Smith MW, 2016, PROG PHYS GEOG, V40, P247, DOI 10.1177/0309133315615805
CR  - Smith WK, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111401
CR  - Staver AC, 2011, ECOLOGY, V92, P1063, DOI 10.1890/i0012-9658-92-5-1063
CR  - Stehman SV, 2011, REMOTE SENS ENVIRON, V115, P3044, DOI 10.1016/j.rse.2011.06.007
CR  - STORY M, 1986, PHOTOGRAMM ENG REM S, V52, P397
CR  - Su W, 2008, INT J REMOTE SENS, V29, P3105, DOI 10.1080/01431160701469016
CR  - Touboul JD, 2018, P NATL ACAD SCI USA, V115, pE1336, DOI 10.1073/pnas.1712356115
CR  - Venter ZS, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04616-8
CR  - Weiss G.M., 2001, MLTR43 RUTG U DEP CO, DOI [10.7282/t3-v9kt-9510, DOI 10.7282/T3-V9KT-9510]
CR  - Whiteside TG, 2011, INT J APPL EARTH OBS, V13, P884, DOI 10.1016/j.jag.2011.06.008
CR  - Xu Z, 2020, INT J APPL EARTH OBS, V92, DOI 10.1016/j.jag.2020.102173
CR  - Ye S, 2018, ISPRS J PHOTOGRAMM, V141, P137, DOI 10.1016/j.isprsjprs.2018.04.002
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - FEB
PY  - 2022
VL  - 14
IS  - 3
DO  - 10.3390/rs14030551
AN  - WOS:000754990400001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  60
ER  -

TY  - JOUR
AU  - Zhou, ML
AU  - Elmore, JA
AU  - Samiappan, S
AU  - Evans, KO
AU  - Pfeiffer, MB
AU  - Blackwell, BF
AU  - Iglay, RB
TI  - Improving Animal Monitoring Using Small Unmanned Aircraft Systems (sUAS) and Deep Learning Networks
T2  - SENSORS
LA  - English
KW  - drone
KW  - RPA
KW  - UAV
KW  - UVS
KW  - CNN
KW  - ResNet
KW  - machine learning
KW  - WILDLIFE RESEARCH
KW  - AERIAL VEHICLE
KW  - BACKPROPAGATION
KW  - GRADIENT
KW  - IMAGES
KW  - RATES
KW  - UAS
AB  - In recent years, small unmanned aircraft systems (sUAS) have been used widely to monitor animals because of their customizability, ease of operating, ability to access difficult to navigate places, and potential to minimize disturbance to animals. Automatic identification and classification of animals through images acquired using a sUAS may solve critical problems such as monitoring large areas with high vehicle traffic for animals to prevent collisions, such as animal-aircraft collisions on airports. In this research we demonstrate automated identification of four animal species using deep learning animal classification models trained on sUAS collected images. We used a sUAS mounted with visible spectrum cameras to capture 1288 images of four different animal species: cattle (Bos taurus), horses (Equus caballus), Canada Geese (Branta canadensis), and white-tailed deer (Odocoileus virginianus). We chose these animals because they were readily accessible and white-tailed deer and Canada Geese are considered aviation hazards, as well as being easily identifiable within aerial imagery. A four-class classification problem involving these species was developed from the acquired data using deep learning neural networks. We studied the performance of two deep neural network models, convolutional neural networks (CNN) and deep residual networks (ResNet). Results indicate that the ResNet model with 18 layers, ResNet 18, may be an effective algorithm at classifying between animals while using a relatively small number of training samples. The best ResNet architecture produced a 99.18% overall accuracy (OA) in animal identification and a Kappa statistic of 0.98. The highest OA and Kappa produced by CNN were 84.55% and 0.79 respectively. These findings suggest that ResNet is effective at distinguishing among the four species tested and shows promise for classifying larger datasets of more diverse animals.
AD  - Mississippi State Univ, Geosyst Res Inst, Oxford, MS 39762 USAAD  - Mississippi State Univ, Dept Wildlife Fisheries & Aquaculture, Box 9690, Oxford, MS 39762 USAAD  - USDA, Anim & Plant Hlth Inspect Serv, Wildlife Serv, Natl Wildlife Res Ctr,Ohio Field Stn, Sandusky, OH 44870 USAC3  - Mississippi State UniversityC3  - Mississippi State UniversityC3  - United States Department of Agriculture (USDA)FU  - U.S. Department of Agriculture Animal and Plant Health Inspection Service (USDA APHIS) [AP20WSNWRC00C010, AP20WSNWRC00C026, 692M15-19-T-00017, 692M15-19-F-00348]; Forest and Wildlife Research Center and College of Forest Resources at Mississippi State University
FX  - This work was funded by U.S. Department of Agriculture Animal and Plant Health Inspection Service (USDA APHIS; Cooperative Agreements AP20WSNWRC00C010 and AP20WSNWRC00C026) to Mississippi State University (R.B. Iglay, S. Samiappan, K. O. Evans) via Interagency Agreement between USDA APHIS and the Federal Aviation Administration (FAA IA No. 692M15-19-T-00017/Task Order No. 692M15-19-F-00348) for Task Order No. 2, Research Activities on Wildlife Hazards to Aviation. Additional support was provided by the Forest and Wildlife Research Center and College of Forest Resources at Mississippi State University.
CR  - AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
CR  - Anderson K, 2013, FRONT ECOL ENVIRON, V11, P138, DOI 10.1890/120150
CR  - [Anonymous], Torchvision.transforms-Torchvision 0.10.0 documentation
CR  - Attoh-Okine NO, 1999, ADV ENG SOFTW, V30, P291, DOI 10.1016/S0965-9978(98)00071-4
CR  - Bennitt E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38610-x
CR  - Blackwell B., AVIAN SURVEY METHODS
CR  - Brownlee J., 2018, DIFFERENCE BATCH EPO
CR  - Buckland ST, 2012, J APPL ECOL, V49, P960, DOI 10.1111/j.1365-2664.2012.02150.x
CR  - Chabot D, 2016, J FIELD ORNITHOL, V87, P343, DOI 10.1111/jofo.12171
CR  - Chabot D, 2015, J UNMANNED VEH SYST, V3, P137, DOI 10.1139/juvs-2015-0021
CR  - Chaganti SY., 2020, 2020 INT C COMP SCI, P1
CR  - Cho K., 2011, P 28 INT C INT C MAC, P105
CR  - Christie KS, 2016, FRONT ECOL ENVIRON, V14, P242, DOI 10.1002/fee.1281
CR  - DeVault T., WILDLIFE AIRPORTS WI
CR  - DeVault TL, 2018, WILDLIFE SOC B, V42, P94, DOI 10.1002/wsb.859
CR  - Dolbeer R.A., WILDLIFE STRIKES CIV
CR  - Frederick P.C., 2003, J FIELD ORNITHOL
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Han XZ, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA 2020), P76, DOI 10.1109/ICCIA49625.2020.00022
CR  - Hayes Madeline C., 2021, Ornithological Applications, V123, pduab022
CR  - Hodgson JC, 2018, METHODS ECOL EVOL, V9, P1160, DOI 10.1111/2041-210X.12974
CR  - Hodgson JC, 2016, SCI REP-UK, V6, DOI 10.1038/srep22574
CR  - Hong SJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071651
CR  - Hubbard S, 2018, J UNMANNED VEH SYST, V6, P1, DOI 10.1139/juvs-2016-0020
CR  - Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
CR  - Kastner, 2014, 2014 IEEE 11 C MOB, DOI 10.1109/mass.2014.48
CR  - Keshari R, 2018, PROC CVPR IEEE, P9349, DOI 10.1109/CVPR.2018.00974
CR  - Lawrence S, 2000, IEEE IJCNN, P114, DOI 10.1109/IJCNN.2000.857823
CR  - Li Y., ARXIV190704595
CR  - Linchant J, 2015, MAMMAL REV, V45, P239, DOI 10.1111/mam.12046
CR  - Liu L, 2021, POSTGRAD MED, V133, P265, DOI 10.1080/00325481.2020.1803666
CR  - Liu T., ARXIV150601195
CR  - Lyons MB, 2019, METHODS ECOL EVOL, V10, P1024, DOI 10.1111/2041-210X.13194
CR  - Manohar N, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P156, DOI 10.1109/ICACCI.2016.7732040
CR  - McEvoy JF, 2016, PEERJ, V4, DOI 10.7717/peerj.1831
CR  - Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
CR  - Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
CR  - Perez L, 2017, ARXIV171204621
CR  - Pfeiffer MB, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206599
CR  - Pimm SL, 2015, TRENDS ECOL EVOL, V30, P685, DOI 10.1016/j.tree.2015.08.008
CR  - QUENOUILLE MH, 1956, BIOMETRIKA, V43, P353
CR  - Ratcliffe N, 2015, J UNMANNED VEH SYST, V3, P95, DOI 10.1139/juvs-2015-0006
CR  - Reintsma KM, 2018, WATERBIRDS, V41, P326, DOI 10.1675/063.041.0314
CR  - Rush GP, 2018, ECOL EVOL, V8, P12322, DOI 10.1002/ece3.4495
CR  - Sasse DB, 2003, WILDLIFE SOC B, V31, P1015
CR  - Scholten CN, 2019, BIOL CONSERV, V233, P241, DOI 10.1016/j.biocon.2019.03.001
CR  - Seymour AC, 2017, SCI REP-UK, V7, DOI 10.1038/srep45127
CR  - Steele WK, 2021, WILDLIFE RES, V48, P422, DOI 10.1071/WR20127
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - Thanapol Panissara, 2020, 2020 5th International Conference on Information Technology (InCIT), P300, DOI 10.1109/InCIT50588.2020.9310787
CR  - Viera AJ, 2005, FAM MED, V37, P360
CR  - Washburn BE, 2021, WILDLIFE SOC B, V45, P237, DOI 10.1002/wsb.1177
CR  - Weinstein BG, 2018, J ANIM ECOL, V87, P533, DOI 10.1111/1365-2656.12780
CR  - Wilson DR, 2001, IEEE IJCNN, P115, DOI 10.1109/IJCNN.2001.939002
CR  - Wu Haibing, 2015, MAX POOLING DROPOUT
CR  - Zualkernan IA, 2020, 2020 IEEE GLOBAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERNET OF THINGS (GCAIOT), P111, DOI 10.1109/GCAIOT51063.2020.9345858
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - SEP
PY  - 2021
VL  - 21
IS  - 17
DO  - 10.3390/s21175697
AN  - WOS:000695608700001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  56
ER  -

TY  - JOUR
AU  - Stratton, C
AU  - Irvine, KM
AU  - Banner, KM
AU  - Wright, WJ
AU  - Lausen, C
AU  - Rae, J
TI  - Coupling validation effort with in situ bioacoustic data improves estimating relative activity and occupancy for multiple species with cross-species misclassifications
T2  - METHODS IN ECOLOGY AND EVOLUTION
LA  - English
KW  - acoustic data
KW  - count detection model
KW  - coupled classification
KW  - false positives
KW  - occupancy modelling
KW  - species misclassification
KW  - survey effort
AB  - The increasing complexity and pace of ecological change requires natural resource managers to consider entire species assemblages. Acoustic recording units (ARUs) require minimal cost and effort to deploy and inform relative activity, or encounter rates, for multiple species simultaneously. ARU-based surveys require post-processing of the recordings via software algorithms that assign a species label to each recording. The automated classification process can result in cross-species misidentifications that should be accounted for when employing statistical modelling for conservation decision-making. Using simulation and ARU-based detection counts from 17 bat species in British Columbia, Canada, we investigate three strategies for adjusting statistical inference for species misclassification: (a) 'coupling' ambiguous and unambiguous detections by validating a subset of survey events post-hoc, (b) using a calibration dataset on the software algorithm's (in)accuracy for species identification or (c) specifying informative Bayesian priors on classification probabilities. We explore the impact of different Bayesian prior specifications for the classification probabilities on posterior estimation. We then consider how the quantity of data validated post-hoc impacts model convergence and resulting inferences for bat species relative activity as related to nightly conditions and yearly site occupancy after accounting for site-level environmental variables. Coupled methods resulted in less bias and uncertainty when estimating relative activity and species classification probabilities relative to calibration approaches. We found that species that were difficult-to-detect and those that were often inaccurately identified by the software required more validation effort than more easily detected and/or identified species. Our results suggest that, when possible, acoustic surveys should rely on coupled validated detection information to account for false-positive detections, rather than uncoupled calibration datasets. However, if the assemblage of interest contains a large number of rarely detected or less prevalent species, an intractable amount of effort may be required, suggesting there are benefits to curating a calibration dataset that is representative of the observation process. Our findings provide insights into the practical challenges associated with statistical analyses of ARU data and possible analytical solutions to support reliable and cost-effective decision-making for wildlife conservation/management in the face of known sources of observation errors.
AD  - Montana State Univ, Bozeman, MT 59717 USAAD  - US Geol Survey, Northern Rocky Mt Sci Ctr, Bozeman, MT 59717 USAAD  - Colorado State Univ, Ft Collins, CO 80523 USAAD  - Wildlife Conservat Soc Canada, Kaslo, BC, CanadaAD  - Wildlife Conservat Soc Canada, Nelson, BC, CanadaC3  - Montana State University SystemC3  - Montana State University BozemanC3  - United States Department of the InteriorC3  - United States Geological SurveyC3  - Colorado State UniversityFU  - Montana State University [G20AC00406]; U.S. Geological Survey
FX  - Montana State University, Grant/Award Number: G20AC00406; U.S. Geological Survey
CR  - Balantic C, 2019, ECOL APPL, V29, DOI 10.1002/eap.1854
CR  - Banner KM, 2018, ECOL EVOL, V8, P6144, DOI 10.1002/ece3.4162
CR  - Baumgardt JA, 2019, RANGELAND ECOL MANAG, V72, P168, DOI 10.1016/j.rama.2018.07.010
CR  - Beason RD, 2019, BIOACOUSTICS, V28, P381, DOI 10.1080/09524622.2018.1463293
CR  - Berger JO, 2015, BAYESIAN ANAL, V10, P189, DOI 10.1214/14-BA915
CR  - Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675
CR  - Chambert T, 2018, METHODS ECOL EVOL, V9, P1468, DOI 10.1111/2041-210X.12985
CR  - Chambert T, 2018, METHODS ECOL EVOL, V9, P560, DOI 10.1111/2041-210X.12910
CR  - Chambert T, 2015, ECOLOGY, V96, P332, DOI 10.1890/14-1507.1
CR  - de Valpine P., 2020, NIMBLE MCMC PARTICLE
CR  - de Valpine P, 2017, J COMPUT GRAPH STAT, V26, P403, DOI 10.1080/10618600.2016.1172487
CR  - Field SA, 2005, J WILDLIFE MANAGE, V69, P473, DOI 10.2193/0022-541X(2005)069[0473:OAOMEU]2.0.CO;2
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Guillera-Arroita G, 2017, METHODS ECOL EVOL, V8, P1081, DOI 10.1111/2041-210X.12743
CR  - Johnson, 2015, PLAN N AM BAT MONITO
CR  - Kery M, 2008, J APPL ECOL, V45, P589, DOI 10.1111/j.1365-2664.2007.01441.x
CR  - Kery M., 2021, APPL HIERARCHICAL MO, V2
CR  - Kiskin I., 2021, ZENODO
CR  - MacKenzie D.I., 2016, OCCUPANCY ESTIMATION
CR  - MacKenzie DI, 2002, ECOLOGY, V83, P2248, DOI 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2
CR  - Measey GJ, 2017, J APPL ECOL, V54, P894, DOI 10.1111/1365-2664.12810
CR  - Sugai LSM, 2019, BIOSCIENCE, V69, P15, DOI 10.1093/biosci/biy147
CR  - Morganti M, 2019, AVIAN RES, V10, DOI 10.1186/s40657-019-0154-9
CR  - Newson SE, 2017, METHODS ECOL EVOL, V8, P1051, DOI 10.1111/2041-210X.12720
CR  - Reichert B., 2018, US GEOLOGICAL SURVEY, P1
CR  - Reichert BE, 2021, AMBIO, V50, P901, DOI 10.1007/s13280-020-01411-y
CR  - Royle JA, 2006, ECOLOGY, V87, P835, DOI 10.1890/0012-9658(2006)87[835:GSOMAF]2.0.CO;2
CR  - Shonfield J, 2017, AVIAN CONSERV ECOL, V12, DOI 10.5751/ACE-00974-120114
CR  - Spiers A., 2021, ESTIMATING OCCUPANCY
CR  - Stratton C., 2022, ZENODO, DOI [10.5281/zenodo.6040068, DOI 10.5281/ZENODO.6040068]
CR  - Wright W. J., 2019, CODE RELEASE BAT DAT, DOI [10.5066/P9QK83LD, DOI 10.5066/P9QK83LD]
CR  - Wright WJ, 2020, METHODS ECOL EVOL, V11, P71, DOI 10.1111/2041-210X.13315
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DO  - 10.1111/2041-210X.13831
AN  - WOS:000774015600001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  32
ER  -

TY  - JOUR
AU  - Tabak, MA
AU  - Murray, KL
AU  - Reed, AM
AU  - Lombardi, JA
AU  - Bay, KJ
TI  - Automated classification of bat echolocation call recordings with artificial intelligence
T2  - ECOLOGICAL INFORMATICS
LA  - English
KW  - Bats
KW  - Computer vision
KW  - Deep learning
KW  - Echolocation
KW  - Passive sampling
KW  - Threatened and endangered species
KW  - CAMERA-TRAP IMAGES
KW  - IDENTIFICATION
AB  - Acoustic recorders are commonly used to remotely monitor and collect data on bats (Order Chiroptera). These efforts result in many acoustic recordings that must be classified by a bat biologist with expertise in call classification in order to obtain useful information. The rarity of this expertise and time constraints have prompted efforts to automatically classify bat species in acoustic recordings using a variety of learning methods. There are several software programs available for this purpose, but they are imperfect and the United States Fish and Wildlife Service often recommends that a qualified acoustic analyst review bat call identifications even if using these software programs. We sought to build a model to classify bat species using modern computer vision techniques. We used images of bat echolocation calls (i.e., plots of the pulses) to train deep learning computer vision models that automatically classify bat calls to species. Our model classifies 10 species, five of which are protected under the Endangered Species Act. We evaluated our models using standard model validation procedures, and performed two external tests. For these tests, an entire dataset was withheld from the procedure before splitting the data into training and validation sets. We found that our validation accuracy (92%) and testing accuracy (90%) were higher than when we used Kaleidoscope Pro and BCID software (65% and 61% accuracy, respectively) to evaluate the same calls. Our results suggest that our approach is effective at classifying bat species from acoustic recordings, and our trained model will be incorporated into new bat call identification software: WEST-EchoVision.
AD  - ULC, Western EcoSyst Technol, 1000 9th Ave SW Suite 303, Calgary, AB T2P 2Y6, CanadaAD  - Western EcoSyst Technol Inc, 408 West 6th St, Bloomington, IN 47404 USAAD  - Western EcoSyst Technol Inc, 415 W 17th St Suite 200, Cheyenne, WY 82001 USAFU  - MidAmerican Energy Company; USFWS "Cooperative Endangered Species Conservation Fund"
FX  - MidAmerican Energy Company funded the development to help support their efforts in developing a Habitat Conservation Plan for wind energy generation assets in Iowa. We thank the Illinois-Iowa Ecological Services Field Office and Iowa Department of Natural Resources for access to acoustic data and the USFWS "Cooperative Endangered Species Conservation Fund" that supported the collection of acoustic data in Iowa. We also thank all of our collaborators for access to acoustic data from multiple states and to those who helped collect and compile known bat calls including Dr. Lynn Robbins, Dr. Eric Britzke, Ryan Allen, and Andrew Krause.
CR  - Armitage DW, 2010, ECOL INFORM, V5, P465, DOI 10.1016/j.ecoinf.2010.08.001
CR  - Arroyo-Cabrales J., 2016, IUCN RED LIST THREAT
CR  - Bat Call Identification, 2016, BCID BAT CALL IDENTI
CR  - Beery S., 2019, EFFICIENT PIPELINE C
CR  - Britzke ER, 2013, ACTA THERIOL, V58, P109, DOI 10.1007/s13364-013-0131-3
CR  - Britzke ER, 2011, J WILDLIFE MANAGE, V75, P660, DOI 10.1002/jwmg.68
CR  - Chen X, 2020, BIOL CONSERV, V241, DOI 10.1016/j.biocon.2019.108269
CR  - Christopoulos D., 2016, SSRN SCHOLARLY PAPER, DOI [10.2139/ssrn.3043076, DOI 10.2139/SSRN.3043076]
CR  - Christopoulos D.T., 2019, INFLECTION FINDS INF
CR  - Clement MJ, 2014, ECOL EVOL, V4, P3482, DOI 10.1002/ece3.1201
CR  - Gibb R, 2019, METHODS ECOL EVOL, V10, P169, DOI 10.1111/2041-210X.13101
CR  - Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
CR  - Hayes MA, 2019, ECOL APPL, V29, DOI 10.1002/eap.1881
CR  - He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
CR  - Hey J, 2003, TRENDS ECOL EVOL, V18, P597, DOI 10.1016/j.tree.2003.08.014
CR  - Hoyt JR, 2021, NAT REV MICROBIOL, V19, P196, DOI 10.1038/s41579-020-00493-5
CR  - Lemen C, 2015, WEST N AM NATURALIST, V75, P218, DOI 10.3398/064.075.0210
CR  - Lopez-Baucells A, 2019, ECOL INFORM, V49, P45, DOI 10.1016/j.ecoinf.2018.11.004
CR  - Mac Aodha O, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005995
CR  - Marchal J, 2021, BIOACOUSTICS, DOI 10.1080/09524622.2021.1945952
CR  - Murray KL, 2009, ACTA CHIROPTEROL, V11, P415, DOI 10.3161/150811009X485639
CR  - Murray KL, 1999, ACTA CHIROPTEROL, V1, P105
CR  - O'Farrell MJ, 1999, J MAMMAL, V80, P11, DOI 10.2307/1383203
CR  - Parsons Stuart, 2009, P91
CR  - Paszke A., 2019, Advances in Neural Information Processing Systems, V32, P8026
CR  - Pedregosa F., 2011, Scikit-learn: machine learning in python
CR  - Platto S, 2021, BIOCHEM BIOPH RES CO, V538, P2, DOI 10.1016/j.bbrc.2020.10.028
CR  - Python Software Foundation, 2020, PYTHON
CR  - Pytorch Core Team, 2021, TORCHVISION IMAGE VI
CR  - R Core Team, 2019, R LANG ENV STAT COMP
CR  - Ruff ZJ, 2020, REMOTE SENS ECOL CON, V6, P79, DOI 10.1002/rse2.125
CR  - Russo D, 2016, ECOL INDIC, V66, P598, DOI 10.1016/j.ecolind.2016.02.036
CR  - Rydell J, 2017, ECOL INDIC, V78, P416, DOI 10.1016/j.ecolind.2017.03.023
CR  - Schneider S, 2020, ECOL EVOL, V10, P3503, DOI 10.1002/ece3.6147
CR  - Schnitzler HU, 2003, TRENDS ECOL EVOL, V18, P386, DOI 10.1016/S0169-5347(03)00185-X
CR  - Singh P, 2020, IEEE SW SYMP IMAG, P66, DOI 10.1109/SSIAI49293.2020.9094613
CR  - Solari S., 2018, IUCN RED LIST THREAT
CR  - Solari S., 2017, IUCN RED LIST THREAT
CR  - Tabak MA, 2020, ECOL EVOL, V10, P10374, DOI 10.1002/ece3.6692
CR  - Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
CR  - United States Fish and Wildlife Service, 2021, SPECIES PROFILE GRAY
CR  - United States Fish and Wildlife Service,, 2021, SPECIES PROFILE INDI
CR  - United States Fish and Wildlife Service,, 2021, SPECIES PROFILE NO L
CR  - Wildlife Acoustics, 2012, KALEIDOSCOPE
CR  - Yates MD, 2006, J WILDLIFE MANAGE, V70, P1238, DOI 10.2193/0022-541X(2006)70[1238:EOFSAF]2.0.CO;2
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - MAY
PY  - 2022
VL  - 68
DO  - 10.1016/j.ecoinf.2021.101526
AN  - WOS:000792134500003
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  45
ER  -

TY  - JOUR
AU  - Ravoor, PC
AU  - Sudarshan, TSB
TI  - Deep Learning Methods for Multi-Species Animal Re-identification and Tracking - a Survey
T2  - COMPUTER SCIENCE REVIEW
LA  - English
KW  - Animal re-identification
KW  - Cross-camera tracking
KW  - Deep learning
KW  - Multi species re-identification
KW  - Open-set re-identification
AB  - Technology has an important part to play in wildlife and ecosystem conservation, and can vastly reduce time and effort spent in the associated tasks. Deep learning methods for computer vision in particular show good performance on a variety of tasks; animal detection and classification using deep learning networks are widely used to assist ecological studies. A related challenge is tracking animal movement over multiple cameras. For effective animal movement tracking, it is necessary to distinguish between individuals of the same species to correctly identify an individual moving between two cameras. Such problems could potentially be solved through animal re-identification methods. In this paper, the applicability of existing animal re-identification techniques for fully automated individual animal tracking in a cross-camera setup is explored. Recent developments in animal re-identification in the context of open-set recognition of individuals, and the extension of these systems to multiple species is examined. Some of the best performing human re-identification and object tracking systems are also reviewed in view of extending ideas within them to individual animal tracking. The survey concludes by presenting common trends in re-identification methods, lists a few challenges in the domain and recommends possible solutions. (C) 2020 Elsevier Inc. All rights reserved.
AD  - PES Univ, Dept CSE, Bengaluru, IndiaC3  - PES UniversityCR  - Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
CR  - Bergamini L, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P184, DOI 10.1109/SITIS.2018.00036
CR  - Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
CR  - Bouma S, 2018, 2018 INT C IM VIS CO, P16, DOI [10.1109/IVCNZ.2018.8634778, DOI 10.1109/IVCNZ.2018.8634778]
CR  - Brust CA, 2017, IEEE INT CONF COMP V, P2820, DOI 10.1109/ICCVW.2017.333
CR  - Cheema GS, 2017, LECT NOTES ARTIF INT, V10536, P27, DOI 10.1007/978-3-319-71273-4_3
CR  - CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
CR  - Deb D., 2018, ARXIV180408790
CR  - Freytag A, 2016, LECT NOTES COMPUT SC, V9796, P51, DOI 10.1007/978-3-319-45886-1_5
CR  - Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
CR  - Hays GC, 2019, TRENDS ECOL EVOL, V34, P459, DOI 10.1016/j.tree.2019.01.009
CR  - Hermans A, 2017, ARXIV PREPRINT
CR  - Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
CR  - Jeon, 2019, ARXIV190700831
CR  - Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
CR  - Koch G., 2015, ICML DEEP LEARN WORK, V2
CR  - Korschens M, 2019, IEEE INT CONF COMP V, P263, DOI 10.1109/ICCVW.2019.00035
CR  - Konovalov D. A., 2018, J GEOSCIENCE ENV PRO, V6, P25
CR  - Korschens M, 2018, ARXIV181204418
CR  - Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
CR  - Li Shuyuan, 2019, ARXIV190605586
CR  - Lit ZY, 2018, 2018 INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND ARTIFICIAL INTELLIGENCE (ACAI 2018), DOI 10.1145/3302425.3302460
CR  - Liu C, 2019, IEEE INT CONF COMP V, P315, DOI 10.1109/ICCVW.2019.00042
CR  - Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
CR  - Luo Hao, 2019, IEEE C COMP VIS PATT
CR  - Matas, 2018, VIS OBS AN VERT INS
CR  - Milan A., 2016, ARXIV160300831
CR  - Phyo C.N., 2018, P INT C IM VIS COMP, P1, DOI DOI 10.1109/IVCNZ.2018.8634739
CR  - Qi He, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P714, DOI 10.1007/978-3-030-31723-2_61
CR  - Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
CR  - Ren SQ, 2015, ADV NEUR IN, V28
CR  - Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
CR  - Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
CR  - Schneider S, 2020, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW50321.2020.9096925
CR  - Schneider S, 2019, METHODS ECOL EVOL, V10, P461, DOI 10.1111/2041-210X.13133
CR  - Schroder G, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P7
CR  - Shukla A, 2019, IEEE INT CONF COMP V, P294, DOI 10.1109/ICCVW.2019.00039
CR  - Shukla A, 2019, LECT NOTES ARTIF INT, V11672, P387, DOI 10.1007/978-3-030-29894-4_32
CR  - Simonyan K., 2014, ARXIV PREPRINT ARXIV, DOI 10.48550/arXiv.1409.1556
CR  - Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
CR  - Wang GC, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8933
CR  - Wang H., 2018, ARXIV181112150
CR  - Whitehead H., 1990, Reports of the International Whaling Commission Special Issue, P71
CR  - Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
CR  - Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
CR  - Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - NOV
PY  - 2020
VL  - 38
DO  - 10.1016/j.cosrev.2020.100289
AN  - WOS:000594311100018
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  46
ER  -

TY  - JOUR
AU  - Vogeler, JC
AU  - Braaten, JD
AU  - Slesak, RA
AU  - Falkowski, MJ
TI  - Extracting the full value of the Landsat archive: Inter-sensor harmonization for the mapping of Minnesota forest canopy cover (1973-2015)
T2  - REMOTE SENSING OF ENVIRONMENT
LA  - English
KW  - Canopy cover
KW  - Landsat time series
KW  - LandsatLinkr
KW  - LandTrendr
KW  - Minnesota
KW  - CONTERMINOUS UNITED-STATES
KW  - TIME-SERIES
KW  - SURFACE REFLECTANCE
KW  - NATIONAL-PARK
KW  - PERCENT TREE
KW  - DISTURBANCE
KW  - CLASSIFICATION
KW  - LANDSCAPE
KW  - IMAGERY
KW  - LEVEL
AB  - Remote sensing estimates of forest canopy cover have frequently been used to support a variety of applications including wildlife habitat modeling, monitoring of watershed health, change detection, and are also correlated to various aspects of forest structure and ecosystem function. Although data from the long running Landsat earth observation program (1972-present) have been previously utilized to characterize forest canopy cover, the variability in spatial and spectral resolutions between the Landsat sensors has generally limited analyses to readily comparable imagery from the TM and ETM + sensors, which omits large portions of the full temporal record. In this study, we present an R package, LandsatLinkr, which automates the processes for harmonizing Landsat MSS and OLI imagery to the spatial and spectral qualities of TM and ETM + imagery, allowing for the generation of annual cloud-free composites of tasseled cap spectral indices across the entire Landsat archive. We demonstrate the utility of LandsatLinkr products, further enhanced through the LandTrendr segmentation algorithm, for characterizing forest attributes through time by developing annual forest masks and maps of estimated canopy cover for the state of Minnesota from 1973 to 2015. The forest mask model had an overall accuracy of 87%, with omission and commission errors for the forest class of 17% and 10%, respectively, and 9% and 16% for non-forest classification. Our resulting maps depicted a significant positive trend in forest cover across all ecological provinces of Minnesota during the study period. A random forest model used to predict continuous canopy cover had a pseudo R-2 of 0.75, with a cross validation RMSE of 5%. Our results are comparable to previous Landsat-based canopy cover mapping efforts, but expand the evaluation time period as we were able to utilize the entire Landsat archive for assessment.
AD  - Univ Minnesota, Dept Forest Resources, St Paul, MN 55108 USAAD  - Oregon State Univ, Coll Earth Ocean & Atmospher Sci, Corvallis, OR 97331 USAAD  - Minnesota Forest Resources Council, St Paul, MN 55108 USAAD  - Colorado State Univ, Dept Ecosyst Sci & Sustainabil, Ft Collins, CO 80523 USAC3  - University of Minnesota SystemC3  - University of Minnesota Twin CitiesC3  - Oregon State UniversityC3  - Colorado State UniversityFU  - Environment and Natural Resources Trust Fund, Minnesota Department of Natural Resources; Minnesota Forest Resources Council
FX  - We would like to acknowledge the Environment and Natural Resources Trust Fund, Minnesota Department of Natural Resources, and the Minnesota Forest Resources Council for project funding. We thank Kevin Buffington and Patrick Fekety for R assistance and additional insights which contributed to our study along with Erik Haunreiter and additional members of Warren Cohen's LARSE laboratory at Oregon State University. We appreciate access to the LandTrendr algorithm granted by Robert Kennedy.
CR  - Ahmed OS, 2015, ISPRS J PHOTOGRAMM, V101, P89, DOI 10.1016/j.isprsjprs.2014.11.007
CR  - Braaten JD, 2015, REMOTE SENS ENVIRON, V169, P128, DOI 10.1016/j.rse.2015.08.006
CR  - Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
CR  - Brooks EB, 2014, IEEE T GEOSCI REMOTE, V52, P3316, DOI 10.1109/TGRS.2013.2272545
CR  - Carreiras JMB, 2006, FOREST ECOL MANAG, V223, P45, DOI 10.1016/j.foreco.2005.10.056
CR  - CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
CR  - Chavez PS, 1996, PHOTOGRAMM ENG REM S, V62, P1025
CR  - COHEN WB, 1995, INT J REMOTE SENS, V16, P721, DOI 10.1080/01431169508954436
CR  - Cohen WB, 2004, BIOSCIENCE, V54, P535, DOI 10.1641/0006-3568(2004)054[0535:LRIEAO]2.0.CO;2
CR  - Core Team R., 2019, R LANG ENV STAT COMP
CR  - Coulston JW, 2012, PHOTOGRAMM ENG REM S, V78, P715, DOI 10.14358/PERS.78.7.715
CR  - CRIST EP, 1984, IEEE T GEOSCI REMOTE, V22, P256, DOI 10.1109/TGRS.1984.350619
CR  - CRIST EP, 1985, REMOTE SENS ENVIRON, V17, P301, DOI 10.1016/0034-4257(85)90102-6
CR  - Crook DA, 1999, MAR FRESHWATER RES, V50, P941, DOI 10.1071/MF99072
CR  - Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
CR  - Falkowski MJ, 2009, REMOTE SENS ENVIRON, V113, P946, DOI 10.1016/j.rse.2009.01.003
CR  - Frescino T. S., 2012, General Technical Report - Southern Research Station, USDA Forest Service, P237
CR  - Greenfield EJ, 2009, PHOTOGRAMM ENG REM S, V75, P1279, DOI 10.14358/PERS.75.11.1279
CR  - Hadi, 2016, INT J APPL EARTH OBS, V53, P118, DOI 10.1016/j.jag.2016.08.009
CR  - Hansen MC, 2011, REMOTE SENS LETT, V2, P279, DOI 10.1080/01431161.2010.519002
CR  - Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1244693, 10.1126/science.1215904]
CR  - Hartanto H, 2003, FOREST ECOL MANAG, V180, P361, DOI 10.1016/S0378-1127(02)00656-4
CR  - Healey SP, 2006, REMOTE SENS ENVIRON, V101, P115, DOI 10.1016/j.rse.2005.12.006
CR  - Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
CR  - Huang CQ, 2010, REMOTE SENS ENVIRON, V114, P183, DOI 10.1016/j.rse.2009.08.017
CR  - Hudak AT, 2008, REMOTE SENS ENVIRON, V112, P2232, DOI 10.1016/j.rse.2007.10.009
CR  - Hughes MJ, 2017, FORESTS, V8, DOI 10.3390/f8050166
CR  - Jennings SB, 1999, FORESTRY, V72, P59, DOI 10.1093/forestry/72.1.59
CR  - Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
CR  - Jones KB, 2001, LANDSCAPE ECOL, V16, P301, DOI 10.1023/A:1011175013278
CR  - Kennedy RE, 2003, INT J REMOTE SENS, V24, P3467, DOI 10.1080/0143116021000024249
CR  - Kennedy RE, 2015, REMOTE SENS ENVIRON, V166, P271, DOI 10.1016/j.rse.2015.05.005
CR  - Kennedy RE, 2010, REMOTE SENS ENVIRON, V114, P2897, DOI 10.1016/j.rse.2010.07.008
CR  - Koy K, 2005, ANIM CONSERV, V8, P289, DOI 10.1017/S1367943005002209
CR  - Lawrence RL, 2006, REMOTE SENS ENVIRON, V100, P356, DOI 10.1016/j.rse.2005.10.014
CR  - Liaw A, 2002, FOREST@, V2, P18, DOI DOI 10.1177/154405910408300516
CR  - Masek JG, 2013, ECOSYSTEMS, V16, P1087, DOI 10.1007/s10021-013-9669-9
CR  - Masek JG, 2006, IEEE GEOSCI REMOTE S, V3, P68, DOI 10.1109/LGRS.2005.857030
CR  - Miles P. D., 2007, USDA FOREST SERVICE
CR  - Miles P. D., 2012, NRS175 USDA FOR SERV
CR  - Miles P. D., 2008, NRS24 USDA FOR SERV
CR  - Miles P. D., 2015, RESOURCE UPDATE FS 4
CR  - Minnesota Department of Natural Resources, 1999, EC CLASS SYST
CR  - Minnesota Department of Natural Resources, 2004, MINN DIG EL MOD 30 M
CR  - Minnesota Pollution Control Agency, 2015, WQBWM109 MIN POLL OC
CR  - Moisen GG, 2016, GLOBAL CHANGE BIOL, V22, P3518, DOI 10.1111/gcb.13358
CR  - Moore RD, 2005, J AM WATER RESOUR AS, V41, P813, DOI 10.1111/j.1752-1688.2005.tb04465.x
CR  - Murphy MA, 2010, ECOLOGY, V91, P252, DOI 10.1890/08-0879.1
CR  - Neigh CSR, 2014, REMOTE SENS-BASEL, V6, P2782, DOI 10.3390/rs6042782
CR  - Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
CR  - Pflugmacher D, 2012, REMOTE SENS ENVIRON, V122, P146, DOI 10.1016/j.rse.2011.09.025
CR  - Pickell PD, 2016, INT J REMOTE SENS, V37, P138, DOI 10.1080/2150704X.2015.1126375
CR  - Pierce AD, 2012, FOREST ECOL MANAG, V279, P77, DOI 10.1016/j.foreco.2012.05.010
CR  - Potapov PV, 2015, REMOTE SENS ENVIRON, V159, P28, DOI 10.1016/j.rse.2014.11.027
CR  - Powell SL, 2010, REMOTE SENS ENVIRON, V114, P1053, DOI 10.1016/j.rse.2009.12.018
CR  - Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1
CR  - Roy DP, 2016, REMOTE SENS ENVIRON, V185, P57, DOI 10.1016/j.rse.2015.12.024
CR  - SCHWAB FE, 1991, CAN J ZOOL, V69, P3071, DOI 10.1139/z91-431
CR  - Sexton JO, 2013, INT J DIGIT EARTH, V6, P427, DOI 10.1080/17538947.2013.786146
CR  - Swanson D. L., 2008, BIRDS N AM
CR  - Vermote E, 2016, REMOTE SENS ENVIRON, V185, P46, DOI 10.1016/j.rse.2016.04.008
CR  - Vogeler JC, 2016, REV TELEDETEC, P1, DOI 10.4995/raet.2016.3981
CR  - Vogelmann JE, 2012, REMOTE SENS ENVIRON, V122, P92, DOI 10.1016/j.rse.2011.06.027
CR  - Woodcock CE, 2008, SCIENCE, V320, P1011, DOI 10.1126/science.320.5879.1011a
CR  - Zhu Z, 2015, REMOTE SENS ENVIRON, V162, P67, DOI 10.1016/j.rse.2015.02.009
CR  - Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
CR  - Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
PU  - ELSEVIER SCIENCE INC
PI  - NEW YORK
PA  - STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
DA  - MAY
PY  - 2018
VL  - 209
SP  - 363
EP  - 374
DO  - 10.1016/j.rse.2018.02.046
AN  - WOS:000430897300026
N1  - Times Cited in Web of Science Core Collection:  43
Total Times Cited:  43
Cited Reference Count:  67
ER  -

TY  - JOUR
AU  - Lostanlen, V
AU  - Salamon, J
AU  - Farnsworth, A
AU  - Kelling, S
AU  - Bello, JP
TI  - Robust sound event detection in bioacoustic sensor networks
T2  - PLOS ONE
LA  - English
KW  - SIGNAL-PROCESSING RESEARCH
KW  - ADAPTIVE NEURAL-NETWORK
KW  - ONSET DETECTION
KW  - BIRD MIGRATION
KW  - FLIGHT CALLS
KW  - WEATHER
KW  - CLASSIFICATION
KW  - DIVERSITY
KW  - ECOLOGY
KW  - MODELS
AB  - Bioacoustic sensors, sometimes known as autonomous recording units (ARUs), can record sounds of wildlife over long periods of time in scalable and minimally invasive ways. Deriving per-species abundance estimates from these sensors requires detection, classification, and quantification of animal vocalizations as individual acoustic events. Yet, variability in ambient noise, both over time and across sensors, hinders the reliability of current automated systems for sound event detection (SED), such as convolutional neural networks (CNN) in the time-frequency domain. In this article, we develop, benchmark, and combine several machine listening techniques to improve the generalizability of SED models across heterogeneous acoustic environments. As a case study, we consider the problem of detecting avian flight calls from a ten-hour recording of nocturnal bird migration, recorded by a network of six ARUs in the presence of heterogeneous background noise. Starting from a CNN yielding state-of-the-art accuracy on this task, we introduce two noise adaptation techniques, respectively integrating short-term (60 ms) and long-term (30 min) context. First, we apply per-channel energy normalization (PCEN) in the time-frequency domain, which applies short-term automatic gain control to every subband in the mel-frequency spectrogram. Secondly, we replace the last dense layer in the network by a context-adaptive neural network (CA-NN) layer, i.e. an affine layer whose weights are dynamically adapted at prediction time by an auxiliary network taking long-term summary statistics of spectrotemporal features as input. We show that PCEN reduces temporal overfitting across dawn vs. dusk audio clips whereas context adaptation on PCEN-based summary statistics reduces spatial overfitting across sensor locations. Moreover, combining them yields state-of-the-art results that are unmatched by artificial data augmentation alone. We release a pre-trained version of our best performing system under the name of BirdVoxDetect, a ready-to-use detector of avian flight calls in field recordings.
AD  - Cornell Univ, Cornell Lab Ornithol, Ithaca, NY 14850 USAAD  - NYU, Mus & Audio Res Lab, New York, NY 10003 USAAD  - NYU, Ctr Urban Sci & Progress, New York, NY 10003 USAC3  - Cornell UniversityC3  - New York UniversityC3  - New York UniversityFU  - National Science Foundation [1633259, 1633206]; Leon Levy Foundation; Google faculty awards
FX  - This research was supported by the National Science Foundation (grants 1633259 to JPB and 1633206 to SK and AF), the Leon Levy Foundation, and Google faculty awards to SK and JPB (https://ai.google/research/outreach/facultyresearch-awards/recipients/).The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
CR  - Andersen J, 2015, PROC INT CONF INTELL, P1
CR  - Bairlein F, 2016, SCIENCE, V354, P547, DOI 10.1126/science.aah6647
CR  - Battenberg E, 2017, 170504400 ARXIV
CR  - Bauer S, 2017, BIOSCIENCE, V67, P912, DOI 10.1093/biosci/bix074
CR  - Baumgartner MF, 2013, J ACOUST SOC AM, V134, P1814, DOI 10.1121/1.4816406
CR  - Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
CR  - Blair RB, 1996, ECOL APPL, V6, P506, DOI 10.2307/2269387
CR  - Blumstein DT, 2011, J APPL ECOL, V48, P758, DOI 10.1111/j.1365-2664.2011.01993.x
CR  - Brumm H, 2017, METHODS ECOL EVOL, V8, P1617, DOI 10.1111/2041-210X.12766
CR  - Cakir E, 2017, EUR SIGNAL PR CONF, P1744, DOI 10.23919/EUSIPCO.2017.8081508
CR  - Chollet F., 2018, KERAS V2 0 0
CR  - Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
CR  - Delcroix M, 2018, IEEE-ACM T AUDIO SPE, V26, P895, DOI 10.1109/TASLP.2018.2798821
CR  - Delcroix M, 2016, INTERSPEECH, P1573, DOI 10.21437/Interspeech.2016-203
CR  - Delcroix M, 2016, INT CONF ACOUST SPEE, P5270, DOI 10.1109/ICASSP.2016.7472683
CR  - Delcroix M, 2015, INT CONF ACOUST SPEE, P4535, DOI 10.1109/ICASSP.2015.7178829
CR  - Devault TL, 2011, WILDLIFE SOC B, V35, P394, DOI 10.1002/wsb.75
CR  - Dokter AM, 2018, NAT ECOL EVOL, V2, P1603, DOI 10.1038/s41559-018-0666-4
CR  - Drewitt AL, 2006, IBIS, V148, P29, DOI 10.1111/j.1474-919X.2006.00516.x
CR  - Efford MG, 2009, ECOLOGY, V90, P2676, DOI 10.1890/08-1735.1
CR  - Ellis, 2018, COMPUTATIONAL ANAL S, P373, DOI DOI 10.1007/978-3-319-63450-0_13
CR  - Ellis D., 2018, COMPUTATIONAL ANAL S, P13, DOI [10.1007/978-3-319-63450-0_2, DOI 10.1007/978-3-319-63450-0.]
CR  - Evans William R., 2005, Passenger Pigeon, V67, P15
CR  - Farnsworth A, 2005, AUK, V122, P733, DOI 10.1642/0004-8038(2005)122[0733:FCATVF]2.0.CO;2
CR  - Farnsworth A, 2016, ECOL APPL, V26, P752, DOI 10.1890/15-0023
CR  - Farnsworth A, 2014, AI MAG, V35, P31, DOI 10.1609/aimag.v35i2.2527
CR  - Fiedler Wolfgang, 2009, Ringing & Migration, V24, P175
CR  - Fink D, 2014, AI MAG, V35, P19, DOI 10.1609/aimag.v35i2.2533
CR  - Fink D, 2010, ECOL APPL, V20, P2131, DOI 10.1890/09-1340.1
CR  - Franceschi JY, 2018, P INT C ART INT STAT, P1280
CR  - Glotin, 2016, 2016 IEEE 26 INT WOR, P1, DOI [DOI 10.1109/MLSP.2016.7738875, 10.1109/MLSP.2016.7738875]
CR  - Gordo O, 2007, CLIM RES, V35, P37, DOI 10.3354/cr00713
CR  - Grill T, 2017, EUR SIGNAL PR CONF, P1764, DOI 10.23919/EUSIPCO.2017.8081512
CR  - Ha D., 2017, P INT C LEARN REPR, P1
CR  - Hecht J, 2016, IEEE SPECTRUM, P11
CR  - Heinicke S, 2015, METHODS ECOL EVOL, V6, P753, DOI 10.1111/2041-210X.12384
CR  - Hobson KA, 2002, WILDLIFE SOC B, V30, P709
CR  - Hopcroft J. E., 1973, SIAM Journal on Computing, V2, P225, DOI 10.1137/0202019
CR  - Huemmer C, 2017, INT CONF ACOUST SPEE, P4875, DOI 10.1109/ICASSP.2017.7953083
CR  - Jia Xu, 2016, NEURIPS, P667
CR  - Joly Alexis, 2017, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 8th International Conference of the CLEF Association, CLEF 2017. Proceedings: LNCS 10456, P255, DOI 10.1007/978-3-319-65813-1_24
CR  - Kaewtip K, 2016, J ACOUST SOC AM, V140, P3691, DOI 10.1121/1.4966592
CR  - Kahl S, 2018, C LABS EV FOR
CR  - Kingma DP, 2014, ARXIV PREPRINT ARXIV
CR  - Klapuri A, 1999, INT CONF ACOUST SPEE, P3089, DOI 10.1109/ICASSP.1999.757494
CR  - Knight EC, 2019, BIOACOUSTICS, V28, P539, DOI 10.1080/09524622.2018.1503971
CR  - Krim H, 1996, IEEE SIGNAL PROC MAG, V13, P67, DOI 10.1109/79.526899
CR  - Krstulovic S., 2018, AUDIO EVENT RECOGNIT, P335
CR  - Laiolo P, 2010, BIOL CONSERV, V143, P1635, DOI 10.1016/j.biocon.2010.03.025
CR  - Lanzone M, 2009, AUK, V126, P511, DOI 10.1525/auk.2009.08187
CR  - Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
CR  - Loss SR, 2015, ANNU REV ECOL EVOL S, V46, P99, DOI 10.1146/annurev-ecolsys-112414-054133
CR  - Lostanlen V, 2017, P IEEE C AC SPEECH S, P266
CR  - Lostanlen V, 2019, IEEE SIGNAL PROC LET, V26, P39, DOI 10.1109/LSP.2018.2878620
CR  - Mack C, 2015, IEEE SPECTRUM, V52, P31, DOI 10.1109/MSPEC.2015.7065415
CR  - Marcarini M, 2008, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2008.4518038
CR  - Marques TA, 2013, BIOL REV, V88, P287, DOI 10.1111/brv.12001
CR  - McCallum JC, 2017, GRAPH MEMORY PRICES
CR  - McFee B., 2015, 16 INT SOC MUS INF R, P248
CR  - McFee B, 2019, IEEE SIGNAL PROC MAG, V36, P128, DOI 10.1109/MSP.2018.2875349
CR  - Merchant ND, 2015, METHODS ECOL EVOL, V6, P257, DOI 10.1111/2041-210X.12330
CR  - Millet J, 2019, INT CONF ACOUST SPEE, P5831, DOI 10.1109/ICASSP.2019.8682324
CR  - Mydlarz C, 2017, APPL ACOUST, V117, P207, DOI 10.1016/j.apacoust.2016.06.010
CR  - Naguib M, 2003, J ACOUST SOC AM, V113, P1749, DOI 10.1121/1.1539050
CR  - Nieukirk SL, 2012, J ACOUST SOC AM, V131, P1102, DOI 10.1121/1.3672648
CR  - Oliver RY, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aaq1084
CR  - Pamula H, 2017, POSTEPY AKUSTYKI, P149
CR  - Pellegrini T, 2017, EUR SIGNAL PR CONF, P1734, DOI 10.23919/EUSIPCO.2017.8081506
CR  - Pijanowski BC, 2011, BIOSCIENCE, V61, P203, DOI 10.1525/bio.2011.61.3.6
CR  - Raffel C., 2014, P 15 INT SOC MUS INF
CR  - Ross SRPJ, 2018, ECOL RES, V33, P135, DOI 10.1007/s11284-017-1509-5
CR  - Salamon J, 2017, IEEE WORK APPL SIG, P344, DOI 10.1109/WASPAA.2017.8170052
CR  - Salamon J, 2017, INT CONF ACOUST SPEE, P141, DOI 10.1109/ICASSP.2017.7952134
CR  - Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
CR  - Salamon J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166866
CR  - Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
CR  - Schluter J, 2018, C LABS EV FOR CLEF
CR  - Schluter J., 2015, P 16 INT SOC MUS INF, P121, DOI 10.5281/zenodo.1417745
CR  - Schluter J, 2018, P C INT SOC MUS INF
CR  - Schwarz A, 2015, INT CONF ACOUST SPEE, P4380, DOI 10.1109/ICASSP.2015.7178798
CR  - Segura-Garcia J, 2015, IEEE SENS J, V15, P836, DOI 10.1109/JSEN.2014.2356342
CR  - Shamoun-Baranes J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160106
CR  - Shan C, 2018, ARXIV180310916 ARXIV
CR  - SHONFIELD J, 2017, AVIAN CONSERV ECOL, V12, DOI DOI 10.5751/ACE-
CR  - Stewart FEC, 2018, ECOSPHERE, V9, DOI 10.1002/ecs2.2112
CR  - Stowell D, 2018, METHODS ECOLOGY EVOL
CR  - Stowell D., 2018, COMPUTATIONAL ANAL S, P303
CR  - Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
CR  - Sullivan BL, 2014, BIOL CONSERV, V169, P31, DOI 10.1016/j.biocon.2013.11.003
CR  - Ulloa JS, 2018, ECOL INDIC, V90, P346, DOI 10.1016/j.ecolind.2018.03.026
CR  - Van Doren BM, 2018, SCIENCE, V361, P1115, DOI 10.1126/science.aat7526
CR  - Van Doren BM, 2017, P NATL ACAD SCI USA, V114, P11175, DOI 10.1073/pnas.1708574114
CR  - Wang YX, 2017, INT CONF ACOUST SPEE, P5670, DOI 10.1109/ICASSP.2017.7953242
CR  - Warren PS, 2006, ANIM BEHAV, V71, P491, DOI 10.1016/j.anbehav.2005.07.014
CR  - Wilson SJ, 2018, AVIAN CONSERV ECOL, V13, DOI 10.5751/ACE-01248-130204
CR  - Yang Zhilin, 2018, P INT C LEARN REPR I
CR  - Zhao ZX, 2014, J PHYS OCEANOGR, V44, P2763, DOI 10.1175/JPO-D-14-0040.1
CR  - Zinemanas P, 2019, PROC CONF OPEN INNOV, P533, DOI 10.23919/FRUCT.2019.8711906
PU  - PUBLIC LIBRARY SCIENCE
PI  - SAN FRANCISCO
PA  - 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
DA  - OCT 24
PY  - 2019
VL  - 14
IS  - 10
DO  - 10.1371/journal.pone.0214168
AN  - WOS:000532631800003
N1  - Times Cited in Web of Science Core Collection:  23
Total Times Cited:  23
Cited Reference Count:  98
ER  -

TY  - JOUR
AU  - Servis, JA
AU  - Reid, BN
AU  - Timmers, MA
AU  - Stergioula, V
AU  - Naro-Maciel, E
TI  - Characterizing coral reef biodiversity: genetic species delimitation in brachyuran crabs of Palmyra Atoll, Central Pacific
T2  - MITOCHONDRIAL DNA PART A
LA  - English
KW  - General mixed Yule-coalescent
KW  - Poisson tree process
KW  - automated barcode gap discovery
KW  - Palmyra Atoll National Wildlife Refuge
KW  - OXIDASE SUBUNIT-I
KW  - CRYPTIC DIVERSITY
KW  - CLIMATE-CHANGE
KW  - DECAPODA
KW  - CRUSTACEA
KW  - BARCODE
KW  - PHYLOGEOGRAPHY
KW  - CONSERVATION
KW  - PATTERNS
KW  - IMPACTS
AB  - Coral reefs are highly threatened ecosystems, yet there are numerous challenges in conducting inventories of their vanishing biodiversity, partly because many taxa remain difficult to detect and describe. Genetic species delimitation methods provide a standardized means for taxonomic classification including of cryptic, rare, or elusive groups, but results can vary by analytical method and genetic marker. In this study, a combination of morphological and genetic identification methods was used to estimate species richness and identify taxonomic units in true crabs (Infraorder Brachyura; n = 200) from coral reefs of Palmyra Atoll, Central Pacific. Genetic identification was based on matches between mitochondrial 16S ribosomal RNA (16S rRNA) and/or cytochromecoxidase subunit I (COI) sequences to GenBank data, while morphological work relied on the taxonomic literature. Broad agreement in the number of candidate species delimited by genetic distance thresholds and tree-based approaches was found, although the multi-rate Poisson tree process (mPTP) was less appropriate for this dataset. The COI sequence data identified 30-32 provisional species and the 16S data revealed 34-35. The occurrence of 10 families, 20 genera, and 19 species of brachyurans at Palmyra was corroborated by at least two methods. Diversity levels withinChlorodiella laevissimaindicated possible undescribed or cryptic species in currently lumped taxa. These results illustrate the efficacy of DNA sequences in identifying organisms and detecting cryptic variation, and underscore the importance of using appropriate genetic markers and multiple species delimitation analyses, with applications for future species descriptions.
AD  - US Fish & Wildlife Serv, Falls Church, VA USAAD  - Michigan State Univ, Kellogg Biol Stn, Hickory Corners, MI 49060 USAAD  - NOAA, Ecosyst Sci Div, Joint Inst Marine & Atmospher Res, Pacific Isl Fisheries Sci Ctr, Honolulu, HI USAAD  - NYU, Liberal Studies, New York, NY 10003 USAC3  - United States Department of the InteriorC3  - US Fish & Wildlife ServiceC3  - Michigan State UniversityC3  - National Oceanic Atmospheric Admin (NOAA) - USAC3  - New York UniversityFU  - Lerner Gray Fund for Marine Research of the American Museum of Natural History; Professional Staff Congress of the City University of New York
FX  - Funding for this project was provided by the Lerner Gray Fund for Marine Research of the American Museum of Natural History (to JAS) and the Professional Staff Congress of the City University of New York (to ENM).
CR  - Blair C, 2017, MOL ECOL RESOUR, V17, P1168, DOI 10.1111/1755-0998.12658
CR  - Braun CL, 2008, 11 INT COR REEF S RE, P865
CR  - Brown SDJ, 2012, MOL ECOL RESOUR, V12, P562, DOI 10.1111/j.1755-0998.2011.03108.x
CR  - Cassone BJ, 2006, MAR BIOL, V149, P213, DOI 10.1007/s00227-005-0197-9
CR  - da Silva JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019449
CR  - Darriba D, 2012, NAT METHODS, V9, P772, DOI 10.1038/nmeth.2109
CR  - Dawson MN, 2011, J BIOGEOGR, V38, P1600, DOI 10.1111/j.1365-2699.2011.02499.x
CR  - Drummond AJ, 2007, BMC EVOL BIOL, V7, DOI 10.1186/1471-2148-7-214
CR  - Edmondson CH, 1923, BERNICE P BISH MUS B, V5, P3
CR  - EtiBioinformatics, MAR SPEC ID PORT
CR  - Folmer O., 1994, Molecular Marine Biology and Biotechnology, V3, P294
CR  - Geller J, 2013, MOL ECOL RESOUR, V13, P851, DOI 10.1111/1755-0998.12138
CR  - Hajibabaei M, 2007, TRENDS GENET, V23, P167, DOI 10.1016/j.tig.2007.02.001
CR  - Hebert PDN, 2004, P NATL ACAD SCI USA, V101, P14812, DOI 10.1073/pnas.0406166101
CR  - Hickerson MJ, 2006, SYST BIOL, V55, P729, DOI 10.1080/10635150600969898
CR  - Hoegh-Guldberg O, 2007, SCIENCE, V318, P1737, DOI 10.1126/science.1152509
CR  - Hubert N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0028987
CR  - Hughes TP, 2003, SCIENCE, V301, P929, DOI 10.1126/science.1085046
CR  - Hurley KKC, 2016, CORAL REEFS, V35, P103, DOI 10.1007/s00338-015-1382-z
CR  - Kapli P, 2017, BIOINFORMATICS, V29, pbtx025
CR  - Kearse M, 2012, BIOINFORMATICS, V28, P1647, DOI 10.1093/bioinformatics/bts199
CR  - KIMURA M, 1980, J MOL EVOL, V16, P111, DOI 10.1007/BF01731581
CR  - Ladner JT, 2012, MOL ECOL, V21, P2224, DOI 10.1111/j.1365-294X.2012.05528.x
CR  - Lai JCY, 2009, INVERTEBR SYST, V23, P402, DOI 10.1071/IS09012
CR  - Larsson A, 2014, BIOINFORMATICS, V30, P3276, DOI 10.1093/bioinformatics/btu531
CR  - Lasley RM, 2015, ZOOL SCR, V44, P165, DOI 10.1111/zsc.12094
CR  - Leray M, 2012, CORAL REEFS, V31, P383, DOI 10.1007/s00338-011-0845-0
CR  - Leray M, 2015, P NATL ACAD SCI USA, V112, P2076, DOI 10.1073/pnas.1424997112
CR  - McFadden KW, 2014, MAR POLLUT BULL, V89, P160, DOI 10.1016/j.marpolbul.2014.10.012
CR  - Palumbi Stephen R., 1991, Molecular Marine Biology and Biotechnology, V1, P27
CR  - Papastamatiou YP, 2012, MAR ECOL PROG SER, V456, P233, DOI 10.3354/meps09721
CR  - Papastamatiou YP, 2010, J EXP MAR BIOL ECOL, V386, P94, DOI 10.1016/j.jembe.2010.02.009
CR  - Plaisance L, 2009, CORAL REEFS, V28, P977, DOI 10.1007/s00338-009-0543-3
CR  - Plaisance Laetitia, 2011, Diversity, V3, P581
CR  - Plaisance L, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025026
CR  - Puillandre N, 2012, MOL ECOL, V21, P1864, DOI 10.1111/j.1365-294X.2011.05239.x
CR  - Ratnasingham S, 2007, MOL ECOL NOTES, V7, P355, DOI 10.1111/j.1471-8286.2007.01678.x
CR  - Ratnasingham S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066213
CR  - Reid NM, 2012, BMC EVOL BIOL, V12, DOI 10.1186/1471-2148-12-196
CR  - Roberts CM, 2002, SCIENCE, V295, P1280, DOI 10.1126/science.1067728
CR  - Sandin SA, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001548
CR  - SIMPSON GG, 1951, EVOLUTION, V5, P285, DOI 10.2307/2405675
CR  - Stamatakis A, 2006, BIOINFORMATICS, V22, P2688, DOI 10.1093/bioinformatics/btl446
CR  - Sterling EJ, 2013, CHELONIAN CONSERV BI, V12, P2, DOI 10.2744/CCB-1014.1
CR  - Tang CQ, 2014, METHODS ECOL EVOL, V5, P1086, DOI 10.1111/2041-210X.12246
CR  - Tsang LM, 2014, MOL BIOL EVOL, V31, P1173, DOI 10.1093/molbev/msu068
CR  - USFDA, 2017, REF STAND SEQ LIBR I
CR  - Valdez-Moreno M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036636
CR  - Vences M, 2005, PHILOS T R SOC B, V360, P1859, DOI 10.1098/rstb.2005.1717
CR  - Victor Benjamin C., 2015, P76
CR  - Williams GJ, 2013, PEERJ, V1, DOI 10.7717/peerj.81
CR  - Yu GC, 2017, METHODS ECOL EVOL, V8, P28, DOI 10.1111/2041-210X.12628
CR  - Zhang JJ, 2013, BIOINFORMATICS, V29, P2869, DOI 10.1093/bioinformatics/btt499
PU  - TAYLOR & FRANCIS LTD
PI  - ABINGDON
PA  - 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
DA  - JUL 3
PY  - 2020
VL  - 31
IS  - 5
SP  - 178
EP  - 189
DO  - 10.1080/24701394.2020.1769087
AN  - WOS:000544364200001
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  2
Cited Reference Count:  53
ER  -

TY  - JOUR
AU  - Chalmers, C
AU  - Fergus, P
AU  - Montanez, CAC
AU  - Longmore, SN
AU  - Wich, SA
TI  - Video analysis for the detection of animals using convolutional neural networks and consumer-grade drones
T2  - JOURNAL OF UNMANNED VEHICLE SYSTEMS
LA  - English
KW  - conservation
KW  - deep learning
KW  - convolutional neural networks
KW  - inferencing
KW  - drone technology
KW  - WILDLIFE RESEARCH
KW  - DEEP
KW  - CNN
AB  - Determining animal distribution and density is important in conservation. The process is both time-consuming and labour-intensive. Drones have been used to help mitigate human-intensive tasks by covering large geographical areas over a much shorter timescale. In this paper we investigate this idea further using a proof of concept to detect rhinos and cars from drone footage. The proof of concept utilises off-the-shelf technology and consumer-grade drone hardware. The study demonstrates the feasibility of using machine learning (ML) to automate routine conservation tasks, such as animal detection and tracking. The prototype has been developed using a DJI Mavic Pro 2 and tested over a global system for mobile communications (GSM) network. The Faster-RCNN Resnet 101 architecture is used for transfer learning. Inference is performed with a frame sampling technique to address the required trade-off between precision, processing speed, and live video feed synchronisation. Inference models are hosted on a web platform and video streams from the drone (using OcuSync) are transmitted to a real-time messaging protocol (RTMP) server for subsequent classification. During training, the best model achieves a mean average precision (mAP) of 0.83 intersection over union (@IOU) 0.50 and 0.69 @IOU 0.75, respectively. On testing the system in Knowsley Safari our prototype was able to achieve the following: sensitivity (Sen), 0.91 (0.869, 0.94); specificity (Spec), 0.78 (0.74, 0.82); and an accuracy (ACC), 0.84 (0.81, 0.87) when detecting rhinos, and Sen, 1.00 (1.00, 1.00); Spec, 1.00 (1.00, 1.00); and an ACC, 1.00 (1.00, 1.00) when detecting cars.
AD  - Liverpool John Moores Univ, Sch Comp Sci, Liverpool L2 2QP, Merseyside, EnglandAD  - Liverpool John Moores Univ, Astrophys Res Inst, Liverpool L3 5RF, Merseyside, EnglandAD  - Liverpool John Moores Univ, Sch Biol & Environm Sci, Liverpool L2 2QP, Merseyside, EnglandC3  - Liverpool John Moores UniversityC3  - Liverpool John Moores UniversityC3  - Liverpool John Moores UniversityFU  - Research Council UK (RCUK) Science and Technology Facilities Council (STFC) [ST/R002673/1]
FX  - The authors would like to thank Naomi Davies at Knowsley Safari for co-ordinating the field trial and providing access to the rhino enclosure. This research was supported by the Research Council UK (RCUK) Science and Technology Facilities Council (STFC) through grant ST/R002673/1.
CR  - Agapito L., LECT NOTES COMPUTER, V8925
CR  - Ba L.J., 2013, P 26 INT C NEUR INF, P3084
CR  - Banerjee DS, 2016, INT CONF CLOUD COMP, P144, DOI [10.1109/CloudCom.2016.0036, 10.1109/CloudCom.2016.33]
CR  - Bondi E, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7741
CR  - Bondi Elizabeth, 2019, P77
CR  - Buckland S.T., 2001, pi
CR  - Buckland S.T., 2004, ADV DISTANCE SAMPLIN
CR  - Chabot D, 2015, J UNMANNED VEH SYST, V3, P137, DOI 10.1139/juvs-2015-0021
CR  - Christie KS, 2016, FRONT ECOL ENVIRON, V14, P242, DOI 10.1002/fee.1281
CR  - Commercial Software Engineering (CSE) group at Microsoft, 2020, VOTT VIS OBJ TAGG TO
CR  - Crunchant AS, 2020, METHODS ECOL EVOL, V11, P542, DOI 10.1111/2041-210X.13362
CR  - Fang YF, 2016, PROCEDIA COMPUT SCI, V92, P13, DOI 10.1016/j.procs.2016.07.316
CR  - Fergus P., CONSERVATION
CR  - Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
CR  - Hensel M, 2017, ADV NEUR IN, V30
CR  - Iwamura S., 2017, ADV NEURAL INFORM PR, P435
CR  - Jakobs S., 2019, ATZHEAVY DUTY WORLDW, V12, P44, DOI [10.1007/s41321-019-0024-8, DOI 10.1007/S41321-019-0024-8]
CR  - King DB, 2015, ACS SYM SER, V1214, P1
CR  - Lamba A, 2019, CURR BIOL, V29, pR977, DOI 10.1016/j.cub.2019.08.016
CR  - LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
CR  - Lee J, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P36, DOI 10.1109/IRC.2017.77
CR  - Lim K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173317
CR  - Lin T.-Y., ND COCO COMMON OBJEC
CR  - Longmore SN, 2017, INT J REMOTE SENS, V38, P2623, DOI 10.1080/01431161.2017.1280639
CR  - Maire F, 2015, LECT NOTES ARTIF INT, V9457, P379, DOI 10.1007/978-3-319-26350-2_33
CR  - Martinez P, 2019, AUTOMAT CONSTR, V97, P151, DOI 10.1016/j.autcon.2018.10.021
CR  - Maxwell S, 2016, NATURE, V536, P143, DOI 10.1038/536143a
CR  - Nichols JD, 2006, TRENDS ECOL EVOL, V21, P668, DOI 10.1016/j.tree.2006.08.007
CR  - Peng JB, 2020, ISPRS J PHOTOGRAMM, V169, P364, DOI 10.1016/j.isprsjprs.2020.08.026
CR  - Rampasek L, 2016, CELL SYST, V2, P12, DOI 10.1016/j.cels.2016.01.009
CR  - Saria S, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002721
CR  - Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
CR  - Talukdar J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P78, DOI 10.1109/SPIN.2018.8474198
CR  - van Gemert JC, 2015, LECT NOTES COMPUT SC, V8925, P255, DOI 10.1007/978-3-319-16178-5_17
CR  - Wich SA, 2018, CONSERVATION DRONES: MAPPING AND MONITORING BIODIVERSITY, P1, DOI 10.1093/oso/9780198787617.001.0001
PU  - CANADIAN SCIENCE PUBLISHING
PI  - OTTAWA
PA  - 65 AURIGA DR, SUITE 203, OTTAWA, ON K2E 7W6, CANADA
DA  - JUN
PY  - 2021
VL  - 9
IS  - 2
SP  - 112
EP  - 127
DO  - 10.1139/juvs-2020-0018
AN  - WOS:000695453500003
N1  - Times Cited in Web of Science Core Collection:  4
Total Times Cited:  4
Cited Reference Count:  35
ER  -

TY  - JOUR
AU  - Song, XP
AU  - Richards, DR
AU  - He, PJ
AU  - Tan, PY
TI  - Does geo-located social media reflect the visit frequency of urban parks? A city-wide analysis using the count and content of photographs
T2  - LANDSCAPE AND URBAN PLANNING
LA  - English
KW  - CULTURAL ECOSYSTEM SERVICES
KW  - EMPLOYED PHOTOGRAPHY
KW  - REVEALED PREFERENCE
KW  - OUTDOOR RECREATION
KW  - GREEN-SPACE
KW  - VEGETATION
KW  - LANDSCAPE
KW  - AMENITY
KW  - VALUES
KW  - IMAGE
AB  - Given the importance of parks and green spaces for outdoor recreation in cities, numerous studies have attempted to describe patterns of usage and understand their determining factors. Recently, social media has emerged as a potentially valuable tool to examine people's use of parks. This study examines park use in Singapore based on the count and visual content of photographs geo-located within parks. Measures of park use-the number of photo-user-days (PUD)-derived from 325,173 and 94,890 photographs on the respective platforms Instagram and Flickr were compared with results from household surveys (n = 2000). We analysed the spatial attributes of parks and their relationships with PUD at an aggregated-level, and for content categories on the Flickr platform produced by automated classification: birds, wildlife, plants, flowers, recreation, water/skyscapes. In contrast to studies of large national parks, we found that PUD at city parks reflected residents' preferences better than their frequency of visits to parks, and that park size had a limited effect on PUD. Some relationships were specific to a particular platform; Instagram users were more likely to upload photographs at parks that were closer to the coast and with more canopy cover, while Flickr users tended to do so at parks with an event space and that had lower-density housing nearby. We conclude that social media can provide reasonable assessments of park popularity, but future studies need to consider scale-effects, the integration of data sources for better accuracy, as well as a diversity of goals beyond park use.
AD  - Natl Univ Singapore, Dept Architecture, 4 Architecture Dr, Singapore 117566, SingaporeAD  - Swiss Fed Inst Technol, Future Cities Lab, Singapore ETH Ctr, 1 Create Way 06-01, Singapore 138602, SingaporeAD  - Swiss Fed Inst Technol, Singapore ETH Ctr, Nat Capital Singapore, Singapore 138602, SingaporeC3  - National University of SingaporeFU  - Singapore's National Research Foundation under its Campus for Research Excellence and Technological Enterprise programme [FI 370074016]
FX  - This research was conducted at the National University of Singapore and Singapore-ETH Centre (Future Cities Laboratory), which was established collaboratively between ETH Zurich and Singapore's National Research Foundation (FI 370074016) under its Campus for Research Excellence and Technological Enterprise programme. We thank Bige Tuncer from the Singapore University of Technology and Design for access to the Instagram data, and are grateful to Centre for Urban Greenery and Ecology (CUGE) of National Parks Board for research collaboration and the nationwide survey of park usage and satisfaction. We also thank Richard N. Belcher for his assistance with obtaining data on property selling prices in Singapore, and Leon Y.F. Gaw for his help in providing the high-resolution map of land cover.
CR  - Angradi TR, 2018, J GREAT LAKES RES, V44, P340, DOI 10.1016/j.jglr.2017.12.007
CR  - Antoniou V., 2010, GEOMATICA, V64, P99, DOI DOI 10.HTTP://DX.D0I.0RG/10.5623/GE0MAT-2010-0009
CR  - Belcher RN, 2019, URBAN ECOSYST, V22, P213, DOI 10.1007/s11252-018-0808-0
CR  - Belcher RN, 2018, ECOL ECON, V149, P149, DOI 10.1016/j.ecolecon.2018.03.012
CR  - Bernaldez F. G., 1987, J ENVIRON PSYCHOL, V7, P169, DOI DOI 10.1016/S0272-4944(87)80024-5
CR  - Brindley P, 2019, URBAN FOR URBAN GREE, V39, P45, DOI 10.1016/j.ufug.2019.01.015
CR  - Chamberlain DE, 2007, BIRD STUDY, V54, P87
CR  - Chang CC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60902-w
CR  - Chiesura A, 2004, LANDSCAPE URBAN PLAN, V68, P129, DOI 10.1016/j.landurbplan.2003.08.003
CR  - Colding J, 2009, ECOSYSTEMS, V12, P191, DOI 10.1007/s10021-008-9217-1
CR  - Coldwell DF, 2018, LANDSCAPE URBAN PLAN, V175, P114, DOI 10.1016/j.landurbplan.2018.02.007
CR  - Cox AM, 2008, INFORM RES, V13
CR  - Di Minin E, 2015, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00063
CR  - Donahue ML, 2018, LANDSCAPE URBAN PLAN, V175, P1, DOI 10.1016/j.landurbplan.2018.02.006
CR  - ESRI, 2018, ARCGIS DESKT REL 10
CR  - Fisher DM, 2018, J ENVIRON MANAGE, V222, P465, DOI 10.1016/j.jenvman.2018.05.045
CR  - Garrod B, 2007, J HERIT TOUR, V2, P14, DOI 10.2167/jht018.0
CR  - Gaw LYF, 2019, DATA, V4, DOI 10.3390/data4030116
CR  - Ghermandi A, 2019, GLOBAL ENVIRON CHANG, V55, P36, DOI 10.1016/j.gloenvcha.2019.02.003
CR  - Ghermandi A, 2018, ECOSYST SERV, V31, P351, DOI 10.1016/j.ecoser.2017.12.012
CR  - Gibson SC, 2018, LANDSCAPE URBAN PLAN, V180, P234, DOI 10.1016/j.landurbplan.2018.08.019
CR  - Gosal AS, 2019, ECOSYST SERV, V38, DOI 10.1016/j.ecoser.2019.100958
CR  - Graham LJ, 2019, PEOPLE NAT, V1, P406, DOI 10.1002/pan3.10042
CR  - Hamstead ZA, 2018, COMPUT ENVIRON URBAN, V72, P38, DOI 10.1016/j.compenvurbsys.2018.01.007
CR  - Hartmann P, 2010, J ENVIRON PSYCHOL, V30, P119, DOI 10.1016/j.jenvp.2009.10.001
CR  - Hausmann A, 2018, CONSERV LETT, V11, DOI 10.1111/conl.12343
CR  - HAYWARD DG, 1984, URBAN ECOL, V8, P243, DOI 10.1016/0304-4009(84)90038-X
CR  - Herzog T. R., 1985, J ENVIRON PSYCHOL, V5, P225, DOI [DOI 10.1016/S0272-4944(85)80024-4, 10.1016/S0272-4944(85)80024-4]
CR  - Hoef JMV, 2007, ECOLOGY, V88, P2766, DOI 10.1890/07-0043.1
CR  - Ives CD, 2017, LANDSCAPE URBAN PLAN, V161, P32, DOI 10.1016/j.landurbplan.2016.12.010
CR  - Kaczynski AT, 2007, LEISURE SCI, V29, P315, DOI 10.1080/01490400701394865
CR  - Kaczynski AT, 2014, INT J BEHAV NUTR PHY, V11, DOI 10.1186/s12966-014-0146-4
CR  - Lapata M, 2006, COMPUT LINGUIST, V32, P471, DOI 10.1162/coli.2006.32.4.471
CR  - Lenormand M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206672
CR  - Marti P, 2019, COMPUT ENVIRON URBAN, V74, P161, DOI 10.1016/j.compenvurbsys.2018.11.001
CR  - Meert K, 2014, J CONSUM PSYCHOL, V24, P195, DOI 10.1016/j.jcps.2013.12.005
CR  - National Parks Board, 2012, DEST PARKS
CR  - OpenStreetMap, 2018, PLANET DUMP
CR  - Oteros-Rozas E, 2018, ECOL INDIC, V94, P74, DOI 10.1016/j.ecolind.2017.02.009
CR  - Plieninger T, 2013, LAND USE POLICY, V33, P118, DOI 10.1016/j.landusepol.2012.12.013
CR  - QGIS.org, 2021, QGIS GEOGR INF SYST
CR  - R Core Team, 2019, R LANG ENV STAT COMP
CR  - Gozalo GR, 2019, URBAN FOR URBAN GREE, V46, DOI 10.1016/j.ufug.2019.126470
CR  - Richards DR, 2018, ECOSYST SERV, V31, P318, DOI 10.1016/j.ecoser.2017.09.004
CR  - Richards DR, 2015, ECOL INDIC, V53, P187, DOI 10.1016/j.ecolind.2015.01.034
CR  - Rossi SD, 2015, APPL GEOGR, V63, P77, DOI 10.1016/j.apgeog.2015.06.008
CR  - Schipperijn J, 2010, URBAN FOR URBAN GREE, V9, P25, DOI 10.1016/j.ufug.2009.09.002
CR  - Schirpke U, 2018, ECOSYST SERV, V31, P336, DOI 10.1016/j.ecoser.2017.11.017
CR  - Scopelliti M, 2016, LANDSCAPE URBAN PLAN, V148, P139, DOI 10.1016/j.landurbplan.2015.11.002
CR  - Sessions C, 2016, J ENVIRON MANAGE, V183, P703, DOI 10.1016/j.jenvman.2016.09.018
CR  - Sinclair M, 2018, SCI TOTAL ENVIRON, V642, P356, DOI 10.1016/j.scitotenv.2018.06.056
CR  - Song XP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-57864-4
CR  - Sonter LJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162372
CR  - Stedman R, 2004, J LEISURE RES, V36, P580, DOI 10.1080/00222216.2004.11950037
CR  - Su SL, 2016, APPL GEOGR, V73, P26, DOI 10.1016/j.apgeog.2016.06.001
CR  - Tenkanen H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18007-4
CR  - Tieskens KF, 2018, LANDSCAPE URBAN PLAN, V177, P128, DOI 10.1016/j.landurbplan.2018.05.002
CR  - Urban Redevelopment Authority, 2017, MP14 SDCP PW PLAN PA
CR  - van Zanten BT, 2016, P NATL ACAD SCI USA, V113, P12974, DOI 10.1073/pnas.1614158113
CR  - Veitch J, 2018, LEISURE SCI, V40, P343, DOI 10.1080/01490400.2017.1325798
CR  - Wang D, 2015, CITIES, V42, P85, DOI 10.1016/j.cities.2014.10.003
CR  - WHO, 2016, URB GREEN SPAC HLTH
CR  - Wong P.P., 1990, RECREATIONAL USES CO, P53, DOI [10.1007/978-94-009-2391-1_4, DOI 10.1007/978-94-009-2391-1_4]
CR  - Wood SA, 2013, SCI REP-UK, V3, DOI 10.1038/srep02976
CR  - Zhang JY, 2019, URBAN FOR URBAN GREE, V44, DOI 10.1016/j.ufug.2019.126420
CR  - Zhang LQ, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16040578
CR  - Zhang S, 2018, LANDSCAPE URBAN PLAN, V180, P27, DOI 10.1016/j.landurbplan.2018.08.004
CR  - Zhang XM, 2018, ADV SOC SCI EDUC HUM, V213, P352
PU  - ELSEVIER
PI  - AMSTERDAM
PA  - RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
DA  - NOV
PY  - 2020
VL  - 203
DO  - 10.1016/j.landurbplan.2020.103908
AN  - WOS:000568997000005
N1  - Times Cited in Web of Science Core Collection:  13
Total Times Cited:  13
Cited Reference Count:  68
ER  -

TY  - JOUR
AU  - Pauli, BP
AU  - Zollner, PA
AU  - Haulton, GS
TI  - Nocturnal Habitat Selection of Bats Using Occupancy Models
T2  - JOURNAL OF WILDLIFE MANAGEMENT
LA  - English
KW  - acoustic
KW  - habitat
KW  - Indiana bat
KW  - little brown bat
KW  - Myotis lucifugus
KW  - Myotis septentrionalis
KW  - Myotis sodalis
KW  - northern long-eared bat
KW  - WHITE-NOSE SYNDROME
KW  - ENDANGERED INDIANA BAT
KW  - HOME-RANGE ANALYSIS
KW  - LONG-EARED BATS
KW  - MYOTIS-SEPTENTRIONALIS
KW  - RESOURCE SELECTION
KW  - SPECIES RICHNESS
KW  - SITE OCCUPANCY
KW  - MATERNITY COLONIES
KW  - ACTIVITY PATTERNS
AB  - Threats to North American bat species necessitate the quantification of bat habitat. To characterize bat habitat, we recorded bat echolocation calls from state forests in Indiana, USA. We identified calls using automated classification software and constructed detection histories for 3 species of conservation concern: Indiana bat (Myotis sodalis), little brown bat (Myotis lucifugus), and northern long-eared bat (Myotis septentrionalis). We analyzed these data using single-and multi-species occupancy approaches to estimate occurrence and detection probabilities at the genus level (Myotis) and for each species separately. We constructed models using a suite of habitat covariates (e.g., forest cover, edge, streams, hibernacula, public roads) and determined the effect of these features on occupancy for each species (or group). We validated all models using training and independent data. Occupancy of all species was affected by the proportion of forest in surrounding areas. For most models, bat occupancy was greatest in areas with a lower proportion of forest within 1 km. Occupancy was also often greatest in recently harvested or intact, mature second-growth stands as opposed to stands 10-30 years following harvest. The spatial configuration of water and roads also affected species occupancy. Our methods allowed us to assess the factors that affect occupancy for the genus and individual species, thus allowing for the identification of features useful in classifying important habitat at both taxonomic levels. The results of this study can aid land managers in identifying habitat that may be used by foraging bats and in planning future timber harvests in managed forests. (C) 2017 The Wildlife Society.
AD  - Purdue Univ, Dept Forestry & Nat Resources, 195 Marsteller St, W Lafayette, IN 47907 USAAD  - Indiana Dept Nat Resources, Div Forestry, 402 West Washington St, Indianapolis, IN 46204 USAAD  - St Marys Univ Minnesota, Dept Biol, 700 Terrace Hts,Box 10, Winona, MN 55987 USAC3  - Purdue University SystemC3  - Purdue UniversityC3  - Purdue University West Lafayette CampusFU  - Indiana Department of Natural Resources, Division of Forestry
FX  - We thank K. L. DeCosta for performing much of the field work for the stationary surveys. R. K. Swihart, G. Shao, S. Fei, and D. W. Sparks provided valuable feedback on earlier drafts of this manuscript. This research was funded by the Indiana Department of Natural Resources, Division of Forestry.
CR  - Adams AM, 2012, METHODS ECOL EVOL, V3, P992, DOI 10.1111/j.2041-210X.2012.00244.x
CR  - Bennett VJ, 2013, LANDSCAPE ECOL, V28, P979, DOI 10.1007/s10980-013-9874-0
CR  - Bennett VJ, 2013, J WILDLIFE MANAGE, V77, P93, DOI 10.1002/jwmg.467
CR  - Bergeson SM, 2013, J MAMMAL, V94, P1311, DOI 10.1644/12-MAMM-A-311
CR  - Berthinussen A, 2012, J APPL ECOL, V49, P82, DOI 10.1111/j.1365-2664.2011.02068.x
CR  - Blehert DS, 2009, SCIENCE, V323, P227, DOI 10.1126/science.1163874
CR  - Brack V, 2001, ACTA CHIROPTEROL, V3, P203
CR  - BrackJr V., 1989, WETLANDS RIVER CORRI, P141
CR  - Brigham RM, 1997, CAN J ZOOL, V75, P131, DOI 10.1139/z97-017
CR  - Britzke ER, 2013, ACTA THERIOL, V58, P109, DOI 10.1007/s13364-013-0131-3
CR  - Britzke E.R. K. L., 2002, INDIANA BAT BIOL MAN, P220
CR  - Britzke ER, 2011, J WILDLIFE MANAGE, V75, P660, DOI 10.1002/jwmg.68
CR  - Broders HG, 2006, J WILDLIFE MANAGE, V70, P1174, DOI 10.2193/0022-541X(2006)70[1174:REASSF]2.0.CO;2
CR  - Burton AC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038007
CR  - Caceres MC, 2000, MAMMAL SPECIES, V634, P1
CR  - Carter TC, 2005, FOREST ECOL MANAG, V219, P259, DOI 10.1016/j.foreco.2005.08.049
CR  - Carter TC, 2006, J WILDLIFE MANAGE, V70, P1185, DOI 10.2193/0022-541X(2006)70[1185:IBITMT]2.0.CO;2
CR  - Carter Timothy C., 2002, P160
CR  - Coleman JL, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020483
CR  - Coleman L.S., 2014, J ECOLOGY NATURAL EN, V6, P56, DOI DOI 10.5897/JENE2013.0424
CR  - Coleman LS, 2014, NORTHEAST NAT, V21, P431, DOI 10.1656/045.021.0309
CR  - Congdon P, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0470092394
CR  - Dorazio RM, 2006, ECOLOGY, V87, P842, DOI 10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2
CR  - Dorazio RM, 2005, J AM STAT ASSOC, V100, P389, DOI 10.1198/016214505000000015
CR  - Duchamp JE, 2006, WILDLIFE SOC B, V34, P408, DOI 10.2193/0091-7648(2006)34[408:EPODFB]2.0.CO;2
CR  - Duchamp JE, 2008, LANDSCAPE ECOL, V23, P849, DOI 10.1007/s10980-008-9241-8
CR  - Dzal Y, 2011, BIOL LETTERS, V7, P392, DOI 10.1098/rsbl.2010.0859
CR  - Ford WM, 2011, J FISH WILDL MANAG, V2, P125, DOI 10.3996/042011-JFWM-027
CR  - Ford WM, 2005, BIOL CONSERV, V126, P528, DOI 10.1016/j.biocon.2005.07.003
CR  - Francl KE, 2012, J FISH WILDL MANAG, V3, P33, DOI 10.3996/062011-JFWM-039
CR  - Frick WF, 2010, SCIENCE, V329, P679, DOI 10.1126/science.1188594
CR  - Gikas Nicholas S., 2009, Proceedings of the Indiana Academy of Science, V118, P203
CR  - Haulton G.S., 2013, US FOR SERV GEN TECH, P339
CR  - Hayes JP, 2000, ACTA CHIROPTEROL, V2, P225
CR  - Henderson LE, 2008, J MAMMAL, V89, P952, DOI 10.1644/07-MAMM-A-214.1
CR  - Henderson LE, 2008, BIOL CONSERV, V141, P1819, DOI 10.1016/j.biocon.2008.04.028
CR  - Homoya M.A., 1985, Proceedings of the Indiana Academy of Science, V94, P245
CR  - Hooten MB, 2015, ECOL MONOGR, V85, P3, DOI 10.1890/14-0661.1
CR  - HUMPHREY SR, 1977, J MAMMAL, V58, P334, DOI 10.2307/1379332
CR  - Jachowski DS, 2014, ENDANGER SPECIES RES, V24, P149, DOI 10.3354/esr00594
CR  - Jantzen MK, 2013, CAN J ZOOL, V91, P287, DOI 10.1139/cjz-2012-0282
CR  - Johnson P. S., 2009, CAB INT
CR  - Kery M, 2009, ENVIRON ECOL STAT SE, V3, P639, DOI 10.1007/978-0-387-78151-8_28
CR  - Kniowski AB, 2014, J WILDLIFE MANAGE, V78, P503, DOI 10.1002/jwmg.677
CR  - Kuo L., 1998, INDIAN J STAT B
CR  - Larson DJ, 2000, ACTA CHIROPTEROL, V2, P209
CR  - LAVAL RK, 1977, J MAMMAL, V58, P592, DOI 10.2307/1380007
CR  - Lele SR, 2013, J ANIM ECOL, V82, P1183, DOI 10.1111/1365-2656.12141
CR  - Lemen C, 2015, WEST N AM NATURALIST, V75, P218, DOI 10.3398/064.075.0210
CR  - Loeb SC, 2011, MANAG FOR ECOSYST, V21, P167, DOI 10.1007/978-94-007-1620-9_10
CR  - Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011
CR  - MacKenzie DI, 2002, ECOLOGY, V83, P2248, DOI 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2
CR  - McCann NP, 2014, J MAMMAL, V95, P369, DOI 10.1644/13-MAMM-A-110
CR  - McGarigal K., 2012, FRAGSTATS V4 SPATIAL
CR  - Menzel JM, 2005, J WILDLIFE MANAGE, V69, P430, DOI 10.2193/0022-541X(2005)069&lt;0430:SHUAHA&gt;2.0.CO;2
CR  - Menzel MA, 2002, FOREST ECOL MANAG, V155, P107, DOI 10.1016/S0378-1127(01)00551-5
CR  - Murray SW, 2004, J ZOOL, V262, P197, DOI 10.1017/S0952836903004503
CR  - O'Shea Thomas J., 2002, P237
CR  - Obrist MK, 2004, MAMMALIA, V68, P307, DOI 10.1515/mamm.2004.030
CR  - Olson GS, 2005, J WILDLIFE MANAGE, V69, P918, DOI 10.2193/0022-541X(2005)069[0918:MOSODF]2.0.CO;2
CR  - Owen SF, 2004, NORTH J APPL FOR, V21, P154, DOI 10.1093/njaf/21.3.154
CR  - Owen SF, 2003, AM MIDL NAT, V150, P352, DOI 10.1674/0003-0031(2003)150[0352:HSAHUB]2.0.CO;2
CR  - Pauli BP, 2015, ECOSPHERE, V6, DOI 10.1890/ES14-00336.1
CR  - Pauli BP, 2015, LANDSCAPE ECOL, V30, P2015, DOI 10.1007/s10980-015-0228-y
CR  - Pauli JN, 2010, CONSERV BIOL, V24, P349, DOI 10.1111/j.1523-1739.2009.01298.x
CR  - Royle J.A., 2008, HIERARCHICAL MODELIN
CR  - Royle JA, 2014, SPATIAL CAPTURE-RECAPTURE, P1
CR  - Russell Amy L., 2009, Endangered Species Research, V8, P49, DOI 10.3354/esr00121
CR  - Russell RE, 2009, ECOL APPL, V19, P1253, DOI 10.1890/08-0910.1
CR  - Schaub A, 2008, J EXP BIOL, V211, P3174, DOI 10.1242/jeb.022863
CR  - Shao G, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083546
CR  - Sheets J. J., 2010, THESIS
CR  - Siemers BM, 2011, P ROY SOC B-BIOL SCI, V278, P1646, DOI 10.1098/rspb.2010.2262
CR  - Sikes RS, 2016, J MAMMAL, V97, P663, DOI 10.1093/jmammal/gyw078
CR  - Silvis A., 2016, 214 US DEP AGR FOR S
CR  - Silvis A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096937
CR  - Sparks DW, 2005, J MAMMAL, V86, P713, DOI 10.1644/1545-1542(2005)086[0713:FHOTIB]2.0.CO;2
CR  - Spencer W, 2011, BIOL CONSERV, V144, P788, DOI 10.1016/j.biocon.2010.10.027
CR  - Stone EL, 2009, CURR BIOL, V19, P1123, DOI 10.1016/j.cub.2009.05.058
CR  - Sturtz S, 2005, J STAT SOFTW, V12, P1, DOI 10.18637/jss.v012.i03
CR  - Thogmartin WE, 2013, BIOL CONSERV, V160, P162, DOI 10.1016/j.biocon.2013.01.010
CR  - Thogmartin WE, 2012, J MAMMAL, V93, P1086, DOI 10.1644/11-MAMM-A-355.1
CR  - Thogmartin WE, 2012, J WILDLIFE DIS, V48, P876, DOI 10.7589/2011-06-176
CR  - Thompson Frank R., 2004, 244 DEP AGR FOR SERV
CR  - THOMSON C E, 1982, Mammalian Species, P1, DOI 10.2307/3504013
CR  - Turner Gregory G., 2011, Bat Research News, V52, P13
CR  - U. S. Fish and Wildlife Service [USFWS], 2007, INDIANA BAT MYOTIS
CR  - U.S. Fish Wildlife Service [USFWS], 2012, N AM BAT DEATH TOLL
CR  - United States Fish and Wildlife Service, 2015, FED REGISTER, V80, P17974
CR  - Weber T., 2013, J CONSERVATION PLANN, V9, P53
CR  - Weller TJ, 2012, J WILDLIFE MANAGE, V76, P619, DOI 10.1002/jwmg.260
CR  - Whitaker John O. Jr, 2002, P48
CR  - WhitakerJr J. O., 2007, BATS INDIANA INDIAN
CR  - Womack KM, 2013, J WILDLIFE MANAGE, V77, P707, DOI 10.1002/jwmg.498
CR  - Yates MD, 2006, J WILDLIFE MANAGE, V70, P1238, DOI 10.2193/0022-541X(2006)70[1238:EOFSAF]2.0.CO;2
CR  - Zipkin EF, 2010, BIOL CONSERV, V143, P479, DOI 10.1016/j.biocon.2009.11.016
CR  - Zipkin EF, 2009, J APPL ECOL, V46, P815, DOI 10.1111/j.1365-2664.2009.01664.x
CR  - Zurcher AA, 2010, ACTA CHIROPTEROL, V12, P337, DOI 10.3161/150811010X537918
PU  - WILEY
PI  - HOBOKEN
PA  - 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
DA  - JUL
PY  - 2017
VL  - 81
IS  - 5
SP  - 878
EP  - 891
DO  - 10.1002/jwmg.21251
AN  - WOS:000404132300013
N1  - Times Cited in Web of Science Core Collection:  7
Total Times Cited:  7
Cited Reference Count:  98
ER  -

TY  - JOUR
AU  - Andries, A
AU  - Murphy, RJ
AU  - Morse, S
AU  - Lynch, J
TI  - Earth Observation for Monitoring, Reporting, and Verification within Environmental Land Management Policy
T2  - SUSTAINABILITY
LA  - English
KW  - very high resolution satellite data
KW  - earth observation
KW  - habitat suitability
KW  - habitat assessment
KW  - Environmental Land Management
KW  - SKYLARKS ALAUDA-ARVENSIS
KW  - ECOSYSTEM SERVICES
KW  - HABITAT SUITABILITY
KW  - BIODIVERSITY
KW  - POPULATION
KW  - CLASSIFICATION
KW  - COVER
KW  - LANDSCAPE
KW  - FARMLAND
KW  - IDENTIFY
AB  - The main aim of the new agricultural scheme, Environmental Land Management, in England is to reward landowners based on their provision of 'public goods' while achieving the goals of the 25 Year Environment Plan and commitment to net zero emission by 2050. Earth Observation (EO) satellites appear to offer an unprecedented opportunity in the process of monitoring, reporting, and verification (MRV) of this scheme. In this study, we worked with ecologists to determine the habitat-species relationships for five wildlife species in the Surrey Hills 'Area of Outstanding Natural Beauty' (AONB), and this information was used to examine the extent to which EO satellite imagery, particularly very high resolution (VHR) imagery, could be used for habitat assessment, via visual interpretation and automated methods. We show that EO satellite products at 10 m resolution and other geospatial datasets enabled the identification and location of broadly suitable habitat for these species and the use of VHR imagery (at 1-4 m spatial resolution) allowed valuable insights for remote assessment of habitat qualities and quantity. Hence, at a fine scale, we obtained additional habitats such as scrub, hedges, field margins, woodland and tree characteristics, and agricultural practices that offer an effective source of information for sustainable land management. The opportunities and limitations of this study are discussed, and we conclude that there is considerable scope for it to offer valuable information for land management decision-making and as support and evidence for MRV for incentive schemes.
AD  - Univ Surrey, Fac Engn & Phys Sci, Ctr Environm & Sustainabil, Guildford GU2 7XH, Surrey, EnglandC3  - University of SurreyFU  - Natural Environment Research Council (NERC) SCENARIO Doctoral Training Partnership [NE/L002566/1]; UKRI/Research England SPF funding via the University of Surrey; University of Surrey
FX  - This research was part-funded by Natural Environment Research Council (NERC) SCENARIO Doctoral Training Partnership, Grant/Award NE/L002566/1, CASE award partner the National Physical Laboratory (NPL) and by UKRI/Research England SPF funding via the University of Surrey. The APC was funded by the University of Surrey.
CR  - Adamo M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091447
CR  - Ahmadipari M, 2021, ECOL INDIC, V126, DOI 10.1016/j.ecolind.2021.107606
CR  - Anderson CB, 2018, ECOL LETT, V21, P1572, DOI 10.1111/ele.13106
CR  - Anderson JR., 1976, LAND USE LAND COVER
CR  - Andrew ME, 2009, DIVERS DISTRIB, V15, P627, DOI 10.1111/j.1472-4642.2009.00568.x
CR  - [Anonymous], SUSTAINABLE SOIL LAN
CR  - [Anonymous], ENV BILL
CR  - [Anonymous], SH AONB SURREY HILLS
CR  - [Anonymous], EXPORT OPEN STREET M
CR  - [Anonymous], GLOBAL OBSERVATION F
CR  - [Anonymous], AGR BILL
CR  - [Anonymous], GOOGLE EARTH ENGINE
CR  - [Anonymous], Making Earth Observation Work (MEOW) for UK Biodiversity Monitoring and Surveillance, Phase 4: Testing Applications in Habitat Condition Assessment A Report to the Department for Environment, Food and Rural Affairs, Prepared by Environment Systems
CR  - [Anonymous], NATL LAND COVER DATA
CR  - [Anonymous], AFRICOVER
CR  - [Anonymous], NATL LAND USE DATABA
CR  - Barbosa CCD, 2015, ECOL INDIC, V52, P430, DOI 10.1016/j.ecolind.2015.01.007
CR  - Bastidas Fegan S, 2019, DS SLM SUSTAINABLE L, P44
CR  - Boumans R, 2015, ECOSYST SERV, V12, P30, DOI 10.1016/j.ecoser.2015.01.004
CR  - Bryan BA, 2013, ENVIRON SCI POLICY, V27, P124, DOI 10.1016/j.envsci.2012.12.010
CR  - Campbell J.B., 2011, INTRO REMOTE SENSING, V5th ed., P130
CR  - Celine E, 2013, GLOBAL CHANGE BIOL, V19, P1173, DOI 10.1111/gcb.12092
CR  - Chamberlain DE, 1999, IBIS, V141, P38, DOI 10.1111/j.1474-919X.1999.tb04261.x
CR  - Cochran F, 2020, REMOTE SENS ENVIRON, V244, DOI 10.1016/j.rse.2020.111796
CR  - Cohen-Shacham E, 2019, ENVIRON SCI POLICY, V98, P20, DOI 10.1016/j.envsci.2019.04.014
CR  - Cord AF, 2017, TRENDS ECOL EVOL, V32, P416, DOI 10.1016/j.tree.2017.03.003
CR  - Crawford BA, 2020, J FISH WILDL MANAG, V11, P130, DOI 10.3996/092019-JFWM-075
CR  - DEFRA, ROADM US EARTH OBS D
CR  - DEFRA, ENV LAND MAN POL DIS
CR  - DEFRA, ENV LAND MAN TESTS T
CR  - Deng XZ, 2016, J GEOGR SCI, V26, P953, DOI 10.1007/s11442-016-1309-9
CR  - Donald PF, 2001, J APPL ECOL, V38, P536, DOI 10.1046/j.1365-2664.2001.00618.x
CR  - Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
CR  - Dwyer J., 2015, PUBLIC GOODS ECOSYST, P1
CR  - Farr TG, 2007, REV GEOPHYS, V45, DOI 10.1029/2005RG000183
CR  - Feranec J., 2016, EUROPEAN LANDSCAPE D, P33
CR  - Fretwell PT, 2021, REMOTE SENS ECOL CON, V7, P139, DOI 10.1002/rse2.176
CR  - Fretwell PT, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088655
CR  - Garibaldi A, 2004, ECOL SOC, V9
CR  - Geospatial Commission, UNL POW LOC UKS GEOS
CR  - Gomez JJ, 2014, J MAMMAL, V95, P824, DOI 10.1644/13-MAMM-A-265
CR  - Goodwin CED, 2018, MAMMAL REV, V48, P209, DOI 10.1111/mam.12125
CR  - Goodwin CED, 2017, MAMMAL REV, V47, P183, DOI 10.1111/mam.12091
CR  - Haines-Young R.H., POLICY IMPACT FUTURE
CR  - Headquarters C, 1998, GLOBAL OBSERVATION F
CR  - Hejnowicz A.P., 2018, NEW DIRECTIONS PUBLI, P1
CR  - Hotker H, 2013, JULIUS-KUHN-ARCH, V442, P91, DOI 10.5073/jka.2013.442.007
CR  - Hurni H., 1997, ITC Journal, P210
CR  - Ibarrola-Ulzurrun E, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120666
CR  - Ivanic K.-Z., 2020, PROTECTED AREAS BENE, P84
CR  - Jackson D.L., 307 JNCC
CR  - Jansen LJM, 2003, LAND USE POLICY, V20, P131, DOI 10.1016/S0264-8377(02)00081-9
CR  - Keesstra S, 2018, SCI TOTAL ENVIRON, V610, P997, DOI 10.1016/j.scitotenv.2017.08.077
CR  - Klimetzek D, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030520
CR  - Kuenzer C, 2014, INT J REMOTE SENS, V35, P6599, DOI 10.1080/01431161.2014.964349
CR  - Kumar P.S.J., 2018, EARTH SCI REMOTE SEN
CR  - Lucas R, 2015, INT J APPL EARTH OBS, V37, P17, DOI 10.1016/j.jag.2014.10.011
CR  - Mairota P, 2015, INT J APPL EARTH OBS, V37, P100, DOI 10.1016/j.jag.2014.09.015
CR  - McMahon CR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092613
CR  - Morton R.D., 2020, DOI 10.5285/499212cd-d64a-43ba-b801-95402e4d4098
CR  - Morton R.D., 2015, JNCC REP, V563, P2
CR  - Morton RD, 2020, EIDC, DOI 10.5285/44C23778-4A73-4A8F-875F-89B23B91ECF8
CR  - Motavalli P, 2013, INT SOIL WATER CONSE, V1, P1
CR  - Mulligan M, 2020, REMOTE SENS ENVIRON, V239, DOI 10.1016/j.rse.2020.111671
CR  - Murray K.A, 2004, FACTORS AFFECTING FO
CR  - Nagendra H, 2015, INT J APPL EARTH OBS, V37, P124, DOI 10.1016/j.jag.2014.10.010
CR  - Natural Capital Committee, 2020, ADV US NAT BAS INT R
CR  - Nelson E, 2009, FRONT ECOL ENVIRON, V7, P4, DOI 10.1890/080023
CR  - Neugarten R., 2018, TOOLS MEASURING MODE, P70
CR  - Open Government Licence,, PRIOR HAB INV ENGL
CR  - Otto CRV, 2016, P NATL ACAD SCI USA, V113, P10430, DOI 10.1073/pnas.1603481113
CR  - Pan H., 2021, ANTHROPOCENE, V35, DOI [10.1016/j.ancene.2021.100297, DOI 10.1016/J.ANCENE.2021.100297]
CR  - Pan HZ, 2019, ECOL INDIC, V102, P426, DOI 10.1016/j.ecolind.2019.02.059
CR  - Pettorelli N, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0190
CR  - Preston S., 2017, ECOSYSTEM SERVICES T
CR  - Randin CF, 2020, REMOTE SENS ENVIRON, V239, DOI 10.1016/j.rse.2019.111626
CR  - Rasanen A, 2020, REMOTE SENS ECOL CON, V6, P457, DOI 10.1002/rse2.140
CR  - Rocchini D, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.05.011
CR  - Rocchini D, 2015, ECOL INFORM, V25, P22, DOI 10.1016/j.ecoinf.2014.10.006
CR  - Rodgers C., 2019, ENV LAW REV, V21, P38, DOI [10.1177/1461452918824504, DOI 10.1177/1461452918824504]
CR  - Rotenberry JT, 2006, ECOLOGY, V87, P1458, DOI 10.1890/0012-9658(2006)87[1458:GNMFMS]2.0.CO;2
CR  - Sadlier G., 2018, VALUE SATELLITE DERI
CR  - Sallustio L, 2017, J ENVIRON MANAGE, V201, P129, DOI 10.1016/j.jenvman.2017.06.031
CR  - Schwilch G, 2011, LAND DEGRAD DEV, V22, P214, DOI 10.1002/ldr.1040
CR  - Secades C., 2014, REV USE REMOTELY SEN, P183
CR  - SIRS, FEAS STUD MAPP MON G
CR  - Society T.R., OBS EARTH EXP VIEWS
CR  - Song YA, 2019, SCI TOTAL ENVIRON, V663, P568, DOI 10.1016/j.scitotenv.2019.01.347
CR  - Sozio G, 2016, MAMM BIOL, V81, P96, DOI 10.1016/j.mambio.2014.12.006
CR  - Surrey Hills AONB, 2020, MAKING SPACE NATURE
CR  - Svatonova H, 2016, INT ARCH PHOTOGRAMM, V41, P675, DOI 10.5194/isprsarchives-XLI-B2-675-2016
CR  - Tansey K, 2009, APPL GEOGR, V29, P145, DOI 10.1016/j.apgeog.2008.08.004
CR  - Thomas N.P., 1987, CLASSIFICATION REMOT, P267
CR  - Townsend PA, 2009, REMOTE SENS ENVIRON, V113, P1410, DOI 10.1016/j.rse.2008.05.023
CR  - Trout RC, 2012, EUR J WILDLIFE RES, V58, P635, DOI 10.1007/s10344-012-0611-9
CR  - Trust S.W., BIODIVERSITY PLANNIN
CR  - Turner W, 2003, TRENDS ECOL EVOL, V18, P306, DOI 10.1016/S0169-5347(03)00070-3
CR  - UN, 2017, EARTH OBSERVATIONS O, P170
CR  - Venter ZS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13122301
CR  - Vihervaara P, 2017, GLOB ECOL CONSERV, V10, P43, DOI 10.1016/j.gecco.2017.01.007
CR  - Watmough GR, 2019, P NATL ACAD SCI USA, V116, P1213, DOI 10.1073/pnas.1812969116
CR  - Wilson JD, 1997, J APPL ECOL, V34, P1462, DOI 10.2307/2405262
CR  - World Bank, 2006, SUSTAINABLE LAND MAN, P108
CR  - Yang H, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6050154
CR  - Zscheischler J., 2021, SUSTAINABLE LAND MAN, P145
PU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
DA  - AUG
PY  - 2021
VL  - 13
IS  - 16
DO  - 10.3390/su13169105
AN  - WOS:000689866300001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  105
ER  -

TY  - JOUR
AU  - Radig, B
AU  - Bodesheim, P
AU  - Korsch, D
AU  - Denzler, J
AU  - Haucke, T
AU  - Klasen, M
AU  - Steinhage, V
TI  - Automated Visual Large Scale Monitoring of Faunal Biodiversity
T2  - PATTERN RECOGNITION AND IMAGE ANALYSIS
LA  - English
KW  - biodiversity monitoring
KW  - species classification
KW  - animal detection
KW  - sensor networks
KW  - camera trapping with color and depth sensors
KW  - motion estimation in color and depth videos
KW  - fine-grained recognition
KW  - multi-object tracking
KW  - depth estimation
KW  - deep learning
KW  - novelty detection
KW  - anomaly detection
KW  - incremental learning
KW  - lifelong learning
KW  - active learning
AB  - To observe biodiversity, the variety of plant and animal life in the world or in a particular habitat, human observers make the most common examinations, often assisted by technical equipment. Measuring objectively the number of different species of animals, plants, fungi, and microbes that make up the ecosystem can be difficult. In order to monitor changes in biodiversity, data have to be compared across space and time. Cameras are an essential sensor to determine the species range, abundance, and behavior of animals. The millions of recordings from camera traps set up in natural environments can no longer be analyzed by biologists. We started research on doing this analysis automatically without human interaction. The focus of our present sensor is on image capture of wildlife and moths. Special hardware elements for the detection of different species are designed, implemented, tested, and improved, as well as the algorithms for classification and counting of samples from images and image sequences, e.g., to calculate presence, absence, and abundance values or the duration of characteristic activities related to the spatial mobilities. For this purpose, we are developing stereo camera traps that allow spatial reconstruction of the observed animals. This allows three-dimensional coordinates to be recorded and the shape to be characterized. With this additional feature data, species identification and movement detection are facilitated. To classify and count moths, they are attracted to an illuminated screen, which is then photographed at intervals by a high-resolution color camera. To greatly reduce the volume of data, redundant elements and elements that are consistent from image to image are eliminated. All design decisions take into account that at remote sites and in fully autonomous operation, power supply on the one hand and possibilities for data exchange with central servers on the other hand are limited. Installation at hard-to-reach locations requires a sophisticated and demanding system design with an optimal balance between power requirements, bandwidth for data transmission, required service and operation in all environmental conditions for at least ten years.
AD  - Tech Univ Munich, Fac Informat, D-80290 Munich, GermanyAD  - Friedrich Schiller Univ Jena, Comp Vis Grp, D-07737 Jena, GermanyAD  - Univ Bonn, Inst Informat, D-53115 Bonn, GermanyC3  - Technical University of MunichC3  - Friedrich Schiller University of JenaC3  - University of BonnFU  - German Federal Ministry of Education and Research (Bundesministerium fur Bildung und Forschung (BMBF), Bonn, Germany) [FKZ 01LC1903B]
FX  - This work was partially done within the project "Automated Multisensor Station for Monitoring of Species Diversity" (AMMOD), which is funded by the German Federal Ministry of Education and Research (Bundesministerium fur Bildung und Forschung (BMBF), Bonn, Germany (FKZ 01LC1903B).
CR  - Apps PJ, 2018, AFR J ECOL, V56, P702, DOI 10.1111/aje.12563
CR  - Bodesheim P, 2015, IEEE WINT CONF APPL, P813, DOI 10.1109/WACV.2015.113
CR  - Bodesheim P, 2013, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2013.433
CR  - Bohlke J, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P466, DOI 10.5220/0010244704660477
CR  - Brehm G, 2021, INSECT CONSERV DIVER, V14, P188, DOI 10.1111/icad.12476
CR  - Brehm G, 2017, NOTA LEPIDOPTEROLOGI, V40, P87, DOI 10.3897/nl.40.11887
CR  - Buckland ST, 2015, METH STAT ECOL, P1, DOI 10.1007/978-3-319-19219-2
CR  - Chambert T, 2015, ECOLOGY, V96, P332, DOI 10.1890/14-1507.1
CR  - Chandler RB, 2014, METHODS ECOL EVOL, V5, P1351, DOI 10.1111/2041-210X.12153
CR  - Crunchant AS, 2020, METHODS ECOL EVOL, V11, P542, DOI 10.1111/2041-210X.13362
CR  - Fiske IJ, 2011, J STAT SOFTW, V43, P1
CR  - Follmann P., 2018, Pattern Recognition and Image Analysis, V28, P605, DOI 10.1134/S1054661818040107
CR  - Haase D, 2014, PROC CVPR IEEE, P1426, DOI 10.1109/CVPR.2014.185
CR  - Haucke T., ARXIV210205607
CR  - He K., 2015, CVPR
CR  - He K, 2017, P 2017 IEEE INT C CO, P2961
CR  - Howe EJ, 2017, METHODS ECOL EVOL, V8, P1558, DOI 10.1111/2041-210X.12790
CR  - Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
CR  - Keselman L., 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPRW.2017.167.
CR  - Korsch D, 2019, LECT NOTES COMPUT SC, V11824, P62, DOI 10.1007/978-3-030-33676-9_5
CR  - Korsch D, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (ICPRAI 2018), P627, DOI 10.1134/S105466181804020X
CR  - Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI [10.1145/3065386, DOI 10.1145/3065386]
CR  - Lin T.Y., 2017, P COMP VIS PATT REC
CR  - Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
CR  - Radig B., 2018, INT C PATTERN RECOGN, P591
CR  - Rodner E, 2015, CVPR WORKSH FIN GRAI
CR  - Rodner E, 2011, PATTERN RECOGN LETT, V32, P244, DOI 10.1016/j.patrec.2010.08.009
CR  - Royle JA, 2003, ECOLOGY, V84, P777, DOI 10.1890/0012-9658(2003)084[0777:EAFRPA]2.0.CO;2
CR  - Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
CR  - Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
CR  - Simon M, 2015, LECT NOTES COMPUT SC, V9004, P162, DOI 10.1007/978-3-319-16808-1_12
CR  - Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
CR  - Yang GS, 2020, PROC CVPR IEEE, P1331, DOI 10.1109/CVPR42600.2020.00141
CR  - Zhou K, 2016, DESTECH TRANS COMP
PU  - SPRINGERNATURE
PI  - LONDON
PA  - CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
DA  - JUL
PY  - 2021
VL  - 31
IS  - 3
SP  - 477
EP  - 488
DO  - 10.1134/S1054661821030214
AN  - WOS:000697671200012
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  34
ER  -

TY  - JOUR
AU  - Waga, K
AU  - Tompalski, P
AU  - Coops, NC
AU  - White, JC
AU  - Wulder, MA
AU  - Malinen, J
AU  - Tokola, T
TI  - Forest Road Status Assessment Using Airborne Laser Scanning
T2  - FOREST SCIENCE
LA  - English
CP  - 17th Symposium on Systems Analysis in Forest Resources
KW  - ALS
KW  - LiDAR
KW  - road quality
KW  - forest management
KW  - land use
KW  - forestry
KW  - road classification
KW  - LOGGING ROADS
KW  - LIDAR
KW  - ALGORITHM
KW  - CANOPY
AB  - Forest roads allow access for silvicultural operations, harvesting, recreational activities, wildlife management, and fire suppression. In British Columbia, Canada, roads that are no longer required must be deactivated (temporarily, semipermanently, or permanently) in order to minimize the impact on the overall forested ecosystem. However, the remoteness and size of the road network present challenges for monitoring. Our aim was to examine the utility of airborne laser scanning data to assess the status and quality of forest roads across 52,000 hectares of coastal forest in British Columbia. Within the forest estate, roads can be active or deactivated, or have an unknown status. We classified road segments based on the vegetation growth on the road surface, and edges, by classifying the height distribution of airborne laser scanning returns within each road segment into four groups: no vegetation, minor vegetation, dense understory vegetation, and dense overstory vegetation. Validation indicated that 73 percent of roads were classified correctly when compared to independent field observations. The majority were classified as active roads with no vegetation or deactivated with dense vegetation. The approach presented herein can aid forest managers in verifying the status of the roads in their management area, especially in remote areas where field assessments are costly and time-consuming.
   Study Implications: Large-area assessments of road status are critically important for operational forest management. We classified road segments based on the vegetation growth on the road surface, and edges, by classifying the height distribution of airborne laser scanning returns within each road segment into four classes: no vegetation, minor vegetation, dense understory vegetation, and dense overstory vegetation. Validation indicated that 73 percent of roads were classified correctly when compared to independent field observations. The majority of road segments were classified as either active roads with no vegetation or deactivated roads with dense vegetation. This information is potentially valuable for forest planners, as it allows for the identification of road segments that require maintenance or, alternatively, informs on successful road deactivation. Additional information on precise road centerlines is a required first step for our approach. We would propose that if this approach were to be made operational, future work should integrate automated road detection using the airborne laser scanning data into the proposed current workflow. Road extraction could also assess the exact width of each road and would further improve the classification results and greatly enhance the automation process.
AD  - Univ Eastern Finland, Sch Forest Sci, POB 111, FI-80101 Joensuu, FinlandAD  - Univ British Columbia, Fac Forestry, 2424 Main Mall, Vancouver, BC V6T 1Z4, CanadaAD  - Nat Resources Canada, Pacific Forestry Ctr, Canadian Forest Serv, 506 West Burnside Rd, Victoria, BC V8Z 1M5, CanadaC3  - University of Eastern FinlandC3  - University of British ColumbiaC3  - Natural Resources CanadaC3  - Canadian Forest ServiceFU  - Canadian Forest Service, Natural Resources Canada; OECD Co-operative Research Programme: Biological Resource Management for Sustainable Agricultural Systems
FX  - Western Forest Products, Inc., is thanked for supplying the data used in this research. The authors acknowledge the support of the Canadian Forest Service, Natural Resources Canada.
FX  - This paper was given at The 17th Symposium on Systems Analysis in Forest Resources (Suquamish, WA, USA, 27-30 August 2017), which was sponsored by the OECD Co-operative Research Programme: Biological Resource Management for Sustainable Agricultural Systems whose financial support made it possible for one of the authors to participate in the symposium.
CR  - [Anonymous], 2015, **DROPPED REF**
CR  - [Anonymous], 2002, FOR PRACT COD FOR RO
CR  - Axelsson P., 2000, INT ARCH PHOTOGRAMM, V33, P110
CR  - AZIZI Z, 2014, J FORESTRY RES, V0025, P00975, DOI DOI 10.1007/S11676-014-0544-0
CR  - CAMPBELL MJ, 2018, REMOTE SENS ENVIRON, V0215, P00330, DOI DOI 10.1016/J.RSE.2018.06.023
CR  - COULTER ED, 2006, SILVA FENN, V0040, P00143, DOI DOI 10.14214/SF.357
CR  - CRAVEN M, 2014, SCAND J FOREST RES, V0029, P00174, DOI DOI 10.1080/02827581.2014.881546
CR  - EVANS JS, 2007, IEEE T GEOSCI REMOTE, V0045, P01029, DOI DOI 10.1109/TGRS.2006.890412
CR  - FERNANDEZ R, 2014
CR  - FERRAZ A, 2016, ISPRS J PHOTOGRAMM, V0112, P00023, DOI DOI 10.1016/J.ISPRSJPRS.2015.12.002
CR  - Goulette F., 2006, ISPRS INT ARCH PHOT, VXXXVI, P1
CR  - HUI ZY, 2016, ISPRS J PHOTOGRAMM, V0118, P00022, DOI DOI 10.1016/J.ISPRSJPRS.2016.04.003
CR  - KISS K, 2015, CAN J FOREST RES, V0045, P01636, DOI DOI 10.1139/CJFR-2015-0067
CR  - KISS K, 2016, ISPRS ANN PHOTOGRAMM, V0003, P00167, DOI DOI 10.5194/ISPRSANNALS-III-8-167-2016
CR  - KOCH B, 2009, INT J REMOTE SENS, V0030, P00935, DOI DOI 10.1080/01431160802395284
CR  - KUMAR P, 2013, ISPRS J PHOTOGRAMM, V0085, P00044, DOI DOI 10.1016/J.ISPRSJPRS.2013.08.003
CR  - MAGUYA AS, 2014, REMOTE SENS BASEL, V0006, P06524, DOI DOI 10.3390/RS6076524
CR  - MCCASHION JD, 1983, J FOREST, V0081, P00023
CR  - MEIDINGER D.V, 1991, ECOSYSTEMS BRIT COLU
CR  - NAESSET E, 2015, 31 INA NMBU
CR  - Rieger W., 1999, INT ARCH PHOTOGRAMME, V32, pW14
CR  - ROSS KL, 2018, INTERFACES, V0048, P00260, DOI DOI 10.1287/INTE.2017.0926
CR  - SHERBA J, 2014, REMOTE SENS BASEL, V0006, P04043, DOI DOI 10.3390/RS6054043
CR  - VIITALA E.-J, 2004, METSATEIDEN LISARAKE, P175
CR  - WATSON D, 1992, CONTOURING GUIDE ANA
CR  - WHITE JC, 2015, FORESTS, V0006, P03704, DOI DOI 10.3390/F6103704
CR  - WHITE RA, 2010, REMOTE SENS BASEL, V0002, P01120, DOI DOI 10.3390/RS2041120
CR  - WULDER MA, 2007, FOREST CHRON, V0083, P00539
CR  - YUAN X, 2008, 2008 10 INT C CONTR, P01097
CR  - ZHANG W, 2016, INT GEOSCI REMOTE SE, P00799, DOI DOI 10.1109/IGARSS.2016.7729201
PU  - OXFORD UNIV PRESS INC
PI  - CARY
PA  - JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
DA  - AUG
PY  - 2020
VL  - 66
IS  - 4
SP  - 501
EP  - 508
DO  - 10.1093/forsci/fxz053
AN  - WOS:000559621500011
N1  - Times Cited in Web of Science Core Collection:  3
Total Times Cited:  3
Cited Reference Count:  30
ER  -

TY  - JOUR
AU  - Gustafson, KB
AU  - Coates, PS
AU  - Roth, CL
AU  - Chenaille, MP
AU  - Ricca, MA
AU  - Sanchez-Chopitea, E
AU  - Casazza, ML
TI  - Using object-based image analysis to conduct high-resolution conifer extraction at regional spatial scales
T2  - INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA  - English
KW  - Object-based image analysis
KW  - Pinyon-juniper
KW  - Sage-grouse
KW  - Sagebrush
KW  - Feature extraction
KW  - Image processing
KW  - GREATER SAGE-GROUSE
KW  - WESTERN NORTH-AMERICA
KW  - JUNIPER WOODLANDS
KW  - SAGEBRUSH STEPPE
KW  - WATER AVAILABILITY
KW  - PINYON
KW  - COVER
KW  - CONSERVATION
KW  - ECOSYSTEMS
KW  - VEGETATION
AB  - Distributional expansion and infill of pinyon (Pinus monophylla) and juniper (Juniperus osteosperma, J. occidentalis) trees (hereinafter, "pinyon-juniper") into sagebrush ecosystems alters the ecological function and economic viability of these ecosystems and represents a major contemporary challenge facing land and wildlife managers. Therefore, accurate and high-resolution maps of pinyon-juniper distribution and abundance across broad geographic extents would facilitate science that quantifies ecological effects of pinyon-juniper expansion and help guide land management decisions that better target areas for pinyon-juniper treatment projects. We mapped conifers at a high (1- m(2); i.e., 1 x 1-m) resolution across the majority of Nevada and northeastern California. We used digitalorthophoto quad tiles from National Agriculture Imagery Program (USDA 2013) to classify conifers using automated feature extraction (AFE) with the program Feature Analyst"' (Overwatch, 2013). Overall accuracy was > 86% across all mapped areas for ground referencing methods. We provide five sets of full-extent maps for land managers: (1) a shapefile representing accuracy results linked to mapping subunits; (2) binary rasters representing conifer presence or absence at a 1-m(2) resolution; (3) a 900-m(2) resolution raster representing percentages of conifer canopy cover within each cell; (4) 1-m(2) resolution canopy cover classification rasters derived from a 50-m radius moving window analysis; and (5) an example map derived from our canopy cover product that prioritizes pinyon-juniper treatment by significance to sage-grouse habitat improvement. Importantly, the canopy cover maps were developed to allow user-specified flexibility based on their own objectives (i.e., develop phases of expansion). These products improve upon or complement existing conifer maps for the Western United States and will help facilitate habitat management and sagebrush ecosystem restoration through an accurate understanding of conifer distribution and abundance at multiple spatial scales.
AD  - US Geol Survey, Western Ecol Res Ctr, Dixon, CA 95620 USAC3  - United States Department of the InteriorC3  - United States Geological SurveyFU  - Nevada Sagebrush Ecosystem Program; Nevada Department of Wildlife; U.S. Bureau of Land Management
FX  - This research was funded by the Nevada Sagebrush Ecosystem Program with support from the Nevada Department of Wildlife and U.S. Bureau of Land Management. Additional logistical coordination was provided by the U.S. Forest Service and California Department of Fish and Wildlife. We extend gratitude to personnel with U.S. Geological Survey, particularly W. Perry for guidance and expertise, K. Mauch and T. Kroger for assistance in developing feature extraction workflows, and R. Kelble and B. Prochazka for coordinating conifer ground referencing conducted by numerous field technicians. We also thank the Great Basin Bird Observatory for field data collection. Use of trade or product names does not imply endorsement by the U.S. Government.
CR  - Baruch-Mordo S, 2013, BIOL CONSERV, V167, P233, DOI 10.1016/j.biocon.2013.08.017
CR  - Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
CR  - BLM USFS, 2015, FACT SHEET BLM USFS
CR  - Boswell A, 2017, AIMS ENVIRON SCI, V4, P1, DOI 10.3934/environsci.2017.1.1
CR  - Bradley BA, 2008, J BIOGEOGR, V35, P951, DOI 10.1111/j.1365-2699.2007.01847.x
CR  - Bruce D.A., 2008, INT ARCH PHOTOGRAMME, V37, P515
CR  - Burnett C, 2003, ECOL MODEL, V168, P233, DOI 10.1016/S0304-3800(03)00139-X
CR  - Chambers JC, 2014, ECOSYSTEMS, V17, P360, DOI 10.1007/s10021-013-9725-5
CR  - Coates P. S., 2016, 20161080 US GEOL SUR, P1
CR  - Coates P. S., 2014, 20141163 US GEOL SUR, DOI [10. 3133/ofr20141163, DOI 10.3133/OFR20141163]
CR  - Coates PS, 2017, RANGELAND ECOL MANAG, V70, P25, DOI 10.1016/j.rama.2016.09.001
CR  - Coates PS, 2016, P NATL ACAD SCI USA, V113, P12745, DOI 10.1073/pnas.1606898113
CR  - Coates PS, 2016, J APPL ECOL, V53, P83, DOI 10.1111/1365-2664.12558
CR  - Congalton RG, 2009, ASSESSING ACCURACY R
CR  - Connelly J.W., 2004, CONSERVATION ASSESSM, P1
CR  - Davenport DW, 1998, J RANGE MANAGE, V51, P231, DOI 10.2307/4003212
CR  - Davies KW, 2011, BIOL CONSERV, V144, P2573, DOI 10.1016/j.biocon.2011.07.016
CR  - Davies KW, 2010, RANGELAND ECOL MANAG, V63, P630, DOI 10.2111/REM-D-09-00129.1
CR  - Falkowski M. J., 2012, 68748210525 NAT RES, P1
CR  - Falkowski MJ, 2017, RANGELAND ECOL MANAG, V70, P15, DOI 10.1016/j.rama.2016.08.002
CR  - Hay GJ, 2003, ISPRS J PHOTOGRAMM, V57, P327, DOI 10.1016/S0924-2716(02)00162-4
CR  - Hay GJ, 2006, INT ARCH PHOTOGRAMME
CR  - Homer C. G., 2009, 20081027 USGS, P1
CR  - Hulet A, 2014, ENVIRON MANAGE, V53, P660, DOI 10.1007/s00267-013-0227-1
CR  - Jakubowski MK, 2013, REMOTE SENS-BASEL, V5, P4163, DOI 10.3390/rs5094163
CR  - Knick ST, 2013, ECOL EVOL, V3, P1539, DOI 10.1002/ece3.557
CR  - Kormos PR, 2017, RANGELAND ECOL MANAG, V70, P116, DOI 10.1016/j.rama.2016.05.003
CR  - LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
CR  - Maier B., 2008, OBJECT BASED IMAGE A, P625
CR  - Miller R.F., 2014, RMRSGTR322 USDA FOR, DOI [10.2737/RMRS-GTR-322, DOI 10.2737/RMRS-GTR-322]
CR  - Miller R. F., 2005, OREGON STATE U TECHN, P1
CR  - Miller R.F., 2001, MISCELLANEOUS PUBLIC, P15
CR  - Miller R.F., 2008, AGE STRUCTURE EXPANS, VRMRS-RP-69, DOI [10.2737/RMRS-RP-69, DOI 10.2737/RMRS-RP-69]
CR  - Miller RF, 2000, J RANGE MANAGE, V53, P574, DOI 10.2307/4003150
CR  - Miller RF, 2017, RANGELAND ECOL MANAG, V70, P1, DOI 10.1016/j.rama.2016.10.004
CR  - Miller RF, 2011, STUD AVIAN BIOL, P145
CR  - Mishra NB, 2014, INT J REMOTE SENS, V35, P1175, DOI 10.1080/01431161.2013.876120
CR  - NOSS RF, 1995, ENDANGERED ECOSYSTEM, P1
CR  - O'Brien M. A., 2003, P AM SOC PHOTOGRAMM, P1
CR  - Opitz D., 2008, OBJECT BASED IMAGE A, P153, DOI [DOI 10.1007/978-3-540-77058-98, 10.1007/978-3-540-77058-98]
CR  - Overwatch, 2013, FEAT AN VERS 5 1 2 0
CR  - Pierson FB, 2010, RANGELAND ECOL MANAG, V63, P614, DOI 10.2111/REM-D-09-00148.1
CR  - Poznanovic AJ, 2014, PHOTOGRAMM ENG REM S, V80, P627, DOI 10.14358/PERS.80.7.627
CR  - Prochazka BG, 2017, RANGELAND ECOL MANAG, V70, P39, DOI 10.1016/j.rama.2016.07.004
CR  - Ricca MA, 2018, ECOL APPL, V28, P878, DOI 10.1002/eap.1690
CR  - Romme WH, 2009, RANGELAND ECOL MANAG, V62, P203, DOI 10.2111/08-188R1.1
CR  - Roth C. L., CUSTOMIZED FRA UNPUB
CR  - Roundy BA, 2014, RANGELAND ECOL MANAG, V67, P495, DOI 10.2111/REM-D-13-00022.1
CR  - Roundy DB, 2016, AIMS ENVIRON SCI, V3, P765, DOI 10.3934/environsci.2016.4.765
CR  - Sankey T, 2011, PHOTOGRAMM ENG REM S, V77, P1241, DOI 10.14358/PERS.77.12.1241
CR  - Schroeder MA, 2004, CONDOR, V106, P363, DOI 10.1650/7425
CR  - Severson JP, 2017, RANGELAND ECOL MANAG, V70, P50, DOI 10.1016/j.rama.2016.07.011
CR  - Soule PT, 2004, ECOL APPL, V14, P96, DOI 10.1890/02-5300
CR  - Soule PT, 1999, J RANGE MANAGE, V52, P525, DOI 10.2307/4003782
CR  - Strand EK, 2013, RANGELAND ECOL MANAG, V66, P667, DOI 10.2111/REM-D-13-00051.1
CR  - Tausch R. J., 2009, USGS CIRC, V1335, P1
CR  - Tsai YH, 2011, REMOTE SENS-BASEL, V3, P2707, DOI 10.3390/rs3122707
CR  - Twidwell D, 2013, ECOSPHERE, V4, DOI 10.1890/ES13-00124.1
CR  - USDA, 2014, 2012 CENSUS AGR US S, V1, P1
CR  - USDA, 2013, NAT AGR IM PROGR NAI
CR  - USDA, 2014, TARG CON REM PROACT, P1
CR  - USFWS, 2013, GREAT SAG GROUS CENT, P1
CR  - USFWS, 2015, FR
CR  - Weiner NI, 2016, ECOSYSTEMS, V19, P1196, DOI 10.1007/s10021-016-9994-x
PU  - ELSEVIER SCIENCE BV
PI  - AMSTERDAM
PA  - PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
DA  - DEC
PY  - 2018
VL  - 73
SP  - 148
EP  - 155
DO  - 10.1016/j.jag.2018.06.002
AN  - WOS:000446291100013
N1  - Times Cited in Web of Science Core Collection:  10
Total Times Cited:  10
Cited Reference Count:  64
ER  -

